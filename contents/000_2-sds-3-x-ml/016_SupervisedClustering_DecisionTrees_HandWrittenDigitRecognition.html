<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>016_SupervisedClustering_DecisionTrees_HandWrittenDigitRecognition - ScaDaMaLe/sds-3.x</title>
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="../../favicon.svg">
        
        
        <link rel="shortcut icon" href="../../favicon.png">
        
        <link rel="stylesheet" href="../../css/variables.css">
        <link rel="stylesheet" href="../../css/general.css">
        <link rel="stylesheet" href="../../css/chrome.css">
        
        <link rel="stylesheet" href="../../css/print.css" media="print">
        

        <!-- Fonts -->
        <link rel="stylesheet" href="../../FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="../../fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../../highlight.css">
        <link rel="stylesheet" href="../../tomorrow-night.css">
        <link rel="stylesheet" href="../../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        
        <link rel="stylesheet" href="../../scroll-mdbook-outputs.css">
        

        
        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../../contents/000_1-sds-3-x/000_ScaDaMaLe.html">000_ScaDaMaLe</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_1-sds-3-x/001_whySpark.html">001_whySpark</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_1-sds-3-x/002_00_loginToDatabricks.html">002_00_loginToDatabricks</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_1-sds-3-x/002_01_multiLingualNotebooks.html">002_01_multiLingualNotebooks</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_1-sds-3-x/003_00_scalaCrashCourse.html">003_00_scalaCrashCourse</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_1-sds-3-x/003_01_scalaCrashCourse.html">003_01_scalaCrashCourse</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_1-sds-3-x/004_RDDsTransformationsActions.html">004_RDDsTransformationsActions</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_1-sds-3-x/005_RDDsTransformationsActionsHOMEWORK.html">005_RDDsTransformationsActionsHOMEWORK</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_1-sds-3-x/006a_PipedRDD.html">006a_PipedRDD</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_1-sds-3-x/006_WordCount.html">006_WordCount</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_1-sds-3-x/007a_SparkSQLProgGuide_HW.html">007a_SparkSQLProgGuide_HW</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_1-sds-3-x/007b_SparkSQLProgGuide_HW.html">007b_SparkSQLProgGuide_HW</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_1-sds-3-x/007c_SparkSQLProgGuide_HW.html">007c_SparkSQLProgGuide_HW</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_1-sds-3-x/007d_SparkSQLProgGuide_HW.html">007d_SparkSQLProgGuide_HW</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_1-sds-3-x/007e_SparkSQLProgGuide_HW.html">007e_SparkSQLProgGuide_HW</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_1-sds-3-x/007f_SparkSQLProgGuide_HW.html">007f_SparkSQLProgGuide_HW</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_1-sds-3-x/007g_PivotInSQL.html">007g_PivotInSQL</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_1-sds-3-x/007_SparkSQLIntroBasics.html">007_SparkSQLIntroBasics</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html">008_DiamondsPipeline_01ETLEDA</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html">009_PowerPlantPipeline_01ETLEDA</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_1-sds-3-x/010_wikipediaClickStream_01ETLEDA.html">010_wikipediaClickStream_01ETLEDA</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_1-sds-3-x/033_OBO_LoadExtract.html">033_OBO_LoadExtract</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html">033_OBO_PipedRDD_RigorousBayesianABTesting</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/010a_packageCells.html">010a_packageCells</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/011_02_IntroToSimulation.html">011_02_IntroToSimulation</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/011_03_IntroToML.html">011_03_IntroToML</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/012_UnsupervisedClustering_1MSongsKMeans_Intro.html">012_UnsupervisedClustering_1MSongsKMeans_Intro</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/013_UnsupervisedClustering_1MSongsKMeans_Stage1ETL.html">013_UnsupervisedClustering_1MSongsKMeans_Stage1ETL</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/014_UnsupervisedClustering_1MSongsKMeans_Stage2Explore.html">014_UnsupervisedClustering_1MSongsKMeans_Stage2Explore</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/015_UnsupervisedClustering_1MSongsKMeans_Stage3Model.html">015_UnsupervisedClustering_1MSongsKMeans_Stage3Model</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/016_SupervisedClustering_DecisionTrees_HandWrittenDigitRecognition.html" class="active">016_SupervisedClustering_DecisionTrees_HandWrittenDigitRecognition</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/017_LAlgIntro.html">017_LAlgIntro</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/018_LinRegIntro.html">018_LinRegIntro</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/019_DistLAlgForLinRegIntro.html">019_DistLAlgForLinRegIntro</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/019x_000_dataTypesProgGuide.html">019x_000_dataTypesProgGuide</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/019x_001_LocalVector.html">019x_001_LocalVector</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/019x_002_LabeledPoint.html">019x_002_LabeledPoint</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/019x_003_LocalMatrix.html">019x_003_LocalMatrix</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/019x_004_DistributedMatrix.html">019x_004_DistributedMatrix</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/019x_005_RowMatrix.html">019x_005_RowMatrix</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/019x_006_IndexedRowMatrix.html">019x_006_IndexedRowMatrix</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/019x_007_CoordinateMatrix.html">019x_007_CoordinateMatrix</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/019x_008_BlockMatrix.html">019x_008_BlockMatrix</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/020_PowerPlantPipeline_02ModelTuneEvaluate.html">020_PowerPlantPipeline_02ModelTuneEvaluate</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/021_recognizeActivityByRandomForest.html">021_recognizeActivityByRandomForest</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/022_GraphFramesUserGuide.html">022_GraphFramesUserGuide</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/023_OnTimeFlightPerformance.html">023_OnTimeFlightPerformance</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/030_PowerPlantPipeline_03ModelTuneEvaluateDeploy.html">030_PowerPlantPipeline_03ModelTuneEvaluateDeploy</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/033_OBO_LoadExtract.html">033_OBO_LoadExtract</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/033_OBO_PipedRDD_RigorousBayesianABTesting.html">033_OBO_PipedRDD_RigorousBayesianABTesting</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/034_LDA_20NewsGroupsSmall.html">034_LDA_20NewsGroupsSmall</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/035_LDA_CornellMovieDialogs.html">035_LDA_CornellMovieDialogs</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/036_ALS_MovieRecommender.html">036_ALS_MovieRecommender</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/998_EX_01_GraphXShortestWeightedPaths.html">998_EX_01_GraphXShortestWeightedPaths</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/999_YT_01_FinancialFraudDetectionUsingDecisionTreeMachineLearningModels.html">999_YT_01_FinancialFraudDetectionUsingDecisionTreeMachineLearningModels</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">ScaDaMaLe/sds-3.x</h1>

                    <div class="right-buttons">
                        
                        <a href="../../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        
                        

                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <div class="cell markdown">
<p>ScaDaMaLe Course <a href="https://lamastex.github.io/scalable-data-science/sds/3/x/">site</a> and <a href="https://lamastex.github.io/ScaDaMaLe/index.html">book</a></p>
</div>
<div class="cell markdown">
<h2 id="supervised-clustering-with-decision-trees"><a class="header" href="#supervised-clustering-with-decision-trees">Supervised Clustering with Decision Trees</a></h2>
<h3 id="visual-introduction-to-decision-trees-and-application-to-hand-written-digit-recognition"><a class="header" href="#visual-introduction-to-decision-trees-and-application-to-hand-written-digit-recognition">Visual Introduction to decision trees and application to hand-written digit recognition</a></h3>
<p><strong>SOURCE:</strong> This is just a couple of decorations on a notebook published in databricks community edition in 2016.</p>
</div>
<div class="cell markdown">
<h1 id="decision-trees-for-handwritten-digit-recognition"><a class="header" href="#decision-trees-for-handwritten-digit-recognition">Decision Trees for handwritten digit recognition</a></h1>
<p>This notebook demonstrates learning a <a href="https://en.wikipedia.org/wiki/Decision_tree_learning">Decision Tree</a> using Spark's distributed implementation. It gives the reader a better understanding of some critical <a href="https://en.wikipedia.org/wiki/Hyperparameter_optimization">hyperparameters</a> for the tree learning algorithm, using examples to demonstrate how tuning the hyperparameters can improve accuracy.</p>
<p><strong>Background</strong>: To learn more about Decision Trees, check out the resources at the end of this notebook. <a href="http://www.r2d3.us/visual-intro-to-machine-learning-part-1/">The visual description of ML and Decision Trees</a> provides nice intuition helpful to understand this notebook, and <a href="https://en.wikipedia.org/wiki/Decision_tree_learning">Wikipedia</a> gives lots of details.</p>
<p><strong>Data</strong>: We use the classic MNIST handwritten digit recognition dataset. It is from LeCun et al. (1998) and may be found under <a href="https://www.csie.ntu.edu.tw/%7Ecjlin/libsvmtools/datasets/multiclass.html#mnist">&quot;mnist&quot; at the LibSVM dataset page</a>.</p>
<p><strong>Goal</strong>: Our goal for our data is to learn how to recognize digits (0 - 9) from images of handwriting. However, we will focus on understanding trees, not on this particular learning problem.</p>
<p><strong>Takeaways</strong>: Decision Trees take several hyperparameters which can affect the accuracy of the learned model. There is no one &quot;best&quot; setting for these for all datasets. To get the optimal accuracy, we need to tune these hyperparameters based on our data.</p>
</div>
<div class="cell markdown">
<h2 id="lets-build-intuition-for-learning-with-decision-trees"><a class="header" href="#lets-build-intuition-for-learning-with-decision-trees">Let's Build Intuition for Learning with Decision Trees</a></h2>
<ul>
<li>Right-click and open the following link in a new Tab:
<ul>
<li><a href="http://www.r2d3.us/visual-intro-to-machine-learning-part-1/">The visual description of ML and Decision Trees</a> which was nominated for a <a href="http://review.wizehive.com/voting/view/nsfvizziesgallery/27428/3236649">NSF Vizzie award</a>.</li>
</ul>
</li>
</ul>
</div>
<div class="cell code" execution_count="1" scrolled="auto">
<div class="output execute_result html_result" execution_count="1">
<iframe 
 src="https://en.wikipedia.org/wiki/Decision_tree_learning"
 width="95%" height="500"
 sandbox>
  <p>
    <a href="http://spark.apache.org/docs/latest/ml-features.html">
      Fallback link for browsers that, unlikely, don't support frames
    </a>
  </p>
</iframe>
</div>
</div>
<div class="cell markdown">
<h2 id="load-mnist-training-and-test-datasets"><a class="header" href="#load-mnist-training-and-test-datasets">Load MNIST training and test datasets</a></h2>
<p>Our datasets are vectors of pixels representing images of handwritten digits. For example:</p>
<p><img src="http://training.databricks.com/databricks_guide/digit.png" alt="Image of a digit" /> <img src="http://training.databricks.com/databricks_guide/MNIST-small.png" alt="Image of all 10 digits" /></p>
</div>
<div class="cell markdown">
<p>These datasets are stored in the popular LibSVM dataset format. We will load them using MLlib's LibSVM dataset reader utility.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">//-----------------------------------------------------------------------------------------------------------------
// using RDD-based MLlib - ok for Spark 1.x
// MLUtils.loadLibSVMFile returns an RDD.
//import org.apache.spark.mllib.util.MLUtils
//val trainingRDD = MLUtils.loadLibSVMFile(sc, &quot;/databricks-datasets/mnist-digits/data-001/mnist-digits-train.txt&quot;)
//val testRDD = MLUtils.loadLibSVMFile(sc, &quot;/databricks-datasets/mnist-digits/data-001/mnist-digits-test.txt&quot;)
// We convert the RDDs to DataFrames to use with ML Pipelines.
//val training = trainingRDD.toDF()
//val test = testRDD.toDF()
// Note: In Spark 1.6 and later versions, Spark SQL has a LibSVM data source.  The above lines can be simplified to:
//// val training = sqlContext.read.format(&quot;libsvm&quot;).load(&quot;/mnt/mllib/mnist-digits-csv/mnist-digits-train.txt&quot;)
//// val test = sqlContext.read.format(&quot;libsvm&quot;).load(&quot;/mnt/mllib/mnist-digits-csv/mnist-digits-test.txt&quot;)
//-----------------------------------------------------------------------------------------------------------------
val training = spark.read.format(&quot;libsvm&quot;)
                    .option(&quot;numFeatures&quot;, &quot;780&quot;)
                    .load(&quot;/databricks-datasets/mnist-digits/data-001/mnist-digits-train.txt&quot;)

val test = spark.read.format(&quot;libsvm&quot;)
                    .option(&quot;numFeatures&quot;, &quot;780&quot;)
                    .load(&quot;/databricks-datasets/mnist-digits/data-001/mnist-digits-test.txt&quot;)
// Cache data for multiple uses.
training.cache()
test.cache()

println(s&quot;We have ${training.count} training images and ${test.count} test images.&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>We have 60000 training images and 10000 test images.
training: org.apache.spark.sql.DataFrame = [label: double, features: vector]
test: org.apache.spark.sql.DataFrame = [label: double, features: vector]
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Display our data. Each image has the true label (the <code>label</code> column) and a vector of <code>features</code> which represent pixel intensities (see below for details of what is in <code>training</code>).</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">training.printSchema()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>root
 |-- label: double (nullable = true)
 |-- features: vector (nullable = true)
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">training.show(3) // replace 'true' by 'false' to see the whole row hidden by '...'
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+-----+--------------------+
|label|            features|
+-----+--------------------+
|  5.0|(780,[152,153,154...|
|  0.0|(780,[127,128,129...|
|  4.0|(780,[160,161,162...|
+-----+--------------------+
only showing top 3 rows
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">display(training) // this is databricks-specific for interactive visual convenience
</code></pre>
</div>
<div class="cell markdown">
<p>The pixel intensities are represented in <code>features</code> as a sparse vector, for example the first observation, as seen in row 1 of the output to <code>display(training)</code> or <code>training.show(2,false)</code> above, has <code>label</code> as <code>5</code>, i.e. the hand-written image is for the number 5. And this hand-written image is the following sparse vector (just click the triangle to the left of the feature in first row to see the following): <code>type: 0 size: 780 indices: [152,153,155,...,682,683] values: [3, 18, 18,18,126,...,132,16]</code></p>
<p>Here,</p>
<ul>
<li><code>type: 0</code> says we have a sparse vector that only represents non-zero entries (as opposed to a dense vector where every entry is represented).</li>
<li><code>size: 780</code> says the vector has 780 indices in total</li>
<li>these indices from 0,...,779 are a unidimensional indexing of the two-dimensional array of pixels in the image</li>
<li><code>indices: [152,153,155,...,682,683]</code> are the indices from the <code>[0,1,...,779]</code> possible indices with non-zero values
<ul>
<li>a value is an integer encoding the gray-level at the pixel index</li>
</ul>
</li>
<li><code>values: [3, 18, 18,18,126,...,132,16]</code> are the actual gray level values, for example:
<ul>
<li>at pixed index <code>152</code> the gray-level value is <code>3</code>,</li>
<li>at index <code>153</code> the gray-level value is <code>18</code>,</li>
<li>..., and finally at</li>
<li>at index <code>683</code> the gray-level value is <code>18</code></li>
</ul>
</li>
</ul>
</div>
<div class="cell markdown">
<h2 id="train-a-decision-tree"><a class="header" href="#train-a-decision-tree">Train a Decision Tree</a></h2>
<p>We begin by training a decision tree using the default settings. Before training, we want to tell the algorithm that the labels are categories 0-9, rather than continuous values. We use the <code>StringIndexer</code> class to do this. We tie this feature preprocessing together with the tree algorithm using a <code>Pipeline</code>. ML Pipelines are tools Spark provides for piecing together Machine Learning algorithms into workflows. To learn more about Pipelines, check out other ML example notebooks in Databricks and the <a href="http://spark.apache.org/docs/latest/ml-guide.html">ML Pipelines user guide</a>. Also See <a href="http://spark.apache.org/docs/latest/mllib-decision-tree.html#basic-algorithm">mllib-decision-tree.html#basic-algorithm</a>.</p>
</div>
<div class="cell markdown">
<p>See <a href="http://spark.apache.org/docs/latest/mllib-decision-tree.html#basic-algorithm">http://spark.apache.org/docs/latest/mllib-decision-tree.html#basic-algorithm</a>.</p>
</div>
<div class="cell markdown">
<p>See <a href="http://spark.apache.org/docs/latest/ml-guide.html#main-concepts-in-pipelines">http://spark.apache.org/docs/latest/ml-guide.html#main-concepts-in-pipelines</a>.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Import the ML algorithms we will use.
import org.apache.spark.ml.classification.{DecisionTreeClassifier, DecisionTreeClassificationModel}
import org.apache.spark.ml.feature.StringIndexer
import org.apache.spark.ml.Pipeline
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>import org.apache.spark.ml.classification.{DecisionTreeClassifier, DecisionTreeClassificationModel}
import org.apache.spark.ml.feature.StringIndexer
import org.apache.spark.ml.Pipeline
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// StringIndexer: Read input column &quot;label&quot; (digits) and annotate them as categorical values.
val indexer = new StringIndexer().setInputCol(&quot;label&quot;).setOutputCol(&quot;indexedLabel&quot;)

// DecisionTreeClassifier: Learn to predict column &quot;indexedLabel&quot; using the &quot;features&quot; column.
val dtc = new DecisionTreeClassifier().setLabelCol(&quot;indexedLabel&quot;)

// Chain indexer + dtc together into a single ML Pipeline.
val pipeline = new Pipeline().setStages(Array(indexer, dtc))
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>indexer: org.apache.spark.ml.feature.StringIndexer = strIdx_5e4c4bafd052
dtc: org.apache.spark.ml.classification.DecisionTreeClassifier = dtc_6916f99c66b5
pipeline: org.apache.spark.ml.Pipeline = pipeline_7c1c5306008c
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Now, let's fit a model to our data.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val model = pipeline.fit(training)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>model: org.apache.spark.ml.PipelineModel = pipeline_7c1c5306008c
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>We can inspect the learned tree by displaying it using Databricks ML visualization. (Visualization is available for several but not all models.)</p>
</div>
<div class="cell code" execution_count="1" scrolled="true">
<pre><code class="language-scala">// The tree is the last stage of the Pipeline.  Display it!
val tree = model.stages.last.asInstanceOf[DecisionTreeClassificationModel]
display(tree)
</code></pre>
<div class="output execute_result tabular_result" execution_count="1">
<table>
<thead>
<tr class="header">
<th>treeNode</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>{"index":31,"featureType":"continuous","prediction":null,"threshold":141.5,"categories":null,"feature":350,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":15,"featureType":"continuous","prediction":null,"threshold":0.5,"categories":null,"feature":568,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":7,"featureType":"continuous","prediction":null,"threshold":0.5,"categories":null,"feature":430,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":3,"featureType":"continuous","prediction":null,"threshold":2.5,"categories":null,"feature":405,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":1,"featureType":"continuous","prediction":null,"threshold":0.5,"categories":null,"feature":484,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":0,"featureType":null,"prediction":1.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":2,"featureType":null,"prediction":4.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":5,"featureType":"continuous","prediction":null,"threshold":14.5,"categories":null,"feature":516,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":4,"featureType":null,"prediction":9.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":6,"featureType":null,"prediction":7.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":11,"featureType":"continuous","prediction":null,"threshold":7.5,"categories":null,"feature":211,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":9,"featureType":"continuous","prediction":null,"threshold":0.5,"categories":null,"feature":98,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":8,"featureType":null,"prediction":8.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":10,"featureType":null,"prediction":6.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":13,"featureType":"continuous","prediction":null,"threshold":0.5,"categories":null,"feature":156,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":12,"featureType":null,"prediction":4.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":14,"featureType":null,"prediction":6.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":23,"featureType":"continuous","prediction":null,"threshold":0.5,"categories":null,"feature":435,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":19,"featureType":"continuous","prediction":null,"threshold":10.5,"categories":null,"feature":489,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":17,"featureType":"continuous","prediction":null,"threshold":12.5,"categories":null,"feature":351,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":16,"featureType":null,"prediction":5.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":18,"featureType":null,"prediction":9.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":21,"featureType":"continuous","prediction":null,"threshold":0.5,"categories":null,"feature":320,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":20,"featureType":null,"prediction":3.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":22,"featureType":null,"prediction":9.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":27,"featureType":"continuous","prediction":null,"threshold":0.5,"categories":null,"feature":347,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":25,"featureType":"continuous","prediction":null,"threshold":1.5,"categories":null,"feature":344,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":24,"featureType":null,"prediction":3.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":26,"featureType":null,"prediction":6.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":29,"featureType":"continuous","prediction":null,"threshold":0.5,"categories":null,"feature":655,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":28,"featureType":null,"prediction":6.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":30,"featureType":null,"prediction":7.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":47,"featureType":"continuous","prediction":null,"threshold":44.5,"categories":null,"feature":489,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":39,"featureType":"continuous","prediction":null,"threshold":41.5,"categories":null,"feature":290,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":35,"featureType":"continuous","prediction":null,"threshold":77.5,"categories":null,"feature":486,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":33,"featureType":"continuous","prediction":null,"threshold":113.5,"categories":null,"feature":490,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":32,"featureType":null,"prediction":2.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":34,"featureType":null,"prediction":0.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":37,"featureType":"continuous","prediction":null,"threshold":0.5,"categories":null,"feature":656,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":36,"featureType":null,"prediction":3.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":38,"featureType":null,"prediction":7.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":43,"featureType":"continuous","prediction":null,"threshold":5.5,"categories":null,"feature":297,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":41,"featureType":"continuous","prediction":null,"threshold":178.5,"categories":null,"feature":486,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":40,"featureType":null,"prediction":9.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":42,"featureType":null,"prediction":6.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":45,"featureType":"continuous","prediction":null,"threshold":0.5,"categories":null,"feature":514,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":44,"featureType":null,"prediction":4.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":46,"featureType":null,"prediction":7.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":55,"featureType":"continuous","prediction":null,"threshold":0.5,"categories":null,"feature":234,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":51,"featureType":"continuous","prediction":null,"threshold":0.5,"categories":null,"feature":402,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":49,"featureType":"continuous","prediction":null,"threshold":5.5,"categories":null,"feature":300,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":48,"featureType":null,"prediction":0.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":50,"featureType":null,"prediction":7.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":53,"featureType":"continuous","prediction":null,"threshold":0.5,"categories":null,"feature":103,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":52,"featureType":null,"prediction":7.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":54,"featureType":null,"prediction":6.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":59,"featureType":"continuous","prediction":null,"threshold":0.5,"categories":null,"feature":658,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":57,"featureType":"continuous","prediction":null,"threshold":24.5,"categories":null,"feature":345,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":56,"featureType":null,"prediction":3.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="even">
<td>{"index":58,"featureType":null,"prediction":6.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
<tr class="odd">
<td>{"index":60,"featureType":null,"prediction":7.0,"threshold":null,"categories":null,"feature":null,"overflow":false}</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="cell markdown">
<p>Above, we can see how the tree makes predictions. When classifying a new example, the tree starts at the &quot;root&quot; node (at the top). Each tree node tests a pixel value and goes either left or right. At the bottom &quot;leaf&quot; nodes, the tree predicts a digit as the image's label.</p>
</div>
<div class="cell markdown">
<h2 id="hyperparameter-tuning"><a class="header" href="#hyperparameter-tuning">Hyperparameter Tuning</a></h2>
<p>Run the next cell and come back into hyper-parameter tuning for a couple minutes.</p>
</div>
<div class="cell code" execution_count="1" scrolled="auto">
<div class="output execute_result html_result" execution_count="1">
<iframe 
 src="https://en.wikipedia.org/wiki/Hyperparameter_optimization"
 width="95%" height="400"
 sandbox>
  <p>
    <a href="http://spark.apache.org/docs/latest/ml-features.html">
      Fallback link for browsers that, unlikely, don't support frames
    </a>
  </p>
</iframe>
</div>
</div>
<div class="cell markdown">
<h2 id="exploring-maxdepth-training-trees-of-different-sizes"><a class="header" href="#exploring-maxdepth-training-trees-of-different-sizes">Exploring &quot;maxDepth&quot;: training trees of different sizes</a></h2>
<p>In this section, we test tuning a single hyperparameter <code>maxDepth</code>, which determines how deep (and large) the tree can be. We will train trees at varying depths and see how it affects the accuracy on our held-out test set.</p>
<p><em>Note: The next cell can take about 1 minute to run since it is training several trees which get deeper and deeper.</em></p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val variedMaxDepthModels = (0 until 8).map { maxDepth =&gt;
  // For this setting of maxDepth, learn a decision tree.
  dtc.setMaxDepth(maxDepth)
  // Create a Pipeline with our feature processing stage (indexer) plus the tree algorithm
  val pipeline = new Pipeline().setStages(Array(indexer, dtc))
  // Run the ML Pipeline to learn a tree.
  pipeline.fit(training)
}
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>variedMaxDepthModels: scala.collection.immutable.IndexedSeq[org.apache.spark.ml.PipelineModel] = Vector(pipeline_310f2d2f2acc, pipeline_cf295c016b8e, pipeline_54e998e43742, pipeline_043069dd1cac, pipeline_d1c3a168b215, pipeline_7440ffd2443d, pipeline_ea992a1dcc18, pipeline_048b83baaf8e)
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>We will use the default metric to evaluate the performance of our classifier:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/F1_score">https://en.wikipedia.org/wiki/F1_score</a>.</li>
</ul>
</div>
<div class="cell code" execution_count="1" scrolled="auto">
<div class="output execute_result html_result" execution_count="1">
<iframe 
 src="https://en.wikipedia.org/wiki/F1_score"
 width="95%" height="400"
 sandbox>
  <p>
    <a href="http://spark.apache.org/docs/latest/index.html">
      Fallback link for browsers that, unlikely, don't support frames
    </a>
  </p>
</iframe>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Define an evaluation metric.  In this case, we will use &quot;accuracy&quot;.
import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator
val evaluator = new MulticlassClassificationEvaluator().setLabelCol(&quot;indexedLabel&quot;).setMetricName(&quot;f1&quot;) // default MetricName
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator
evaluator: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = MulticlassClassificationEvaluator: uid=mcEval_763f80cd3db6, metricName=f1, metricLabel=0.0, beta=1.0, eps=1.0E-15
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// For each maxDepth setting, make predictions on the test data, and compute the classifier's f1 performance metric.
val f1MetricPerformanceMeasures = (0 until 8).map { maxDepth =&gt;
  val model = variedMaxDepthModels(maxDepth)
  // Calling transform() on the test set runs the fitted pipeline.
  // The learned model makes predictions on each test example.
  val predictions = model.transform(test)
  // Calling evaluate() on the predictions DataFrame computes our performance metric.
  (maxDepth, evaluator.evaluate(predictions))
}.toDF(&quot;maxDepth&quot;, &quot;f1&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>f1MetricPerformanceMeasures: org.apache.spark.sql.DataFrame = [maxDepth: int, f1: double]
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>We can display our accuracy results and see immediately that deeper, larger trees are more powerful classifiers, achieving higher accuracies.</p>
<p><em>Note:</em> When you run <code>f1MetricPerformanceMeasures.show()</code>, you will get a table with f1 score getting better (i.e., approaching 1) with depth.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">f1MetricPerformanceMeasures.show()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+--------+-------------------+
|maxDepth|                 f1|
+--------+-------------------+
|       0|  0.023138302649304|
|       1|0.07724539080137968|
|       2|0.21450119544051488|
|       3| 0.4328937409827488|
|       4| 0.5851464721123918|
|       5|  0.680614417707604|
|       6|  0.752106383232933|
|       7| 0.7875867636754111|
+--------+-------------------+
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Even though deeper trees are more powerful, they are not always better (recall from the SF/NYC city classification from house features at <a href="http://www.r2d3.us/visual-intro-to-machine-learning-part-1/">The visual description of ML and Decision Trees</a>). If we kept increasing the depth on a rich enough dataset, training would take longer and longer. We also might risk <a href="https://en.wikipedia.org/wiki/Overfitting">overfitting</a> (fitting the training data so well that our predictions get worse on test data); it is important to tune parameters <em>based on <a href="https://en.wikipedia.org/wiki/Test_set">held-out data</a></em> to prevent overfitting. This will ensure that the fitted model generalizes well to yet unseen data, i.e. minimizes <a href="https://en.wikipedia.org/wiki/Generalization_error">generalization error</a> in a mathematical statistical sense.</p>
</div>
<div class="cell markdown">
<h2 id="exploring-maxbins-discretization-for-efficient-distributed-computing"><a class="header" href="#exploring-maxbins-discretization-for-efficient-distributed-computing">Exploring &quot;maxBins&quot;: discretization for efficient distributed computing</a></h2>
<p>This section explores a more expert-level setting <code>maxBins</code>. For efficient distributed training of Decision Trees, Spark and most other libraries discretize (or &quot;bin&quot;) continuous features (such as pixel values) into a finite number of values. This is an important step for the distributed implementation, but it introduces a tradeoff: Larger <code>maxBins</code> mean your data will be more accurately represented, but it will also mean more communication (and slower training).</p>
<p>The default value of <code>maxBins</code> generally works, but it is interesting to explore on our handwritten digit dataset. Remember our digit image from above:</p>
<p><img src="http://training.databricks.com/databricks_guide/digit.png" alt="Image of a digit" /></p>
<p>It is grayscale. But if we set <code>maxBins = 2</code>, then we are effectively making it a black-and-white image, not grayscale. Will that affect the accuracy of our model? Let's see!</p>
<p><em>Note: The next cell can take about 35 seconds to run since it trains several trees.</em> Read the details on <code>maxBins</code> at <a href="http://spark.apache.org/docs/latest/mllib-decision-tree.html#split-candidates">mllib-decision-tree.html#split-candidates</a>.</p>
</div>
<div class="cell markdown">
<p>See <a href="http://spark.apache.org/docs/latest/mllib-decision-tree.html#split-candidates">http://spark.apache.org/docs/latest/mllib-decision-tree.html#split-candidates</a>.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">dtc.setMaxDepth(6) // Set maxDepth to a reasonable value.
// now try the maxBins &quot;hyper-parameter&quot; which actually acts as a &quot;coarsener&quot; 
//     mathematical researchers should note that it is a sub-algebra of the finite 
//     algebra of observable pixel images at the finest resolution available to us
// giving a compression of the image to fewer coarsely represented pixels
val f1MetricPerformanceMeasures = Seq(2, 4, 8, 16, 32).map { case maxBins =&gt;
  // For this value of maxBins, learn a tree.
  dtc.setMaxBins(maxBins)
  val pipeline = new Pipeline().setStages(Array(indexer, dtc))
  val model = pipeline.fit(training)
  // Make predictions on test data, and compute accuracy.
  val predictions = model.transform(test)
  (maxBins, evaluator.evaluate(predictions))
}.toDF(&quot;maxBins&quot;, &quot;f1&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>f1MetricPerformanceMeasures: org.apache.spark.sql.DataFrame = [maxBins: int, f1: double]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">f1MetricPerformanceMeasures.show()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+-------+------------------+
|maxBins|                f1|
+-------+------------------+
|      2|0.7400788627816512|
|      4|0.7389031841129898|
|      8|0.7442844661661937|
|     16|0.7447853737964406|
|     32| 0.752106383232933|
+-------+------------------+
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>We can see that extreme discretization (black and white) hurts performance as measured by F1-error, but only a bit. Using more bins increases the accuracy (but also makes learning more costly).</p>
</div>
<div class="cell markdown">
<h4 id="whats-next"><a class="header" href="#whats-next">What's next?</a></h4>
<ul>
<li><strong>Explore</strong>: Try out tuning other parameters of trees---or even ensembles like <a href="http://spark.apache.org/docs/latest/ml-classification-regression.html#tree-ensembles">Random Forests or Gradient-Boosted Trees</a>.</li>
<li><strong>Automated tuning</strong>: This type of tuning does not have to be done by hand. (We did it by hand here to show the effects of tuning in detail.) MLlib provides automated tuning functionality via <code>CrossValidator</code>. Check out the other Databricks ML Pipeline guides or the <a href="http://spark.apache.org/docs/latest/ml-guide.html">Spark ML user guide</a> for details.</li>
</ul>
<p><strong>Resources</strong></p>
<p>If you are interested in learning more on these topics, these resources can get you started:</p>
<ul>
<li><a href="http://www.r2d3.us/visual-intro-to-machine-learning-part-1/">Excellent visual description of Machine Learning and Decision Trees</a>
<ul>
<li><em>This gives an intuitive visual explanation of ML, decision trees, overfitting, and more.</em></li>
</ul>
</li>
<li><a href="https://databricks.com/blog/2015/01/21/random-forests-and-boosting-in-mllib.html">Blog post on MLlib Random Forests and Gradient-Boosted Trees</a>
<ul>
<li><em>Random Forests and Gradient-Boosted Trees combine many trees into more powerful ensemble models. This is the original post describing MLlib's forest and GBT implementations.</em></li>
</ul>
</li>
<li>Wikipedia
<ul>
<li><a href="https://en.wikipedia.org/wiki/Decision_tree_learning">Decision tree learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Overfitting">Overfitting</a></li>
<li><a href="https://en.wikipedia.org/wiki/Hyperparameter_optimization">Hyperparameter tuning</a></li>
</ul>
</li>
</ul>
</div>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        
                            <a rel="prev" href="../../contents/000_2-sds-3-x-ml/015_UnsupervisedClustering_1MSongsKMeans_Stage3Model.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>
                        

                        
                            <a rel="next" href="../../contents/000_2-sds-3-x-ml/017_LAlgIntro.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>
                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                
                    <a rel="prev" href="../../contents/000_2-sds-3-x-ml/015_UnsupervisedClustering_1MSongsKMeans_Stage3Model.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>
                

                
                    <a rel="next" href="../../contents/000_2-sds-3-x-ml/017_LAlgIntro.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
                
            </nav>

        </div>

        
        <!-- Livereload script (if served using the cli tool) -->
        <script type="text/javascript">
            var socket = new WebSocket("ws://localhost:3000/__livereload");
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>
        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="../../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="../../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        

    </body>
</html>

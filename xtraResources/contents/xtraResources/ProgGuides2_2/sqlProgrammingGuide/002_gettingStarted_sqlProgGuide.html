<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>002_gettingStarted_sqlProgGuide - sds-3.x/ScaDaMaLe</title>
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="../../../../favicon.svg">
        
        
        <link rel="shortcut icon" href="../../../../favicon.png">
        
        <link rel="stylesheet" href="../../../../css/variables.css">
        <link rel="stylesheet" href="../../../../css/general.css">
        <link rel="stylesheet" href="../../../../css/chrome.css">
        
        <link rel="stylesheet" href="../../../../css/print.css" media="print">
        

        <!-- Fonts -->
        <link rel="stylesheet" href="../../../../FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="../../../../fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../../../../highlight.css">
        <link rel="stylesheet" href="../../../../tomorrow-night.css">
        <link rel="stylesheet" href="../../../../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        
        <link rel="stylesheet" href="../../../../scroll-mdbook-outputs.css">
        

        
        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../../../../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../../../../contents/000_1-sds-3-x/033_OBO_LoadExtract.html">033_OBO_LoadExtract</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/000_2-sds-3-x-ml/033_OBO_LoadExtract.html">033_OBO_LoadExtract</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/LinearAlgebra/LAlgCheatSheet.html">LAlgCheatSheet</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/ProgGuides2_2/MLlibProgrammingGuide/000_MLlibProgGuide.html">000_MLlibProgGuide</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/ProgGuides2_2/MLlibProgrammingGuide/dataTypes/000_dataTypesProgGuide.html">000_dataTypesProgGuide</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/ProgGuides2_2/MLlibProgrammingGuide/dataTypes/001_LocalVector.html">001_LocalVector</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/ProgGuides2_2/MLlibProgrammingGuide/dataTypes/002_LabeledPoint.html">002_LabeledPoint</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/ProgGuides2_2/MLlibProgrammingGuide/dataTypes/003_LocalMatrix.html">003_LocalMatrix</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/ProgGuides2_2/MLlibProgrammingGuide/dataTypes/004_DistributedMatrix.html">004_DistributedMatrix</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/ProgGuides2_2/MLlibProgrammingGuide/dataTypes/005_RowMatrix.html">005_RowMatrix</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/ProgGuides2_2/MLlibProgrammingGuide/dataTypes/006_IndexedRowMatrix.html">006_IndexedRowMatrix</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/ProgGuides2_2/MLlibProgrammingGuide/dataTypes/007_CoordinateMatrix.html">007_CoordinateMatrix</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/ProgGuides2_2/MLlibProgrammingGuide/dataTypes/008_BlockMatrix.html">008_BlockMatrix</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/ProgGuides2_2/sqlProgrammingGuide/000_sqlProgGuide.html">000_sqlProgGuide</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/ProgGuides2_2/sqlProgrammingGuide/001_overview_sqlProgGuide.html">001_overview_sqlProgGuide</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/ProgGuides2_2/sqlProgrammingGuide/002_gettingStarted_sqlProgGuide.html" class="active">002_gettingStarted_sqlProgGuide</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/ProgGuides2_2/sqlProgrammingGuide/003_dataSources_sqlProgGuide.html">003_dataSources_sqlProgGuide</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/ProgGuides2_2/sqlProgrammingGuide/004_performanceTuning_sqlProgGuide.html">004_performanceTuning_sqlProgGuide</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/ProgGuides2_2/sqlProgrammingGuide/005_distributedSqlEngine_sqlProgGuide.html">005_distributedSqlEngine_sqlProgGuide</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/sdsDatasets/scraperUSStateofUnionAddresses.html">scraperUSStateofUnionAddresses</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/support/sdsFunctions.html">sdsFunctions</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/visualRDDApi/guide.html">guide</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/visualRDDApi/recall/actions/collect.html">collect</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/visualRDDApi/recall/actions/getNumPartitions.html">getNumPartitions</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/visualRDDApi/recall/actions/reduce.html">reduce</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/visualRDDApi/recall/transformations/coalesce.html">coalesce</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/visualRDDApi/recall/transformations/distinct.html">distinct</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/visualRDDApi/recall/transformations/filter.html">filter</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/visualRDDApi/recall/transformations/flatMap.html">flatMap</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/visualRDDApi/recall/transformations/groupByKey.html">groupByKey</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/visualRDDApi/recall/transformations/groupBy.html">groupBy</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/visualRDDApi/recall/transformations/join.html">join</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/visualRDDApi/recall/transformations/keyBy.html">keyBy</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/visualRDDApi/recall/transformations/map.html">map</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/visualRDDApi/recall/transformations/mapPartitions.html">mapPartitions</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/visualRDDApi/recall/transformations/mapPartitionsWithIndex.html">mapPartitionsWithIndex</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/visualRDDApi/recall/transformations/partitionBy.html">partitionBy</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/visualRDDApi/recall/transformations/reduceByKey.html">reduceByKey</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/visualRDDApi/recall/transformations/sample.html">sample</a></li><li class="chapter-item expanded affix "><a href="../../../../contents/xtraResources/visualRDDApi/recall/transformations/union.html">union</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">sds-3.x/ScaDaMaLe</h1>

                    <div class="right-buttons">
                        
                        <a href="../../../../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        
                        

                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <div class="cell markdown">
<h1 id="a-hrefhttpslamastexgithubioscalable-data-sciencesds22sds-22-scalable-data-sciencea"><a class="header" href="#a-hrefhttpslamastexgithubioscalable-data-sciencesds22sds-22-scalable-data-sciencea"><a href="https://lamastex.github.io/scalable-data-science/sds/2/2/">SDS-2.2, Scalable Data Science</a></a></h1>
</div>
<div class="cell markdown">
<p>This is an elaboration of the <a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Apache Spark 2.2 sql-progamming-guide</a>.</p>
<h1 id="a-hrefworkspacescalable-data-sciencextraresourcesprogguides1_6sqlprogrammingguide002_gettingstarted_sqlprogguidegetting-starteda"><a class="header" href="#a-hrefworkspacescalable-data-sciencextraresourcesprogguides1_6sqlprogrammingguide002_gettingstarted_sqlprogguidegetting-starteda"><a href="/#workspace/scalable-data-science/xtraResources/ProgGuides1_6/sqlProgrammingGuide/002_gettingStarted_sqlProgGuide">Getting Started</a></a></h1>
<h2 id="a-hrefworkspacescalable-data-sciencextraresourcesprogguides1_6sqlprogrammingguide000_sqlprogguidespark-sql-programming-guidea"><a class="header" href="#a-hrefworkspacescalable-data-sciencextraresourcesprogguides1_6sqlprogrammingguide000_sqlprogguidespark-sql-programming-guidea"><a href="/#workspace/scalable-data-science/xtraResources/ProgGuides1_6/sqlProgrammingGuide/000_sqlProgGuide">Spark Sql Programming Guide</a></a></h2>
<ul>
<li><a href="/#workspace/scalable-data-science/xtraResources/ProgGuides1_6/sqlProgrammingGuide/001_overview_sqlProgGuide">Overview</a>
<ul>
<li>SQL</li>
<li>DataFrames</li>
<li>Datasets</li>
</ul>
</li>
<li><a href="/#workspace/scalable-data-science/xtraResources/ProgGuides1_6/sqlProgrammingGuide/002_gettingStarted_sqlProgGuide">Getting Started</a>
<ul>
<li>Starting Point: SQLContext</li>
<li>Creating DataFrames</li>
<li>DataFrame Operations</li>
<li>Running SQL Queries Programmatically</li>
<li>Creating Datasets</li>
<li>Interoperating with RDDs
<ul>
<li>Inferring the Schema Using Reflection</li>
<li>Programmatically Specifying the Schema</li>
</ul>
</li>
</ul>
</li>
<li><a href="/#workspace/scalable-data-science/xtraResources/ProgGuides1_6/sqlProgrammingGuide/003_dataSources_sqlProgGuide">Data Sources</a>
<ul>
<li>Generic Load/Save Functions
<ul>
<li>Manually Specifying Options</li>
<li>Run SQL on files directly</li>
<li>Save Modes</li>
<li>Saving to Persistent Tables</li>
</ul>
</li>
<li>Parquet Files
<ul>
<li>Loading Data Programmatically</li>
<li>Partition Discovery</li>
<li>Schema Merging</li>
<li>Hive metastore Parquet table conversion
<ul>
<li>Hive/Parquet Schema Reconciliation</li>
<li>Metadata Refreshing</li>
</ul>
</li>
<li>Configuration</li>
</ul>
</li>
<li>JSON Datasets</li>
<li>Hive Tables
<ul>
<li>Interacting with Different Versions of Hive Metastore</li>
</ul>
</li>
<li>JDBC To Other Databases</li>
<li>Troubleshooting</li>
</ul>
</li>
<li><a href="/#workspace/scalable-data-science/xtraResources/ProgGuides1_6/sqlProgrammingGuide/004_performanceTuning_sqlProgGuide">Performance Tuning</a>
<ul>
<li>Caching Data In Memory</li>
<li>Other Configuration Options</li>
</ul>
</li>
<li><a href="/#workspace/scalable-data-science/xtraResources/ProgGuides1_6/sqlProgrammingGuide/005_distributedSqlEngine_sqlProgGuide">Distributed SQL Engine</a>
<ul>
<li>Running the Thrift JDBC/ODBC server</li>
<li>Running the Spark SQL CLI</li>
</ul>
</li>
</ul>
</div>
<div class="cell markdown">
<h1 id="a-hrefworkspacescalable-data-sciencextraresourcesprogguides1_6sqlprogrammingguide002_gettingstarted_sqlprogguidegetting-starteda-1"><a class="header" href="#a-hrefworkspacescalable-data-sciencextraresourcesprogguides1_6sqlprogrammingguide002_gettingstarted_sqlprogguidegetting-starteda-1"><a href="/#workspace/scalable-data-science/xtraResources/ProgGuides1_6/sqlProgrammingGuide/002_gettingStarted_sqlProgGuide">Getting Started</a></a></h1>
<h2 id="starting-point-sqlcontext"><a class="header" href="#starting-point-sqlcontext">Starting Point: SQLContext</a></h2>
<p>The entry point into all functionality in Spark SQL is the <a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.SparkSession"><code>SparkSession</code></a> class and/or <code>SQLContext</code>/<code>HiveContext</code>. Spark session is created for you as <code>spark</code> when you start <strong>spark-shell</strong> or <strong>pyspark</strong>. You will need to create <code>SparkSession</code> usually when building an application (running on production-like on-premises cluster). n this case follow code below to create Spark session.</p>
<pre><code class="language-scala">import org.apache.spark.sql.SparkSession

val spark = SparkSession.builder().appName(&quot;Spark SQL basic example&quot;).getOrCreate()

// you could get SparkContext and SQLContext from SparkSession
val sc = spark.sparkContext
val sqlContext = spark.sqlContext

// This is used to implicitly convert an RDD or Seq to a DataFrame (see examples below)
import spark.implicits._
</code></pre>
<p>But in Databricks notebook (similar to <code>spark-shell</code>) <code>SparkSession</code> is already created for you and is available as <code>spark</code>.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Evaluation of the cell by Ctrl+Enter will print spark session available in notebook
spark
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res0: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@2d0c6c9
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>After evaluation you should see something like this:</p>
<pre><code>res0: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@2d0c6c9
</code></pre>
<p>In order to enable Hive support use <code>enableHiveSupport()</code> method on builder when constructing Spark session, which provides richer functionality over standard Spark SQL context, for example, usage of Hive user-defined functions or loading and writing data from/into Hive. Note that most of the SQL functionality is available regardless Hive support.</p>
</div>
<div class="cell markdown">
<h2 id="creating-dataframes"><a class="header" href="#creating-dataframes">Creating DataFrames</a></h2>
<p>With a <code>SparkSessions</code>, applications can create <a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset">Dataset</a> or <a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrame"><code>DataFrame</code></a> from an <a href="sql-programming-guide.html#interoperating-with-rdds">existing <code>RDD</code></a>, from a Hive table, or from various <a href="sql-programming-guide.html#data-sources">datasources</a>.</p>
<p>Just to recap, a DataFrame is a distributed collection of data organized into named columns. You can think of it as an organized into table RDD of case class <code>Row</code> (which is not exactly true). DataFrames, in comparison to RDDs, are backed by rich optimizations, including tracking their own schema, adaptive query execution, code generation including whole stage codegen, extensible Catalyst optimizer, and project <a href="https://databricks.com/blog/2015/04/28/project-tungsten-bringing-spark-closer-to-bare-metal.html">Tungsten</a>.</p>
<p>Dataset provides type-safety when working with SQL, since <code>Row</code> is mapped to a case class, so that each column can be referenced by property of that class.</p>
<blockquote>
<p>Note that performance for Dataset/DataFrames is the same across languages Scala, Java, Python, and R. This is due to the fact that the planning phase is just language-specific, only logical plan is constructed in Python, and all the physical execution is compiled and executed as JVM bytecode.</p>
</blockquote>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Spark has some of the pre-built methods to create simple Dataset/DataFrame

// 1. Empty Dataset/DataFrame, not really interesting, is it?
println(spark.emptyDataFrame)
println(spark.emptyDataset[Int])
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>[]
[value: int]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// 2. Range of numbers, note that Spark automatically names column as &quot;id&quot;
val range = spark.range(0, 10)

// In order to get a preview of data in DataFrame use &quot;show()&quot;
range.show(3)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+---+
| id|
+---+
|  0|
|  1|
|  2|
+---+
only showing top 3 rows

range: org.apache.spark.sql.Dataset[Long] = [id: bigint]
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>You can also use different datasources that will be shown later or load Hive tables directly into Spark.</p>
<p>We have already created a table of social media usage from NYC (you will see later how this table was built from raw data).</p>
<blockquote>
<p>See the very bottom of this worksheet to see how this was done.</p>
</blockquote>
<p>First let's make sure this table is available for us.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Let's find out what tables are already available for loading
spark.catalog.listTables.show()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+--------------------+--------+-----------+---------+-----------+
|                name|database|description|tableType|isTemporary|
+--------------------+--------+-----------+---------+-----------+
|          cities_csv| default|       null| EXTERNAL|      false|
|       cleaned_taxes| default|       null|  MANAGED|      false|
|commdettrumpclint...| default|       null|  MANAGED|      false|
|   donaldtrumptweets| default|       null| EXTERNAL|      false|
|             linkage| default|       null| EXTERNAL|      false|
|             nations| default|       null| EXTERNAL|      false|
|           newmplist| default|       null| EXTERNAL|      false|
|       ny_baby_names| default|       null|  MANAGED|      false|
|       nzmpsandparty| default|       null| EXTERNAL|      false|
|    pos_neg_category| default|       null| EXTERNAL|      false|
|                 rna| default|       null|  MANAGED|      false|
|                samh| default|       null| EXTERNAL|      false|
|  social_media_usage| default|       null| EXTERNAL|      false|
|              table1| default|       null| EXTERNAL|      false|
|          test_table| default|       null| EXTERNAL|      false|
|             uscites| default|       null| EXTERNAL|      false|
+--------------------+--------+-----------+---------+-----------+
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>It looks like the table <code>social_media_usage</code> is available as a permanent table (<code>isTemporary</code> set as <code>false</code>).</p>
<p>Next let us do the following: * load this table as a DataFrame * print its schema and * show the first 20 rows.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val df = spark.table(&quot;social_media_usage&quot;) // Ctrl+Enter
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>df: org.apache.spark.sql.DataFrame = [agency: string, platform: string ... 3 more fields]
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>As you can see the immutable value <code>df</code> is a DataFrame and more specifically it is:</p>
<blockquote>
<p><code>org.apache.spark.sql.DataFrame = [agency: string, platform: string, url: string, visits: int]</code>.</p>
</blockquote>
</div>
<div class="cell markdown">
<p>Now let us print schema of the DataFrame <code>df</code> and have a look at the actual data:</p>
</div>
<div class="cell code" execution_count="1" scrolled="true">
<pre><code class="language-scala">// Ctrl+Enter
df.printSchema() // prints schema of the DataFrame
df.show() // shows first n (default is 20) rows
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>root
 |-- agency: string (nullable = true)
 |-- platform: string (nullable = true)
 |-- url: string (nullable = true)
 |-- date: string (nullable = true)
 |-- visits: integer (nullable = true)

+----------+----------+--------------------+--------------------+------+
|    agency|  platform|                 url|                date|visits|
+----------+----------+--------------------+--------------------+------+
|       OEM|       SMS|                null|02/17/2012 12:00:...| 61652|
|       OEM|       SMS|                null|11/09/2012 12:00:...| 44547|
|       EDC|    Flickr|http://www.flickr...|05/09/2012 12:00:...|  null|
|     NYCHA|Newsletter|                null|05/09/2012 12:00:...|  null|
|       DHS|   Twitter|www.twitter.com/n...|06/13/2012 12:00:...|   389|
|       DHS|   Twitter|www.twitter.com/n...|08/02/2012 12:00:...|   431|
|       DOH|   Android|       Condom Finder|08/08/2011 12:00:...|  5026|
|       DOT|   Android|         You The Man|08/08/2011 12:00:...|  null|
|      MOME|   Android|      MiNY Venor app|08/08/2011 12:00:...|   313|
|       DOT|Broadcastr|                null|08/08/2011 12:00:...|  null|
|       DPR|Broadcastr|http://beta.broad...|08/08/2011 12:00:...|  null|
|     ENDHT|  Facebook|http://www.facebo...|08/08/2011 12:00:...|     3|
|       VAC|  Facebook|https://www.faceb...|08/08/2011 12:00:...|    36|
|    PlaNYC|  Facebook|http://www.facebo...|08/08/2011 12:00:...|    47|
|      DFTA|  Facebook|http://www.facebo...|08/08/2011 12:00:...|    90|
| energyNYC|  Facebook|http://www.facebo...|08/08/2011 12:00:...|   105|
|      MOIA|  Facebook|http://www.facebo...|08/08/2011 12:00:...|   123|
|City Store|  Facebook|http://www.facebo...|08/08/2011 12:00:...|   119|
|      OCDV|  Facebook|http://www.facebo...|08/08/2011 12:00:...|   148|
|       HIA|  Facebook|http://www.facebo...|08/08/2011 12:00:...|   197|
+----------+----------+--------------------+--------------------+------+
only showing top 20 rows
</code></pre>
</div>
</div>
<div class="cell markdown">
<blockquote>
<p>Note that <code>(nullable = true)</code> simply means if the value is allowed to be <code>null</code>.</p>
</blockquote>
<p>Let us count the number of rows in <code>df</code>.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">df.count() // Ctrl+Enter
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res7: Long = 5899
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>So there are 5899 records or rows in the DataFrame <code>df</code>. Pretty good! You can also select individual columns using so-called DataFrame API, as follows:</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val platforms = df.select(&quot;platform&quot;) // Shift+Enter
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>platforms: org.apache.spark.sql.DataFrame = [platform: string]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">platforms.count() // Shift+Enter to count the number of rows
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res8: Long = 5899
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">platforms.show(5) // Ctrl+Enter to show top 5 rows
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+----------+
|  platform|
+----------+
|       SMS|
|       SMS|
|    Flickr|
|Newsletter|
|   Twitter|
+----------+
only showing top 5 rows
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>You can also apply <code>.distinct()</code> to extract only unique entries as follows:</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val uniquePlatforms = df.select(&quot;platform&quot;).distinct() // Shift+Enter
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>uniquePlatforms: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [platform: string]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">uniquePlatforms.count() // Ctrl+Enter to count the number of distinct platforms
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res10: Long = 23
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Let's see all the rows of the DataFrame <code>uniquePlatforms</code>.</p>
<blockquote>
<p>Note that <code>display(uniquePlatforms)</code> unlike <code>uniquePlatforms.show()</code> displays all rows of the DataFrame + gives you ability to select different view, e.g. charts.</p>
</blockquote>
</div>
<div class="cell code" execution_count="1" scrolled="true">
<pre><code class="language-scala">display(uniquePlatforms) // Ctrl+Enter to show all rows; use the scroll-bar on the right of the display to see all platforms
</code></pre>
<div class="output execute_result tabular_result" execution_count="1">
<table>
<thead>
<tr class="header">
<th>platform</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>nyc.gov</td>
</tr>
<tr class="even">
<td>Flickr</td>
</tr>
<tr class="odd">
<td>Vimeo</td>
</tr>
<tr class="even">
<td>iPhone</td>
</tr>
<tr class="odd">
<td>YouTube</td>
</tr>
<tr class="even">
<td>WordPress</td>
</tr>
<tr class="odd">
<td>SMS</td>
</tr>
<tr class="even">
<td>iPhone App</td>
</tr>
<tr class="odd">
<td>Youtube</td>
</tr>
<tr class="even">
<td>Instagram</td>
</tr>
<tr class="odd">
<td>iPhone app</td>
</tr>
<tr class="even">
<td>Linked-In</td>
</tr>
<tr class="odd">
<td>Twitter</td>
</tr>
<tr class="even">
<td>TOTAL</td>
</tr>
<tr class="odd">
<td>Tumblr</td>
</tr>
<tr class="even">
<td>Newsletter</td>
</tr>
<tr class="odd">
<td>Pinterest</td>
</tr>
<tr class="even">
<td>Broadcastr</td>
</tr>
<tr class="odd">
<td>Android</td>
</tr>
<tr class="even">
<td>Foursquare</td>
</tr>
<tr class="odd">
<td>Google+</td>
</tr>
<tr class="even">
<td>Foursquare (Badge Unlock)</td>
</tr>
<tr class="odd">
<td>Facebook</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="cell markdown">
<h3 id="spark-sql-and-dataframe-api"><a class="header" href="#spark-sql-and-dataframe-api">Spark SQL and DataFrame API</a></h3>
<p>Spark SQL provides DataFrame API that can perform relational operations on both external data sources and internal collections, which is similar to widely used data frame concept in R, but evaluates operations support lazily (remember RDDs?), so that it can perform relational optimizations. This API is also available in Java, Python and R, but some functionality may not be available, although with every release of Spark people minimize this gap.</p>
<p>So we give some examples how to query data in Python and R, but continue with Scala. You can do all DataFrame operations in this notebook using Python or R.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python"># Ctrl+Enter to evaluate this python cell, recall '#' is the pre-comment character in python
# Using Python to query our &quot;social_media_usage&quot; table
pythonDF = spark.table(&quot;social_media_usage&quot;).select(&quot;platform&quot;).distinct()
pythonDF.show(3)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+--------+
|platform|
+--------+
| nyc.gov|
|  Flickr|
|   Vimeo|
+--------+
only showing top 3 rows
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="true">
<pre><code class="language-sql">-- Ctrl+Enter to achieve the same result using standard SQL syntax!
select distinct platform from social_media_usage
</code></pre>
<div class="output execute_result tabular_result" execution_count="1">
<table>
<thead>
<tr class="header">
<th>platform</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>nyc.gov</td>
</tr>
<tr class="even">
<td>Flickr</td>
</tr>
<tr class="odd">
<td>Vimeo</td>
</tr>
<tr class="even">
<td>iPhone</td>
</tr>
<tr class="odd">
<td>YouTube</td>
</tr>
<tr class="even">
<td>WordPress</td>
</tr>
<tr class="odd">
<td>SMS</td>
</tr>
<tr class="even">
<td>iPhone App</td>
</tr>
<tr class="odd">
<td>Youtube</td>
</tr>
<tr class="even">
<td>Instagram</td>
</tr>
<tr class="odd">
<td>iPhone app</td>
</tr>
<tr class="even">
<td>Linked-In</td>
</tr>
<tr class="odd">
<td>Twitter</td>
</tr>
<tr class="even">
<td>TOTAL</td>
</tr>
<tr class="odd">
<td>Tumblr</td>
</tr>
<tr class="even">
<td>Newsletter</td>
</tr>
<tr class="odd">
<td>Pinterest</td>
</tr>
<tr class="even">
<td>Broadcastr</td>
</tr>
<tr class="odd">
<td>Android</td>
</tr>
<tr class="even">
<td>Foursquare</td>
</tr>
<tr class="odd">
<td>Google+</td>
</tr>
<tr class="even">
<td>Foursquare (Badge Unlock)</td>
</tr>
<tr class="odd">
<td>Facebook</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="cell markdown">
<p>Now it is time for some tips around how you use <code>select</code> and what the difference is between <code>$&quot;a&quot;</code>, <code>col(&quot;a&quot;)</code>, <code>df(&quot;a&quot;)</code>.</p>
<p>As you probably have noticed by now, you can specify individual columns to select by providing String values in select statement. But sometimes you need to: - distinguish between columns with the same name - use it to filter (actually you can still filter using full String expression) - do some &quot;magic&quot; with joins and user-defined functions (this will be shown later)</p>
<p>So Spark gives you ability to actually specify columns when you select. Now the difference between all those three notations is ... none, those things are just aliases for a <code>Column</code> in Spark SQL, which means following expressions yield the same result:</p>
<pre><code class="language-scala">// Using string expressions
df.select(&quot;agency&quot;, &quot;visits&quot;)

// Using &quot;$&quot; alias for column
df.select($&quot;agency&quot;, $&quot;visits&quot;)

// Using &quot;col&quot; alias for column
df.select(col(&quot;agency&quot;), col(&quot;visits&quot;))

// Using DataFrame name for column
df.select(df(&quot;agency&quot;), df(&quot;visits&quot;))
</code></pre>
<p>This &quot;same-difference&quot; applies to filtering, i.e. you can either use full expression to filter, or column as shown in the following example:</p>
<pre><code class="language-scala">// Using column to filter
df.select(&quot;visits&quot;).filter($&quot;visits&quot; &gt; 100)

// Or you can use full expression as string
df.select(&quot;visits&quot;).filter(&quot;visits &gt; 100&quot;)
</code></pre>
<blockquote>
<p>Note that <code>$&quot;visits&quot; &gt; 100</code> expression looks amazing, but under the hood it is just another column, and it equals to <code>df(&quot;visits&quot;).&gt;(100)</code>, where, thanks to Scala paradigm <code>&gt;</code> is just another function that you can define.</p>
</blockquote>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val sms = df.select($&quot;agency&quot;, $&quot;platform&quot;, $&quot;visits&quot;).filter($&quot;platform&quot; === &quot;SMS&quot;)
sms.show() // Ctrl+Enter
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+------+--------+------+
|agency|platform|visits|
+------+--------+------+
|   OEM|     SMS| 61652|
|   OEM|     SMS| 44547|
|   DOE|     SMS|   382|
| NYCHA|     SMS|  null|
|   OEM|     SMS| 61652|
|   DOE|     SMS|   382|
| NYCHA|     SMS|  null|
|   OEM|     SMS| 61652|
|   OEM|     SMS|  null|
|   DOE|     SMS|  null|
| NYCHA|     SMS|  null|
|   OEM|     SMS|  null|
|   DOE|     SMS|  null|
| NYCHA|     SMS|  null|
|   DOE|     SMS|   382|
| NYCHA|     SMS|  null|
|   OEM|     SMS| 61652|
|   DOE|     SMS|   382|
| NYCHA|     SMS|  null|
|   OEM|     SMS| 61652|
+------+--------+------+
only showing top 20 rows

sms: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [agency: string, platform: string ... 1 more field]
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Again you could have written the query above using any column aliases or String names or even writing the query directly.</p>
<p>For example, we can do it using String names, as follows:</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Ctrl+Enter Note that we are using &quot;platform = 'SMS'&quot; since it will be evaluated as actual SQL
val sms = df.select(df(&quot;agency&quot;), df(&quot;platform&quot;), df(&quot;visits&quot;)).filter(&quot;platform = 'SMS'&quot;)
sms.show(5)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+------+--------+------+
|agency|platform|visits|
+------+--------+------+
|   OEM|     SMS| 61652|
|   OEM|     SMS| 44547|
|   DOE|     SMS|   382|
| NYCHA|     SMS|  null|
|   OEM|     SMS| 61652|
+------+--------+------+
only showing top 5 rows

sms: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [agency: string, platform: string ... 1 more field]
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Refer to the <a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrame">DataFrame API</a> for more detailed API. In addition to simple column references and expressions, DataFrames also have a rich library of functions including string manipulation, date arithmetic, common math operations and more. The complete list is available in the <a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$">DataFrame Function Reference</a>.</p>
</div>
<div class="cell markdown">
<p>Let's next explore some of the functionality that is available by transforming this DataFrame <code>df</code> into a new DataFrame called <code>fixedDF</code>.</p>
<ul>
<li>First, note that some columns are not exactly what we want them to be.
<ul>
<li>For example date column should be standard Date/Timestamp SQL column, and</li>
<li>visits should not contain null values, but <code>0</code>s instead.</li>
</ul>
</li>
<li>Let us fix it using some code that is briefly explained here (don't worry if you don't get it completely now, you will get the hang of it by playing more)
<ul>
<li>The <code>coalesce</code> function is similar to <code>if-else</code> statement, i.e., if first column in expression is <code>null</code>, then the value of the second column is used and so on.</li>
<li><code>lit</code> just means column of constant value (<code>lit</code>erally speaking!).</li>
<li>the &quot;funky&quot; time conversion is essentially conversion from current format -&gt; unix timestamp as a number -&gt; Spark SQL Date format</li>
<li>we also remove <code>TOTAL</code> value from <code>platform</code> column.</li>
</ul>
</li>
</ul>
</div>
<div class="cell code" execution_count="1" scrolled="true">
<pre><code class="language-scala">// Ctrl+Enter to make fixedDF

// import the needed sql functions
import org.apache.spark.sql.functions.{coalesce, from_unixtime, lit, to_date, unix_timestamp}

// make the fixedDF DataFrame
val fixedDF = df.
   select(
     $&quot;agency&quot;, 
     $&quot;platform&quot;, 
     $&quot;url&quot;, 
     to_date(from_unixtime(unix_timestamp($&quot;date&quot;, &quot;MM/dd/yyyy hh:mm:ss aaa&quot;))).as(&quot;date&quot;), 
     coalesce($&quot;visits&quot;, lit(0)).as(&quot;visits&quot;)).
   filter($&quot;platform&quot; !== &quot;TOTAL&quot;)

fixedDF.printSchema() // print its schema 
// and show the top 20 records fully
fixedDF.show(false) // the false argument does not truncate the rows, so you will not see something like this &quot;anot...&quot;
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>root
 |-- agency: string (nullable = true)
 |-- platform: string (nullable = true)
 |-- url: string (nullable = true)
 |-- date: date (nullable = true)
 |-- visits: integer (nullable = false)

+----------+----------+---------------------------------------------------------------------------------------+----------+------+
|agency    |platform  |url                                                                                    |date      |visits|
+----------+----------+---------------------------------------------------------------------------------------+----------+------+
|OEM       |SMS       |null                                                                                   |2012-02-17|61652 |
|OEM       |SMS       |null                                                                                   |2012-11-09|44547 |
|EDC       |Flickr    |http://www.flickr.com/nycedc                                                           |2012-05-09|0     |
|NYCHA     |Newsletter|null                                                                                   |2012-05-09|0     |
|DHS       |Twitter   |www.twitter.com/nycdhs                                                                 |2012-06-13|389   |
|DHS       |Twitter   |www.twitter.com/nycdhs                                                                 |2012-08-02|431   |
|DOH       |Android   |Condom Finder                                                                          |2011-08-08|5026  |
|DOT       |Android   |You The Man                                                                            |2011-08-08|0     |
|MOME      |Android   |MiNY Venor app                                                                         |2011-08-08|313   |
|DOT       |Broadcastr|null                                                                                   |2011-08-08|0     |
|DPR       |Broadcastr|http://beta.broadcastr.com/Echo.html?audioId=670026-4001                               |2011-08-08|0     |
|ENDHT     |Facebook  |http://www.facebook.com/pages/NYC-Lets-End-Human-Trafficking/125730490795659?sk=wall   |2011-08-08|3     |
|VAC       |Facebook  |https://www.facebook.com/pages/NYC-Voter-Assistance-Commission/110226709012110         |2011-08-08|36    |
|PlaNYC    |Facebook  |http://www.facebook.com/pages/New-York-NY/PlaNYC/160454173971169?ref=ts                |2011-08-08|47    |
|DFTA      |Facebook  |http://www.facebook.com/pages/NYC-Department-for-the-Aging/109028655823590             |2011-08-08|90    |
|energyNYC |Facebook  |http://www.facebook.com/EnergyNYC?sk=wall                                              |2011-08-08|105   |
|MOIA      |Facebook  |http://www.facebook.com/ihwnyc                                                         |2011-08-08|123   |
|City Store|Facebook  |http://www.facebook.com/citystorenyc                                                   |2011-08-08|119   |
|OCDV      |Facebook  |http://www.facebook.com/pages/NYC-Healthy-Relationship-Training-Academy/134637829901065|2011-08-08|148   |
|HIA       |Facebook  |http://www.facebook.com/pages/New-York-City-Health-Insurance-Link/145920551598         |2011-08-08|197   |
+----------+----------+---------------------------------------------------------------------------------------+----------+------+
only showing top 20 rows

&lt;console&gt;:47: warning: method !== in class Column is deprecated: !== does not have the same precedence as ===, use =!= instead
          filter($&quot;platform&quot; !== &quot;TOTAL&quot;)
                             ^
import org.apache.spark.sql.functions.{coalesce, from_unixtime, lit, to_date, unix_timestamp}
fixedDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [agency: string, platform: string ... 3 more fields]
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Okay, this is better, but <code>url</code>s are still inconsistent.</p>
<p>Let's fix this by writing our own UDF (user-defined function) to deal with special cases.</p>
<p>Note that if you <strong>CAN USE Spark functions library</strong>, do it. But for the sake of the example, custom UDF is shown below.</p>
<p>We take value of a column as String type and return the same String type, but ignore values that do not start with <code>http</code>.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Ctrl+Enter to evaluate this UDF which takes a input String called &quot;value&quot;
// and converts it into lower-case if it begins with http and otherwise leaves it as null, so we sort of remove non valid web-urls
val cleanUrl = udf((value: String) =&gt; if (value != null &amp;&amp; value.startsWith(&quot;http&quot;)) value.toLowerCase() else null)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>cleanUrl: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(&lt;function1&gt;,StringType,Some(List(StringType)))
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Let us apply our UDF on <code>fixedDF</code> to create a new DataFrame called <code>cleanedDF</code> as follows:</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Ctrl+Enter
val cleanedDF = fixedDF.select($&quot;agency&quot;, $&quot;platform&quot;, cleanUrl($&quot;url&quot;).as(&quot;url&quot;), $&quot;date&quot;, $&quot;visits&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>cleanedDF: org.apache.spark.sql.DataFrame = [agency: string, platform: string ... 3 more fields]
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Now, let's check that it actually worked by seeing the first 5 rows of the <code>cleanedDF</code> whose <code>url</code> <code>isNull</code> and <code>isNotNull</code>, as follows:</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Shift+Enter
cleanedDF.filter($&quot;url&quot;.isNull).show(5)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+------+----------+----+----------+------+
|agency|  platform| url|      date|visits|
+------+----------+----+----------+------+
|   OEM|       SMS|null|2012-02-17| 61652|
|   OEM|       SMS|null|2012-11-09| 44547|
| NYCHA|Newsletter|null|2012-05-09|     0|
|   DHS|   Twitter|null|2012-06-13|   389|
|   DHS|   Twitter|null|2012-08-02|   431|
+------+----------+----+----------+------+
only showing top 5 rows
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Ctrl+Enter
cleanedDF.filter($&quot;url&quot;.isNotNull).show(5, false) // false in .show(5, false) shows rows untruncated
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+------+----------+------------------------------------------------------------------------------------+----------+------+
|agency|platform  |url                                                                                 |date      |visits|
+------+----------+------------------------------------------------------------------------------------+----------+------+
|EDC   |Flickr    |http://www.flickr.com/nycedc                                                        |2012-05-09|0     |
|DPR   |Broadcastr|http://beta.broadcastr.com/echo.html?audioid=670026-4001                            |2011-08-08|0     |
|ENDHT |Facebook  |http://www.facebook.com/pages/nyc-lets-end-human-trafficking/125730490795659?sk=wall|2011-08-08|3     |
|VAC   |Facebook  |https://www.facebook.com/pages/nyc-voter-assistance-commission/110226709012110      |2011-08-08|36    |
|PlaNYC|Facebook  |http://www.facebook.com/pages/new-york-ny/planyc/160454173971169?ref=ts             |2011-08-08|47    |
+------+----------+------------------------------------------------------------------------------------+----------+------+
only showing top 5 rows
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Now there is a suggestion from you manager's manager's manager that due to some perceived privacy concerns we want to replace <code>agency</code> with some unique identifier.</p>
<p>So we need to do the following: * create unique list of agencies with ids and * join them with main DataFrame.</p>
<p>Sounds easy, right? Let's do it.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Crtl+Enter
// Import Spark SQL function that will give us unique id across all the records in this DataFrame
import org.apache.spark.sql.functions.monotonically_increasing_id

// We append column as SQL function that creates unique ids across all records in DataFrames 
val agencies = cleanedDF.select(cleanedDF(&quot;agency&quot;))
                        .distinct()
                        .withColumn(&quot;id&quot;, monotonically_increasing_id())
agencies.show(5)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+--------------------+-----------+
|              agency|         id|
+--------------------+-----------+
|              PlaNYC|34359738368|
|                 HIA|34359738369|
|NYC Digital: exte...|34359738370|
|           NYCGLOBAL|42949672960|
|              nycgov|68719476736|
+--------------------+-----------+
only showing top 5 rows

import org.apache.spark.sql.functions.monotonically_increasing_id
agencies: org.apache.spark.sql.DataFrame = [agency: string, id: bigint]
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Those who want to understand left/right inner/outer joins can see the <a href="/#workspace/scalable-data-science/xtraResources/edXBigDataSeries2015/CS100-1x/Module%203:%20Lectures">video lectures in Module 3 of Anthony Joseph's Introduction to Big data edX course</a> from the Community Edition of databricks. The course has been added to this databricks shard at <a href="/#workspace/scalable-data-science/xtraResources/edXBigDataSeries2015/CS100-1x">/#workspace/scalable-data-science/xtraResources/edXBigDataSeries2015/CS100-1x</a> as extra resources for the project-focussed course <a href="http://www.math.canterbury.ac.nz/%7Er.sainudiin/courses/ScalableDataScience/">Scalable Data Science</a>.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Ctrl+Enter
// And join with the rest of the data, note how join condition is specified 
val anonym = cleanedDF.join(agencies, cleanedDF(&quot;agency&quot;) === agencies(&quot;agency&quot;), &quot;inner&quot;).select(&quot;id&quot;, &quot;platform&quot;, &quot;url&quot;, &quot;date&quot;, &quot;visits&quot;)

// We also cache DataFrame since it can be quite expensive to recompute join
anonym.cache()

// Display result
anonym.show(5)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+-------------+----------+--------------------+----------+------+
|           id|  platform|                 url|      date|visits|
+-------------+----------+--------------------+----------+------+
|1580547964928|       SMS|                null|2012-02-17| 61652|
|1580547964928|       SMS|                null|2012-11-09| 44547|
| 412316860416|    Flickr|http://www.flickr...|2012-05-09|     0|
|1649267441664|Newsletter|                null|2012-05-09|     0|
|1529008357376|   Twitter|                null|2012-06-13|   389|
+-------------+----------+--------------------+----------+------+
only showing top 5 rows

anonym: org.apache.spark.sql.DataFrame = [id: bigint, platform: string ... 3 more fields]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">spark.catalog.listTables().show() // look at the available tables
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+--------------------+--------+-----------+---------+-----------+
|                name|database|description|tableType|isTemporary|
+--------------------+--------+-----------+---------+-----------+
|          cities_csv| default|       null| EXTERNAL|      false|
|       cleaned_taxes| default|       null|  MANAGED|      false|
|commdettrumpclint...| default|       null|  MANAGED|      false|
|   donaldtrumptweets| default|       null| EXTERNAL|      false|
|             linkage| default|       null| EXTERNAL|      false|
|             nations| default|       null| EXTERNAL|      false|
|           newmplist| default|       null| EXTERNAL|      false|
|       ny_baby_names| default|       null|  MANAGED|      false|
|       nzmpsandparty| default|       null| EXTERNAL|      false|
|    pos_neg_category| default|       null| EXTERNAL|      false|
|                 rna| default|       null|  MANAGED|      false|
|                samh| default|       null| EXTERNAL|      false|
|  social_media_usage| default|       null| EXTERNAL|      false|
|              table1| default|       null| EXTERNAL|      false|
|          test_table| default|       null| EXTERNAL|      false|
|             uscites| default|       null| EXTERNAL|      false|
+--------------------+--------+-----------+---------+-----------+
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-sql">-- to remove a TempTable if it exists already
drop table if exists anonym
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Register table for Spark SQL, we also import &quot;month&quot; function 
import org.apache.spark.sql.functions.month

anonym.createOrReplaceTempView(&quot;anonym&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>import org.apache.spark.sql.functions.month
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="true">
<pre><code class="language-sql">-- Interesting. Now let's do some aggregation. Display platform, month, visits
-- Date column allows us to extract month directly

select platform, month(date) as month, sum(visits) as visits from anonym group by platform, month(date)
</code></pre>
<div class="output execute_result tabular_result" execution_count="1">
<table>
<thead>
<tr class="header">
<th>platform</th>
<th>month</th>
<th>visits</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Instagram</td>
<td>9.0</td>
<td>27891.0</td>
</tr>
<tr class="even">
<td>Linked-In</td>
<td>10.0</td>
<td>60156.0</td>
</tr>
<tr class="odd">
<td>Foursquare (Badge Unlock)</td>
<td>6.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>iPhone</td>
<td>8.0</td>
<td>10336.0</td>
</tr>
<tr class="odd">
<td>Instagram</td>
<td>1.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>Twitter</td>
<td>9.0</td>
<td>819290.0</td>
</tr>
<tr class="odd">
<td>Vimeo</td>
<td>11.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>Linked-In</td>
<td>1.0</td>
<td>19007.0</td>
</tr>
<tr class="odd">
<td>iPhone app</td>
<td>9.0</td>
<td>33348.0</td>
</tr>
<tr class="even">
<td>SMS</td>
<td>10.0</td>
<td>54100.0</td>
</tr>
<tr class="odd">
<td>YouTube</td>
<td>2.0</td>
<td>4937.0</td>
</tr>
<tr class="even">
<td>Instagram</td>
<td>11.0</td>
<td>58968.0</td>
</tr>
<tr class="odd">
<td>YouTube</td>
<td>3.0</td>
<td>6066.0</td>
</tr>
<tr class="even">
<td>iPhone</td>
<td>2.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>Newsletter</td>
<td>11.0</td>
<td>3079091.0</td>
</tr>
<tr class="even">
<td>Google+</td>
<td>2.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>Android</td>
<td>4.0</td>
<td>724.0</td>
</tr>
<tr class="even">
<td>Instagram</td>
<td>2.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>Android</td>
<td>3.0</td>
<td>343.0</td>
</tr>
<tr class="even">
<td>Youtube</td>
<td>10.0</td>
<td>429.0</td>
</tr>
<tr class="odd">
<td>Android</td>
<td>11.0</td>
<td>11259.0</td>
</tr>
<tr class="even">
<td>Newsletter</td>
<td>12.0</td>
<td>1606654.0</td>
</tr>
<tr class="odd">
<td>iPhone App</td>
<td>4.0</td>
<td>55960.0</td>
</tr>
<tr class="even">
<td>iPhone app</td>
<td>12.0</td>
<td>21352.0</td>
</tr>
<tr class="odd">
<td>Facebook</td>
<td>3.0</td>
<td>291971.0</td>
</tr>
<tr class="even">
<td>Google+</td>
<td>5.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>Newsletter</td>
<td>5.0</td>
<td>847813.0</td>
</tr>
<tr class="even">
<td>Instagram</td>
<td>10.0</td>
<td>28145.0</td>
</tr>
<tr class="odd">
<td>Linked-In</td>
<td>7.0</td>
<td>31758.0</td>
</tr>
<tr class="even">
<td>Tumblr</td>
<td>5.0</td>
<td>26932.0</td>
</tr>
<tr class="odd">
<td>SMS</td>
<td>2.0</td>
<td>62034.0</td>
</tr>
<tr class="even">
<td>Linked-In</td>
<td>6.0</td>
<td>30867.0</td>
</tr>
<tr class="odd">
<td>YouTube</td>
<td>11.0</td>
<td>22820.0</td>
</tr>
<tr class="even">
<td>Foursquare</td>
<td>3.0</td>
<td>25786.0</td>
</tr>
<tr class="odd">
<td>SMS</td>
<td>11.0</td>
<td>170234.0</td>
</tr>
<tr class="even">
<td>Foursquare (Badge Unlock)</td>
<td>11.0</td>
<td>22512.0</td>
</tr>
<tr class="odd">
<td>Youtube</td>
<td>11.0</td>
<td>770.0</td>
</tr>
<tr class="even">
<td>iPhone App</td>
<td>2.0</td>
<td>21672.0</td>
</tr>
<tr class="odd">
<td>YouTube</td>
<td>12.0</td>
<td>9505.0</td>
</tr>
<tr class="even">
<td>Foursquare</td>
<td>8.0</td>
<td>42230.0</td>
</tr>
<tr class="odd">
<td>Foursquare (Badge Unlock)</td>
<td>4.0</td>
<td>20152.0</td>
</tr>
<tr class="even">
<td>Facebook</td>
<td>5.0</td>
<td>351601.0</td>
</tr>
<tr class="odd">
<td>Tumblr</td>
<td>3.0</td>
<td>5098.0</td>
</tr>
<tr class="even">
<td>Linked-In</td>
<td>8.0</td>
<td>45346.0</td>
</tr>
<tr class="odd">
<td>Google+</td>
<td>10.0</td>
<td>8.0</td>
</tr>
<tr class="even">
<td>Facebook</td>
<td>6.0</td>
<td>399330.0</td>
</tr>
<tr class="odd">
<td>Foursquare</td>
<td>1.0</td>
<td>10126.0</td>
</tr>
<tr class="even">
<td>YouTube</td>
<td>4.0</td>
<td>12542.0</td>
</tr>
<tr class="odd">
<td>Newsletter</td>
<td>6.0</td>
<td>1137677.0</td>
</tr>
<tr class="even">
<td>YouTube</td>
<td>7.0</td>
<td>6748.0</td>
</tr>
<tr class="odd">
<td>Google+</td>
<td>4.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>Youtube</td>
<td>6.0</td>
<td>229.0</td>
</tr>
<tr class="odd">
<td>Linked-In</td>
<td>11.0</td>
<td>75747.0</td>
</tr>
<tr class="even">
<td>Facebook</td>
<td>1.0</td>
<td>259797.0</td>
</tr>
<tr class="odd">
<td>Youtube</td>
<td>5.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>Vimeo</td>
<td>10.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>iPhone App</td>
<td>1.0</td>
<td>21672.0</td>
</tr>
<tr class="even">
<td>Android</td>
<td>5.0</td>
<td>381.0</td>
</tr>
<tr class="odd">
<td>Flickr</td>
<td>8.0</td>
<td>493.0</td>
</tr>
<tr class="even">
<td>iPhone app</td>
<td>8.0</td>
<td>41389.0</td>
</tr>
<tr class="odd">
<td>Facebook</td>
<td>10.0</td>
<td>1010914.0</td>
</tr>
<tr class="even">
<td>Foursquare (Badge Unlock)</td>
<td>10.0</td>
<td>11256.0</td>
</tr>
<tr class="odd">
<td>Instagram</td>
<td>8.0</td>
<td>5995.0</td>
</tr>
<tr class="even">
<td>Vimeo</td>
<td>12.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>Flickr</td>
<td>1.0</td>
<td>217.0</td>
</tr>
<tr class="even">
<td>WordPress</td>
<td>2.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>Android</td>
<td>10.0</td>
<td>5473.0</td>
</tr>
<tr class="even">
<td>Youtube</td>
<td>2.0</td>
<td>155.0</td>
</tr>
<tr class="odd">
<td>Android</td>
<td>6.0</td>
<td>102.0</td>
</tr>
<tr class="even">
<td>Tumblr</td>
<td>7.0</td>
<td>47121.0</td>
</tr>
<tr class="odd">
<td>Pinterest</td>
<td>1.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>Linked-In</td>
<td>3.0</td>
<td>20761.0</td>
</tr>
<tr class="odd">
<td>iPhone app</td>
<td>10.0</td>
<td>30713.0</td>
</tr>
<tr class="even">
<td>Youtube</td>
<td>3.0</td>
<td>163.0</td>
</tr>
<tr class="odd">
<td>WordPress</td>
<td>6.0</td>
<td>4641.0</td>
</tr>
<tr class="even">
<td>iPhone</td>
<td>11.0</td>
<td>25848.0</td>
</tr>
<tr class="odd">
<td>Broadcastr</td>
<td>3.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>Youtube</td>
<td>7.0</td>
<td>240.0</td>
</tr>
<tr class="odd">
<td>iPhone App</td>
<td>11.0</td>
<td>96342.0</td>
</tr>
<tr class="even">
<td>SMS</td>
<td>12.0</td>
<td>124068.0</td>
</tr>
<tr class="odd">
<td>Facebook</td>
<td>4.0</td>
<td>674303.0</td>
</tr>
<tr class="even">
<td>Youtube</td>
<td>12.0</td>
<td>291.0</td>
</tr>
<tr class="odd">
<td>Twitter</td>
<td>1.0</td>
<td>364376.0</td>
</tr>
<tr class="even">
<td>Newsletter</td>
<td>3.0</td>
<td>803327.0</td>
</tr>
<tr class="odd">
<td>iPhone</td>
<td>5.0</td>
<td>8203.0</td>
</tr>
<tr class="even">
<td>iPhone app</td>
<td>5.0</td>
<td>30598.0</td>
</tr>
<tr class="odd">
<td>Tumblr</td>
<td>8.0</td>
<td>54224.0</td>
</tr>
<tr class="even">
<td>iPhone App</td>
<td>12.0</td>
<td>43344.0</td>
</tr>
<tr class="odd">
<td>WordPress</td>
<td>1.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>iPhone app</td>
<td>3.0</td>
<td>10676.0</td>
</tr>
<tr class="odd">
<td>Flickr</td>
<td>12.0</td>
<td>432.0</td>
</tr>
<tr class="even">
<td>Twitter</td>
<td>10.0</td>
<td>859354.0</td>
</tr>
<tr class="odd">
<td>Android</td>
<td>12.0</td>
<td>686.0</td>
</tr>
<tr class="even">
<td>Vimeo</td>
<td>6.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>Vimeo</td>
<td>8.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>iPhone App</td>
<td>6.0</td>
<td>34966.0</td>
</tr>
<tr class="odd">
<td>iPhone</td>
<td>6.0</td>
<td>9643.0</td>
</tr>
<tr class="even">
<td>SMS</td>
<td>5.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>Vimeo</td>
<td>7.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>Android</td>
<td>1.0</td>
<td>343.0</td>
</tr>
<tr class="odd">
<td>WordPress</td>
<td>12.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>iPhone app</td>
<td>6.0</td>
<td>2713.0</td>
</tr>
<tr class="odd">
<td>Newsletter</td>
<td>10.0</td>
<td>2359712.0</td>
</tr>
<tr class="even">
<td>Pinterest</td>
<td>11.0</td>
<td>312.0</td>
</tr>
<tr class="odd">
<td>Broadcastr</td>
<td>6.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>Google+</td>
<td>1.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>Android</td>
<td>8.0</td>
<td>5784.0</td>
</tr>
<tr class="even">
<td>Pinterest</td>
<td>6.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>Newsletter</td>
<td>4.0</td>
<td>1606654.0</td>
</tr>
<tr class="even">
<td>Newsletter</td>
<td>9.0</td>
<td>1941202.0</td>
</tr>
<tr class="odd">
<td>WordPress</td>
<td>10.0</td>
<td>66299.0</td>
</tr>
<tr class="even">
<td>iPhone</td>
<td>1.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>SMS</td>
<td>8.0</td>
<td>116134.0</td>
</tr>
<tr class="even">
<td>Foursquare (Badge Unlock)</td>
<td>12.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>Twitter</td>
<td>7.0</td>
<td>470477.0</td>
</tr>
<tr class="even">
<td>Linked-In</td>
<td>12.0</td>
<td>35231.0</td>
</tr>
<tr class="odd">
<td>Foursquare (Badge Unlock)</td>
<td>1.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>iPhone</td>
<td>4.0</td>
<td>8203.0</td>
</tr>
<tr class="odd">
<td>Flickr</td>
<td>3.0</td>
<td>227.0</td>
</tr>
<tr class="even">
<td>iPhone app</td>
<td>11.0</td>
<td>72102.0</td>
</tr>
<tr class="odd">
<td>YouTube</td>
<td>1.0</td>
<td>4904.0</td>
</tr>
<tr class="even">
<td>Flickr</td>
<td>10.0</td>
<td>153231.0</td>
</tr>
<tr class="odd">
<td>Instagram</td>
<td>4.0</td>
<td>3404.0</td>
</tr>
<tr class="even">
<td>WordPress</td>
<td>8.0</td>
<td>5017.0</td>
</tr>
<tr class="odd">
<td>YouTube</td>
<td>9.0</td>
<td>12107.0</td>
</tr>
<tr class="even">
<td>iPhone app</td>
<td>4.0</td>
<td>41274.0</td>
</tr>
<tr class="odd">
<td>Broadcastr</td>
<td>12.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>Linked-In</td>
<td>4.0</td>
<td>43582.0</td>
</tr>
<tr class="odd">
<td>YouTube</td>
<td>8.0</td>
<td>10974.0</td>
</tr>
<tr class="even">
<td>iPhone</td>
<td>12.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>Newsletter</td>
<td>1.0</td>
<td>803327.0</td>
</tr>
<tr class="even">
<td>Broadcastr</td>
<td>9.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>Broadcastr</td>
<td>2.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>Flickr</td>
<td>5.0</td>
<td>287.0</td>
</tr>
<tr class="odd">
<td>Tumblr</td>
<td>10.0</td>
<td>97401.0</td>
</tr>
<tr class="even">
<td>Linked-In</td>
<td>2.0</td>
<td>19920.0</td>
</tr>
<tr class="odd">
<td>Broadcastr</td>
<td>8.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>iPhone App</td>
<td>9.0</td>
<td>42128.0</td>
</tr>
<tr class="odd">
<td>Pinterest</td>
<td>2.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>Twitter</td>
<td>4.0</td>
<td>844718.0</td>
</tr>
<tr class="odd">
<td>Broadcastr</td>
<td>10.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>Foursquare</td>
<td>12.0</td>
<td>19110.0</td>
</tr>
<tr class="odd">
<td>Tumblr</td>
<td>6.0</td>
<td>41248.0</td>
</tr>
<tr class="even">
<td>Vimeo</td>
<td>2.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>WordPress</td>
<td>4.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>Twitter</td>
<td>11.0</td>
<td>1660542.0</td>
</tr>
<tr class="odd">
<td>Linked-In</td>
<td>9.0</td>
<td>49299.0</td>
</tr>
<tr class="even">
<td>Twitter</td>
<td>12.0</td>
<td>690189.0</td>
</tr>
<tr class="odd">
<td>Android</td>
<td>9.0</td>
<td>445.0</td>
</tr>
<tr class="even">
<td>iPhone</td>
<td>9.0</td>
<td>12924.0</td>
</tr>
<tr class="odd">
<td>WordPress</td>
<td>9.0</td>
<td>4897.0</td>
</tr>
<tr class="even">
<td>Tumblr</td>
<td>1.0</td>
<td>2645.0</td>
</tr>
<tr class="odd">
<td>Foursquare</td>
<td>2.0</td>
<td>21181.0</td>
</tr>
<tr class="even">
<td>Foursquare</td>
<td>10.0</td>
<td>69598.0</td>
</tr>
<tr class="odd">
<td>Broadcastr</td>
<td>1.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>Pinterest</td>
<td>10.0</td>
<td>141.0</td>
</tr>
<tr class="odd">
<td>Facebook</td>
<td>9.0</td>
<td>754875.0</td>
</tr>
<tr class="even">
<td>YouTube</td>
<td>10.0</td>
<td>9100.0</td>
</tr>
<tr class="odd">
<td>Twitter</td>
<td>3.0</td>
<td>400250.0</td>
</tr>
<tr class="even">
<td>Broadcastr</td>
<td>11.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>Pinterest</td>
<td>8.0</td>
<td>38.0</td>
</tr>
<tr class="even">
<td>Twitter</td>
<td>6.0</td>
<td>461261.0</td>
</tr>
<tr class="odd">
<td>Foursquare (Badge Unlock)</td>
<td>2.0</td>
<td>8878.0</td>
</tr>
<tr class="even">
<td>Google+</td>
<td>12.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>Google+</td>
<td>3.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>Linked-In</td>
<td>5.0</td>
<td>29808.0</td>
</tr>
<tr class="odd">
<td>Vimeo</td>
<td>1.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>Foursquare</td>
<td>5.0</td>
<td>29991.0</td>
</tr>
<tr class="odd">
<td>Foursquare</td>
<td>7.0</td>
<td>38590.0</td>
</tr>
<tr class="even">
<td>iPhone app</td>
<td>7.0</td>
<td>30713.0</td>
</tr>
<tr class="odd">
<td>Newsletter</td>
<td>2.0</td>
<td>803327.0</td>
</tr>
<tr class="even">
<td>Twitter</td>
<td>8.0</td>
<td>704438.0</td>
</tr>
<tr class="odd">
<td>Facebook</td>
<td>2.0</td>
<td>107993.0</td>
</tr>
<tr class="even">
<td>Broadcastr</td>
<td>4.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>Instagram</td>
<td>5.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>Android</td>
<td>7.0</td>
<td>445.0</td>
</tr>
<tr class="odd">
<td>Flickr</td>
<td>9.0</td>
<td>549.0</td>
</tr>
<tr class="even">
<td>WordPress</td>
<td>11.0</td>
<td>9294.0</td>
</tr>
<tr class="odd">
<td>Flickr</td>
<td>11.0</td>
<td>1007.0</td>
</tr>
<tr class="even">
<td>Pinterest</td>
<td>4.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>iPhone</td>
<td>10.0</td>
<td>12924.0</td>
</tr>
<tr class="even">
<td>Pinterest</td>
<td>12.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>Flickr</td>
<td>4.0</td>
<td>545.0</td>
</tr>
<tr class="even">
<td>Facebook</td>
<td>7.0</td>
<td>451076.0</td>
</tr>
<tr class="odd">
<td>Google+</td>
<td>8.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>Tumblr</td>
<td>9.0</td>
<td>62742.0</td>
</tr>
<tr class="odd">
<td>Android</td>
<td>2.0</td>
<td>343.0</td>
</tr>
<tr class="even">
<td>Foursquare</td>
<td>4.0</td>
<td>57337.0</td>
</tr>
<tr class="odd">
<td>SMS</td>
<td>1.0</td>
<td>62034.0</td>
</tr>
<tr class="even">
<td>WordPress</td>
<td>3.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>Instagram</td>
<td>3.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>iPhone App</td>
<td>3.0</td>
<td>21672.0</td>
</tr>
<tr class="odd">
<td>Tumblr</td>
<td>4.0</td>
<td>31247.0</td>
</tr>
<tr class="even">
<td>Pinterest</td>
<td>9.0</td>
<td>74.0</td>
</tr>
<tr class="odd">
<td>Broadcastr</td>
<td>5.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>YouTube</td>
<td>5.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>Facebook</td>
<td>8.0</td>
<td>657312.0</td>
</tr>
<tr class="even">
<td>iPhone App</td>
<td>5.0</td>
<td>34288.0</td>
</tr>
<tr class="odd">
<td>Youtube</td>
<td>1.0</td>
<td>150.0</td>
</tr>
<tr class="even">
<td>SMS</td>
<td>9.0</td>
<td>116134.0</td>
</tr>
<tr class="odd">
<td>iPhone</td>
<td>3.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>Vimeo</td>
<td>5.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>Google+</td>
<td>7.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>SMS</td>
<td>6.0</td>
<td>54100.0</td>
</tr>
<tr class="odd">
<td>Vimeo</td>
<td>9.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>Google+</td>
<td>11.0</td>
<td>26.0</td>
</tr>
<tr class="odd">
<td>Pinterest</td>
<td>7.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>Foursquare (Badge Unlock)</td>
<td>9.0</td>
<td>11256.0</td>
</tr>
<tr class="odd">
<td>SMS</td>
<td>3.0</td>
<td>62034.0</td>
</tr>
<tr class="even">
<td>Instagram</td>
<td>7.0</td>
<td>5450.0</td>
</tr>
<tr class="odd">
<td>iPhone App</td>
<td>10.0</td>
<td>64589.0</td>
</tr>
<tr class="even">
<td>Instagram</td>
<td>12.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>Flickr</td>
<td>2.0</td>
<td>219.0</td>
</tr>
<tr class="even">
<td>Instagram</td>
<td>6.0</td>
<td>4764.0</td>
</tr>
<tr class="odd">
<td>Foursquare (Badge Unlock)</td>
<td>7.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>Flickr</td>
<td>6.0</td>
<td>332.0</td>
</tr>
<tr class="odd">
<td>SMS</td>
<td>7.0</td>
<td>54100.0</td>
</tr>
<tr class="even">
<td>Tumblr</td>
<td>12.0</td>
<td>5005.0</td>
</tr>
<tr class="odd">
<td>Twitter</td>
<td>5.0</td>
<td>435148.0</td>
</tr>
<tr class="even">
<td>Youtube</td>
<td>9.0</td>
<td>281.0</td>
</tr>
<tr class="odd">
<td>iPhone App</td>
<td>8.0</td>
<td>57513.0</td>
</tr>
<tr class="even">
<td>Google+</td>
<td>9.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>Foursquare (Badge Unlock)</td>
<td>8.0</td>
<td>11256.0</td>
</tr>
<tr class="even">
<td>Pinterest</td>
<td>5.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>Facebook</td>
<td>11.0</td>
<td>1408965.0</td>
</tr>
<tr class="even">
<td>Twitter</td>
<td>2.0</td>
<td>385091.0</td>
</tr>
<tr class="odd">
<td>iPhone App</td>
<td>7.0</td>
<td>35841.0</td>
</tr>
<tr class="even">
<td>iPhone app</td>
<td>1.0</td>
<td>10676.0</td>
</tr>
<tr class="odd">
<td>Vimeo</td>
<td>3.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>SMS</td>
<td>4.0</td>
<td>124068.0</td>
</tr>
<tr class="odd">
<td>WordPress</td>
<td>7.0</td>
<td>4647.0</td>
</tr>
<tr class="even">
<td>Youtube</td>
<td>4.0</td>
<td>367.0</td>
</tr>
<tr class="odd">
<td>Foursquare (Badge Unlock)</td>
<td>5.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>Foursquare</td>
<td>6.0</td>
<td>34193.0</td>
</tr>
<tr class="odd">
<td>Google+</td>
<td>6.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>Youtube</td>
<td>8.0</td>
<td>258.0</td>
</tr>
<tr class="odd">
<td>Pinterest</td>
<td>3.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>Newsletter</td>
<td>7.0</td>
<td>1137868.0</td>
</tr>
<tr class="odd">
<td>Foursquare</td>
<td>9.0</td>
<td>50489.0</td>
</tr>
<tr class="even">
<td>Foursquare</td>
<td>11.0</td>
<td>118323.0</td>
</tr>
<tr class="odd">
<td>iPhone app</td>
<td>2.0</td>
<td>10676.0</td>
</tr>
<tr class="even">
<td>Flickr</td>
<td>7.0</td>
<td>342.0</td>
</tr>
<tr class="odd">
<td>Newsletter</td>
<td>8.0</td>
<td>1941197.0</td>
</tr>
<tr class="even">
<td>Tumblr</td>
<td>11.0</td>
<td>195881.0</td>
</tr>
<tr class="odd">
<td>Foursquare (Badge Unlock)</td>
<td>3.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>Facebook</td>
<td>12.0</td>
<td>502687.0</td>
</tr>
<tr class="odd">
<td>Broadcastr</td>
<td>7.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>WordPress</td>
<td>5.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>YouTube</td>
<td>6.0</td>
<td>6509.0</td>
</tr>
<tr class="even">
<td>Tumblr</td>
<td>2.0</td>
<td>4406.0</td>
</tr>
<tr class="odd">
<td>Vimeo</td>
<td>4.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>iPhone</td>
<td>7.0</td>
<td>10336.0</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="cell markdown">
<blockquote>
<p>Note, that we could have done aggregation using DataFrame API instead of Spark SQL.</p>
</blockquote>
</div>
<div class="cell markdown">
<p>Alright, now let's see some <em>cool</em> operations with window functions.</p>
<p>Our next task is to compute <code>(daily visits / monthly average)</code> for all platforms.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">import org.apache.spark.sql.functions.{dayofmonth, month, row_number, sum}
import org.apache.spark.sql.expressions.Window

val coolDF = anonym.select($&quot;id&quot;, $&quot;platform&quot;, dayofmonth($&quot;date&quot;).as(&quot;day&quot;), month($&quot;date&quot;).as(&quot;month&quot;), $&quot;visits&quot;).
  groupBy($&quot;id&quot;, $&quot;platform&quot;, $&quot;day&quot;, $&quot;month&quot;).agg(sum(&quot;visits&quot;).as(&quot;visits&quot;))

// Run window aggregation on visits per month and platform
val window = coolDF.select($&quot;id&quot;, $&quot;day&quot;, $&quot;visits&quot;, sum($&quot;visits&quot;).over(Window.partitionBy(&quot;platform&quot;, &quot;month&quot;)).as(&quot;monthly_visits&quot;))

// Create and register percent table
val percent = window.select($&quot;id&quot;, $&quot;day&quot;, ($&quot;visits&quot; / $&quot;monthly_visits&quot;).as(&quot;percent&quot;))

percent.createOrReplaceTempView(&quot;percent&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>import org.apache.spark.sql.functions.{dayofmonth, month, row_number, sum}
import org.apache.spark.sql.expressions.Window
coolDF: org.apache.spark.sql.DataFrame = [id: bigint, platform: string ... 3 more fields]
window: org.apache.spark.sql.DataFrame = [id: bigint, day: int ... 2 more fields]
percent: org.apache.spark.sql.DataFrame = [id: bigint, day: int ... 1 more field]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="true">
<pre><code class="language-sql">-- A little bit of visualization as result of our efforts
select id, day, `percent` from percent where `percent` &gt; 0.3 and day = 2
</code></pre>
<div class="output execute_result tabular_result" execution_count="1">
<table>
<thead>
<tr class="header">
<th>id</th>
<th>day</th>
<th>percent</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>6.52835028992e11</td>
<td>2.0</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>5.06806140929e11</td>
<td>2.0</td>
<td>0.4993894993894994</td>
</tr>
<tr class="odd">
<td>6.52835028992e11</td>
<td>2.0</td>
<td>0.446576072475353</td>
</tr>
<tr class="even">
<td>9.01943132161e11</td>
<td>2.0</td>
<td>0.5</td>
</tr>
<tr class="odd">
<td>6.52835028992e11</td>
<td>2.0</td>
<td>0.3181818181818182</td>
</tr>
<tr class="even">
<td>9.01943132161e11</td>
<td>2.0</td>
<td>0.6180914042150131</td>
</tr>
<tr class="odd">
<td>2.147483648e11</td>
<td>2.0</td>
<td>0.3663035756571158</td>
</tr>
<tr class="even">
<td>1.322849927168e12</td>
<td>2.0</td>
<td>0.5265514047545539</td>
</tr>
<tr class="odd">
<td>1.322849927168e12</td>
<td>2.0</td>
<td>0.3109034021149352</td>
</tr>
<tr class="even">
<td>1.408749273089e12</td>
<td>2.0</td>
<td>0.6937119675456389</td>
</tr>
<tr class="odd">
<td>6.52835028992e11</td>
<td>2.0</td>
<td>0.6765082509845611</td>
</tr>
<tr class="even">
<td>5.06806140929e11</td>
<td>2.0</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>6.52835028992e11</td>
<td>2.0</td>
<td>0.5</td>
</tr>
<tr class="even">
<td>4.12316860416e11</td>
<td>2.0</td>
<td>0.3408084980820301</td>
</tr>
<tr class="odd">
<td>1.580547964928e12</td>
<td>2.0</td>
<td>0.383582757848692</td>
</tr>
<tr class="even">
<td>6.52835028992e11</td>
<td>2.0</td>
<td>0.38833874233724447</td>
</tr>
<tr class="odd">
<td>2.06158430208e11</td>
<td>2.0</td>
<td>0.9262507474586407</td>
</tr>
<tr class="even">
<td>1.666447310848e12</td>
<td>2.0</td>
<td>0.9473684210526315</td>
</tr>
<tr class="odd">
<td>2.06158430208e11</td>
<td>2.0</td>
<td>0.5</td>
</tr>
<tr class="even">
<td>1.408749273089e12</td>
<td>2.0</td>
<td>0.394240317775571</td>
</tr>
<tr class="odd">
<td>6.8719476736e10</td>
<td>2.0</td>
<td>0.38461538461538464</td>
</tr>
<tr class="even">
<td>1.640677507072e12</td>
<td>2.0</td>
<td>0.44748143897901344</td>
</tr>
<tr class="odd">
<td>9.01943132161e11</td>
<td>2.0</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>6.52835028992e11</td>
<td>2.0</td>
<td>0.8449612403100775</td>
</tr>
<tr class="odd">
<td>9.01943132161e11</td>
<td>2.0</td>
<td>0.3060168545490231</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="true">
<pre><code class="language-sql">-- You also could just use plain SQL to write query above, note that you might need to group by id and day as well.
with aggr as (
  select id, dayofmonth(date) as day, visits / sum(visits) over (partition by (platform, month(date))) as percent
  from anonym
)
select * from aggr where day = 2 and percent &gt; 0.3
</code></pre>
<div class="output execute_result tabular_result" execution_count="1">
<table>
<thead>
<tr class="header">
<th>id</th>
<th>day</th>
<th>percent</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>6.52835028992e11</td>
<td>2.0</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>5.06806140929e11</td>
<td>2.0</td>
<td>0.4993894993894994</td>
</tr>
<tr class="odd">
<td>6.52835028992e11</td>
<td>2.0</td>
<td>0.446576072475353</td>
</tr>
<tr class="even">
<td>9.01943132161e11</td>
<td>2.0</td>
<td>0.5</td>
</tr>
<tr class="odd">
<td>6.52835028992e11</td>
<td>2.0</td>
<td>0.3181818181818182</td>
</tr>
<tr class="even">
<td>2.147483648e11</td>
<td>2.0</td>
<td>0.3663035756571158</td>
</tr>
<tr class="odd">
<td>9.01943132161e11</td>
<td>2.0</td>
<td>0.6180914042150131</td>
</tr>
<tr class="even">
<td>1.322849927168e12</td>
<td>2.0</td>
<td>0.4718608035989944</td>
</tr>
<tr class="odd">
<td>1.408749273089e12</td>
<td>2.0</td>
<td>0.6937119675456389</td>
</tr>
<tr class="even">
<td>6.52835028992e11</td>
<td>2.0</td>
<td>0.6765082509845611</td>
</tr>
<tr class="odd">
<td>5.06806140929e11</td>
<td>2.0</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>6.52835028992e11</td>
<td>2.0</td>
<td>0.5</td>
</tr>
<tr class="odd">
<td>4.12316860416e11</td>
<td>2.0</td>
<td>0.3408084980820301</td>
</tr>
<tr class="even">
<td>1.580547964928e12</td>
<td>2.0</td>
<td>0.383582757848692</td>
</tr>
<tr class="odd">
<td>6.52835028992e11</td>
<td>2.0</td>
<td>0.38833874233724447</td>
</tr>
<tr class="even">
<td>2.06158430208e11</td>
<td>2.0</td>
<td>0.9262507474586407</td>
</tr>
<tr class="odd">
<td>1.666447310848e12</td>
<td>2.0</td>
<td>0.9473684210526315</td>
</tr>
<tr class="even">
<td>2.06158430208e11</td>
<td>2.0</td>
<td>0.5</td>
</tr>
<tr class="odd">
<td>1.408749273089e12</td>
<td>2.0</td>
<td>0.394240317775571</td>
</tr>
<tr class="even">
<td>6.8719476736e10</td>
<td>2.0</td>
<td>0.38461538461538464</td>
</tr>
<tr class="odd">
<td>1.640677507072e12</td>
<td>2.0</td>
<td>0.44748143897901344</td>
</tr>
<tr class="even">
<td>9.01943132161e11</td>
<td>2.0</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>6.52835028992e11</td>
<td>2.0</td>
<td>0.8449612403100775</td>
</tr>
<tr class="even">
<td>9.01943132161e11</td>
<td>2.0</td>
<td>0.3060168545490231</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="cell markdown">
<h2 id="interoperating-with-rdds"><a class="header" href="#interoperating-with-rdds">Interoperating with RDDs</a></h2>
<p>Spark SQL supports two different methods for converting existing RDDs into DataFrames. The first method uses reflection to infer the schema of an RDD that contains specific types of objects. This reflection based approach leads to more concise code and works well when you already know the schema.</p>
<p>The second method for creating DataFrames is through a programmatic interface that allows you to construct a schema and then apply it to an existing RDD. While this method is more verbose, it allows you to construct DataFrames when the columns and their types are not known until runtime.</p>
<h3 id="inferring-the-schema-using-reflection"><a class="header" href="#inferring-the-schema-using-reflection">Inferring the Schema Using Reflection</a></h3>
<p>The Scala interface for Spark SQL supports automatically converting an RDD containing case classes to a DataFrame. The case class defines the schema of the table. The names of the arguments to the case class are read using reflection and become the names of the columns. Case classes can also be nested or contain complex types such as Sequences or Arrays. This RDD can be implicitly converted to a DataFrame and then be registered as a table.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Define case class that will be our schema for DataFrame
case class Hubot(name: String, year: Int, manufacturer: String, version: Array[Int], details: Map[String, String])

// You can process a text file, for example, to convert every row to our Hubot, but we will create RDD manually
val rdd = sc.parallelize(
  Array(
    Hubot(&quot;Jerry&quot;, 2015, &quot;LCorp&quot;, Array(1, 2, 3), Map(&quot;eat&quot; -&gt; &quot;yes&quot;, &quot;sleep&quot; -&gt; &quot;yes&quot;, &quot;drink&quot; -&gt; &quot;yes&quot;)),
    Hubot(&quot;Mozart&quot;, 2010, &quot;LCorp&quot;, Array(1, 2), Map(&quot;eat&quot; -&gt; &quot;no&quot;, &quot;sleep&quot; -&gt; &quot;no&quot;, &quot;drink&quot; -&gt; &quot;no&quot;)),
    Hubot(&quot;Einstein&quot;, 2012, &quot;LCorp&quot;, Array(1, 2, 3), Map(&quot;eat&quot; -&gt; &quot;yes&quot;, &quot;sleep&quot; -&gt; &quot;yes&quot;, &quot;drink&quot; -&gt; &quot;no&quot;))
  )
)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>defined class Hubot
rdd: org.apache.spark.rdd.RDD[Hubot] = ParallelCollectionRDD[23107] at parallelize at &lt;console&gt;:45
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// In order to convert RDD into DataFrame you need to do this:
val hubots = rdd.toDF()

// Display DataFrame, note how array and map fields are displayed
hubots.printSchema()
hubots.show()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>root
 |-- name: string (nullable = true)
 |-- year: integer (nullable = false)
 |-- manufacturer: string (nullable = true)
 |-- version: array (nullable = true)
 |    |-- element: integer (containsNull = false)
 |-- details: map (nullable = true)
 |    |-- key: string
 |    |-- value: string (valueContainsNull = true)

+--------+----+------------+---------+--------------------+
|    name|year|manufacturer|  version|             details|
+--------+----+------------+---------+--------------------+
|   Jerry|2015|       LCorp|[1, 2, 3]|Map(eat -&gt; yes, s...|
|  Mozart|2010|       LCorp|   [1, 2]|Map(eat -&gt; no, sl...|
|Einstein|2012|       LCorp|[1, 2, 3]|Map(eat -&gt; yes, s...|
+--------+----+------------+---------+--------------------+

hubots: org.apache.spark.sql.DataFrame = [name: string, year: int ... 3 more fields]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// You can query complex type the same as you query any other column
// By the way you can use `sql` function to invoke Spark SQL to create DataFrame
hubots.createOrReplaceTempView(&quot;hubots&quot;)

val onesThatEat = sqlContext.sql(&quot;select name, details.eat from hubots where details.eat = 'yes'&quot;)

onesThatEat.show()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+--------+---+
|    name|eat|
+--------+---+
|   Jerry|yes|
|Einstein|yes|
+--------+---+

onesThatEat: org.apache.spark.sql.DataFrame = [name: string, eat: string]
</code></pre>
</div>
</div>
<div class="cell markdown">
<h3 id="programmatically-specifying-the-schema"><a class="header" href="#programmatically-specifying-the-schema">Programmatically Specifying the Schema</a></h3>
<p>When case classes cannot be defined ahead of time (for example, the structure of records is encoded in a string, or a text dataset will be parsed and fields will be projected differently for different users), a <code>DataFrame</code> can be created programmatically with three steps.</p>
<ol>
<li>Create an RDD of <code>Row</code>s from the original RDD</li>
<li>Create the schema represented by a <a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.types.StructType">StructType</a> and <a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.types.StructField">StructField</a> classes matching the structure of <code>Row</code>s in the RDD created in Step 1.</li>
<li>Apply the schema to the RDD of <code>Row</code>s via <code>createDataFrame</code> method provided by <code>SQLContext</code>.</li>
</ol>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">import org.apache.spark.sql.types._

// Let's say we have an RDD of String and we need to convert it into a DataFrame with schema &quot;name&quot;, &quot;year&quot;, and &quot;manufacturer&quot;
// As you can see every record is space-separated.
val rdd = sc.parallelize(
  Array(
    &quot;Jerry 2015 LCorp&quot;,
    &quot;Mozart 2010 LCorp&quot;,
    &quot;Einstein 2012 LCorp&quot;
  )
)

// Create schema as StructType //
val schema = StructType(
  StructField(&quot;name&quot;, StringType, false) :: 
  StructField(&quot;year&quot;, IntegerType, false) :: 
  StructField(&quot;manufacturer&quot;, StringType, false) :: 
  Nil
)

// Prepare RDD[Row]
val rows = rdd.map { entry =&gt; 
  val arr = entry.split(&quot;\\s+&quot;)
  val name = arr(0)
  val year = arr(1).toInt
  val manufacturer = arr(2)
  
  Row(name, year, manufacturer)
}

// Create DataFrame
val bots = sqlContext.createDataFrame(rows, schema)
bots.printSchema()
bots.show()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>root
 |-- name: string (nullable = false)
 |-- year: integer (nullable = false)
 |-- manufacturer: string (nullable = false)

+--------+----+------------+
|    name|year|manufacturer|
+--------+----+------------+
|   Jerry|2015|       LCorp|
|  Mozart|2010|       LCorp|
|Einstein|2012|       LCorp|
+--------+----+------------+

import org.apache.spark.sql.types._
rdd: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[23118] at parallelize at &lt;console&gt;:47
schema: org.apache.spark.sql.types.StructType = StructType(StructField(name,StringType,false), StructField(year,IntegerType,false), StructField(manufacturer,StringType,false))
rows: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = MapPartitionsRDD[23119] at map at &lt;console&gt;:64
bots: org.apache.spark.sql.DataFrame = [name: string, year: int ... 1 more field]
</code></pre>
</div>
</div>
<div class="cell markdown">
<h2 id="creating-datasets"><a class="header" href="#creating-datasets">Creating Datasets</a></h2>
<p>A <a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset">Dataset</a> is a strongly-typed, immutable collection of objects that are mapped to a relational schema. At the core of the Dataset API is a new concept called an <a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Encoder">encoder</a>, which is responsible for converting between JVM objects and tabular representation. The tabular representation is stored using Sparks internal Tungsten binary format, allowing for operations on serialized data and improved memory utilization. Spark 2.2 comes with support for automatically generating encoders for a wide variety of types, including primitive types (e.g. String, Integer, Long), and Scala case classes.</p>
<blockquote>
<p>Simply put, you will get all the benefits of DataFrames with fair amount of flexibility of RDD API.</p>
</blockquote>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// We can start working with Datasets by using our &quot;hubots&quot; table

// To create Dataset from DataFrame do this (assuming that case class Hubot exists):
val ds = hubots.as[Hubot]
ds.show()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+--------+----+------------+---------+--------------------+
|    name|year|manufacturer|  version|             details|
+--------+----+------------+---------+--------------------+
|   Jerry|2015|       LCorp|[1, 2, 3]|Map(eat -&gt; yes, s...|
|  Mozart|2010|       LCorp|   [1, 2]|Map(eat -&gt; no, sl...|
|Einstein|2012|       LCorp|[1, 2, 3]|Map(eat -&gt; yes, s...|
+--------+----+------------+---------+--------------------+

ds: org.apache.spark.sql.Dataset[Hubot] = [name: string, year: int ... 3 more fields]
</code></pre>
</div>
</div>
<div class="cell markdown">
<blockquote>
<p><strong>Side-note:</strong> Dataset API is first-class citizen in Spark, and DataFrame is an alias for Dataset[Row]. Note that Python and R still use DataFrames (since they are dynamically typed), but it is essentially a Dataset.</p>
</blockquote>
</div>
<div class="cell markdown">
<h2 id="finally"><a class="header" href="#finally">Finally</a></h2>
<p>DataFrames and Datasets can simplify and improve most of the applications pipelines by bringing concise syntax and performance optimizations. We would highly recommend you to check out the official API documentation, specifically around * <a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrame">DataFrame API</a>, * <a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$">Spark SQL functions library</a>, * <a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.GroupedData">GroupBy clause and aggregated functions</a>.</p>
<p>Unfortunately, this is just <em>a getting started quickly</em> course, and we skip features like custom aggregations, types, pivoting, etc., but if you are keen to know then start from the links above and this notebook and others in this directory.</p>
</div>
<div class="cell markdown">
<h2 id="appendix"><a class="header" href="#appendix">Appendix</a></h2>
<h3 id="how-to-download-data-and-make-a-table"><a class="header" href="#how-to-download-data-and-make-a-table">How to download data and make a table</a></h3>
<p>Okay, so how did we actually make table &quot;social<em>media</em>usage&quot;? Databricks allows us to upload/link external data and make it available as registerd SQL table. It involves several steps: 1. Find interesting set of data - Google can be your friend for most cases here, or you can have your own dataset as CSV file, for example. Good source of data can also be found here: http://www.data.gov/ 2. Download / prepare it to be either on S3, or human-readable format like CSV, or JSON 3. Go to Databricks cloud (where you log in to use Databricks notebooks) and open tab <strong>Tables</strong> 4. On the very top of the left sub-menu you will see button <strong>+ Create table</strong>, click on it 5. You will see page with drop-down menu of the list of sources you can provide, <strong>File</strong> means any file (Parquet, Avro, CSV), but it works the best with CSV format 6. Once you have chosen file and loaded it, you can change column names, or tweak types (mainly for CSV format) 7. That is it. Just click on final button to create table. After that you can refer to the table using <code>sqlContext.table(&quot;YOUR_TABLE_NAME&quot;)</code></p>
</div>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        
                            <a rel="prev" href="../../../../contents/xtraResources/ProgGuides2_2/sqlProgrammingGuide/001_overview_sqlProgGuide.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>
                        

                        
                            <a rel="next" href="../../../../contents/xtraResources/ProgGuides2_2/sqlProgrammingGuide/003_dataSources_sqlProgGuide.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>
                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                
                    <a rel="prev" href="../../../../contents/xtraResources/ProgGuides2_2/sqlProgrammingGuide/001_overview_sqlProgGuide.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>
                

                
                    <a rel="next" href="../../../../contents/xtraResources/ProgGuides2_2/sqlProgrammingGuide/003_dataSources_sqlProgGuide.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="../../../../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../../../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../../../searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="../../../../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../../../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../../../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        

    </body>
</html>

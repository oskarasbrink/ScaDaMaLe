<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>013_UnsupervisedClustering_1MSongsKMeans_Stage1ETL</title>


        <!-- Custom HTML head -->

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="../../favicon.svg">
        <link rel="shortcut icon" href="../../favicon.png">
        <link rel="stylesheet" href="../../css/variables.css">
        <link rel="stylesheet" href="../../css/general.css">
        <link rel="stylesheet" href="../../css/chrome.css">
        <link rel="stylesheet" href="../../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../../highlight.css">
        <link rel="stylesheet" href="../../tomorrow-night.css">
        <link rel="stylesheet" href="../../ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/010a_packageCells.html">010a_packageCells</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/011_02_IntroToSimulation.html">011_02_IntroToSimulation</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/011_03_IntroToML.html">011_03_IntroToML</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/012_UnsupervisedClustering_1MSongsKMeans_Intro.html">012_UnsupervisedClustering_1MSongsKMeans_Intro</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/013_UnsupervisedClustering_1MSongsKMeans_Stage1ETL.html" class="active">013_UnsupervisedClustering_1MSongsKMeans_Stage1ETL</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/014_UnsupervisedClustering_1MSongsKMeans_Stage2Explore.html">014_UnsupervisedClustering_1MSongsKMeans_Stage2Explore</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/015_UnsupervisedClustering_1MSongsKMeans_Stage3Model.html">015_UnsupervisedClustering_1MSongsKMeans_Stage3Model</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/016_SupervisedClustering_DecisionTrees_HandWrittenDigitRecognition.html">016_SupervisedClustering_DecisionTrees_HandWrittenDigitRecognition</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/017_LAlgIntro.html">017_LAlgIntro</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/018_LinRegIntro.html">018_LinRegIntro</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/019_DistLAlgForLinRegIntro.html">019_DistLAlgForLinRegIntro</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/019x_000_dataTypesProgGuide.html">019x_000_dataTypesProgGuide</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/019x_001_LocalVector.html">019x_001_LocalVector</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/019x_002_LabeledPoint.html">019x_002_LabeledPoint</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/019x_003_LocalMatrix.html">019x_003_LocalMatrix</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/019x_004_DistributedMatrix.html">019x_004_DistributedMatrix</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/019x_005_RowMatrix.html">019x_005_RowMatrix</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/019x_006_IndexedRowMatrix.html">019x_006_IndexedRowMatrix</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/019x_007_CoordinateMatrix.html">019x_007_CoordinateMatrix</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/019x_008_BlockMatrix.html">019x_008_BlockMatrix</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/020_PowerPlantPipeline_02ModelTuneEvaluate.html">020_PowerPlantPipeline_02ModelTuneEvaluate</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/021_recognizeActivityByRandomForest.html">021_recognizeActivityByRandomForest</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/022_GraphFramesUserGuide.html">022_GraphFramesUserGuide</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/023_OnTimeFlightPerformance.html">023_OnTimeFlightPerformance</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/030_PowerPlantPipeline_03ModelTuneEvaluateDeploy.html">030_PowerPlantPipeline_03ModelTuneEvaluateDeploy</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/036_ALS_MovieRecommender.html">036_ALS_MovieRecommender</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_2-sds-3-x-ml/998_EX_01_GraphXShortestWeightedPaths.html">998_EX_01_GraphXShortestWeightedPaths</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title"></h1>

                    <div class="right-buttons">
                        <a href="../../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <div class="cell markdown">
<p>ScaDaMaLe Course <a href="https://lamastex.github.io/scalable-data-science/sds/3/x/">site</a> and <a href="https://lamastex.github.io/ScaDaMaLe/index.html">book</a></p>
</div>
<div class="cell markdown">
<h1 id="million-song-dataset---kaggle-challenge"><a class="header" href="#million-song-dataset---kaggle-challenge">Million Song Dataset - Kaggle Challenge</a></h1>
<h2 id="predict-which-songs-a-user-will-listen-to"><a class="header" href="#predict-which-songs-a-user-will-listen-to">Predict which songs a user will listen to.</a></h2>
<p><strong>SOURCE:</strong> This is just a <em>Scala</em>-rification of the <em>Python</em> notebook published in databricks community edition in 2016.</p>
<p><em>CAUTION:</em> This notebook is expected to have an error in command 28 (<code>Cmd 28</code> in databricks notebook). You are meant to learn how to fix this error with simple exception-handling to become a better data scientist. So ignore this warning, if any.</p>
</div>
<div class="cell markdown">
<h1 id="stage-1-parsing-songs-data"><a class="header" href="#stage-1-parsing-songs-data">Stage 1: Parsing songs data</a></h1>
<p><img src="http://training.databricks.com/databricks_guide/end-to-end-01.png" alt="ETL" /></p>
<p>This is the first notebook in this tutorial. In this notebook we will read data from DBFS (DataBricks FileSystem). We will parse data and load it as a table that can be readily used in following notebooks.</p>
<p>By going through this notebook you can expect to learn how to read distributed data as an RDD, how to transform RDDs, and how to construct a Spark DataFrame from an RDD and register it as a table.</p>
<p>We first explore different files in our distributed file system. We use a header file to construct a Spark <code>Schema</code> object. We write a function that takes the header and casts strings in each line of our data to corresponding types. Once we run this function on the data we find that it fails on some corner caes. We update our function and finally get a parsed RDD. We combine that RDD and the Schema to construct a DataFame and register it as a temporary table in SparkSQL.</p>
</div>
<div class="cell markdown">
<h3 id="text-data-files-are-stored-in-dbfsdatabricks-datasetssongsdata-001"><a class="header" href="#text-data-files-are-stored-in-dbfsdatabricks-datasetssongsdata-001">Text data files are stored in <code>dbfs:/databricks-datasets/songs/data-001</code></a></h3>
<p>You can conveniently list files on distributed file system (DBFS, S3 or HDFS) using <code>%fs</code> commands.</p>
</div>
<div class="cell code" execution_count="1" scrolled="true">
<pre><code class="language-fs">ls /databricks-datasets/songs/data-001/
</code></pre>
<div class="output execute_result tabular_result" execution_count="1">
<table>
<thead>
<tr class="header">
<th>path</th>
<th>name</th>
<th>size</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/header.txt</td>
<td>header.txt</td>
<td>377.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00000</td>
<td>part-00000</td>
<td>52837.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00001</td>
<td>part-00001</td>
<td>52469.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00002</td>
<td>part-00002</td>
<td>51778.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00003</td>
<td>part-00003</td>
<td>50551.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00004</td>
<td>part-00004</td>
<td>53449.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00005</td>
<td>part-00005</td>
<td>53301.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00006</td>
<td>part-00006</td>
<td>54184.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00007</td>
<td>part-00007</td>
<td>50924.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00008</td>
<td>part-00008</td>
<td>52533.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00009</td>
<td>part-00009</td>
<td>54570.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00010</td>
<td>part-00010</td>
<td>54338.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00011</td>
<td>part-00011</td>
<td>51836.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00012</td>
<td>part-00012</td>
<td>52297.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00013</td>
<td>part-00013</td>
<td>52044.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00014</td>
<td>part-00014</td>
<td>50704.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00015</td>
<td>part-00015</td>
<td>54158.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00016</td>
<td>part-00016</td>
<td>50080.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00017</td>
<td>part-00017</td>
<td>47708.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00018</td>
<td>part-00018</td>
<td>8858.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00019</td>
<td>part-00019</td>
<td>53323.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00020</td>
<td>part-00020</td>
<td>57877.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00021</td>
<td>part-00021</td>
<td>52491.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00022</td>
<td>part-00022</td>
<td>54791.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00023</td>
<td>part-00023</td>
<td>50682.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00024</td>
<td>part-00024</td>
<td>52863.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00025</td>
<td>part-00025</td>
<td>47416.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00026</td>
<td>part-00026</td>
<td>50130.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00027</td>
<td>part-00027</td>
<td>53462.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00028</td>
<td>part-00028</td>
<td>54179.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00029</td>
<td>part-00029</td>
<td>52738.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00030</td>
<td>part-00030</td>
<td>54159.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00031</td>
<td>part-00031</td>
<td>51247.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00032</td>
<td>part-00032</td>
<td>51610.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00033</td>
<td>part-00033</td>
<td>53895.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00034</td>
<td>part-00034</td>
<td>53125.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00035</td>
<td>part-00035</td>
<td>54066.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00036</td>
<td>part-00036</td>
<td>54265.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00037</td>
<td>part-00037</td>
<td>54264.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00038</td>
<td>part-00038</td>
<td>50540.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00039</td>
<td>part-00039</td>
<td>55193.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00040</td>
<td>part-00040</td>
<td>54537.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00041</td>
<td>part-00041</td>
<td>52402.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00042</td>
<td>part-00042</td>
<td>54673.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00043</td>
<td>part-00043</td>
<td>53009.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00044</td>
<td>part-00044</td>
<td>51789.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00045</td>
<td>part-00045</td>
<td>52986.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00046</td>
<td>part-00046</td>
<td>54442.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00047</td>
<td>part-00047</td>
<td>52971.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00048</td>
<td>part-00048</td>
<td>53331.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00049</td>
<td>part-00049</td>
<td>44263.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00050</td>
<td>part-00050</td>
<td>54841.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00051</td>
<td>part-00051</td>
<td>54306.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00052</td>
<td>part-00052</td>
<td>53610.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00053</td>
<td>part-00053</td>
<td>53573.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00054</td>
<td>part-00054</td>
<td>53854.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00055</td>
<td>part-00055</td>
<td>54236.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00056</td>
<td>part-00056</td>
<td>54455.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00057</td>
<td>part-00057</td>
<td>52307.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00058</td>
<td>part-00058</td>
<td>52313.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00059</td>
<td>part-00059</td>
<td>52446.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00060</td>
<td>part-00060</td>
<td>51958.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00061</td>
<td>part-00061</td>
<td>53859.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00062</td>
<td>part-00062</td>
<td>53698.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00063</td>
<td>part-00063</td>
<td>54482.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00064</td>
<td>part-00064</td>
<td>40182.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00065</td>
<td>part-00065</td>
<td>54410.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00066</td>
<td>part-00066</td>
<td>49123.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00067</td>
<td>part-00067</td>
<td>50796.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00068</td>
<td>part-00068</td>
<td>49561.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00069</td>
<td>part-00069</td>
<td>52294.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00070</td>
<td>part-00070</td>
<td>51250.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00071</td>
<td>part-00071</td>
<td>58942.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00072</td>
<td>part-00072</td>
<td>54589.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00073</td>
<td>part-00073</td>
<td>54233.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00074</td>
<td>part-00074</td>
<td>54725.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00075</td>
<td>part-00075</td>
<td>54877.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00076</td>
<td>part-00076</td>
<td>54333.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00077</td>
<td>part-00077</td>
<td>51927.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00078</td>
<td>part-00078</td>
<td>51744.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00079</td>
<td>part-00079</td>
<td>53187.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00080</td>
<td>part-00080</td>
<td>43246.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00081</td>
<td>part-00081</td>
<td>54269.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00082</td>
<td>part-00082</td>
<td>48464.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00083</td>
<td>part-00083</td>
<td>52144.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00084</td>
<td>part-00084</td>
<td>53375.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00085</td>
<td>part-00085</td>
<td>55139.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00086</td>
<td>part-00086</td>
<td>50924.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00087</td>
<td>part-00087</td>
<td>52013.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00088</td>
<td>part-00088</td>
<td>54262.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00089</td>
<td>part-00089</td>
<td>53007.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00090</td>
<td>part-00090</td>
<td>55142.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00091</td>
<td>part-00091</td>
<td>52049.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00092</td>
<td>part-00092</td>
<td>54714.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00093</td>
<td>part-00093</td>
<td>52906.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00094</td>
<td>part-00094</td>
<td>52188.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00095</td>
<td>part-00095</td>
<td>50768.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00096</td>
<td>part-00096</td>
<td>55242.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00097</td>
<td>part-00097</td>
<td>52059.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00098</td>
<td>part-00098</td>
<td>52982.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00099</td>
<td>part-00099</td>
<td>52015.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00100</td>
<td>part-00100</td>
<td>51467.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00101</td>
<td>part-00101</td>
<td>50926.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00102</td>
<td>part-00102</td>
<td>55018.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00103</td>
<td>part-00103</td>
<td>50043.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00104</td>
<td>part-00104</td>
<td>51936.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00105</td>
<td>part-00105</td>
<td>57311.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00106</td>
<td>part-00106</td>
<td>55090.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00107</td>
<td>part-00107</td>
<td>54396.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00108</td>
<td>part-00108</td>
<td>56594.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00109</td>
<td>part-00109</td>
<td>53260.0</td>
</tr>
<tr class="even">
<td>dbfs:/databricks-datasets/songs/data-001/part-00110</td>
<td>part-00110</td>
<td>42007.0</td>
</tr>
<tr class="odd">
<td>dbfs:/databricks-datasets/songs/data-001/part-00119</td>
<td>part-00119</td>
<td>0.0</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="cell markdown">
<p>As you can see in the listing we have data files and a single header file. The header file seems interesting and worth a first inspection at first. The file is 377 bytes, therefore it is safe to collect the entire content of the file in the notebook.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">sc.textFile(&quot;databricks-datasets/songs/data-001/header.txt&quot;).collect() 
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res1: Array[String] = Array(artist_id:string, artist_latitude:double, artist_longitude:double, artist_location:string, artist_name:string, duration:double, end_of_fade_in:double, key:int, key_confidence:double, loudness:double, release:string, song_hotnes:double, song_id:string, start_of_fade_out:double, tempo:double, time_signature:double, time_signature_confidence:double, title:string, year:double, partial_sequence:int)
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Remember you can <code>collect()</code> a huge RDD and crash the driver program - so it is a good practise to take a couple lines and count the number of lines, especially if you have no idea what file you are trying to read.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">sc.textFile(&quot;databricks-datasets/songs/data-001/header.txt&quot;).take(2)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res2: Array[String] = Array(artist_id:string, artist_latitude:double)
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">sc.textFile(&quot;databricks-datasets/songs/data-001/header.txt&quot;).count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res3: Long = 20
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">sc.textFile(&quot;databricks-datasets/songs/data-001/header.txt&quot;).collect.map(println) // uncomment to see line-by-line
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>artist_id:string
artist_latitude:double
artist_longitude:double
artist_location:string
artist_name:string
duration:double
end_of_fade_in:double
key:int
key_confidence:double
loudness:double
release:string
song_hotnes:double
song_id:string
start_of_fade_out:double
tempo:double
time_signature:double
time_signature_confidence:double
title:string
year:double
partial_sequence:int
res4: Array[Unit] = Array((), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), ())
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>As seen above each line in the header consists of a name and a type separated by colon. We will need to parse the header file as follows:</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val header = sc.textFile(&quot;/databricks-datasets/songs/data-001/header.txt&quot;).map(
      line =&gt; {
                val headerElement = line.split(&quot;:&quot;)
                (headerElement(0), headerElement(1))
            }
           ).collect()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>header: Array[(String, String)] = Array((artist_id,string), (artist_latitude,double), (artist_longitude,double), (artist_location,string), (artist_name,string), (duration,double), (end_of_fade_in,double), (key,int), (key_confidence,double), (loudness,double), (release,string), (song_hotnes,double), (song_id,string), (start_of_fade_out,double), (tempo,double), (time_signature,double), (time_signature_confidence,double), (title,string), (year,double), (partial_sequence,int))
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Let's define a <code>case class</code> called <code>Song</code> that will be used to represent each row of data in the files:</p>
<ul>
<li><code>/databricks-datasets/songs/data-001/part-00000</code> through <code>/databricks-datasets/songs/data-001/part-00119</code> or the last <code>.../part-*****</code> file.</li>
</ul>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">case class Song(artist_id: String, artist_latitude: Double, artist_longitude: Double, artist_location: String, artist_name: String, duration: Double, end_of_fade_in: Double, key: Int, key_confidence: Double, loudness: Double, release: String, song_hotness: Double, song_id: String, start_of_fade_out: Double, tempo: Double, time_signature: Double, time_signature_confidence: Double, title: String, year: Double, partial_sequence: Int)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>defined class Song
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Now we turn to data files. First, step is inspecting the first line of data to inspect its format.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// this is loads all the data - a subset of the 1M songs dataset
val dataRDD = sc.textFile(&quot;/databricks-datasets/songs/data-001/part-*&quot;) 
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>dataRDD: org.apache.spark.rdd.RDD[String] = /databricks-datasets/songs/data-001/part-* MapPartitionsRDD[54] at textFile at command-2971213210276292:2
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">dataRDD.count // number of songs
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res5: Long = 31369
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">dataRDD.take(3)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res6: Array[String] = Array(AR81V6H1187FB48872	nan	nan		Earl Sixteen	213.7073	0.0	11	0.419	-12.106	Soldier of Jah Army	nan	SOVNZSZ12AB018A9B8	208.289	125.882	1	0.0	Rastaman	2003	--, ARVVZQP11E2835DBCB	nan	nan		Wavves	133.25016	0.0	0	0.282	0.596	Wavvves	0.471578247701	SOJTQHQ12A8C143C5F	128.116	89.519	1	0.0	I Want To See You (And Go To The Movies)	2009	--, ARFG9M11187FB3BBCB	nan	nan	Nashua USA	C-Side	247.32689	0.0	9	0.612	-4.896	Santa Festival Compilation 2008 vol.1	nan	SOAJSQL12AB0180501	242.196	171.278	5	1.0	Loose on the Dancefloor	0	225261)
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Each line of data consists of multiple fields separated by <code>\t</code>. With that information and what we learned from the header file, we set out to parse our data.</p>
<ul>
<li>We have already created a case class based on the header (which seems to agree with the 3 lines above).</li>
<li>Next, we will create a function that takes each line as input and returns the case class as output.</li>
</ul>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// let's do this 'by hand' to re-flex our RDD-muscles :)
// although this is not a robust way to read from a data engineering perspective (without fielding exceptions)
def parseLine(line: String): Song = {
  
  val tokens = line.split(&quot;\t&quot;)
  Song(tokens(0), tokens(1).toDouble, tokens(2).toDouble, tokens(3), tokens(4), tokens(5).toDouble, tokens(6).toDouble, tokens(7).toInt, tokens(8).toDouble, tokens(9).toDouble, tokens(10), tokens(11).toDouble, tokens(12), tokens(13).toDouble, tokens(14).toDouble, tokens(15).toDouble, tokens(16).toDouble, tokens(17), tokens(18).toDouble, tokens(19).toInt)
}
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>parseLine: (line: String)Song
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>With this function we can transform the dataRDD to another RDD that consists of Song case classes</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val parsedRDD = dataRDD.map(parseLine)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>parsedRDD: org.apache.spark.rdd.RDD[Song] = MapPartitionsRDD[55] at map at command-2971213210276298:1
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>To convert an RDD of case classes to a DataFrame, we just need to call the toDF method</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val df = parsedRDD.toDF
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>df: org.apache.spark.sql.DataFrame = [artist_id: string, artist_latitude: double ... 18 more fields]
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Once we get a DataFrame we can register it as a temporary table. That will allow us to use its name in SQL queries.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">df.createOrReplaceTempView(&quot;songsTable&quot;)
</code></pre>
</div>
<div class="cell markdown">
<p>We can now cache our table. So far all operations have been lazy. This is the first time Spark will attempt to actually read all our data and apply the transformations.</p>
<p><strong>If you are running Spark 1.6+ the next command will throw a parsing error.</strong></p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-sql">cache table songsTable
</code></pre>
</div>
<div class="cell markdown">
<p>The error means that we are trying to convert a missing value to a Double. Here is an updated version of the parseLine function to deal with missing values</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// good data engineering science practise
def parseLine(line: String): Song = {
  
  
  def toDouble(value: String, defaultVal: Double): Double = {
    try {
       value.toDouble
    } catch {
      case e: Exception =&gt; defaultVal
    }
  }

  def toInt(value: String, defaultVal: Int): Int = {
    try {
       value.toInt
      } catch {
      case e: Exception =&gt; defaultVal
    }
  }
  
  val tokens = line.split(&quot;\t&quot;)
  Song(tokens(0), toDouble(tokens(1), 0.0), toDouble(tokens(2), 0.0), tokens(3), tokens(4), toDouble(tokens(5), 0.0), toDouble(tokens(6), 0.0), toInt(tokens(7), -1), toDouble(tokens(8), 0.0), toDouble(tokens(9), 0.0), tokens(10), toDouble(tokens(11), 0.0), tokens(12), toDouble(tokens(13), 0.0), toDouble(tokens(14), 0.0), toDouble(tokens(15), 0.0), toDouble(tokens(16), 0.0), tokens(17), toDouble(tokens(18), 0.0), toInt(tokens(19), -1))
}
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>parseLine: (line: String)Song
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val df = dataRDD.map(parseLine).toDF
df.createOrReplaceTempView(&quot;songsTable&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>df: org.apache.spark.sql.DataFrame = [artist_id: string, artist_latitude: double ... 18 more fields]
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>And let's try caching the table. We are going to access this data multiple times in following notebooks, therefore it is a good idea to cache it in memory for faster subsequent access.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-sql">cache table songsTable
</code></pre>
</div>
<div class="cell markdown">
<p>From now on we can easily query our data using the temporary table we just created and cached in memory. Since it is registered as a table we can conveniently use SQL as well as Spark API to access it.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-sql">select * from songsTable limit 10
</code></pre>
<div class="output execute_result tabular_result" execution_count="1">
<table>
<thead>
<tr class="header">
<th>artist_id</th>
<th>artist_latitude</th>
<th>artist_longitude</th>
<th>artist_location</th>
<th>artist_name</th>
<th>duration</th>
<th>end_of_fade_in</th>
<th>key</th>
<th>key_confidence</th>
<th>loudness</th>
<th>release</th>
<th>song_hotness</th>
<th>song_id</th>
<th>start_of_fade_out</th>
<th>tempo</th>
<th>time_signature</th>
<th>time_signature_confidence</th>
<th>title</th>
<th>year</th>
<th>partial_sequence</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>AR81V6H1187FB48872</td>
<td>0.0</td>
<td>0.0</td>
<td></td>
<td>Earl Sixteen</td>
<td>213.7073</td>
<td>0.0</td>
<td>11.0</td>
<td>0.419</td>
<td>-12.106</td>
<td>Soldier of Jah Army</td>
<td>0.0</td>
<td>SOVNZSZ12AB018A9B8</td>
<td>208.289</td>
<td>125.882</td>
<td>1.0</td>
<td>0.0</td>
<td>Rastaman</td>
<td>2003.0</td>
<td>-1.0</td>
</tr>
<tr class="even">
<td>ARVVZQP11E2835DBCB</td>
<td>0.0</td>
<td>0.0</td>
<td></td>
<td>Wavves</td>
<td>133.25016</td>
<td>0.0</td>
<td>0.0</td>
<td>0.282</td>
<td>0.596</td>
<td>Wavvves</td>
<td>0.471578247701</td>
<td>SOJTQHQ12A8C143C5F</td>
<td>128.116</td>
<td>89.519</td>
<td>1.0</td>
<td>0.0</td>
<td>I Want To See You (And Go To The Movies)</td>
<td>2009.0</td>
<td>-1.0</td>
</tr>
<tr class="odd">
<td>ARFG9M11187FB3BBCB</td>
<td>0.0</td>
<td>0.0</td>
<td>Nashua USA</td>
<td>C-Side</td>
<td>247.32689</td>
<td>0.0</td>
<td>9.0</td>
<td>0.612</td>
<td>-4.896</td>
<td>Santa Festival Compilation 2008 vol.1</td>
<td>0.0</td>
<td>SOAJSQL12AB0180501</td>
<td>242.196</td>
<td>171.278</td>
<td>5.0</td>
<td>1.0</td>
<td>Loose on the Dancefloor</td>
<td>0.0</td>
<td>225261.0</td>
</tr>
<tr class="even">
<td>ARK4Z2O1187FB45FF0</td>
<td>0.0</td>
<td>0.0</td>
<td></td>
<td>Harvest</td>
<td>337.05751</td>
<td>0.247</td>
<td>4.0</td>
<td>0.46</td>
<td>-9.092</td>
<td>Underground Community</td>
<td>0.0</td>
<td>SOTDRVW12AB018BEB9</td>
<td>327.436</td>
<td>84.986</td>
<td>4.0</td>
<td>0.673</td>
<td>No Return</td>
<td>0.0</td>
<td>101619.0</td>
</tr>
<tr class="odd">
<td>AR4VQSG1187FB57E18</td>
<td>35.25082</td>
<td>-91.74015</td>
<td>Searcy, AR</td>
<td>Gossip</td>
<td>430.23628</td>
<td>0.0</td>
<td>2.0</td>
<td>3.4e-2</td>
<td>-6.846</td>
<td>Yr  Mangled Heart</td>
<td>0.0</td>
<td>SOTVOCL12A8AE478DD</td>
<td>424.06</td>
<td>121.998</td>
<td>4.0</td>
<td>0.847</td>
<td>Yr Mangled Heart</td>
<td>2006.0</td>
<td>740623.0</td>
</tr>
<tr class="even">
<td>ARNBV1X1187B996249</td>
<td>0.0</td>
<td>0.0</td>
<td></td>
<td>Alex</td>
<td>186.80118</td>
<td>0.0</td>
<td>4.0</td>
<td>0.641</td>
<td>-16.108</td>
<td>Jolgaledin</td>
<td>0.0</td>
<td>SODTGRY12AB0182438</td>
<td>166.156</td>
<td>140.735</td>
<td>4.0</td>
<td>5.5e-2</td>
<td>Mariu Sonur Jesus</td>
<td>0.0</td>
<td>673970.0</td>
</tr>
<tr class="odd">
<td>ARXOEZX1187B9B82A1</td>
<td>0.0</td>
<td>0.0</td>
<td></td>
<td>Elie Attieh</td>
<td>361.89995</td>
<td>0.0</td>
<td>7.0</td>
<td>0.863</td>
<td>-4.919</td>
<td>ELITE</td>
<td>0.0</td>
<td>SOIINTJ12AB0180BA6</td>
<td>354.476</td>
<td>128.024</td>
<td>4.0</td>
<td>0.399</td>
<td>Fe Yom We Leila</td>
<td>0.0</td>
<td>280304.0</td>
</tr>
<tr class="even">
<td>ARXPUIA1187B9A32F1</td>
<td>0.0</td>
<td>0.0</td>
<td>Rome, Italy</td>
<td>Simone Cristicchi</td>
<td>220.00281</td>
<td>2.119</td>
<td>4.0</td>
<td>0.486</td>
<td>-6.52</td>
<td>Dall'Altra Parte Del Cancello</td>
<td>0.484225272411</td>
<td>SONHXJK12AAF3B5290</td>
<td>214.761</td>
<td>99.954</td>
<td>1.0</td>
<td>0.928</td>
<td>L'Italiano</td>
<td>2007.0</td>
<td>745962.0</td>
</tr>
<tr class="odd">
<td>ARNPPTH1187B9AD429</td>
<td>51.4855</td>
<td>-0.37196</td>
<td>Heston, Middlesex, England</td>
<td>Jimmy Page</td>
<td>156.86485</td>
<td>0.334</td>
<td>7.0</td>
<td>0.493</td>
<td>-9.962</td>
<td>No Introduction Necessary [Deluxe Edition]</td>
<td>0.0</td>
<td>SOGUHGW12A58A80E06</td>
<td>149.269</td>
<td>162.48</td>
<td>4.0</td>
<td>0.534</td>
<td>Wailing Sounds</td>
<td>2004.0</td>
<td>599250.0</td>
</tr>
<tr class="even">
<td>AROGWRA122988FEE45</td>
<td>0.0</td>
<td>0.0</td>
<td></td>
<td>Christos Dantis</td>
<td>256.67873</td>
<td>2.537</td>
<td>9.0</td>
<td>0.742</td>
<td>-13.404</td>
<td>Daktilika Apotipomata</td>
<td>0.0</td>
<td>SOJJOYI12A8C13399D</td>
<td>248.912</td>
<td>134.944</td>
<td>4.0</td>
<td>0.162</td>
<td>Stin Proigoumeni Zoi</td>
<td>0.0</td>
<td>611396.0</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="cell markdown">
<p>Next up is exploring this data. Click on the Exploration notebook to continue the tutorial.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
</div>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../../contents/000_2-sds-3-x-ml/012_UnsupervisedClustering_1MSongsKMeans_Intro.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next" href="../../contents/000_2-sds-3-x-ml/014_UnsupervisedClustering_1MSongsKMeans_Stage2Explore.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../../contents/000_2-sds-3-x-ml/012_UnsupervisedClustering_1MSongsKMeans_Intro.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next" href="../../contents/000_2-sds-3-x-ml/014_UnsupervisedClustering_1MSongsKMeans_Stage2Explore.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="../../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="../../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->


    </body>
</html>

<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>053_DLbyABr_03-HelloTensorFlow - sds-3.x/ScaDaMaLe</title>


        <!-- Custom HTML head -->

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="../../favicon.svg">
        <link rel="shortcut icon" href="../../favicon.png">
        <link rel="stylesheet" href="../../css/variables.css">
        <link rel="stylesheet" href="../../css/general.css">
        <link rel="stylesheet" href="../../css/chrome.css">
        <link rel="stylesheet" href="../../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../../highlight.css">
        <link rel="stylesheet" href="../../tomorrow-night.css">
        <link rel="stylesheet" href="../../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../../scroll-mdbook-outputs.css">

        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../../contents/000_6-sds-3-x-dl/000_6-sds-3-x-dl.html">000_6-sds-3-x-dl</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_6-sds-3-x-dl/049_DeepLearningIntro.html">049_DeepLearningIntro</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_6-sds-3-x-dl/050_DLbyABr_01-Intro.html">050_DLbyABr_01-Intro</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_6-sds-3-x-dl/051_DLbyABr_02-Neural-Networks.html">051_DLbyABr_02-Neural-Networks</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_6-sds-3-x-dl/052_DLbyABr_02a-Keras-DFFN.html">052_DLbyABr_02a-Keras-DFFN</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_6-sds-3-x-dl/053_DLbyABr_03-HelloTensorFlow.html" class="active">053_DLbyABr_03-HelloTensorFlow</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_6-sds-3-x-dl/054_DLbyABr_03a-BatchTensorFlowWithMatrices.html">054_DLbyABr_03a-BatchTensorFlowWithMatrices</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_6-sds-3-x-dl/055_DLbyABr_04-ConvolutionalNetworks.html">055_DLbyABr_04-ConvolutionalNetworks</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_6-sds-3-x-dl/056_DLbyABr_04a-Hands-On-MNIST-MLP.html">056_DLbyABr_04a-Hands-On-MNIST-MLP</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_6-sds-3-x-dl/057_DLbyABr_04b-Hands-On-MNIST-CNN.html">057_DLbyABr_04b-Hands-On-MNIST-CNN</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_6-sds-3-x-dl/058_DLbyABr_04c-CIFAR-10.html">058_DLbyABr_04c-CIFAR-10</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_6-sds-3-x-dl/059_DLbyABr_05-RecurrentNetworks.html">059_DLbyABr_05-RecurrentNetworks</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_6-sds-3-x-dl/060_DLByABr_05a-LSTM-Solution.html">060_DLByABr_05a-LSTM-Solution</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_6-sds-3-x-dl/061_DLByABr_05b-LSTM-Language.html">061_DLByABr_05b-LSTM-Language</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_6-sds-3-x-dl/062_DLbyABr_06-GenerativeNetworks.html">062_DLbyABr_06-GenerativeNetworks</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_6-sds-3-x-dl/063_DLbyABr_07-ReinforcementLearning.html">063_DLbyABr_07-ReinforcementLearning</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_6-sds-3-x-dl/064_DLbyABr_08-Operations.html">064_DLbyABr_08-Operations</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_6-sds-3-x-dl/064x_MLOps_with_Pytorch_and_MLflow_for_Image_Classification.html">064x_MLOps_with_Pytorch_and_MLflow_for_Image_Classification</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">sds-3.x/ScaDaMaLe</h1>

                    <div class="right-buttons">
                        <a href="../../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <div class="cell markdown">
<p>ScaDaMaLe Course <a href="https://lamastex.github.io/scalable-data-science/sds/3/x/">site</a> and <a href="https://lamastex.github.io/ScaDaMaLe/index.html">book</a></p>
<p>This is a 2019-2021 augmentation and update of <a href="https://www.linkedin.com/in/adbreind">Adam Breindel</a>'s initial notebooks.</p>
<p><em>Thanks to <a href="https://www.linkedin.com/in/christianvonkoch/">Christian von Koch</a> and <a href="https://www.linkedin.com/in/william-anz%C3%A9n-b52003199/">William Anzén</a> for their contributions towards making these materials Spark 3.0.1 and Python 3+ compliant.</em></p>
</div>
<div class="cell markdown">
<h1 id="tensorflow"><a class="header" href="#tensorflow">TensorFlow</a></h1>
<h3 id="-is-a-general-math-framework"><a class="header" href="#-is-a-general-math-framework">... is a general math framework</a></h3>
<p>TensorFlow is designed to accommodate...</p>
<ul>
<li>Easy operations on tensors (n-dimensional arrays)</li>
<li>Mappings to performant low-level implementations, including native CPU and GPU</li>
<li>Optimization via gradient descent variants
<ul>
<li>Including high-performance differentiation</li>
</ul>
</li>
</ul>
<p>Low-level math primitives called &quot;Ops&quot;</p>
<p>From these primitives, linear algebra and other higher-level constructs are formed.</p>
<p>Going up one more level common neural-net components have been built and included.</p>
<p>At an even higher level of abstraction, various libraries have been created that simplify building and wiring common network patterns. Over the last 2 years, we've seen 3-5 such libraries.</p>
<p>We will focus later on one, Keras, which has now been adopted as the &quot;official&quot; high-level wrapper for TensorFlow.</p>
</div>
<div class="cell markdown">
<h3 id="well-get-familiar-with-tensorflow-so-that-it-is-not-a-magic-black-box"><a class="header" href="#well-get-familiar-with-tensorflow-so-that-it-is-not-a-magic-black-box">We'll get familiar with TensorFlow so that it is not a &quot;magic black box&quot;</a></h3>
<p>But for most of our work, it will be more productive to work with the higher-level wrappers. At the end of this notebook, we'll make the connection between the Keras API we've used and the TensorFlow code underneath.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">import tensorflow as tf

x = tf.constant(100, name='x')
y = tf.Variable(x + 50, name='y')

print(y)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>WARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
&lt;tf.Variable 'y:0' shape=() dtype=int32_ref&gt;
</code></pre>
</div>
</div>
<div class="cell markdown">
<h3 id="theres-a-bit-of-ceremony-there"><a class="header" href="#theres-a-bit-of-ceremony-there">There's a bit of &quot;ceremony&quot; there...</a></h3>
<p>... and ... where's the actual output?</p>
<p>For performance reasons, TensorFlow separates the design of the computation from the actual execution.</p>
<p>TensorFlow programs describe a computation graph -- an abstract DAG of data flow -- that can then be analyzed, optimized, and implemented on a variety of hardware, as well as potentially scheduled across a cluster of separate machines.</p>
<p>Like many query engines and compute graph engines, evaluation is <strong>lazy</strong> ... so we don't get &quot;real numbers&quot; until we force TensorFlow to run the calculation:</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">init_node = tf.global_variables_initializer()

with tf.Session() as session:
    session.run(init_node)
    print(session.run(y))
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>150
</code></pre>
</div>
</div>
<div class="cell markdown">
<h3 id="tensorflow-integrates-tightly-with-numpy"><a class="header" href="#tensorflow-integrates-tightly-with-numpy">TensorFlow integrates tightly with NumPy</a></h3>
<p>and we typically use NumPy to create and manage the tensors (vectors, matrices, etc.) that will &quot;flow&quot; through our graph</p>
<p>New to NumPy? Grab a cheat sheet: https://s3.amazonaws.com/assets.datacamp.com/blog<em>assets/Numpy</em>Python<em>Cheat</em>Sheet.pdf</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">import numpy as np
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">data = np.random.normal(loc=10.0, scale=2.0, size=[3,3]) # mean 10, std dev 2

print(data)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>[[11.39104009 10.74646715  9.97434901]
 [10.85377817 10.18047268  8.54517234]
 [ 7.50991424  8.92290223  7.32137675]]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python"># all nodes get added to default graph (unless we specify otherwise)
# we can reset the default graph -- so it's not cluttered up:
tf.reset_default_graph()

x = tf.constant(data, name='x')
y = tf.Variable(x * 10, name='y')

init_node = tf.global_variables_initializer()

with tf.Session() as session:
    session.run(init_node)
    print(session.run(y))
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>[[113.91040088 107.46467153  99.74349013]
 [108.53778169 101.80472682  85.45172335]
 [ 75.09914241  89.22902232  73.21376755]]
</code></pre>
</div>
</div>
<div class="cell markdown">
<h3 id="we-will-often-iterate-on-a-calculation-"><a class="header" href="#we-will-often-iterate-on-a-calculation-">We will often iterate on a calculation ...</a></h3>
<p>Calling <code>session.run</code> runs just one step, so we can iterate using Python as a control:</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">with tf.Session() as session:
    for i in range(3):
        x = x + 1
        print(session.run(x))
        print(&quot;----------------------------------------------&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>[[12.39104009 11.74646715 10.97434901]
 [11.85377817 11.18047268  9.54517234]
 [ 8.50991424  9.92290223  8.32137675]]
----------------------------------------------
[[13.39104009 12.74646715 11.97434901]
 [12.85377817 12.18047268 10.54517234]
 [ 9.50991424 10.92290223  9.32137675]]
----------------------------------------------
[[14.39104009 13.74646715 12.97434901]
 [13.85377817 13.18047268 11.54517234]
 [10.50991424 11.92290223 10.32137675]]
----------------------------------------------
</code></pre>
</div>
</div>
<div class="cell markdown">
<h3 id="optimizers"><a class="header" href="#optimizers">Optimizers</a></h3>
<p>TF includes a set of built-in algorithm implementations (though you could certainly write them yourself) for performing optimization.</p>
<p>These are oriented around gradient-descent methods, with a set of handy extension flavors to make things converge faster.</p>
</div>
<div class="cell markdown">
<h4 id="using-tf-optimizer-to-solve-problems"><a class="header" href="#using-tf-optimizer-to-solve-problems">Using TF optimizer to solve problems</a></h4>
<p>We can use the optimizers to solve anything (not just neural networks) so let's start with a simple equation.</p>
<p>We supply a bunch of data points, that represent inputs. We will generate them based on a known, simple equation (y will always be 2*x + 6) but we won't tell TF that. Instead, we will give TF a function structure ... linear with 2 parameters, and let TF try to figure out the parameters by minimizing an error function.</p>
<p>What is the error function?</p>
<p>The &quot;real&quot; error is the absolute value of the difference between TF's current approximation and our ground-truth y value.</p>
<p>But absolute value is not a friendly function to work with there, so instead we'll square it. That gets us a nice, smooth function that TF can work with, and it's just as good:</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">np.random.rand()
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">x = tf.placeholder(&quot;float&quot;) 
y = tf.placeholder(&quot;float&quot;)

m = tf.Variable([1.0], name=&quot;m-slope-coefficient&quot;) # initial values ... for now they don't matter much
b = tf.Variable([1.0], name=&quot;b-intercept&quot;)

y_model = tf.multiply(x, m) + b

error = tf.square(y - y_model)

train_op = tf.train.GradientDescentOptimizer(0.01).minimize(error)

model = tf.global_variables_initializer()

with tf.Session() as session:
    session.run(model)
    for i in range(10):
        x_value = np.random.rand()
        y_value = x_value * 2 + 6 # we know these params, but we're making TF learn them
        session.run(train_op, feed_dict={x: x_value, y: y_value})

    out = session.run([m, b])
    print(out)
    print(&quot;Model: {r:.3f}x + {s:.3f}&quot;.format(r=out[0][0], s=out[1][0]))
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>[array([1.6890278], dtype=float32), array([1.9976655], dtype=float32)]
Model: 1.689x + 1.998
</code></pre>
</div>
</div>
<div class="cell markdown">
<h4 id="thats-pretty-terrible-"><a class="header" href="#thats-pretty-terrible-">That's pretty terrible :)</a></h4>
<p>Try two experiments. Change the number of iterations the optimizer runs, and -- independently -- try changing the learning rate (that's the number we passed to <code>GradientDescentOptimizer</code>)</p>
<p>See what happens with different values.</p>
</div>
<div class="cell markdown">
<h4 id="these-are-scalars-where-do-the-tensors-come-in"><a class="header" href="#these-are-scalars-where-do-the-tensors-come-in">These are scalars. Where do the tensors come in?</a></h4>
<p>Using matrices allows us to represent (and, with the right hardware, compute) the data-weight dot products for lots of data vectors (a mini batch) and lots of weight vectors (neurons) at the same time.</p>
<p>Tensors are useful because some of our data &quot;vectors&quot; are really multidimensional -- for example, with a color image we may want to preserve height, width, and color planes. We can hold multiple color images, with their shapes, in a 4-D (or 4 &quot;axis&quot;) tensor.</p>
</div>
<div class="cell markdown">
<h3 id="lets-also-make-the-connection-from-keras-down-to-tensorflow"><a class="header" href="#lets-also-make-the-connection-from-keras-down-to-tensorflow">Let's also make the connection from Keras down to Tensorflow.</a></h3>
<p>We used a Keras class called <code>Dense</code>, which represents a &quot;fully-connected&quot; layer of -- in this case -- linear perceptrons. Let's look at the source code to that, just to see that there's no mystery.</p>
<p>https://github.com/fchollet/keras/blob/master/keras/layers/core.py</p>
<p>It calls down to the &quot;back end&quot; by calling <code>output = K.dot(inputs, self.kernel)</code> where <code>kernel</code> means this layer's weights.</p>
<p><code>K</code> represents the pluggable backend wrapper. You can trace K.dot on Tensorflow by looking at</p>
<p>https://github.com/fchollet/keras/blob/master/keras/backend/tensorflow_backend.py</p>
<p>Look for <code>def dot(x, y):</code> and look right toward the end of the method. The math is done by calling <code>tf.matmul(x, y)</code></p>
</div>
<div class="cell markdown">
<h4 id="what-else-helps-tensorflow-and-other-frameworks-run-fast"><a class="header" href="#what-else-helps-tensorflow-and-other-frameworks-run-fast">What else helps Tensorflow (and other frameworks) run fast?</a></h4>
<ul>
<li>A fast, simple mechanism for calculating all of the partial derivatives we need, called <em>reverse-mode autodifferentiation</em></li>
<li>Implementations of low-level operations in optimized CPU code (e.g., C++, MKL) and GPU code (CUDA/CuDNN/HLSL)</li>
<li>Support for distributed parallel training, although parallelizing deep learning is non-trivial ... not automagic like with, e.g., Apache Spark</li>
</ul>
</div>
<div class="cell markdown">
<h3 id="that-is-the-essence-of-tensorflow"><a class="header" href="#that-is-the-essence-of-tensorflow">That is the essence of TensorFlow!</a></h3>
<p>There are three principal directions to explore further:</p>
<ul>
<li>
<p>Working with tensors instead of scalars: this is not intellectually difficult, but takes some practice to wrangle the shaping and re-shaping of tensors. If you get the shape of a tensor wrong, your script will blow up. Just takes practice.</p>
</li>
<li>
<p>Building more complex models. You can write these yourself using lower level &quot;Ops&quot; -- like matrix multiply -- or using higher level classes like <code>tf.layers.dense</code> <em>Use the source, Luke!</em></p>
</li>
<li>
<p>Operations and integration ecosystem: as TensorFlow has matured, it is easier to integrate additional tools and solve the peripheral problems:</p>
<ul>
<li>TensorBoard for visualizing training</li>
<li>tfdbg command-line debugger</li>
<li>Distributed TensorFlow for clustered training</li>
<li>GPU integration</li>
<li>Feeding large datasets from external files</li>
<li>Tensorflow Serving for serving models (i.e., using an existing model to predict on new incoming data)</li>
</ul>
</li>
</ul>
</div>
<div class="cell markdown">
<h1 id="distirbuted-training-for-dl"><a class="header" href="#distirbuted-training-for-dl">Distirbuted Training for DL</a></h1>
<ul>
<li>https://docs.azuredatabricks.net/applications/deep-learning/distributed-training/horovod-runner.html
<ul>
<li>https://docs.azuredatabricks.net/applications/deep-learning/distributed-training/mnist-tensorflow-keras.html</li>
</ul>
</li>
<li>https://software.intel.com/en-us/articles/bigdl-distributed-deep-learning-on-apache-spark</li>
</ul>
</div>
<div class="cell code" execution_count="1" scrolled="false">
</div>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../../contents/000_6-sds-3-x-dl/052_DLbyABr_02a-Keras-DFFN.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next" href="../../contents/000_6-sds-3-x-dl/054_DLbyABr_03a-BatchTensorFlowWithMatrices.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../../contents/000_6-sds-3-x-dl/052_DLbyABr_02a-Keras-DFFN.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next" href="../../contents/000_6-sds-3-x-dl/054_DLbyABr_03a-BatchTensorFlowWithMatrices.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="../../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="../../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->


    </body>
</html>

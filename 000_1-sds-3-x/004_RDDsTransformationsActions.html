
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Introduction to Spark &#8212; Scalable Data Science &amp; Distributed Machine Learning</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="HOMEWORK on RDD Transformations and Actions" href="005_RDDsTransformationsActionsHOMEWORK.html" />
    <link rel="prev" title="Scala Crash Course Continued" href="003_01_scalaCrashCourse.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Scalable Data Science & Distributed Machine Learning</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="000_ScaDaMaLe.html">
   Introduction
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction to Apache Spark Core
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="001_whySpark.html">
   Why Apache Spark?
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="002_00_loginToDatabricks.html">
     Login to databricks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="002_00_loginToDatabricks.html#import-course-content-now">
     Import Course Content Now!
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="002_00_loginToDatabricks.html#cloud-free-computing-environment">
     Cloud-free Computing Environment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="002_01_multiLingualNotebooks.html">
     Multi-lingual Notebooks
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="003_00_scalaCrashCourse.html">
   Scala Crash Course
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="003_01_scalaCrashCourse.html">
     Scala Crash Course Continued
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="current reference internal" href="#">
   Introduction to Spark
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="005_RDDsTransformationsActionsHOMEWORK.html">
     HOMEWORK on RDD Transformations and Actions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="006a_PipedRDD.html">
     Piped RDDs and Bayesian AB Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="006a_PipedRDD.html#from-a-local-collection">
     From a Local Collection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="006a_PipedRDD.html#glom">
     glom
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="006a_PipedRDD.html#checkpointing">
     Checkpointing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="006a_PipedRDD.html#pipe-rdds-to-system-commands">
     Pipe RDDs to System Commands
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="006a_PipedRDD.html#mappartitions">
     mapPartitions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="006a_PipedRDD.html#foreachpartition">
     foreachPartition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="006a_PipedRDD.html#numerically-rigorous-bayesian-ab-testing">
     Numerically Rigorous Bayesian AB Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="006a_PipedRDD.html#usage-instructions-for-isit1or2coins">
     Usage instructions for IsIt1or2Coins
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="006_WordCount.html">
     Word Count on US State of the Union (SoU) Addresses
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction to Apache Spark SQL
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="007_SparkSQLIntroBasics.html">
   Introduction to Spark SQL
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="007_SparkSQLIntroBasics.html#getting-started-in-spark-2-x">
   Getting Started in Spark 2.x
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="007a_SparkSQLProgGuide_HW.html">
     Spark Sql Programming Guide
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007b_SparkSQLProgGuide_HW.html">
     Getting Started
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007b_SparkSQLProgGuide_HW.html#id1">
     Getting Started
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007c_SparkSQLProgGuide_HW.html">
     Getting Started - Exercise
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007d_SparkSQLProgGuide_HW.html">
     Data Sources
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007d_SparkSQLProgGuide_HW.html#id1">
     Data Sources
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007e_SparkSQLProgGuide_HW.html">
     Performance Tuning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007f_SparkSQLProgGuide_HW.html">
     Distributed SQL Engine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007f_SparkSQLProgGuide_HW.html#id1">
     Distributed SQL Engine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007g_PivotInSQL.html">
     ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007g_PivotInSQL.html#sql-pivoting-since-spark-2-4">
     SQL Pivoting since Spark 2.4
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007g_PivotInSQL.html#load-data">
     Load Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007g_PivotInSQL.html#pivoting-in-sql">
     Pivoting in SQL
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007g_PivotInSQL.html#pivoting-with-multiple-aggregate-expressions">
     Pivoting with Multiple Aggregate Expressions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007g_PivotInSQL.html#pivoting-with-multiple-grouping-columns">
     Pivoting with Multiple Grouping Columns
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007g_PivotInSQL.html#pivoting-with-multiple-pivot-columns">
     Pivoting with Multiple Pivot Columns
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Extract Transform and Load
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="008_DiamondsPipeline_01ETLEDA.html">
   Diamonds ML Pipeline Workflow - DataFrame ETL and EDA Part
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="008_DiamondsPipeline_01ETLEDA.html#step-1-load-data-as-dataframe">
   Step 1. Load data as DataFrame
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="008_DiamondsPipeline_01ETLEDA.html#step-2-understand-the-data">
   Step 2. Understand the data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="008_DiamondsPipeline_01ETLEDA.html#let-us-run-through-some-basic-inteactive-sql-queries-next">
   Let us run through some basic inteactive SQL queries next
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="008_DiamondsPipeline_01ETLEDA.html#why-do-we-need-to-know-these-interactive-sql-queries">
   Why do we need to know these interactive SQL queries?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="008_DiamondsPipeline_01ETLEDA.html#we-will-continue-later-with-ml-pipelines-to-do-prediction-with-a-fitted-model-from-this-dataset">
   We will continue later with ML pipelines to do prediction with a fitted model from this dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="009_PowerPlantPipeline_01ETLEDA.html">
   Power Plant ML Pipeline Application - DataFrame Part
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="009_PowerPlantPipeline_01ETLEDA.html#step-1-business-understanding">
   Step 1: Business Understanding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="009_PowerPlantPipeline_01ETLEDA.html#step-2-load-your-data">
   Step 2: Load Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="009_PowerPlantPipeline_01ETLEDA.html#use-this-for-other-smallish-datasets-you-want-to-import-to-your-ce">
   USE THIS FOR OTHER SMALLish DataSets you want to import to your CE
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="009_PowerPlantPipeline_01ETLEDA.html#step-3-explore-your-data">
   Step 3: Explore Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="009_PowerPlantPipeline_01ETLEDA.html#step-4-visualize-your-data">
   Step 4: Visualize Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="010_wikipediaClickStream_01ETLEDA.html">
   Wiki Clickstream Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="010_wikipediaClickStream_01ETLEDA.html#wikipedia-logo">
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_LoadExtract.html">
   Old Bailey Online Data Analysis in Apache Spark
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="033_OBO_LoadExtract.html#analysing-the-full-old-bailey-online-sessions-papers-dataset">
   Analysing the Full Old Bailey Online Sessions Papers Dataset
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html">
     Piped RDDs and Bayesian AB Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#from-a-local-collection">
     From a Local Collection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#glom">
     glom
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#checkpointing">
     Checkpointing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#pipe-rdds-to-system-commands">
     Pipe RDDs to System Commands
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#mappartitions">
     mapPartitions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#foreachpartition">
     foreachPartition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#numerically-rigorous-bayesian-ab-testing">
     Numerically Rigorous Bayesian AB Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#usage-instructions-for-isit1or2coins">
     Usage instructions for IsIt1or2Coins
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#parsing-the-output-from-isit1or2coins">
     Parsing the output from
     <code class="docutils literal notranslate">
      <span class="pre">
       IsIt1or2Coins
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#providing-case-classes-for-input-and-output-for-easy-spark-communication">
     Providing case classes for input and output for easy spark communication
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="035_LDA_CornellMovieDialogs.html">
   Topic Modeling of Movie Dialogs with Latent Dirichlet Allocation
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Trends in Money and News
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_9-sds-3-x-trends/000_TrendsInFinancialStocksAndNewsEvents.html">
   Trends in Financial Stocks and News Events
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_9-sds-3-x-trends/00a_FX1M.html">
     Historical FX-1-M Financial Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_9-sds-3-x-trends/00b_yfinance.html">
     yfinance Stock Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_9-sds-3-x-trends/000a_finance_utils.html">
     Utilities Needed for Financial Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_9-sds-3-x-trends/000b_gdelt_utils.html">
     Utilities Needed for Mass Media Data
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_9-sds-3-x-trends/01_trend_calculus_showcase.html">
   Finding trends in oil price data.
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_9-sds-3-x-trends/02_streamable_trend_calculus.html">
     Streaming Trend Calculus with Maximum Necessary Reversals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_9-sds-3-x-trends/03_streamable_trend_calculus_estimators.html">
     Markov Model for Trend Calculus
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_9-sds-3-x-trends/030_Spark_GDELT_project_001.html">
   Plugging into GDELT Mass Media Streams
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_9-sds-3-x-trends/030a_gdelt_EOI_detection.html">
     Detecting Events of Interest to OIL/GAS Price Trends
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_9-sds-3-x-trends/030b_gdelt_POI_detection.html">
     Detecting Persons of Interest to OIL/GAS Price Trends
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Distributed Deep Learning with Horovod
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_7-sds-3-x-ddl/00_DDL_Introduction.html">
   Introduction to Distributed Deep Learning (DDL) with Horovod over Tensorflow/keras and Pytorch
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_7-sds-3-x-ddl/0x_mnist-tensorflow-keras.html">
     Distributed deep learning training using TensorFlow and Keras with HorovodRunner
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_7-sds-3-x-ddl/0y_mnist-pytorch.html">
     Distributed deep learning training using PyTorch with HorovodRunner for MNIST
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  WASP AI-Track Student Projects
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-01_group-TheTwoCultures/00_download_data.html">
   The two cultures
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-01_group-TheTwoCultures/01_load_data.html">
     Preprocessing and loading the relevant data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-01_group-TheTwoCultures/02_logisticregression.html">
     The two cultures - Classifying threads with logistic regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-01_group-TheTwoCultures/03_word2vec.html">
     Classification using Word2Vec
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-01_group-TheTwoCultures/04_LDA.html">
     Topic Modeling with LDA
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-02_group-LiUUmeaSceneGraphMotifs/01_SceneGraphMotifs.html">
   Exploring the GQA Scene Graph Dataset Structure and Properties
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-03_group-GuangyiZhang/01_triads.html">
   Signed Triads in Social Media
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-04_group-DistributedLinearAlgebra/01_DistributedSVD.html">
   Distributed Linear Algebra
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-04_group-DistributedLinearAlgebra/02_CollaborativeFiltering.html">
     Music Recommendation System
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-05_group-LundDirichletAnalysts/01_Wikipedia_LDA_Analysis.html">
   Wikipedia analysis using Latent Dirichlet Allocation (LDA)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-06_group-ParticleClustering/00_Introduction.html">
   Unsupervised clustering of particle physics data with distributed training
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-06_group-ParticleClustering/00_Introduction.html#introduction">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-06_group-ParticleClustering/00_Introduction.html#background">
   Background
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-06_group-ParticleClustering/00_Introduction.html#the-uclusted-algorithm">
   The UClusted algorithm
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-06_group-ParticleClustering/00_Introduction.html#motivation">
   Motivation
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-06_group-ParticleClustering/00_Introduction.html#our-contribution">
   Our contribution
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-06_group-ParticleClustering/01_data_and_preprocessing.html">
     Important!
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-06_group-ParticleClustering/01_data_and_preprocessing.html#important-continued-from-above">
     Important (continued from above)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-06_group-ParticleClustering/04_evaluate.html">
     Evaluation
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-07_group-MathAtKTH/01_Coding_Motifs.html">
   Motif Finding
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-07_group-MathAtKTH/01_Coding_Motifs.html#application">
   Application
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-07_group-MathAtKTH/02_Data_Processing.html">
     Data Processing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-07_group-MathAtKTH/03_graph_string_converter.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-07_group-MathAtKTH/03_graph_string_converter.html#examples">
     Examples
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-08_group-DistributedEnsemble/00_project.html">
   Distributed ensembles
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-08_group-DistributedEnsemble/00_project.html#distributed-ensembles-prediction-api">
   Distributed ensembles prediction API
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-08_group-DistributedEnsemble/00_project.html#application-example-distributed-predictions">
   Application example: Distributed predictions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-08_group-DistributedEnsemble/00_project.html#application-example-out-of-distribution-detection">
   Application example: Out of distribution detection
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-09_group-TopicModeling/01_Introduction.html">
   Topic Modeling with SARS-Cov-2 Genome ðŸ§¬
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-09_group-TopicModeling/02_Data_Processing.html">
     Extract (overlapping [since yet do not know which parts corresponds to coding regions]) 3-mers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-09_group-TopicModeling/03_LDA.html">
     Load processed data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-09_group-TopicModeling/03_LDA.html#format-data-for-apache-spark-mllib-clustering-lda-adapted-from-the-lda-course-tutorial-034lda20newsgroupssmall">
     Format data for apache.spark.mllib.clustering.LDA (adapted from the LDA course tutorial â€˜034
     <em>
      LDA
     </em>
     20NewsGroupsSmallâ€™)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-09_group-TopicModeling/03_LDA.html#visualise-results">
     Visualise Results
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-09_group-TopicModeling/04_Classification_CountVector.html">
     Load processed data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-09_group-TopicModeling/04_Classification_CountVector.html#format-data">
     Format data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-09_group-TopicModeling/04_Classification_CountVector.html#classification">
     Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-09_group-TopicModeling/04_Classification_CountVector.html#evaluation">
     Evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-09_group-TopicModeling/05_Classification.html">
     Load processed data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-09_group-TopicModeling/05_Classification.html#explore-data">
     Explore data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-09_group-TopicModeling/05_Classification.html#classification">
     Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-09_group-TopicModeling/05_Classification.html#evaluation">
     Evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-09_group-TopicModeling/06_Results.html">
     Results and Conclusion
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-10_group-Geosmus/01_Introduction.html">
   Twitter Streaming Using Geolocation and Emoji Based Sentiment Analysis
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-10_group-Geosmus/02_ClusteringEmoticonsBasedOnTweets.html">
     Clustering emoticons based on tweets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-10_group-Geosmus/03_Dynamic_Tweet_Maps.html">
     Dynamic Tweet Maps
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-10_group-Geosmus/04_conclusion.html">
     Conclusion
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-10_group-Geosmus/05_appendix_get-cc-data.html">
     Notebook for collecting tweets with country codes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-10_group-Geosmus/07_a_appendix_extendedTwitterUtils2run.html">
     ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-10_group-Geosmus/07_a_appendix_extendedTwitterUtils2run.html#extended-spark-streaming-twitter-twitterutils">
     Extended spark.streaming.twitter.TwitterUtils
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-10_group-Geosmus/07_b_appendix_TTTDFfunctions.html">
     ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-11_group-Sketchings/00_QuantileEstimation.html">
   Anomaly Detection with Iterative Quantile Estimation and T-digest
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/00_ProjectDescriptionAndPlanning.html">
   Project Description and Introduction
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/01_DownloadFilesPeriodicallyScript.html">
     Download Files Periodically
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/01_StreamToFile.html">
     Stream to parquet file
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/021_DataPreprocess_Explain.html">
     Loading data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/021_DataPreprocess_Explain.html#preprocessing">
     Preprocessing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/02_DataPreprocess.html">
     Loading data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/02_DataPreprocess.html#preprocessing">
     Preprocessing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html">
     This notebook is for explosive analysis of features in data.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html#statistics-of-invariant-features">
     Statistics of invariant features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html#correlation-between-invariant-features">
     Correlation between invariant features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html#correlation-between-new-case-per-million-total-case-new-death-per-million-total-death-per-million-reproduction-rate-and-stringency-index">
     Correlation between new case per million, total case, new death per million, total death per million, reproduction rate and stringency index.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/04_DataVisualize.html">
     Show reproduction rate of selected countries i.e. Sweden, Germany, Danmark, Finland, Norway
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/04_DataVisualize.html#visualize-total-cases-total-deaths-new-cases-and-new-deaths-during-pandemic">
     Visualize total cases, total deaths, new cases and new deaths during pandemic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/04_DataVisualize.html#total-deaths">
     Total Deaths
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/04_DataVisualize.html#new-cases">
     New Cases
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/04_DataVisualize.html#new-deaths">
     New Deaths
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/05_Clustering.html">
     Clustering of country features in the Covid 19 dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/06_DataPredicton_LR.html">
     Prediction with Linear Regression (LR) Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/07_DataPredicton_ARIMA.html">
     Prediction with Time Series model - ARIMA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/08_DataPrediction_GP.html">
     Prediction with time series model - Gaussian Processes
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-13_group-Genomics/01_1000genomes.html">
   Genomics Analysis with Glow and Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-13_group-Genomics/01_1000genomes.html#load-libs-and-define-helper-functions">
   Load libs and define helper functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-13_group-Genomics/01_1000genomes.html#read-data">
   Read data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-13_group-Genomics/01_1000genomes.html#pca">
   PCA
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-13_group-Genomics/01_1000genomes.html#predicting-ethinicity">
   Predicting Ethinicity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-13_group-Genomics/01_1000genomes.html#filtering-of-snps-based-on-chi-squared-test">
   Filtering of SNPs based on chi-squared test
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-14_group-NullHypothesisEvaluationCriteria/00_distributed_combinatorial_bandit.html">
   Distributional combinatorial bandits
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-15_group-FinancialDataStreams/00_video.html">
   Reinforcement Learning for Intraday Trading
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-15_group-FinancialDataStreams/01_rl_intraday_trading.html">
     Reinforcement Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-15_group-FinancialDataStreams/01_rl_intraday_trading.html#summary-and-outlook">
     Summary and Outlook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html">
     Reinforcement Learning - Distributed model tuning with Elephas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html#elephas">
     Elephas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html#notes-to-the-elephas-training">
     Notes to the elephas training
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-15_group-FinancialDataStreams/03_resources.html">
     Resources
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-16_group-IntrusionDetection/00_Introduction.html">
   Intrusion Detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-16_group-IntrusionDetection/00_Introduction.html#preparing-the-dataframe-for-training-classifers">
   Preparing the DataFrame for training classifers
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-17_group-TowardsScalableTDA/00_introduction.html">
   Density Estimation via Voronoi Diagrams in High Dimensions
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-17_group-TowardsScalableTDA/03_robotics_dataset.html">
     Robotics Dataset
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-18_group-ProjectRL/00_Problem_Description.html">
   Recommender System
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-18_group-ProjectRL/01_The_ALS_method.html">
     <span class="xref myst">
      The Alternating Least Squares method (ALS)
     </span>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-18_group-ProjectRL/01_The_ALS_method.html#on-a-small-dataset">
     <span class="xref myst">
      On a small dataset
     </span>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-18_group-ProjectRL/01_The_ALS_method.html#on-a-large-dataset-netflix-dataset">
     <span class="xref myst">
      On a large dataset - Netflix dataset
     </span>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-18_group-ProjectRL/02_Extensions.html">
     Extensions
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-19_group-Featuring/01_FundamentalMatrix.html">
   Fundamental Matrix
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-20_group-Generalization/01_Background.html">
   MixUp and Generalization
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-20_group-Generalization/02_Random_Forest.html">
     Random Forests and MixUp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-20_group-Generalization/03_CNN_MNIST.html">
     CNN for MNIST
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-20_group-Generalization/04_CNN_Intel_Image.html">
     CNN for Intel Image Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-20_group-Generalization/05_Horovod_test.html">
     CNNs and MixUp with Horovod
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-21_group-GraphSpectralAnalysis/00_introduction.html">
   Graph Spectral Analysis
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-21_group-GraphSpectralAnalysis/01_preprocess_data.html">
     Preprocess the data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-21_group-GraphSpectralAnalysis/02_generate_graphs.html">
     Generate random graphs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-21_group-GraphSpectralAnalysis/03_compute_rsvd.html">
     Compute RSVD
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-21_group-GraphSpectralAnalysis/04_analyse_eigenvalues.html">
     Analyse the eigenvalue spectrum
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-22_group-SwapWithDDP/00_Introduction.html">
   SWAP
   <em>
    With
   </em>
   DDP
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-22_group-SwapWithDDP/01_SWAP_with_DDP.html">
     SWAP
     <em>
      With
     </em>
     DDP
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/000_1-sds-3-x/004_RDDsTransformationsActions.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://lamastex.github.io/ScaDaMaLe/index.html"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://lamastex.github.io/ScaDaMaLe/index.html/issues/new?title=Issue%20on%20page%20%2F000_1-sds-3-x/004_RDDsTransformationsActions.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#spark-essentials-rdds-transformations-and-actions">
   Spark Essentials: RDDs, Transformations and Actions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#spark-cluster-overview">
   Spark Cluster Overview:
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-abstraction-of-resilient-distributed-dataset-rdd">
   The Abstraction of Resilient Distributed Dataset (RDD)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#transformations">
     Transformations
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#actions">
     Actions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#key-points">
     Key Points
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#let-s-get-our-hands-dirty-in-spark">
   Letâ€™s get our hands dirty in Spark!
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#running-spark">
     Running
     <strong>
      Spark
     </strong>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#we-will-do-the-following-next">
     We will do the following next:
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#entry-point">
       Entry Point
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#create-an-rdd-using-sc-parallelize">
       1. Create an RDD using
       <code class="docutils literal notranslate">
        <span class="pre">
         sc.parallelize
        </span>
       </code>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#perform-the-collect-action-on-the-rdd-and-find-the-number-of-partitions-in-it-using-getnumpartitions-action">
       2. Perform the
       <code class="docutils literal notranslate">
        <span class="pre">
         collect
        </span>
       </code>
       action on the RDD and find the number of partitions in it using
       <code class="docutils literal notranslate">
        <span class="pre">
         getNumPartitions
        </span>
       </code>
       action
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#let-us-look-at-the-collect-action-in-detail-and-return-here-to-try-out-the-example-codes">
         Let us look at the collect action in detail and return here to try out the example codes.
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#let-us-look-at-the-getnumpartitions-action-in-detail-and-return-here-to-try-out-the-example-codes">
         Let us look at the getNumPartitions action in detail and return here to try out the example codes.
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#you-try">
         You Try!
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#perform-the-take-action-on-the-rdd">
       3. Perform the
       <code class="docutils literal notranslate">
        <span class="pre">
         take
        </span>
       </code>
       action on the RDD
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id1">
         You Try!
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#transform-the-rdd-by-map-to-make-another-rdd">
       4. Transform the RDD by
       <code class="docutils literal notranslate">
        <span class="pre">
         map
        </span>
       </code>
       to make another RDD
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#let-us-look-at-the-map-transformation-in-detail-and-return-here-to-try-out-the-example-codes">
         Let us look at the map transformation in detail and return here to try out the example codes.
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#transform-the-rdd-by-filter-to-make-another-rdd">
       5. Transform the RDD by
       <code class="docutils literal notranslate">
        <span class="pre">
         filter
        </span>
       </code>
       to make another RDD
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#let-us-look-at-the-filter-transformation-in-detail-and-return-here-to-try-out-the-example-codes">
         Let us look at the filter transformation in detail and return here to try out the example codes.
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#perform-the-reduce-action-on-the-rdd">
       6. Perform the
       <code class="docutils literal notranslate">
        <span class="pre">
         reduce
        </span>
       </code>
       action on the RDD
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#let-us-look-at-the-reduce-action-in-detail-and-return-here-to-try-out-the-example-codes">
         Let us look at the reduce action in detail and return here to try out the example codes.
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#transform-an-rdd-by-flatmap-to-make-another-rdd">
       7. Transform an RDD by
       <code class="docutils literal notranslate">
        <span class="pre">
         flatMap
        </span>
       </code>
       to make another RDD
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#let-us-look-at-the-flatmap-transformation-in-detail-and-return-here-to-try-out-the-example-codes">
         Let us look at the flatMap transformation in detail and return here to try out the example codes.
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#create-a-pair-rdd">
       8. Create a Pair RDD
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#wide-transformations-and-shuffles">
       Wide Transformations and Shuffles
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#perform-some-transformations-on-a-pair-rdd">
       9. Perform some transformations on a Pair RDD
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id2">
         You Try!
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#understanding-closures-where-in-the-cluster-is-your-computation-running">
       10. Understanding Closures - Where in the cluster is your computation running?
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#shipping-closures-broadcast-variables-and-accumulator-variables">
       11. Shipping Closures, Broadcast Variables and Accumulator Variables
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#closures-broadcast-and-accumulator-variables">
         Closures, Broadcast and Accumulator Variables
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#summary">
         SUMMARY
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#accumulators">
         Accumulators
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#broadcast-variables">
         Broadcast Variables
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#a-more-interesting-example-of-broadcast-variable">
         A more interesting example of broadcast variable
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#spark-essentials-summary">
       12. Spark Essentials: Summary
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#homework">
       13. HOMEWORK
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#importing-standard-scala-and-java-libraries">
       14. Importing Standard Scala and Java libraries
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p>ScaDaMaLe Course
<a class="reference external" href="https://lamastex.github.io/scalable-data-science/sds/3/x/">site</a> and
<a class="reference external" href="https://lamastex.github.io/ScaDaMaLe/index.html">book</a></p>
<div class="section" id="introduction-to-spark">
<h1>Introduction to Spark<a class="headerlink" href="#introduction-to-spark" title="Permalink to this headline">Â¶</a></h1>
<div class="section" id="spark-essentials-rdds-transformations-and-actions">
<h2>Spark Essentials: RDDs, Transformations and Actions<a class="headerlink" href="#spark-essentials-rdds-transformations-and-actions" title="Permalink to this headline">Â¶</a></h2>
<ul class="simple">
<li><p>This introductory notebook describes how to get started running
Spark (Scala) code in Notebooks.</p></li>
<li><p>Working with Sparkâ€™s Resilient Distributed Datasets (RDDs)</p>
<ul>
<li><p>creating RDDs</p></li>
<li><p>performing basic transformations on RDDs</p></li>
<li><p>performing basic actions on RDDs</p></li>
</ul>
</li>
</ul>
<p><strong>RECOLLECT</strong> from <code class="docutils literal notranslate"><span class="pre">001_WhySpark</span></code> notebook and AJâ€™s videos that <em>Spark
does fault-tolerant, distributed, in-memory computing</em></p>
<p><strong>THEORY CAVEAT</strong> This module is focused on getting you to quickly write
Spark programs with a high-level appreciation of the underlying
concepts.</p>
<p>In the last module, we will spend more time on analyzing the core
algorithms in parallel and distributed setting of a typical Spark
cluster today â€“ where several multi-core parallel computers (Spark
workers) are networked together to provide a fault-tolerant distributed
computing platform.</p>
</div>
<div class="section" id="spark-cluster-overview">
<h2>Spark Cluster Overview:<a class="headerlink" href="#spark-cluster-overview" title="Permalink to this headline">Â¶</a></h2>
<p><strong>Driver Program, Cluster Manager and Worker Nodes</strong></p>
<p>The <em>driver</em> does the following:</p>
<ol class="simple">
<li><p>connects to a <em>cluster manager</em> to allocate resources across
applications</p></li>
</ol>
<ul class="simple">
<li><p>acquire <em>executors</em> on cluster nodes</p>
<ul>
<li><p>executor processs run compute tasks and cache data in memory or
disk on a <em>worker node</em></p></li>
</ul>
</li>
<li><p>sends <em>application</em> (user program built on Spark) to the executors</p></li>
<li><p>sends <em>tasks</em> for the executors to run</p>
<ul>
<li><p>task is a unit of work that will be sent to one executor</p></li>
</ul>
</li>
</ul>
<p><img alt="" src="http://spark.apache.org/docs/latest/img/cluster-overview.png" /></p>
<p>See <a class="reference external" href="http://spark.apache.org/docs/latest/cluster-overview.html">http://spark.apache.org/docs/latest/cluster-overview.html</a> for an
overview of the spark cluster.</p>
</div>
<div class="section" id="the-abstraction-of-resilient-distributed-dataset-rdd">
<h2>The Abstraction of Resilient Distributed Dataset (RDD)<a class="headerlink" href="#the-abstraction-of-resilient-distributed-dataset-rdd" title="Permalink to this headline">Â¶</a></h2>
<p><strong>RDD is a fault-tolerant collection of elements that can be operated on
in parallel.</strong></p>
<p><strong>Two types of Operations are possible on an RDD:</strong></p>
<ul class="simple">
<li><p>Transformations</p></li>
<li><p>Actions</p></li>
</ul>
<p><strong>(watch now 2:26)</strong>:</p>
<p><a class="reference external" href="https://www.youtube.com/watch?v=3nreQ1N7Jvk?rel=0&amp;autoplay=1&amp;modestbranding=1&amp;start=1&amp;end=146"><img alt="RDD in Spark by Anthony Joseph inBerkeleyX/CS100.1x" src="http://img.youtube.com/vi/3nreQ1N7Jvk/0.jpg" /></a></p>
<hr class="docutils" />
<div class="section" id="transformations">
<h3>Transformations<a class="headerlink" href="#transformations" title="Permalink to this headline">Â¶</a></h3>
<p><strong>(watch now 1:18)</strong>:</p>
<p><a class="reference external" href="https://www.youtube.com/watch?v=360UHWy052k?rel=0&amp;autoplay=1&amp;modestbranding=1"><img alt="Spark Transformations by Anthony Joseph inBerkeleyX/CS100.1x" src="http://img.youtube.com/vi/360UHWy052k/0.jpg" /></a></p>
</div>
<hr class="docutils" />
<div class="section" id="actions">
<h3>Actions<a class="headerlink" href="#actions" title="Permalink to this headline">Â¶</a></h3>
<p><strong>(watch now 0:48)</strong>:</p>
<p><a class="reference external" href="https://www.youtube.com/watch?v=F2G4Wbc5ZWQ?rel=0&amp;autoplay=1&amp;modestbranding=1&amp;start=1&amp;end=48"><img alt="Spark Actions by Anthony Joseph inBerkeleyX/CS100.1x" src="http://img.youtube.com/vi/F2G4Wbc5ZWQ/0.jpg" /></a></p>
</div>
<hr class="docutils" />
<div class="section" id="key-points">
<h3>Key Points<a class="headerlink" href="#key-points" title="Permalink to this headline">Â¶</a></h3>
<ul class="simple">
<li><p>Resilient distributed datasets (RDDs) are the primary abstraction in
Spark.</p></li>
<li><p>RDDs are immutable once created:</p>
<ul>
<li><p>can transform it.</p></li>
<li><p>can perform actions on it.</p></li>
<li><p>but cannot change an RDD once you construct it.</p></li>
</ul>
</li>
<li><p>Spark tracks each RDDâ€™s lineage information or recipe to enable its
efficient recomputation if a machine fails.</p></li>
<li><p>RDDs enable operations on collections of elements in parallel.</p></li>
<li><p>We can construct RDDs by:</p>
<ul>
<li><p>parallelizing Scala collections such as lists or arrays</p></li>
<li><p>by transforming an existing RDD,</p></li>
<li><p>from files in distributed file systems such as (HDFS, S3, etc.).</p></li>
</ul>
</li>
<li><p>We can specify the number of partitions for an RDD</p></li>
<li><p>The more partitions in an RDD, the more opportunities for
parallelism</p></li>
<li><p>There are <strong>two types of operations</strong> you can perform on an RDD:</p>
<ul>
<li><p><strong>transformations</strong> (are lazily evaluated)</p>
<ul>
<li><p>map</p></li>
<li><p>flatMap</p></li>
<li><p>filter</p></li>
<li><p>distinct</p></li>
<li><p>â€¦</p></li>
</ul>
</li>
<li><p><strong>actions</strong> (actual evaluation happens)</p>
<ul>
<li><p>count</p></li>
<li><p>reduce</p></li>
<li><p>take</p></li>
<li><p>collect</p></li>
<li><p>takeOrdered</p></li>
<li><p>â€¦</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Spark transformations enable us to create new RDDs from an existing
RDD.</p></li>
<li><p>RDD transformations are lazy evaluations (results are not computed
right away)</p></li>
<li><p>Spark remembers the set of transformations that are applied to a
base data set (this is the lineage graph of RDD)</p></li>
<li><p>The allows Spark to automatically recover RDDs from failures and
slow workers.</p></li>
<li><p>The lineage graph is a recipe for creating a result and it can be
optimized before execution.</p></li>
<li><p>A transformed RDD is executed only when an action runs on it.</p></li>
<li><p>You can also persist, or cache, RDDs in memory or on disk (this
speeds up iterative ML algorithms that transforms the initial RDD
iteratively).</p></li>
<li><p>Here is a great reference URL for programming guides for Spark that
one should try to cover first</p>
<ul>
<li><p><a class="reference external" href="http://spark.apache.org/docs/latest/programming-guide.html">http://spark.apache.org/docs/latest/programming-guide.html</a>.</p></li>
<li><p>and specifically for RDDs:
<a class="reference external" href="https://spark.apache.org/docs/latest/rdd-programming-guide.html">https://spark.apache.org/docs/latest/rdd-programming-guide.html</a></p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="let-s-get-our-hands-dirty-in-spark">
<h2>Letâ€™s get our hands dirty in Spark!<a class="headerlink" href="#let-s-get-our-hands-dirty-in-spark" title="Permalink to this headline">Â¶</a></h2>
<p><strong>DO NOW!</strong></p>
<p>In your databricks community edition:</p>
<ol class="simple">
<li><p>In your <code class="docutils literal notranslate"><span class="pre">WorkSpace</span></code> create a Folder named <code class="docutils literal notranslate"><span class="pre">scalable-data-science</span></code></p></li>
<li><p><em>Import</em> the databricks archive file at the following URL:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/lamastex/scalable-data-science/raw/master/dbcArchives/2017/parts/xtraResources.dbc">https://github.com/lamastex/scalable-data-science/raw/master/dbcArchives/2017/parts/xtraResources.dbc</a></p></li>
</ul>
</li>
<li><p>This should open a structure of directories in with path:
<code class="docutils literal notranslate"><span class="pre">/Workspace/scalable-data-science/xtraResources/</span></code></p></li>
</ol>
<p><strong>Let us look at the legend and overview of the visual RDD Api by doing
the following first:</strong></p>
<p><img alt="" src="https://raw.githubusercontent.com/lamastex/scalable-data-science/master/db/visualapi/med/visualapi-1.png" /></p>
<div class="section" id="running-spark">
<h3>Running <strong>Spark</strong><a class="headerlink" href="#running-spark" title="Permalink to this headline">Â¶</a></h3>
<p>The variable <strong>sc</strong> allows you to access a Spark Context to run your
Spark programs. Recall <code class="docutils literal notranslate"><span class="pre">SparkContext</span></code> is in the Driver Program.</p>
<p><img alt="" src="http://spark.apache.org/docs/latest/img/cluster-overview.png" /></p>
<p>**NOTE: Do not create the <em>sc</em> variable - it is already initialized for
you in spark-shell REPL, that includes notebook environments like
databricks, Jupyter, zeppelin, etc. **</p>
</div>
<div class="section" id="we-will-do-the-following-next">
<h3>We will do the following next:<a class="headerlink" href="#we-will-do-the-following-next" title="Permalink to this headline">Â¶</a></h3>
<ol class="simple">
<li><p>Create an RDD using <code class="docutils literal notranslate"><span class="pre">sc.parallelize</span></code></p></li>
</ol>
<ul class="simple">
<li><p>Perform the <code class="docutils literal notranslate"><span class="pre">collect</span></code> action on the RDD and find the number of
partitions it is made of using <code class="docutils literal notranslate"><span class="pre">getNumPartitions</span></code> action</p></li>
<li><p>Perform the <code class="docutils literal notranslate"><span class="pre">take</span></code> action on the RDD</p></li>
<li><p>Transform the RDD by <code class="docutils literal notranslate"><span class="pre">map</span></code> to make another RDD</p></li>
<li><p>Transform the RDD by <code class="docutils literal notranslate"><span class="pre">filter</span></code> to make another RDD</p></li>
<li><p>Perform the <code class="docutils literal notranslate"><span class="pre">reduce</span></code> action on the RDD</p></li>
<li><p>Transform the RDD by <code class="docutils literal notranslate"><span class="pre">flatMap</span></code> to make another RDD</p></li>
<li><p>Create a Pair RDD</p></li>
<li><p>Perform some transformations on a Pair RDD</p></li>
<li><p>Where in the cluster is your computation running?</p></li>
<li><p>Shipping Closures, Broadcast Variables and Accumulator Variables</p></li>
<li><p>Spark Essentials: Summary</p></li>
<li><p>HOMEWORK</p></li>
<li><p>Importing Standard Scala and Java libraries</p></li>
</ul>
<div class="section" id="entry-point">
<h4>Entry Point<a class="headerlink" href="#entry-point" title="Permalink to this headline">Â¶</a></h4>
<p>Now we are ready to start programming in Spark!</p>
<p>Our entry point for Spark 2.x applications is the class <code class="docutils literal notranslate"><span class="pre">SparkSession</span></code>.
An instance of this object is already instantiated for us which can be
easily demonstrated by running the next cell</p>
<p>We will need these docs!</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spark.apache.org/docs/3.0.1/api/scala/org/apache/spark/rdd/RDD.html">RDD Scala
Docs</a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/3.0.1/api/scala/org/apache/spark/sql/Dataset.html">Dataset Scala
Docs</a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/3.0.1/api/scala/index.html">https://spark.apache.org/docs/3.0.1/api/scala/index.html</a> you can
simply search for other Spark classes, methods, etc here</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">println</span><span class="p">(</span><span class="n">spark</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>org.apache.spark.sql.SparkSession@69141846
</pre></div>
</div>
</div>
</div>
<p>NOTE that since Spark 2.0 <code class="docutils literal notranslate"><span class="pre">SparkSession</span></code> is a replacement for the other
entry points: * <code class="docutils literal notranslate"><span class="pre">SparkContext</span></code>, available in our notebook as <strong>sc</strong>. *
<code class="docutils literal notranslate"><span class="pre">SQLContext</span></code>, or more specifically its subclass <code class="docutils literal notranslate"><span class="pre">HiveContext</span></code>, available
in our notebook as <strong>sqlContext</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">println</span><span class="p">(</span><span class="n">sc</span><span class="p">)</span>
<span class="n">println</span><span class="p">(</span><span class="n">sqlContext</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>org.apache.spark.SparkContext@517c9049
org.apache.spark.sql.hive.HiveContext@6c5b5052
</pre></div>
</div>
</div>
</div>
<p>We will be using the pre-made SparkContext <code class="docutils literal notranslate"><span class="pre">sc</span></code> when learning about
RDDs.</p>
</div>
<div class="section" id="create-an-rdd-using-sc-parallelize">
<h4>1. Create an RDD using <code class="docutils literal notranslate"><span class="pre">sc.parallelize</span></code><a class="headerlink" href="#create-an-rdd-using-sc-parallelize" title="Permalink to this headline">Â¶</a></h4>
<p>First, let us create an RDD of three elements (of integer type <code class="docutils literal notranslate"><span class="pre">Int</span></code>)
from a Scala <code class="docutils literal notranslate"><span class="pre">Seq</span></code> (or <code class="docutils literal notranslate"><span class="pre">List</span></code> or <code class="docutils literal notranslate"><span class="pre">Array</span></code>) with two partitions by using
the <code class="docutils literal notranslate"><span class="pre">parallelize</span></code> method of the available Spark Context <code class="docutils literal notranslate"><span class="pre">sc</span></code> as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">x</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>    <span class="o">//</span> <span class="o">&lt;</span><span class="n">Ctrl</span><span class="o">+</span><span class="n">Enter</span><span class="o">&gt;</span> <span class="n">to</span> <span class="n">evaluate</span> <span class="n">this</span> <span class="n">cell</span> <span class="p">(</span><span class="n">using</span> <span class="mi">2</span> <span class="n">partitions</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[33] at parallelize at command-685894176422457:1
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span><span class="n">x</span><span class="o">.</span>  <span class="o">//</span> <span class="n">place</span> <span class="n">the</span> <span class="n">cursor</span> <span class="n">after</span> <span class="s1">&#39;x.&#39;</span> <span class="ow">and</span> <span class="n">hit</span> <span class="n">Tab</span> <span class="n">to</span> <span class="n">see</span> <span class="n">the</span> <span class="n">methods</span> <span class="n">available</span> <span class="k">for</span> <span class="n">the</span> <span class="n">RDD</span> <span class="n">x</span> <span class="n">we</span> <span class="n">created</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="perform-the-collect-action-on-the-rdd-and-find-the-number-of-partitions-in-it-using-getnumpartitions-action">
<h4>2. Perform the <code class="docutils literal notranslate"><span class="pre">collect</span></code> action on the RDD and find the number of partitions in it using <code class="docutils literal notranslate"><span class="pre">getNumPartitions</span></code> action<a class="headerlink" href="#perform-the-collect-action-on-the-rdd-and-find-the-number-of-partitions-in-it-using-getnumpartitions-action" title="Permalink to this headline">Â¶</a></h4>
<p>No action has been taken by <code class="docutils literal notranslate"><span class="pre">sc.parallelize</span></code> above. To see what is
â€œcookedâ€ by the recipe for RDD <code class="docutils literal notranslate"><span class="pre">x</span></code> we need to take an action.</p>
<p>The simplest is the <code class="docutils literal notranslate"><span class="pre">collect</span></code> action which returns all of the elements
of the RDD as an <code class="docutils literal notranslate"><span class="pre">Array</span></code> to the driver program and displays it.</p>
<p><em>So you have to make sure that all of that data will fit in the driver
program if you call <code class="docutils literal notranslate"><span class="pre">collect</span></code> action!</em></p>
<div class="section" id="let-us-look-at-the-collect-action-in-detail-and-return-here-to-try-out-the-example-codes">
<h5>Let us look at the <a class="reference external" href="/#workspace/scalable-data-science/xtraResources/visualRDDApi/recall/actions/collect">collect action in detail</a> and return here to try out the example codes.<a class="headerlink" href="#let-us-look-at-the-collect-action-in-detail-and-return-here-to-try-out-the-example-codes" title="Permalink to this headline">Â¶</a></h5>
<p><img alt="" src="https://raw.githubusercontent.com/lamastex/scalable-data-science/master/db/visualapi/med/visualapi-90.png" /></p>
<p>Let us perform a <code class="docutils literal notranslate"><span class="pre">collect</span></code> action on RDD <code class="docutils literal notranslate"><span class="pre">x</span></code> as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>    <span class="o">//</span> <span class="o">&lt;</span><span class="n">Ctrl</span><span class="o">+</span><span class="n">Enter</span><span class="o">&gt;</span> <span class="n">to</span> <span class="n">collect</span> <span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="n">elements</span> <span class="n">of</span> <span class="n">rdd</span><span class="p">;</span> <span class="n">should</span> <span class="n">be</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>res44: Array[Int] = Array(1, 2, 3)
</pre></div>
</div>
</div>
</div>
<p><em>CAUTION:</em> <code class="docutils literal notranslate"><span class="pre">collect</span></code> can crash the driver when called upon an RDD with
massively many elements.<br />
So, it is better to use other diplaying actions like <code class="docutils literal notranslate"><span class="pre">take</span></code> or
<code class="docutils literal notranslate"><span class="pre">takeOrdered</span></code> as follows:</p>
</div>
<div class="section" id="let-us-look-at-the-getnumpartitions-action-in-detail-and-return-here-to-try-out-the-example-codes">
<h5>Let us look at the <a class="reference external" href="/#workspace/scalable-data-science/xtraResources/visualRDDApi/recall/actions/getNumPartitions">getNumPartitions action in detail</a> and return here to try out the example codes.<a class="headerlink" href="#let-us-look-at-the-getnumpartitions-action-in-detail-and-return-here-to-try-out-the-example-codes" title="Permalink to this headline">Â¶</a></h5>
<p><img alt="" src="https://raw.githubusercontent.com/lamastex/scalable-data-science/master/db/visualapi/med/visualapi-88.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="o">&lt;</span><span class="n">Ctrl</span><span class="o">+</span><span class="n">Enter</span><span class="o">&gt;</span> <span class="n">to</span> <span class="n">evaluate</span> <span class="n">this</span> <span class="n">cell</span> <span class="ow">and</span> <span class="n">find</span> <span class="n">the</span> <span class="n">number</span> <span class="n">of</span> <span class="n">partitions</span> <span class="ow">in</span> <span class="n">RDD</span> <span class="n">x</span>
<span class="n">x</span><span class="o">.</span><span class="n">getNumPartitions</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>res45: Int = 2
</pre></div>
</div>
</div>
</div>
<p>We can see which elements of the RDD are in which parition by calling
<code class="docutils literal notranslate"><span class="pre">glom()</span></code> before <code class="docutils literal notranslate"><span class="pre">collect()</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">glom()</span></code> flattens elements of the same partition into an <code class="docutils literal notranslate"><span class="pre">Array</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">glom</span><span class="p">()</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span> <span class="o">//</span> <span class="n">glom</span><span class="p">()</span> <span class="n">flattens</span> <span class="n">elements</span> <span class="n">on</span> <span class="n">the</span> <span class="n">same</span> <span class="n">partition</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>res46: Array[Array[Int]] = Array(Array(1), Array(2, 3))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">a</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">glom</span><span class="p">()</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>a: Array[Array[Int]] = Array(Array(1), Array(2, 3))
</pre></div>
</div>
</div>
</div>
<p>Thus from the output above,
<code class="docutils literal notranslate"><span class="pre">Array[Array[Int]]</span> <span class="pre">=</span> <span class="pre">Array(Array(1),</span> <span class="pre">Array(2,</span> <span class="pre">3))</span></code>, we know that <code class="docutils literal notranslate"><span class="pre">1</span></code> is
in one partition while <code class="docutils literal notranslate"><span class="pre">2</span></code> and <code class="docutils literal notranslate"><span class="pre">3</span></code> are in another partition.</p>
</div>
<div class="section" id="you-try">
<h5>You Try!<a class="headerlink" href="#you-try" title="Permalink to this headline">Â¶</a></h5>
<p>Crate an RDD <code class="docutils literal notranslate"><span class="pre">x</span></code> with three elements, 1,2,3, and this time do not
specifiy the number of partitions. Then the default number of partitions
will be used. Find out what this is for the cluster you are attached to.</p>
<p>The default number of partitions for an RDD depends on the cluster this
notebook is attached to among others - see
<a class="reference external" href="http://spark.apache.org/docs/latest/programming-guide.html">programming-guide</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">x</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">Seq</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>    <span class="o">//</span> <span class="o">&lt;</span><span class="n">Shift</span><span class="o">+</span><span class="n">Enter</span><span class="o">&gt;</span> <span class="n">to</span> <span class="n">evaluate</span> <span class="n">this</span> <span class="n">cell</span> <span class="p">(</span><span class="n">using</span> <span class="n">default</span> <span class="n">number</span> <span class="n">of</span> <span class="n">partitions</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[36] at parallelize at command-685894176422471:1
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">getNumPartitions</span> <span class="o">//</span> <span class="o">&lt;</span><span class="n">Shift</span><span class="o">+</span><span class="n">Enter</span><span class="o">&gt;</span> <span class="n">to</span> <span class="n">evaluate</span> <span class="n">this</span> <span class="n">cell</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>res47: Int = 8
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">glom</span><span class="p">()</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span> <span class="o">//</span> <span class="o">&lt;</span><span class="n">Ctrl</span><span class="o">+</span><span class="n">Enter</span><span class="o">&gt;</span> <span class="n">to</span> <span class="n">evaluate</span> <span class="n">this</span> <span class="n">cell</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>res48: Array[Array[Int]] = Array(Array(), Array(), Array(1), Array(), Array(), Array(2), Array(), Array(3))
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="perform-the-take-action-on-the-rdd">
<h4>3. Perform the <code class="docutils literal notranslate"><span class="pre">take</span></code> action on the RDD<a class="headerlink" href="#perform-the-take-action-on-the-rdd" title="Permalink to this headline">Â¶</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">.take(n)</span></code> action returns an array with the first <code class="docutils literal notranslate"><span class="pre">n</span></code> elements of
the RDD.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">//</span> <span class="n">Ctrl</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">take</span> <span class="n">two</span> <span class="n">elements</span> <span class="kn">from</span> <span class="nn">the</span> <span class="n">RDD</span> <span class="n">x</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>res49: Array[Int] = Array(1, 2)
</pre></div>
</div>
</div>
</div>
<div class="section" id="id1">
<h5>You Try!<a class="headerlink" href="#id1" title="Permalink to this headline">Â¶</a></h5>
<p>Fill in the parenthes <code class="docutils literal notranslate"><span class="pre">(</span> <span class="pre">)</span></code> below in order to <code class="docutils literal notranslate"><span class="pre">take</span></code> just one element
from RDD <code class="docutils literal notranslate"><span class="pre">x</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span><span class="n">x</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">uncomment</span> <span class="n">by</span> <span class="n">removing</span> <span class="s1">&#39;//&#39;</span> <span class="n">before</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">cell</span> <span class="ow">and</span> <span class="n">fill</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">parenthesis</span> <span class="n">to</span> <span class="n">take</span> <span class="n">just</span> <span class="n">one</span> <span class="n">element</span> <span class="kn">from</span> <span class="nn">RDD</span> <span class="n">x</span> <span class="ow">and</span> <span class="n">Cntrl</span><span class="o">+</span><span class="n">Enter</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="transform-the-rdd-by-map-to-make-another-rdd">
<h4>4. Transform the RDD by <code class="docutils literal notranslate"><span class="pre">map</span></code> to make another RDD<a class="headerlink" href="#transform-the-rdd-by-map-to-make-another-rdd" title="Permalink to this headline">Â¶</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">map</span></code> transformation returns a new RDD thatâ€™s formed by passing each
element of the source RDD through a function (closure). The closure is
automatically passed on to the workers for evaluation (when an action is
called later).</p>
<div class="section" id="let-us-look-at-the-map-transformation-in-detail-and-return-here-to-try-out-the-example-codes">
<h5>Let us look at the <a class="reference external" href="/#workspace/scalable-data-science/xtraResources/visualRDDApi/recall/transformations/map">map transformation in detail</a> and return here to try out the example codes.<a class="headerlink" href="#let-us-look-at-the-map-transformation-in-detail-and-return-here-to-try-out-the-example-codes" title="Permalink to this headline">Â¶</a></h5>
<p><img alt="" src="https://raw.githubusercontent.com/lamastex/scalable-data-science/master/db/visualapi/med/visualapi-18.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Shift</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">make</span> <span class="n">RDD</span> <span class="n">x</span> <span class="ow">and</span> <span class="n">RDD</span> <span class="n">y</span> <span class="n">that</span> <span class="ow">is</span> <span class="n">mapped</span> <span class="kn">from</span> <span class="nn">x</span>
<span class="n">val</span> <span class="n">x</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">))</span> <span class="o">//</span> <span class="n">make</span> <span class="n">RDD</span> <span class="n">x</span><span class="p">:</span> <span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span>
<span class="n">val</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">z</span> <span class="o">=&gt;</span> <span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>                    <span class="o">//</span> <span class="nb">map</span> <span class="n">x</span> <span class="n">into</span> <span class="n">RDD</span> <span class="n">y</span><span class="p">:</span> <span class="p">[(</span><span class="n">b</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>x: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[38] at parallelize at command-685894176422480:2
y: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[39] at map at command-685894176422480:3
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Cntrl</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">collect</span> <span class="ow">and</span> <span class="nb">print</span> <span class="n">the</span> <span class="n">two</span> <span class="n">RDDs</span>
<span class="n">println</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span><span class="o">.</span><span class="n">mkString</span><span class="p">(</span><span class="s2">&quot;, &quot;</span><span class="p">))</span>
<span class="n">println</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span><span class="o">.</span><span class="n">mkString</span><span class="p">(</span><span class="s2">&quot;, &quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>b, a, c
(b,1), (a,1), (c,1)
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="transform-the-rdd-by-filter-to-make-another-rdd">
<h4>5. Transform the RDD by <code class="docutils literal notranslate"><span class="pre">filter</span></code> to make another RDD<a class="headerlink" href="#transform-the-rdd-by-filter-to-make-another-rdd" title="Permalink to this headline">Â¶</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">filter</span></code> transformation returns a new RDD thatâ€™s formed by selecting
those elements of the source RDD on which the function returns <code class="docutils literal notranslate"><span class="pre">true</span></code>.</p>
<div class="section" id="let-us-look-at-the-filter-transformation-in-detail-and-return-here-to-try-out-the-example-codes">
<h5>Let us look at the <a class="reference external" href="/#workspace/scalable-data-science/xtraResources/visualRDDApi/recall/transformations/filter">filter transformation in detail</a> and return here to try out the example codes.<a class="headerlink" href="#let-us-look-at-the-filter-transformation-in-detail-and-return-here-to-try-out-the-example-codes" title="Permalink to this headline">Â¶</a></h5>
<p><img alt="" src="https://raw.githubusercontent.com/lamastex/scalable-data-science/master/db/visualapi/med/visualapi-24.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span><span class="n">Shift</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">make</span> <span class="n">RDD</span> <span class="n">x</span> <span class="ow">and</span> <span class="nb">filter</span> <span class="n">it</span> <span class="n">by</span> <span class="p">(</span><span class="n">n</span> <span class="o">=&gt;</span> <span class="n">n</span><span class="o">%</span><span class="mi">2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="n">to</span> <span class="n">make</span> <span class="n">RDD</span> <span class="n">y</span>
<span class="n">val</span> <span class="n">x</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="o">//</span> <span class="n">the</span> <span class="n">closure</span> <span class="p">(</span><span class="n">n</span> <span class="o">=&gt;</span> <span class="n">n</span><span class="o">%</span><span class="mi">2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">in</span> <span class="n">the</span> <span class="nb">filter</span> <span class="n">will</span> 
<span class="o">//</span> <span class="k">return</span> <span class="kc">True</span> <span class="k">if</span> <span class="n">element</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">RDD</span> <span class="n">x</span> <span class="n">has</span> <span class="n">remainder</span> <span class="mi">1</span> <span class="n">when</span> <span class="n">divided</span> <span class="n">by</span> <span class="mi">2</span> <span class="p">(</span><span class="n">i</span><span class="o">.</span><span class="n">e</span><span class="o">.</span><span class="p">,</span> <span class="k">if</span> <span class="n">n</span> <span class="ow">is</span> <span class="n">odd</span><span class="p">)</span>
<span class="n">val</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">n</span> <span class="o">=&gt;</span> <span class="n">n</span><span class="o">%</span><span class="mi">2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[40] at parallelize at command-685894176422484:2
y: org.apache.spark.rdd.RDD[Int] = MapPartitionsRDD[41] at filter at command-685894176422484:5
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Cntrl</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">collect</span> <span class="ow">and</span> <span class="nb">print</span> <span class="n">the</span> <span class="n">two</span> <span class="n">RDDs</span>
<span class="n">println</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span><span class="o">.</span><span class="n">mkString</span><span class="p">(</span><span class="s2">&quot;, &quot;</span><span class="p">))</span>
<span class="n">println</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span><span class="o">.</span><span class="n">mkString</span><span class="p">(</span><span class="s2">&quot;, &quot;</span><span class="p">))</span>
<span class="o">//</span><span class="n">y</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1, 2, 3
1, 3
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="perform-the-reduce-action-on-the-rdd">
<h4>6. Perform the <code class="docutils literal notranslate"><span class="pre">reduce</span></code> action on the RDD<a class="headerlink" href="#perform-the-reduce-action-on-the-rdd" title="Permalink to this headline">Â¶</a></h4>
<p>Reduce aggregates a data set element using a function (closure). This
function takes two arguments and returns one and can often be seen as a
binary operator. This operator has to be commutative and associative so
that it can be computed correctly in parallel (where we have little
control over the order of the operations!).</p>
<div class="section" id="let-us-look-at-the-reduce-action-in-detail-and-return-here-to-try-out-the-example-codes">
<h5>Let us look at the <a class="reference external" href="/#workspace/scalable-data-science/xtraResources/visualRDDApi/recall/actions/reduce">reduce action in detail</a> and return here to try out the example codes.<a class="headerlink" href="#let-us-look-at-the-reduce-action-in-detail-and-return-here-to-try-out-the-example-codes" title="Permalink to this headline">Â¶</a></h5>
<p><img alt="" src="https://raw.githubusercontent.com/lamastex/scalable-data-science/master/db/visualapi/med/visualapi-94.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span><span class="n">Shift</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">make</span> <span class="n">RDD</span> <span class="n">x</span> <span class="n">of</span> <span class="n">inteegrs</span> <span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span> <span class="ow">and</span> <span class="n">reduce</span> <span class="n">it</span> <span class="n">to</span> <span class="nb">sum</span>
<span class="n">val</span> <span class="n">x</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">val</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reduce</span><span class="p">((</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">a</span><span class="o">+</span><span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[42] at parallelize at command-685894176422488:2
y: Int = 10
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span><span class="n">Cntrl</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">collect</span> <span class="ow">and</span> <span class="nb">print</span> <span class="n">RDD</span> <span class="n">x</span> <span class="ow">and</span> <span class="n">the</span> <span class="n">Int</span> <span class="n">y</span><span class="p">,</span> <span class="nb">sum</span> <span class="n">of</span> <span class="n">x</span>
<span class="n">println</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">collect</span><span class="o">.</span><span class="n">mkString</span><span class="p">(</span><span class="s2">&quot;, &quot;</span><span class="p">))</span>
<span class="n">println</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1, 2, 3, 4
10
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="transform-an-rdd-by-flatmap-to-make-another-rdd">
<h4>7. Transform an RDD by <code class="docutils literal notranslate"><span class="pre">flatMap</span></code> to make another RDD<a class="headerlink" href="#transform-an-rdd-by-flatmap-to-make-another-rdd" title="Permalink to this headline">Â¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">flatMap</span></code> is similar to <code class="docutils literal notranslate"><span class="pre">map</span></code> but each element from input RDD can be
mapped to zero or more output elements. Therefore your function should
return a sequential collection such as an <code class="docutils literal notranslate"><span class="pre">Array</span></code> rather than a single
element as shown below.</p>
<div class="section" id="let-us-look-at-the-flatmap-transformation-in-detail-and-return-here-to-try-out-the-example-codes">
<h5>Let us look at the <a class="reference external" href="/#workspace/scalable-data-science/xtraResources/visualRDDApi/recall/transformations/flatMap">flatMap transformation in detail</a> and return here to try out the example codes.<a class="headerlink" href="#let-us-look-at-the-flatmap-transformation-in-detail-and-return-here-to-try-out-the-example-codes" title="Permalink to this headline">Â¶</a></h5>
<p><img alt="" src="https://raw.githubusercontent.com/lamastex/scalable-data-science/master/db/visualapi/med/visualapi-31.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span><span class="n">Shift</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">make</span> <span class="n">RDD</span> <span class="n">x</span> <span class="ow">and</span> <span class="n">flatMap</span> <span class="n">it</span> <span class="n">into</span> <span class="n">RDD</span> <span class="n">by</span> <span class="n">closure</span> <span class="p">(</span><span class="n">n</span> <span class="o">=&gt;</span> <span class="n">Array</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">42</span><span class="p">))</span>
<span class="n">val</span> <span class="n">x</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">val</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">flatMap</span><span class="p">(</span><span class="n">n</span> <span class="o">=&gt;</span> <span class="n">Array</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">42</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[43] at parallelize at command-685894176422492:2
y: org.apache.spark.rdd.RDD[Int] = MapPartitionsRDD[44] at flatMap at command-685894176422492:3
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span><span class="n">Cntrl</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">collect</span> <span class="ow">and</span> <span class="nb">print</span> <span class="n">RDDs</span> <span class="n">x</span> <span class="ow">and</span> <span class="n">y</span>
<span class="n">println</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span><span class="o">.</span><span class="n">mkString</span><span class="p">(</span><span class="s2">&quot;, &quot;</span><span class="p">))</span>
<span class="n">println</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span><span class="o">.</span><span class="n">mkString</span><span class="p">(</span><span class="s2">&quot;, &quot;</span><span class="p">))</span>
<span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">n</span> <span class="o">=&gt;</span> <span class="n">Array</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="mi">42</span><span class="p">))</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1, 2, 3
1, 100, 42, 2, 200, 42, 3, 300, 42
res54: Array[Array[Int]] = Array(Array(1, 100, 42), Array(2, 200, 42), Array(3, 300, 42))
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="create-a-pair-rdd">
<h4>8. Create a Pair RDD<a class="headerlink" href="#create-a-pair-rdd" title="Permalink to this headline">Â¶</a></h4>
<p>Letâ€™s next work with RDD of <code class="docutils literal notranslate"><span class="pre">(key,value)</span></code> pairs called a <em>Pair RDD</em> or
<em>Key-Value RDD</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Cntrl</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">make</span> <span class="n">RDD</span> <span class="n">words</span> <span class="ow">and</span> <span class="n">display</span> <span class="n">it</span> <span class="n">by</span> <span class="n">collect</span>
<span class="n">val</span> <span class="n">words</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">))</span>
<span class="n">words</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>words: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[47] at parallelize at command-685894176422495:2
res55: Array[String] = Array(a, b, a, a, b, b, a, a, a, b, b)
</pre></div>
</div>
</div>
</div>
<p>Letâ€™s make a Pair RDD called <code class="docutils literal notranslate"><span class="pre">wordCountPairRDD</span></code> that is made of
(key,value) pairs with key=word and value=1 in order to encode each
occurrence of each word in the RDD <code class="docutils literal notranslate"><span class="pre">words</span></code>, as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Cntrl</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">make</span> <span class="ow">and</span> <span class="n">collect</span> <span class="n">Pair</span> <span class="n">RDD</span> <span class="n">wordCountPairRDD</span>
<span class="n">val</span> <span class="n">wordCountPairRDD</span> <span class="o">=</span> <span class="n">words</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">s</span> <span class="o">=&gt;</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">wordCountPairRDD</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>wordCountPairRDD: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[48] at map at command-685894176422497:2
res56: Array[(String, Int)] = Array((a,1), (b,1), (a,1), (a,1), (b,1), (b,1), (a,1), (a,1), (a,1), (b,1), (b,1))
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="wide-transformations-and-shuffles">
<h4>Wide Transformations and Shuffles<a class="headerlink" href="#wide-transformations-and-shuffles" title="Permalink to this headline">Â¶</a></h4>
<p>So far we have seen transformations that are <strong>narrow</strong> â€“ with no data
transfer between partitions. Think of <code class="docutils literal notranslate"><span class="pre">map</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">ReduceByKey</span></code> and <code class="docutils literal notranslate"><span class="pre">GroupByKey</span></code> are <strong>wide</strong> transformations as data has
to be shuffled across the partitions in different executors â€“ this is
generally very expensive operation.</p>
<p><img alt="" src="https://raw.githubusercontent.com/raazesh-sainudiin/scalable-data-science/master/db/visualapi/med/visualapi-40.png" /></p>
<p>READ the <strong>Background</strong> about Shuffles in the programming guide below.</p>
<blockquote>
<div><p>In Spark, data is generally not distributed across partitions to be in
the necessary place for a specific operation. During computations, a
single task will operate on a single partition - thus, to organize all
the data for a single reduceByKey reduce task to execute, Spark needs
to perform an all-to-all operation. It must read from all partitions
to find all the values for all keys, and then bring together values
across partitions to compute the final result for each key - this is
called the shuffle</p>
</div></blockquote>
<p>READ the <strong>Performance Impact</strong> about Shuffles in the programming guide
below.</p>
<blockquote>
<div><p>The Shuffle is an expensive operation since it involves disk I/O, data
serialization, and network I/O. To organize data for the shuffle,
Spark generates sets of tasks - map tasks to organize the data, and a
set of reduce tasks to aggregate it. This nomenclature comes from
MapReduce and does not directly relate to Sparkâ€™s map and reduce
operations.</p>
</div></blockquote>
<blockquote>
<div><p>Internally, results from individual map tasks are kept in memory until
they canâ€™t fit. Then, these are sorted based on the target partition
and written to a single file. On the reduce side, tasks read the
relevant sorted blocks.</p>
</div></blockquote>
<p><a class="reference external" href="https://spark.apache.org/docs/latest/rdd-programming-guide.html#shuffle-operations">https://spark.apache.org/docs/latest/rdd-programming-guide.html#shuffle-operations</a></p>
</div>
<div class="section" id="perform-some-transformations-on-a-pair-rdd">
<h4>9. Perform some transformations on a Pair RDD<a class="headerlink" href="#perform-some-transformations-on-a-pair-rdd" title="Permalink to this headline">Â¶</a></h4>
<p>Letâ€™s next work with RDD of <code class="docutils literal notranslate"><span class="pre">(key,value)</span></code> pairs called a <em>Pair RDD</em> or
<em>Key-Value RDD</em>.</p>
<p>Now some of the Key-Value transformations that we could perform include
the following.</p>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">reduceByKey</span></code> transformation</strong></p>
<ul>
<li><p>which takes an RDD and returns a new RDD of key-value pairs,
such that:</p>
<ul>
<li><p>the values for each key are aggregated using the given
reduced function</p></li>
<li><p>and the reduce function has to be of the type that takes two
values and returns one value.</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">sortByKey</span></code> transformation</strong></p>
<ul>
<li><p>this returns a new RDD of key-value pairs thatâ€™s sorted by keys
in ascending order</p></li>
</ul>
</li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">groupByKey</span></code> transformation</strong></p>
<ul>
<li><p>this returns a new RDD consisting of key and iterable-valued
pairs.</p></li>
</ul>
</li>
</ul>
<p>Letâ€™s see some concrete examples next.</p>
<p><img alt="" src="https://raw.githubusercontent.com/lamastex/scalable-data-science/master/db/visualapi/med/visualapi-44.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Cntrl</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">reduceByKey</span> <span class="ow">and</span> <span class="n">collect</span> <span class="n">wordcounts</span> <span class="n">RDD</span>
<span class="o">//</span><span class="n">val</span> <span class="n">wordcounts</span> <span class="o">=</span> <span class="n">wordCountPairRDD</span><span class="o">.</span><span class="n">reduceByKey</span><span class="p">(</span> <span class="n">_</span> <span class="o">+</span> <span class="n">_</span> <span class="p">)</span>
<span class="n">val</span> <span class="n">wordcounts</span> <span class="o">=</span> <span class="n">wordCountPairRDD</span><span class="o">.</span><span class="n">reduceByKey</span><span class="p">(</span> <span class="p">(</span><span class="n">value1</span><span class="p">,</span> <span class="n">value2</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">value1</span> <span class="o">+</span> <span class="n">value2</span> <span class="p">)</span>
<span class="n">wordcounts</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>wordcounts: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[49] at reduceByKey at command-685894176422504:3
res58: Array[(String, Int)] = Array((a,6), (b,5))
</pre></div>
</div>
</div>
</div>
<p>Now, let us do just the crucial steps and avoid collecting intermediate
RDDs (something we should avoid for large datasets anyways, as they may
not fit in the driver program).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span><span class="n">Cntrl</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">make</span> <span class="n">words</span> <span class="n">RDD</span> <span class="ow">and</span> <span class="n">do</span> <span class="n">the</span> <span class="n">word</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">two</span> <span class="n">lines</span>
<span class="n">val</span> <span class="n">words</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">))</span>
<span class="n">val</span> <span class="n">wordcounts</span> <span class="o">=</span> <span class="n">words</span>
                    <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">s</span> <span class="o">=&gt;</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
                    <span class="o">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="n">_</span> <span class="o">+</span> <span class="n">_</span><span class="p">)</span>
                    <span class="o">.</span><span class="n">collect</span><span class="p">()</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>words: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[50] at parallelize at command-685894176422506:2
wordcounts: Array[(String, Int)] = Array((a,6), (b,5))
</pre></div>
</div>
</div>
</div>
<div class="section" id="id2">
<h5>You Try!<a class="headerlink" href="#id2" title="Permalink to this headline">Â¶</a></h5>
<p>You try evaluating <code class="docutils literal notranslate"><span class="pre">sortByKey()</span></code> which will make a new RDD that consists
of the elements of the original pair RDD that are sorted by Keys.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Shift</span><span class="o">+</span><span class="n">Enter</span> <span class="ow">and</span> <span class="n">comprehend</span> <span class="n">code</span>
<span class="n">val</span> <span class="n">words</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">))</span>
<span class="n">val</span> <span class="n">wordCountPairRDD</span> <span class="o">=</span> <span class="n">words</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">s</span> <span class="o">=&gt;</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">val</span> <span class="n">wordCountPairRDDSortedByKey</span> <span class="o">=</span> <span class="n">wordCountPairRDD</span><span class="o">.</span><span class="n">sortByKey</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>words: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[53] at parallelize at command-685894176422508:2
wordCountPairRDD: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[54] at map at command-685894176422508:3
wordCountPairRDDSortedByKey: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[57] at sortByKey at command-685894176422508:4
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">wordCountPairRDD</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span> <span class="o">//</span> <span class="n">Shift</span><span class="o">+</span><span class="n">Enter</span> <span class="ow">and</span> <span class="n">comprehend</span> <span class="n">code</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>res59: Array[(String, Int)] = Array((a,1), (b,1), (a,1), (a,1), (b,1), (b,1), (a,1), (a,1), (a,1), (b,1), (b,1))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">wordCountPairRDDSortedByKey</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span> <span class="o">//</span> <span class="n">Cntrl</span><span class="o">+</span><span class="n">Enter</span> <span class="ow">and</span> <span class="n">comprehend</span> <span class="n">code</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>res60: Array[(String, Int)] = Array((a,1), (a,1), (a,1), (a,1), (a,1), (a,1), (b,1), (b,1), (b,1), (b,1), (b,1))
</pre></div>
</div>
</div>
</div>
<p>The next key value transformation we will see is <code class="docutils literal notranslate"><span class="pre">groupByKey</span></code></p>
<p>When we apply the <code class="docutils literal notranslate"><span class="pre">groupByKey</span></code> transformation to <code class="docutils literal notranslate"><span class="pre">wordCountPairRDD</span></code> we
end up with a new RDD that contains two elements. The first element is
the tuple <code class="docutils literal notranslate"><span class="pre">b</span></code> and an iterable <code class="docutils literal notranslate"><span class="pre">CompactBuffer(1,1,1,1,1)</span></code> obtained by
grouping the value <code class="docutils literal notranslate"><span class="pre">1</span></code> for each of the five key value pairs <code class="docutils literal notranslate"><span class="pre">(b,1)</span></code>.
Similarly the second element is the key <code class="docutils literal notranslate"><span class="pre">a</span></code> and an iterable
<code class="docutils literal notranslate"><span class="pre">CompactBuffer(1,1,1,1,1,1)</span></code> obtained by grouping the value <code class="docutils literal notranslate"><span class="pre">1</span></code> for each
of the six key value pairs <code class="docutils literal notranslate"><span class="pre">(a,1)</span></code>.</p>
<p><em>CAUTION</em>: <code class="docutils literal notranslate"><span class="pre">groupByKey</span></code> can cause a large amount of data movement across
the network. It also can create very large iterables at a worker.
Imagine you have an RDD where you have 1 billion pairs that have the key
<code class="docutils literal notranslate"><span class="pre">a</span></code>. All of the values will have to fit in a single worker if you use
group by key. So instead of a group by key, consider using reduced by
key.</p>
<p><img alt="" src="https://raw.githubusercontent.com/lamastex/scalable-data-science/master/db/visualapi/med/visualapi-45.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>val wordCountPairRDDGroupByKey = wordCountPairRDD.groupByKey() // &lt;Shift+Enter&gt; CAUTION: this transformation can be very wide!
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>wordCountPairRDDGroupByKey: org.apache.spark.rdd.RDD[(String, Iterable[Int])] = ShuffledRDD[58] at groupByKey at command-685894176422513:1
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">wordCountPairRDDGroupByKey</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>  <span class="o">//</span> <span class="n">Cntrl</span><span class="o">+</span><span class="n">Enter</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>res61: Array[(String, Iterable[Int])] = Array((a,CompactBuffer(1, 1, 1, 1, 1, 1)), (b,CompactBuffer(1, 1, 1, 1, 1)))
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="understanding-closures-where-in-the-cluster-is-your-computation-running">
<h4>10. Understanding Closures - Where in the cluster is your computation running?<a class="headerlink" href="#understanding-closures-where-in-the-cluster-is-your-computation-running" title="Permalink to this headline">Â¶</a></h4>
<blockquote>
<div><p>One of the harder things about Spark is understanding the scope and
life cycle of variables and methods when executing code across a
cluster. RDD operations that modify variables outside of their scope
can be a frequent source of confusion. In the example below weâ€™ll look
at code that uses <code class="docutils literal notranslate"><span class="pre">foreach()</span></code> to increment a counter, but similar
issues can occur for other operations as well.</p>
</div></blockquote>
<p><a class="reference external" href="https://spark.apache.org/docs/latest/rdd-programming-guide.html#understanding-closures-">https://spark.apache.org/docs/latest/rdd-programming-guide.html#understanding-closures-</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Array</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">var</span> <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">var</span> <span class="n">rdd</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="o">//</span> <span class="n">Wrong</span><span class="p">:</span> <span class="n">Don</span><span class="s1">&#39;t do this!!</span>
<span class="n">rdd</span><span class="o">.</span><span class="n">foreach</span><span class="p">(</span><span class="n">x</span> <span class="o">=&gt;</span> <span class="n">counter</span> <span class="o">+=</span> <span class="n">x</span><span class="p">)</span>

<span class="n">println</span><span class="p">(</span><span class="s2">&quot;Counter value: &quot;</span> <span class="o">+</span> <span class="n">counter</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Counter value: 0
data: Array[Int] = Array(1, 2, 3, 4, 5)
counter: Int = 0
rdd: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[59] at parallelize at command-685894176422517:3
</pre></div>
</div>
</div>
</div>
<p>From RDD programming guide:</p>
<blockquote>
<div><p>The behavior of the above code is undefined, and may not work as
intended. To execute jobs, Spark breaks up the processing of RDD
operations into tasks, each of which is executed by an executor. Prior
to execution, Spark computes the taskâ€™s closure. The closure is those
variables and methods which must be visible for the executor to
perform its computations on the RDD (in this case foreach()). This
closure is serialized and sent to each executor.</p>
</div></blockquote>
<blockquote>
<div><p>The variables within the closure sent to each executor are now copies
and thus, when counter is referenced within the foreach function, itâ€™s
no longer the counter on the driver node. There is still a counter in
the memory of the driver node but this is no longer visible to the
executors! The executors only see the copy from the serialized
closure. Thus, the final value of counter will still be zero since all
operations on counter were referencing the value within the serialized
closure.</p>
</div></blockquote>
</div>
<div class="section" id="shipping-closures-broadcast-variables-and-accumulator-variables">
<h4>11. Shipping Closures, Broadcast Variables and Accumulator Variables<a class="headerlink" href="#shipping-closures-broadcast-variables-and-accumulator-variables" title="Permalink to this headline">Â¶</a></h4>
<div class="section" id="closures-broadcast-and-accumulator-variables">
<h5>Closures, Broadcast and Accumulator Variables<a class="headerlink" href="#closures-broadcast-and-accumulator-variables" title="Permalink to this headline">Â¶</a></h5>
<p><strong>(watch now 2:06)</strong>:</p>
<p><a class="reference external" href="https://www.youtube.com/watch?v=I9Zcr4R35Ao?rel=0&amp;autoplay=1&amp;modestbranding=1"><img alt="Closures, Broadcast and Accumulators by Anthony Joseph inBerkeleyX/CS100.1x" src="http://img.youtube.com/vi/I9Zcr4R35Ao/0.jpg" /></a></p>
<p>We will use these variables in the sequel.</p>
</div>
<div class="section" id="summary">
<h5>SUMMARY<a class="headerlink" href="#summary" title="Permalink to this headline">Â¶</a></h5>
<p>Spark automatically creates closures</p>
<ul class="simple">
<li><p>for functions that run on RDDs at workers,</p></li>
<li><p>and for any global variables that are used by those workers</p></li>
<li><p>one closure per worker is sent with every task</p></li>
<li><p>and thereâ€™s no communication between workers</p></li>
<li><p>closures are one way from the driver to the worker</p></li>
<li><p>any changes that you make to the global variables at the workers</p>
<ul>
<li><p>are not sent to the driver or</p></li>
<li><p>are not sent to other workers.</p></li>
</ul>
</li>
</ul>
<p>The problem we have is that these closures</p>
<ul class="simple">
<li><p>are automatically created are sent or re-sent with every job</p></li>
<li><p>with a large global variable it gets inefficient to send/resend lots
of data to each worker</p></li>
<li><p>we cannot communicate that back to the driver</p></li>
</ul>
<p>To do this, Spark provides shared variables in two different types.</p>
<ul class="simple">
<li><p><strong>broadcast variables</strong></p>
<ul>
<li><p>lets us to efficiently send large read-only values to all of the
workers</p></li>
<li><p>these are saved at the workers for use in one or more Spark
operations.</p></li>
</ul>
</li>
<li><p><strong>accumulator variables</strong></p>
<ul>
<li><p>These allow us to aggregate values from workers back to the
driver.</p></li>
<li><p>only the driver can access the value of the accumulator</p></li>
<li><p>for the tasks, the accumulators are basically write-only</p></li>
</ul>
</li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="accumulators">
<h5>Accumulators<a class="headerlink" href="#accumulators" title="Permalink to this headline">Â¶</a></h5>
<blockquote>
<div><p>Accumulators are variables that are only â€œaddedâ€ to through an
associative and commutative operation and can therefore be efficiently
supported in parallel. They can be used to implement counters (as in
MapReduce) or sums. Spark natively supports accumulators of numeric
types, and programmers can add support for new types.</p>
</div></blockquote>
<p>Read:
<a class="reference external" href="https://spark.apache.org/docs/latest/rdd-programming-guide.html#accumulators">https://spark.apache.org/docs/latest/rdd-programming-guide.html#accumulators</a>.</p>
<blockquote>
<div><p>A numeric accumulator can be created by calling
SparkContext.longAccumulator() or SparkContext.doubleAccumulator() to
accumulate values of type Long or Double, respectively. Tasks running
on a cluster can then add to it using the add method. However, they
cannot read its value. Only the driver program can read the
accumulatorâ€™s value, using its value method.</p>
</div></blockquote>
<blockquote>
<div><p>The code below shows an accumulator being used to add up the elements
of an array:</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">accum</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">longAccumulator</span><span class="p">(</span><span class="s2">&quot;My Accumulator&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>accum: org.apache.spark.util.LongAccumulator = LongAccumulator(id: 1891, name: Some(My Accumulator), value: 0)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span><span class="o">.</span><span class="n">foreach</span><span class="p">(</span><span class="n">x</span> <span class="o">=&gt;</span> <span class="n">accum</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">accum</span><span class="o">.</span><span class="n">value</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>res66: Long = 10
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="broadcast-variables">
<h5>Broadcast Variables<a class="headerlink" href="#broadcast-variables" title="Permalink to this headline">Â¶</a></h5>
<p>From
<a class="reference external" href="https://spark.apache.org/docs/latest/rdd-programming-guide.html#broadcast-variables">https://spark.apache.org/docs/latest/rdd-programming-guide.html#broadcast-variables</a>:</p>
<blockquote>
<div><p>Broadcast variables allow the programmer to keep a read-only variable
cached on each machine rather than shipping a copy of it with tasks.
They can be used, for example, to give every node a copy of a large
input dataset in an efficient manner. Spark also attempts to
distribute broadcast variables using efficient broadcast algorithms to
reduce communication cost.</p>
</div></blockquote>
<blockquote>
<div><p>Spark actions are executed through a set of stages, separated by
distributed â€œshuffleâ€ operations. Spark automatically broadcasts the
common data needed by tasks within each stage. The data broadcasted
this way is cached in serialized form and deserialized before running
each task. This means that explicitly creating broadcast variables is
only useful when tasks across multiple stages need the same data or
when caching the data in deserialized form is important.</p>
</div></blockquote>
<blockquote>
<div><p>Broadcast variables are created from a variable v by calling
SparkContext.broadcast(v). The broadcast variable is a wrapper around
v, and its value can be accessed by calling the value method. The code
below shows this in action.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">broadcastVar</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>broadcastVar: org.apache.spark.broadcast.Broadcast[Array[Int]] = Broadcast(67)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">broadcastVar</span><span class="o">.</span><span class="n">value</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>res68: Array[Int] = Array(1, 2, 3)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">broadcastVar</span><span class="o">.</span><span class="n">value</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>res69: Int = 1
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">rdd</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="mi">1</span> <span class="n">to</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>rdd: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[61] at parallelize at command-685894176422531:1
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">rdd</span><span class="o">.</span><span class="n">collect</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>res70: Array[Int] = Array(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">rdd</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">x</span> <span class="o">=&gt;</span> <span class="n">x</span><span class="o">%</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>res71: Array[Int] = Array(1, 2, 0, 1, 2, 0, 1, 2, 0, 1)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">rdd</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">x</span> <span class="o">=&gt;</span> <span class="n">x</span><span class="o">+</span><span class="n">broadcastVar</span><span class="o">.</span><span class="n">value</span><span class="p">(</span><span class="n">x</span><span class="o">%</span><span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">collect</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>res72: Array[Int] = Array(3, 5, 4, 6, 8, 7, 9, 11, 10, 12)
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p>After the broadcast variable is created, it should be used instead of
the value v in any functions run on the cluster so that v is not
shipped to the nodes more than once. In addition, the object v should
not be modified after it is broadcast in order to ensure that all
nodes get the same value of the broadcast variable (e.g. if the
variable is shipped to a new node later).</p>
</div></blockquote>
<blockquote>
<div><p>To release the resources that the broadcast variable copied onto
executors, call .unpersist(). If the broadcast is used again
afterwards, it will be re-broadcast. To permanently release all
resources used by the broadcast variable, call .destroy(). The
broadcast variable canâ€™t be used after that. Note that these methods
do not block by default. To block until resources are freed, specify
blocking=true when calling them.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">broadcastVar</span><span class="o">.</span><span class="n">unpersist</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="a-more-interesting-example-of-broadcast-variable">
<h5>A more interesting example of broadcast variable<a class="headerlink" href="#a-more-interesting-example-of-broadcast-variable" title="Permalink to this headline">Â¶</a></h5>
<p>Let us broadcast maps and use them to lookup the values at each
executor. This example is taken from: -
<a class="reference external" href="https://sparkbyexamples.com/spark/spark-broadcast-variables/">https://sparkbyexamples.com/spark/spark-broadcast-variables/</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">states</span> <span class="o">=</span> <span class="n">Map</span><span class="p">((</span><span class="s2">&quot;NY&quot;</span><span class="p">,</span><span class="s2">&quot;New York&quot;</span><span class="p">),(</span><span class="s2">&quot;CA&quot;</span><span class="p">,</span><span class="s2">&quot;California&quot;</span><span class="p">),(</span><span class="s2">&quot;FL&quot;</span><span class="p">,</span><span class="s2">&quot;Florida&quot;</span><span class="p">))</span>
<span class="n">val</span> <span class="n">countries</span> <span class="o">=</span> <span class="n">Map</span><span class="p">((</span><span class="s2">&quot;USA&quot;</span><span class="p">,</span><span class="s2">&quot;United States of America&quot;</span><span class="p">),(</span><span class="s2">&quot;IN&quot;</span><span class="p">,</span><span class="s2">&quot;India&quot;</span><span class="p">))</span>

<span class="n">val</span> <span class="n">broadcastStates</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span><span class="n">states</span><span class="p">)</span>
<span class="n">val</span> <span class="n">broadcastCountries</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span><span class="n">countries</span><span class="p">)</span>

<span class="n">val</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Seq</span><span class="p">((</span><span class="s2">&quot;James&quot;</span><span class="p">,</span><span class="s2">&quot;Smith&quot;</span><span class="p">,</span><span class="s2">&quot;USA&quot;</span><span class="p">,</span><span class="s2">&quot;CA&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Michael&quot;</span><span class="p">,</span><span class="s2">&quot;Rose&quot;</span><span class="p">,</span><span class="s2">&quot;USA&quot;</span><span class="p">,</span><span class="s2">&quot;NY&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Robert&quot;</span><span class="p">,</span><span class="s2">&quot;Williams&quot;</span><span class="p">,</span><span class="s2">&quot;USA&quot;</span><span class="p">,</span><span class="s2">&quot;CA&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Maria&quot;</span><span class="p">,</span><span class="s2">&quot;Jones&quot;</span><span class="p">,</span><span class="s2">&quot;USA&quot;</span><span class="p">,</span><span class="s2">&quot;FL&quot;</span><span class="p">))</span>

<span class="n">val</span> <span class="n">rdd</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">//</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span> <span class="ow">is</span> <span class="n">the</span> <span class="n">same</span> <span class="k">as</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span> <span class="ow">in</span> <span class="n">spark</span><span class="o">-</span><span class="n">shell</span><span class="o">/</span><span class="n">notebook</span>

  <span class="n">val</span> <span class="n">rdd2</span> <span class="o">=</span> <span class="n">rdd</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">f</span><span class="o">=&gt;</span><span class="p">{</span>
    <span class="n">val</span> <span class="n">country</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">_3</span>
    <span class="n">val</span> <span class="n">state</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">_4</span>
    <span class="n">val</span> <span class="n">fullCountry</span> <span class="o">=</span> <span class="n">broadcastCountries</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">country</span><span class="p">)</span><span class="o">.</span><span class="n">get</span>
    <span class="n">val</span> <span class="n">fullState</span> <span class="o">=</span> <span class="n">broadcastStates</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="o">.</span><span class="n">get</span>
    <span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">_1</span><span class="p">,</span><span class="n">f</span><span class="o">.</span><span class="n">_2</span><span class="p">,</span><span class="n">fullCountry</span><span class="p">,</span><span class="n">fullState</span><span class="p">)</span>
  <span class="p">})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>states: scala.collection.immutable.Map[String,String] = Map(NY -&gt; New York, CA -&gt; California, FL -&gt; Florida)
countries: scala.collection.immutable.Map[String,String] = Map(USA -&gt; United States of America, IN -&gt; India)
broadcastStates: org.apache.spark.broadcast.Broadcast[scala.collection.immutable.Map[String,String]] = Broadcast(71)
broadcastCountries: org.apache.spark.broadcast.Broadcast[scala.collection.immutable.Map[String,String]] = Broadcast(72)
data: Seq[(String, String, String, String)] = List((James,Smith,USA,CA), (Michael,Rose,USA,NY), (Robert,Williams,USA,CA), (Maria,Jones,USA,FL))
rdd: org.apache.spark.rdd.RDD[(String, String, String, String)] = ParallelCollectionRDD[64] at parallelize at command-685894176422538:12
rdd2: org.apache.spark.rdd.RDD[(String, String, String, String)] = MapPartitionsRDD[65] at map at command-685894176422538:14
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">println</span><span class="p">(</span><span class="n">rdd2</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span><span class="o">.</span><span class="n">mkString</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(James,Smith,United States of America,California)
(Michael,Rose,United States of America,New York)
(Robert,Williams,United States of America,California)
(Maria,Jones,United States of America,Florida)
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="spark-essentials-summary">
<h4>12. Spark Essentials: Summary<a class="headerlink" href="#spark-essentials-summary" title="Permalink to this headline">Â¶</a></h4>
<p><strong>(watch now: 0:29)</strong></p>
<p><a class="reference external" href="https://www.youtube.com/watch?v=F50Vty9Ia8Y?rel=0&amp;autoplay=1&amp;modestbranding=1"><img alt="Spark Essentials Summary by Anthony Joseph inBerkeleyX/CS100.1x" src="http://img.youtube.com/vi/F50Vty9Ia8Y/0.jpg" /></a></p>
<p><em>NOTE:</em> In databricks cluster, we (the course
coordinator/administrators) set the number of workers for you.</p>
</div>
<div class="section" id="homework">
<h4>13. HOMEWORK<a class="headerlink" href="#homework" title="Permalink to this headline">Â¶</a></h4>
<p>See the notebook in this folder named
<code class="docutils literal notranslate"><span class="pre">005_RDDsTransformationsActionsHOMEWORK</span></code>. This notebook will give you
more examples of the operations above as well as others we will be using
later, including:</p>
<ul class="simple">
<li><p>Perform the <code class="docutils literal notranslate"><span class="pre">takeOrdered</span></code> action on the RDD</p></li>
<li><p>Transform the RDD by <code class="docutils literal notranslate"><span class="pre">distinct</span></code> to make another RDD and</p></li>
<li><p>Doing a bunch of transformations to our RDD and performing an action
in a single cell.</p></li>
</ul>
<hr class="docutils" />
</div>
<hr class="docutils" />
<div class="section" id="importing-standard-scala-and-java-libraries">
<h4>14. Importing Standard Scala and Java libraries<a class="headerlink" href="#importing-standard-scala-and-java-libraries" title="Permalink to this headline">Â¶</a></h4>
<ul class="simple">
<li><p>For other libraries that are not available by default, you can
upload other libraries to the Workspace.</p></li>
<li><p>Refer to the
<strong><a class="reference external" href="https://docs.databricks.com/user-guide/libraries.html">Libraries</a></strong>
guide for more details.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scala.math._</span>
<span class="n">val</span> <span class="n">x</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>import scala.math._
x: Int = 1
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.HashMap</span>
<span class="n">val</span> <span class="nb">map</span> <span class="o">=</span> <span class="n">new</span> <span class="n">HashMap</span><span class="p">[</span><span class="n">String</span><span class="p">,</span> <span class="n">Int</span><span class="p">]()</span>
<span class="nb">map</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">map</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">map</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">map</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="nb">map</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="s2">&quot;e&quot;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>import java.util.HashMap
map: java.util.HashMap[String,Int] = {a=1, b=2, c=3, d=4, e=5}
res75: Int = 0
</pre></div>
</div>
</div>
</div>
<div class="toctree-wrapper compound">
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./000_1-sds-3-x"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="003_01_scalaCrashCourse.html" title="previous page">Scala Crash Course Continued</a>
    <a class='right-next' id="next-link" href="005_RDDsTransformationsActionsHOMEWORK.html" title="next page">HOMEWORK on RDD Transformations and Actions</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By ScaDaMaLe Team<br/>
        
            &copy; Copyright 2020 Creative Commons Zero v1.0 Universal.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>
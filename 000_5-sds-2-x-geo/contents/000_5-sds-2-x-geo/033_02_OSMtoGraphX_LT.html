<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>033_02_OSMtoGraphX_LT - sds-3.x/ScaDaMaLe</title>


        <!-- Custom HTML head -->

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="../../favicon.svg">
        <link rel="shortcut icon" href="../../favicon.png">
        <link rel="stylesheet" href="../../css/variables.css">
        <link rel="stylesheet" href="../../css/general.css">
        <link rel="stylesheet" href="../../css/chrome.css">
        <link rel="stylesheet" href="../../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../../highlight.css">
        <link rel="stylesheet" href="../../tomorrow-night.css">
        <link rel="stylesheet" href="../../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../../scroll-mdbook-outputs.css">

        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/000_5-sds-2-x-geo-changes.html">000_5-sds-2-x-geo-changes</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/001_CrashCourseGIS.html">001_CrashCourseGIS</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/031_GeospatialAnalyticsInMagellan.html">031_GeospatialAnalyticsInMagellan</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/031a_MagellanOSMIngestion.html">031a_MagellanOSMIngestion</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/032_NYtaxisInMagellan.html">032_NYtaxisInMagellan</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/032a_MSR_BeijingTaxiTrajectories_MagellanQueries.html">032a_MSR_BeijingTaxiTrajectories_MagellanQueries</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/032b_UberMapMatchingAndVisualization.html">032b_UberMapMatchingAndVisualization</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/032d_MobileSampleSQL.html">032d_MobileSampleSQL</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/032e_CallDetailRecords.html">032e_CallDetailRecords</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/032x_ComingAttractions.html">032x_ComingAttractions</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/033_00_Intro2PointsOnGraphs.html">033_00_Intro2PointsOnGraphs</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/033_01_OSMtoGraphXUppsalaTiny.html">033_01_OSMtoGraphXUppsalaTiny</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/033_02_OSMtoGraphX_LT.html" class="active">033_02_OSMtoGraphX_LT</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/033_03_LT_PageRank.html">033_03_LT_PageRank</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/034_01_MapMatching_with_GeoMatch_UppsalaTiny.html">034_01_MapMatching_with_GeoMatch_UppsalaTiny</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/034_02_MapMatching_on_a_Graph_UppsalaTiny.html">034_02_MapMatching_on_a_Graph_UppsalaTiny</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/034_03_MapMatching_on_a_Graph_LT.html">034_03_MapMatching_on_a_Graph_LT</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/034_04_MapMatching_on_a_G1_LT.html">034_04_MapMatching_on_a_G1_LT</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/034_05DistributionOfStates.html">034_05DistributionOfStates</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/034_06SimulatingArrivalTimesNHPP_Inversion.html">034_06SimulatingArrivalTimesNHPP_Inversion</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_01_Arcgis_coordinates_transformation.html">035_01_Arcgis_coordinates_transformation</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_02_Segmentation_municipalities_Magellan.html">035_02_Segmentation_municipalities_Magellan</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_03_Visualization_municipalities.html">035_03_Visualization_municipalities</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_04_MapMatching_intersections.html">035_04_MapMatching_intersections</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_05_UndirectedG0.html">035_05_UndirectedG0</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_06_ConnectedComponent_PageRank.html">035_06_ConnectedComponent_PageRank</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_07_PoissonRegression.html">035_07_PoissonRegression</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">sds-3.x/ScaDaMaLe</h1>

                    <div class="right-buttons">
                        <a href="../../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <div class="cell markdown">
<p>ScaDaMaLe Course <a href="https://lamastex.github.io/scalable-data-science/sds/3/x/">site</a> and <a href="https://lamastex.github.io/ScaDaMaLe/index.html">book</a></p>
</div>
<div class="cell markdown">
<h2 id="creating-a-road-graph-from-openstreetmap-osm-data-with-graphx"><a class="header" href="#creating-a-road-graph-from-openstreetmap-osm-data-with-graphx">Creating a road graph from OpenStreetMap (OSM) data with GraphX</a></h2>
<p>Stavroula Rafailia Vlachou (<a href="https://www.linkedin.com/in/stavroula-rafailia-vlachou/">LinkedIn</a>), Virginia Jimenez Mohedano (<a href="https://www.linkedin.com/in/virginiajimenezmohedano/">LinkedIn</a>) and Raazesh Sainudiin (<a href="https://www.linkedin.com/in/raazesh-sainudiin-45955845/">LinkedIn</a>).</p>
<pre><code>This project was supported by SENSMETRY through a Data Science Project Internship 
between 2022-01-17 and 2022-06-05 to Stavroula R. Vlachou and Virginia J. Mohedano 
and Databricks University Alliance with infrastructure credits from AWS to 
Raazesh Sainudiin, Department of Mathematics, Uppsala University, Sweden.
</code></pre>
<p>2022, Uppsala, Sweden</p>
<p>This project builds on top of the work of Dillon George (2016-2018).</p>
<pre><code>Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
</code></pre>
</div>
<div class="cell markdown">
<h3 id="step-0-download-the-data---once-per-cluster"><a class="header" href="#step-0-download-the-data---once-per-cluster">Step 0. Download the data - once per cluster</a></h3>
</div>
<div class="cell markdown">
<p>Download the road network representation of Lithuania through OSM data distributed from GeoFabrik <a href="https://download.geofabrik.de/europe/lithuania.html">https://download.geofabrik.de/europe/lithuania.html</a></p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-sh">curl -O https://download.geofabrik.de/europe/lithuania-latest.osm.pbf
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
  0  155M    0  512k    0     0   906k      0  0:02:55 --:--:--  0:02:55  906k
 19  155M   19 30.4M    0     0  19.5M      0  0:00:07  0:00:01  0:00:06 19.5M
 41  155M   41 64.1M    0     0  25.0M      0  0:00:06  0:00:02  0:00:04 25.0M
 65  155M   65  101M    0     0  28.5M      0  0:00:05  0:00:03  0:00:02 28.5M
 92  155M   92  143M    0     0  31.5M      0  0:00:04  0:00:04 --:--:-- 31.4M
100  155M  100  155M    0     0  32.1M      0  0:00:04  0:00:04 --:--:-- 36.3M
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">dbutils.fs.mv(&quot;file:/databricks/driver/lithuania-latest.osm.pbf&quot;, &quot;dbfs:/datasets/osm/lithuania/lithuania.osm.pbf&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res6: Boolean = true
</code></pre>
</div>
</div>
<div class="cell markdown">
<h3 id="step-1---load-the-data"><a class="header" href="#step-1---load-the-data">Step 1 - Load the data</a></h3>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">import crosby.binary.osmosis.OsmosisReader

import org.apache.hadoop.mapreduce.{TaskAttemptContext, JobContext}
import org.apache.hadoop.fs.FileSystem
import org.apache.hadoop.conf.Configuration
import org.apache.hadoop.fs.Path

import org.openstreetmap.osmosis.core.container.v0_6.EntityContainer
import org.openstreetmap.osmosis.core.domain.v0_6._
import org.openstreetmap.osmosis.core.task.v0_6.Sink

import sqlContext.implicits._

import scala.collection.mutable.ArrayBuffer
import scala.collection.mutable.Map
import scala.collection.JavaConversions._

import org.apache.spark.sql.functions._

import org.apache.spark.graphx._
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>import crosby.binary.osmosis.OsmosisReader
import org.apache.hadoop.mapreduce.{TaskAttemptContext, JobContext}
import org.apache.hadoop.fs.FileSystem
import org.apache.hadoop.conf.Configuration
import org.apache.hadoop.fs.Path
import org.openstreetmap.osmosis.core.container.v0_6.EntityContainer
import org.openstreetmap.osmosis.core.domain.v0_6._
import org.openstreetmap.osmosis.core.task.v0_6.Sink
import sqlContext.implicits._
import scala.collection.mutable.ArrayBuffer
import scala.collection.mutable.Map
import scala.collection.JavaConversions._
import org.apache.spark.sql.functions._
import org.apache.spark.graphx._
</code></pre>
</div>
</div>
<div class="cell markdown">
<ul>
<li>For the ingestion of the entire OSM Lithuanian road network dataset, the PBF file obtained from OSM is transformed to three parquet files; one for each primitive (nodes, ways and relations), by utilising methods of the <a href="https://github.com/adrianulbona/osm-parquetizer">osm-parquetizer project</a>. The first two generated files, corresponding to the nodes and ways are then transferred into the distributed file system for further exploitation.</li>
</ul>
</div>
<div class="cell markdown">
<h4 id="install-the-osm-parquetizer-in-the-cluster"><a class="header" href="#install-the-osm-parquetizer-in-the-cluster">Install the osm-parquetizer in the cluster</a></h4>
<p>Clone the repository from <a href="https://github.com/adrianulbona/osm-parquetizer">osm-parquetizer project</a> and build the library that will be updated to the cluster.</p>
<p>Later, it will be used to load the osm data faster.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">//Run this command only once per cluster 
%sh 
java -jar /dbfs/FileStore/jars/2706d711_3963_4d88_92e7_a8870d0164d1-osm_parquetizer_1_0_1_SNAPSHOT-80d25.jar /dbfs/datasets/osm/lithuania/lithuania.osm.pbf
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>2022-04-06 07:40:54 INFO  CodecPool:153 - Got brand-new compressor [.snappy]
2022-04-06 07:40:55 INFO  CodecPool:153 - Got brand-new compressor [.snappy]
2022-04-06 07:40:55 INFO  CodecPool:153 - Got brand-new compressor [.snappy]
2022-04-06 07:40:58 INFO  App$MultiEntitySinkObserver:118 - Entities processed: 1000000
2022-04-06 07:40:59 INFO  App$MultiEntitySinkObserver:118 - Entities processed: 2000000
2022-04-06 07:41:00 INFO  App$MultiEntitySinkObserver:118 - Entities processed: 3000000
2022-04-06 07:41:02 INFO  App$MultiEntitySinkObserver:118 - Entities processed: 4000000
2022-04-06 07:41:03 INFO  App$MultiEntitySinkObserver:118 - Entities processed: 5000000
2022-04-06 07:41:04 INFO  App$MultiEntitySinkObserver:118 - Entities processed: 6000000
2022-04-06 07:41:11 INFO  App$MultiEntitySinkObserver:118 - Entities processed: 7000000
2022-04-06 07:41:12 INFO  App$MultiEntitySinkObserver:118 - Entities processed: 8000000
2022-04-06 07:41:13 INFO  App$MultiEntitySinkObserver:118 - Entities processed: 9000000
2022-04-06 07:41:14 INFO  App$MultiEntitySinkObserver:118 - Entities processed: 10000000
2022-04-06 07:41:15 INFO  App$MultiEntitySinkObserver:118 - Entities processed: 11000000
2022-04-06 07:41:16 INFO  App$MultiEntitySinkObserver:118 - Entities processed: 12000000
2022-04-06 07:41:23 INFO  App$MultiEntitySinkObserver:118 - Entities processed: 13000000
2022-04-06 07:41:24 INFO  App$MultiEntitySinkObserver:118 - Entities processed: 14000000
2022-04-06 07:41:25 INFO  App$MultiEntitySinkObserver:118 - Entities processed: 15000000
2022-04-06 07:41:25 INFO  App$MultiEntitySinkObserver:118 - Entities processed: 16000000
2022-04-06 07:41:27 INFO  App$MultiEntitySinkObserver:118 - Entities processed: 17000000
2022-04-06 07:41:28 INFO  App$MultiEntitySinkObserver:118 - Entities processed: 18000000
2022-04-06 07:41:29 INFO  App$MultiEntitySinkObserver:118 - Entities processed: 19000000
2022-04-06 07:41:36 INFO  App$MultiEntitySinkObserver:118 - Entities processed: 20000000
2022-04-06 07:41:37 INFO  App$MultiEntitySinkObserver:118 - Entities processed: 21000000
2022-04-06 07:41:43 INFO  App$MultiEntitySinkObserver:118 - Entities processed: 22000000
2022-04-06 07:41:48 INFO  App$MultiEntitySinkObserver:118 - Entities processed: 23000000
2022-04-06 07:42:01 INFO  App$MultiEntitySinkObserver:125 - Total entities processed: 23727209
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-sh">ls /dbfs/datasets/osm/lithuania/
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>lithuania.osm.pbf
lithuania.osm.pbf.node.parquet
lithuania.osm.pbf.relation.parquet
lithuania.osm.pbf.way.parquet
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Read the parquet files of the nodes and ways obtained from the osm-parquetizer.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">spark.conf.set(&quot;spark.sql.parquet.binaryAsString&quot;, true)

val nodes_df = spark.read.parquet(&quot;dbfs:/datasets/osm/lithuania/lithuania.osm.pbf.node.parquet&quot;)
val ways_df = spark.read.parquet(&quot;dbfs:/datasets/osm/lithuania/lithuania.osm.pbf.way.parquet&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>nodes_df: org.apache.spark.sql.DataFrame = [id: bigint, version: int ... 7 more fields]
ways_df: org.apache.spark.sql.DataFrame = [id: bigint, version: int ... 6 more fields]
</code></pre>
</div>
</div>
<div class="cell markdown">
<h3 id="step-2---construction-of-a-road-graph-out-of-a-road-network"><a class="header" href="#step-2---construction-of-a-road-graph-out-of-a-road-network">Step 2 - Construction of a Road Graph out of a Road Network</a></h3>
</div>
<div class="cell markdown">
<ul>
<li>The list of tags chosen for this work. For the semantic meaning of each tag see the <a href="https://wiki.openstreetmap.org/wiki/Map_features">OSM description</a>. The list is non exhaustive and should be adapted according to the desired granulatiry of and level of detail of the project at hand.</li>
</ul>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val allowableWays = Seq(
  &quot;motorway&quot;,
  &quot;motorway_link&quot;,
  &quot;trunk&quot;,
  &quot;trunk_link&quot;,
  &quot;primary&quot;,
  &quot;primary_link&quot;,
  &quot;secondary&quot;,
  &quot;secondary_link&quot;,
  &quot;tertiary&quot;,
  &quot;tertiary_link&quot;,
  &quot;living_street&quot;,
  &quot;residential&quot;,
  &quot;road&quot;,
  &quot;construction&quot;,
  &quot;motorway_junction&quot;
)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>allowableWays: Seq[String] = List(motorway, motorway_link, trunk, trunk_link, primary, primary_link, secondary, secondary_link, tertiary, tertiary_link, living_street, residential, road, construction, motorway_junction)
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">//convert the nodes to Dataset containing the fields of interest

case class NodeEntry(nodeId: Long, latitude: Double, longitude: Double, tags: Seq[String])

val nodeDS = nodes_df.map(node =&gt; 
  NodeEntry(node.getAs[Long](&quot;id&quot;),
       node.getAs[Double](&quot;latitude&quot;),
       node.getAs[Double](&quot;longitude&quot;),
       node.getAs[Seq[Row]](&quot;tags&quot;).map{case Row(key:String, value:String) =&gt; value}
)).cache()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>defined class NodeEntry
nodeDS: org.apache.spark.sql.Dataset[NodeEntry] = [nodeId: bigint, latitude: double ... 2 more fields]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">nodeDS.count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res2: Long = 21212155
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">//convert the ways to Dataset containing the fields of interest

case class WayEntry(wayId: Long, tags: Array[String], nodes: Array[Long])

val wayDS = ways_df.flatMap(way =&gt; {
        val tagSet = way.getAs[Seq[Row]](&quot;tags&quot;).map{case Row(key:String, value:String) =&gt;  value}.toArray
        if (tagSet.intersect(allowableWays).nonEmpty ){
            Array(WayEntry(way.getAs[Long](&quot;id&quot;),
            tagSet,
            way.getAs[Seq[Row]](&quot;nodes&quot;).map{case Row(index:Integer, nodeId:Long) =&gt;  nodeId}.toArray
            ))
        }
        else { Array[WayEntry]()}
}
).cache()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>defined class WayEntry
wayDS: org.apache.spark.sql.Dataset[WayEntry] = [wayId: bigint, tags: array&lt;string&gt; ... 1 more field]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">wayDS.count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res4: Long = 137540
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val nodeCounts = wayDS
                    .select(explode('nodes).as(&quot;node&quot;))
                    .groupBy('node).count
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>nodeCounts: org.apache.spark.sql.DataFrame = [node: bigint, count: bigint]
</code></pre>
</div>
</div>
<div class="cell markdown">
<ul>
<li>An intersection node is defined here as a node that lies in at least two ways.</li>
</ul>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val intersectionNodes = nodeCounts.filter('count &gt;= 2).select('node.alias(&quot;intersectionNode&quot;))
val true_intersections = intersectionNodes
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>intersectionNodes: org.apache.spark.sql.DataFrame = [intersectionNode: bigint]
true_intersections: org.apache.spark.sql.DataFrame = [intersectionNode: bigint]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">intersectionNodes.count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res8: Long = 162325
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val distinctNodesWays = wayDS.flatMap(_.nodes).distinct //the distinct nodes within the ways 
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>distinctNodesWays: org.apache.spark.sql.Dataset[Long] = [value: bigint]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">distinctNodesWays.count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res10: Long = 1299907
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val wayNodes = nodeDS.as(&quot;nodes&quot;) 
  .joinWith(distinctNodesWays.as(&quot;ways&quot;), $&quot;ways.value&quot; === $&quot;nodes.nodeId&quot;)
  .map(_._1).cache
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>wayNodes: org.apache.spark.sql.Dataset[NodeEntry] = [nodeId: bigint, latitude: double ... 2 more fields]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">wayNodes.count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res12: Long = 1299907
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val intersectionSetVal = intersectionNodes.as[Long].collect.toSet; //turn intersectionNodes to Set 
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>intersectionSetVal: scala.collection.immutable.Set[Long] = Set(3954894392, 1028098141, 8327933356, 1192596601, 1036402120, 5840172474, 691993192, 7280204168, 3837546128, 1509692779, 3774745375, 2888929887, 3882298102, 4456063981, 1812836277, 6219174203, 1132762870, 2704534617, 1036358572, 1314515551, 5887601785, 3472814007, 935011580, 2266417234, 2218477159, 3830971192, 3758026612, 2628269378, 2450295578, 2036730950, 4014928315, 4047561472, 3742211751, 417473667, 710972352, 1240304711, 2344640802, 3175136574, 3610788315, 1152426347, 3843702680, 2135301596, 3463371091, 2578259945, 2272646209, 9288252126, 8659906497, 5046236674, 3882606462, 6853150636, 2348202899, 1827020895, 1034351953, 2872587837, 7598921441, 4441135707, 7154408678, 2143313902, 6358524504, 1827841626, 51401434, 2104687370, 3169288908, 2203661858, 509277213, 7398865298, 2706131803, 7020673974, 2482655992, 410873070, 40599892, 2718581564, 1136446055, 2612123258, 5856761891, 896143820, 1723158680, 3692175721, 7973969958, 2596488268, 2746044544, 1145714624, 1057404723, 412963083, 81203920, 1258193303, 7277561125, 5215875721, 9119375173, 2095081588, 1017873867, 1151243019, 1848119391, 1924034959, 277888047, 3124645299, 3796300978, 34825612, 2234211037, 2378775918, 2533534558, 3387536812, 262278719, 3539046584, 2600271017, 2343507669, 6198589614, 798855679, 2955786090, 31452099, 2255897649, 4069602981, 5821435649, 8510338674, 9118314553, 727235490, 1632026970, 1138846538, 7817950226, 9500011302, 2491378894, 2659296775, 6510669593, 2245343559, 1549190307, 4723634502, 5975664368, 834528382, 1144264294, 3398600261, 2934302676, 2620066696, 2512528358, 1026705634, 3846262838, 4944746627, 4475382645, 2045995025, 2043449667, 2800589982, 6562241076, 6466080351, 1639532336, 8006034862, 4572083119, 4102652469, 2135301330, 1848200775, 2725675664, 321982547, 2379130060, 9236572852, 1834676531, 7342960659, 3481040164, 3773275282, 4723676068, 4508131633, 4426839331, 2419523846, 7279732924, 1156860008, 3591788118, 1946671545, 1636124896, 3492717581, 4949411117, 1044390922, 6845662470, 371663507, 3385128084, 5962770335, 1242544881, 457526430, 981428783, 4961114540, 2262631506, 2297448445, 9603285842, 1474540484, 5940837836, 1700351712, 2320635099, 2146958637, 9270519896, 4872990619, 2928092139, 4425066655, 2206664581, 7280235988, 1535287197, 1183618876, 6485160551, 4411398966, 3991141456, 1628728176, 4889396284, 4759399991, 3946596452, 2229195631, 6327513918, 2033129308, 2585464548, 1800850400, 1104097855, 1801836841, 5543206580, 1733360477, 2192183580, 1286185458, 1039741678, 3071904626, 1479129180, 8159625958, 8153576878, 137356770, 9512132640, 2889406310, 9282951374, 2772945378, 7087700888, 299690975, 7496589529, 363422207, 1258118530, 3717631194, 2769080208, 873542203, 6203485294, 2213415589, 1826893692, 1295860361, 1991899638, 7142870533, 2636482814, 2228819220, 2486409125, 1408251311, 1163019147, 1986264613, 722809386, 1032791795, 2372253123, 7280236132, 3012402670, 410410926, 1632013830, 4185213749, 8422801035, 5082283666, 8390975598, 717553500, 8903760367, 1426181723, 2486831606, 2706132069, 7082082762, 3629722595, 1827841682, 1663312625, 1116078354, 809918023, 1634421784, 2294078407, 6371632243, 6942832214, 3103437026, 4778848191, 5609948419, 928079952, 2643946553, 2219142846, 3259798128, 972705422, 4532894711, 1147389163, 4200665722, 1621450716, 3446435974, 3508982006, 2914931552, 267993651, 8609633816, 1583332389, 8437833869, 3954868130, 2844494775, 307436405, 9537310383, 1011788287, 1218743199, 289957295, 1751074538, 1156335745, 1146179866, 3281587820, 8742132605, 7194943159, 730037695, 2210300341, 4067081255, 2120972958, 2431147071, 1822938498, 6538086425, 4002602910, 5353103914, 4983226891, 4213376931, 7637618131, 289974999, 897017041, 3784378983, 863076967, 2548257942, 664083103, 2107860391, 1933944950, 316984109, 7234677785, 2078466041, 1643397002, 1947951854, 1022668729, 3923653099, 430592144, 9526786026, 1647829111, 4350345841, 8299422853, 1388346027, 1333297066, 5713163211, 1610127502, 1788952448, 2458903268, 3791809345, 948084432, 1316591108, 31451994, 3143625714, 2760666691, 3828309401, 2597263264, 3266940454, 1316448033, 440186291, 8180441284, 420327660, 509915470, 2514797704, 3780311361, 8559264289, 3394551775, 3212336035, 6679942853, 4709809401, 3653215774, 1583370181, 987421444, 1833211352, 1144264023, 6630983072, 3378700352, 59966924, 2349179912, 7262854702, 8467921475, 3440462099, 2575696642, 3026960820, 1218743216, 3027688464, 2229173598, 3410180667, 6556729270, 2291514844, 3593937592, 258334236, 3014185666, 4413684252, 3110697588, 2241312126, 3730438791, 5936924029, 3751286821, 9026315361, 2338538874, 3060553050, 2141652614, 5875853605, 3784808168, 9465276921, 2403703365, 1583370191, 7077003935, 1026388850, 7194944311, 5859419005, 2473521017, 3842318629, 3376486271, 802900320, 8252803189, 2208380506, 1156333576, 4483834287, 270417965, 7237069225, 360358257, 2210300378, 2420411103, 4535542163, 6216923884, 2051653884, 2636348593, 1472252644, 4993989546, 4109866667, 828100084, 1765999049, 2718581586, 8301377775, 1698483524, 7363586219, 2218608237, 2291119222, 3167440934, 2651981227, 1584052082, 4054735777, 309903458, 8603152470, 9476909282, 1409939961, 4301868799, 59597223, 2189861315, 267993634, 2929972394, 9225032695, 135506977, 2798742686, 975863053, 5311900085, 3488545429, 875843248, 2183169598, 34831827, 1838097699, 9374557330, 2977367244, 9431428140, 4843262174, 2338503812, 8865734959, 417459235, 3721512253, 2782161816, 1991225594, 4458953260, 5801770199, 3267338755, 4020271732, 2221734300, 2527141662, 7182319546, 1184532267, 3731435296, 1492744502, 1798375955, 3077206333, 519329015, 3729938977, 1682401466, 2291847466, 6964491980, 297195057, 3917165782, 5941024645, 3739153439, 3001058738, 5958222327, 8314763501, 1066074385, 316413715, 2278156350, 5347857056, 1666690939, 4183327417, 3856244360, 2064604400, 4250281533, 2060142472, 2403235372, 32841598, 2386188237, 1097991668, 2183690668, 2630516839, 928079854, 6065705344, 307761081, 6353759494, 5353548326, 3404472949, 5781659914, 9498221622, 1425162913, 3577210444, 7279644065, 2225499506, 983975927, 9425700741, 1784462203, 1518862773, 5731650357, 460421744, 1057745021, 1869057080, 3835591790, 9556653974, 3287551559, 1388523717, 4895686278, 1669536064, 6679519540, 863767755, 279031554, 1675549394, 2218477211, 3733218337, 33696568, 2304694881, 1628815710, 2865789132, 3784627841, 2291591139, 4428630254, 1399469264, 82665220, 1184706242, 1132762659, 2249967109, 2206365893, 2132763286, 4011368562, 1376095268, 2204877189, 4548183278, 5496029012, 1869298008, 1362530886, 5743781594, 983988377, 9376200974, 1406174749, 7924188545, 7057373803, 5109656203, 6565466018, 6176044211, 3012400575, 4937071805, 2883700859, 2599495143, 2717130199, 3766909365, 5713162376, 1194658790, 5737707544, 307434796, 1232671903, 2636315241, 8259520715, 2305314281, 1622596513, 387188500, 5810398683, 3013782338, 8542643608, 1136279036, 3001000032, 1414401838, 1679739780, 196452763, 2184428808, 8480819385, 2162630967, 5737707289, 833173029, 9594321488, 1283445383, 918958651, 875887014, 957483875, 2598507082, 2098286970, 1834140639, 3394367897, 270955266, 2396052669, 2635681054, 2557177227, 738262392, 3852199229, 7253699761, 4014087118, 4772352886, 1317359171, 2457760635, 2081277045, 477279781, 6565459647, 994420612, 4103058760, 2206318153, 8609775508, 1408174608, 853085910, 1201326444, 969236676, 2234945974, 3385153797, 8807447960, 2667148223, 1717012137, 2392972139, 7179029668, 8354869319, 2571067773, 938485933, 6737257768, 5650317935, 1800873402, 5737707311, 6860929497, 2107860313, 3747571216, 3274638558, 882543449, 8148693091, 428894557, 33351960, 4834093689, 4319213787, 2199942142, 956228765, 4843283834, 774449468, 2278776107, 8942677479, 9245138140, 4382734481, 1582432158, 1369282096, 983978646, 1073909045, 1834040946, 759821178, 2609163849, 1119737116, 2354970285, 3387522495, 2272646056, 1026388570, 5958221291, 845238880, 5827167555, 4781018322, 7296351534, 2882366814, 8408590758, 2720703388, 877483437, 1786405258, 3307278453, 3751405818, 7106436389, 2148903330, 5494802007, 3555422221, 60178273, 1099711886, 2585151355, 3974900096, 8428736128, 7954360226, 7598764758, 4375255572, 1240307170, 2205035462, 3714158040, 1316590749, 3001059117, 1562239376, 7176474600, 2352440636, 692905899, 1020477653, 4503154089, 5018686059, 1146179488, 6205024586, 2372252431, 1572488857, 468212277, 32444415, 841684817, 4994858487, 2484703166, 60735101, 416868242, 1473000644, 1106088085, 1833573595, 2108526263, 6794671031, 2331881331, 1304629131, 3583899803, 2314813365, 417459748, 307436400, 130184820, 1478353614, 6150026276, 5854494346, 613391647, 1789002993, 2093484483, 3883005032, 3651396832, 672383763, 7661640286, 2206307106, 672882902, 672383810, 2794473788, 628916719, 3351527927, 363415410, 2447375338, 1045091692, 1071180106, 2206664533, 509915492, 774102472, 2427890952, 1985569687, 1043674973, 2622769778, 1028097980, 7672655414, 903875660, 448106871, 1242375740, 3406764205, 1426181269, 2047701609, 2327214518, 32137407, 2565898533, 1378715716, 2391162479, 7254849968, 3105466444, 334074652, 3766872158, 3394225486, 7220822425, 1825537562, 2213482293, 213103643, 3762598178, 2299315684, 4149587762, 1190924291, 3771852909, 2249019343, 2234997832, 1234754014, 1436522954, 3539132652, 8777124688, 444382405, 3991092613, 5849683848, 3458040974, 1640691492, 1305960244, 8108544369, 2578259841, 6231031628, 3097531642, 4015318844, 1367988073, 2394951419, 984017310, 1584852514, 8486499516, 1430930928, 1425162944, 4292888171, 1821448220, 4007267980, 5132586877, 7065792490, 32070346, 1625011580, 1639391465, 2379921223, 2926434071, 1156355235, 1874799141, 1229897058, 2277634548, 2206390743, 5075625954, 3659517817, 2216244891, 1747606437, 669898636, 6298083892, 1962417346, 2156378184, 7255498135, 9309540804, 1156337096, 3783267692, 2706118851, 2218679650, 2457780505, 2436488867, 9248641052, 4419542059, 2579616352, 8655173923, 3784465264, 3660955552, 967978729, 6718424372, 1599651948, 3076644627, 894241402, 2405003030, 2425004096, 838667615, 747170701, 2364173809, 509915338, 2079707910, 1367982120, 2592464646, 423134683, 7704615140, 360346943, 1093565436, 2346919436, 8078819601, 8479967689, 1139668748, 2486831545, 1323305098, 8974061782, 3255347567, 7695291822, 834596921, 6221589470, 3086066032, 364862229, 4014880532, 3385093676, 4147558019, 32325860, 59602095, 8914071661, 9205403028, 1091178299, 1640421992, 3235859832, 8553407645, 2088182463, 1066074463, 1144263463, 9399410933, 3614818103, 1037021065, 2339350243, 2234992547, 482372352, 8365607345, 9407899787, 2503238675, 4052869743, 4057398263, 2752337390, 6022389760, 3757229740, 3664167280, 1109786253, 9420175990, 1639229904, 4936629565, 7194943988, 948085015, 1859172543, 1037238437, 1475777575, 2378760997, 2202910372, 2250873936, 4059537745, 34823041, 833756825, 926087368, 2301065976, 8664365690, 5733289457, 2225499406, 316030135, 4485856605, 4183327389, 39720895, 7762319766, 1786533553, 3773213186, 4096000552, 3583815488, 8904198808, 4002388889, 1827843225, 1151245225, 1633730199, 1711891073, 1818530578, 4015319010, 1043674554, 9277109190, 1305078052, 1070210060, 993790515, 2293770972, 3075151948, 3001199427, 87871140, 8221996479, 1811038357, 8628592241, 3173095658, 905162047, 2163102239, 1068906801, 4428831607, 2245344052, 2299428801, 5466134779, 2044841002, 5037480685, 3783505652, 1955251123, 1568102895, 4100065051, 3923639220, 285961845, 3256252817, 5102966903, 2225499382, 2535189315, 1082645551, 2723635886, 2266375430, 707871678, 2519920004, 475246698, 9172574938, 1399469459, 1344873524, 5707764259, 2683347689, 1642173525, 846815313, 4934403402, 1153785449, 2771898228, 7248424922, 1566236272, 912155364, 7923015520, 1069856530, 1332023401, 5739790119, 1771110833, 367155036, 1250349086, 3456840005, 9213970172, 1072204527, 1421435056, 270904459)
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">import org.apache.spark.sql.functions.{collect_list, map, udf}
import org.apache.spark.sql.functions._

val remove_first_and_last = udf((x: Seq[Long]) =&gt; x.drop(1).dropRight(1))

val nodes = wayDS.
  select($&quot;wayId&quot;, $&quot;nodes&quot;).
  withColumn(&quot;node&quot;, explode($&quot;nodes&quot;)).
  drop(&quot;nodes&quot;)

val get_first_and_last = udf((x: Seq[Long]) =&gt; {val first = x(0); val last = x.reverse(0); Array(first, last)})

val first_and_last_nodes = wayDS.
  select($&quot;wayId&quot;, get_first_and_last($&quot;nodes&quot;).as(&quot;nodes&quot;)).
  withColumn(&quot;node&quot;, explode($&quot;nodes&quot;)).
  drop(&quot;nodes&quot;)

val dead_end_points = first_and_last_nodes.select($&quot;node&quot;).distinct().withColumnRenamed(&quot;node&quot;, &quot;value&quot;)

// Turn intersection set into a dataset to join (all values must be unique)
val intersections = intersectionNodes.union(dead_end_points).distinct      
 
val wayNodesLocated = nodes.join(wayNodes, wayNodes.col(&quot;nodeId&quot;) === nodes.col(&quot;node&quot;)).select($&quot;wayId&quot;, $&quot;node&quot;, $&quot;latitude&quot;, $&quot;longitude&quot;)


case class MappedWay(wayId: Long, labels_located: Seq[Map[Long, (Boolean, Double, Double)]])


val maps = wayNodesLocated.join(intersections, 'node === 'intersectionNode, &quot;left_outer&quot;).
  //left outer joins returns all rows from the left DataFrame/Dataset regardless of match found on the right dataset
    select($&quot;wayId&quot;, $&quot;node&quot;, $&quot;intersectionNode&quot;.isNotNull.as(&quot;contains&quot;), $&quot;latitude&quot;, $&quot;longitude&quot;).
   groupBy(&quot;wayId&quot;).agg(collect_list(map($&quot;node&quot;, struct($&quot;contains&quot;.as(&quot;_1&quot;), $&quot;latitude&quot;.as(&quot;_2&quot;), $&quot;longitude&quot;.as(&quot;_3&quot;)))).as(&quot;labels_located&quot;)).as[MappedWay] 
 

val combine = udf((nodes: Seq[Long], labels_located: Seq[scala.collection.immutable.Map[Long, (Boolean, Double, Double)]]) =&gt; {
  // If labels does not have &quot;node&quot;, then it is either start/end - we assign label = true, latitude = 0, longitude = 0 for it, TO DO: revise it later, not sure
  val m = labels_located.map(_.toSeq).flatten.toMap

  nodes.map { node =&gt; (node, m.getOrElse(node, (true, 0D, 0D))) } //add structure

})


val strSchema = &quot;array&lt;struct&lt;nodeId:long, nodeInfo:struct&lt;label:boolean, latitude:double, longitude: double&gt;&gt;&gt;&quot;
val labeledWays = wayDS.join(maps, &quot;wayId&quot;)
                     .select($&quot;wayId&quot;, $&quot;tags&quot;, combine($&quot;nodes&quot;, $&quot;labels_located&quot;).as(&quot;labeledNodes&quot;).cast(strSchema))
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>import org.apache.spark.sql.functions.{collect_list, map, udf}
import org.apache.spark.sql.functions._
remove_first_and_last: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(&lt;function1&gt;,ArrayType(LongType,false),Some(List(ArrayType(LongType,false))))
nodes: org.apache.spark.sql.DataFrame = [wayId: bigint, node: bigint]
get_first_and_last: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(&lt;function1&gt;,ArrayType(LongType,false),Some(List(ArrayType(LongType,false))))
first_and_last_nodes: org.apache.spark.sql.DataFrame = [wayId: bigint, node: bigint]
dead_end_points: org.apache.spark.sql.DataFrame = [value: bigint]
intersections: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [intersectionNode: bigint]
wayNodesLocated: org.apache.spark.sql.DataFrame = [wayId: bigint, node: bigint ... 2 more fields]
defined class MappedWay
maps: org.apache.spark.sql.Dataset[MappedWay] = [wayId: bigint, labels_located: array&lt;map&lt;bigint,struct&lt;_1:boolean,_2:double,_3:double&gt;&gt;&gt;]
combine: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(&lt;function2&gt;,ArrayType(StructType(StructField(_1,LongType,false), StructField(_2,StructType(StructField(_1,BooleanType,false), StructField(_2,DoubleType,false), StructField(_3,DoubleType,false)),true)),true),Some(List(ArrayType(LongType,false), ArrayType(MapType(LongType,StructType(StructField(_1,BooleanType,false), StructField(_2,DoubleType,false), StructField(_3,DoubleType,false)),true),true))))
strSchema: String = array&lt;struct&lt;nodeId:long, nodeInfo:struct&lt;label:boolean, latitude:double, longitude: double&gt;&gt;&gt;
labeledWays: org.apache.spark.sql.DataFrame = [wayId: bigint, tags: array&lt;string&gt; ... 1 more field]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">case class Intersection(OSMId: Long , latitude: Double, longitude: Double, inBuf: ArrayBuffer[(Long, Double, Double)], outBuf: ArrayBuffer[(Long, Double, Double)])

val segmentedWays = labeledWays.map(way =&gt; {
  
  val labeledNodes = way.getAs[Seq[Row]](&quot;labeledNodes&quot;).map{case Row(k: Long, Row(v: Boolean, w:Double, x:Double)) =&gt; (k, v,w,x)}.toSeq //labeledNodes: (nodeid, label, lat, long)
  val wayId = way.getAs[Long](&quot;wayId&quot;)
  
  val indexedNodes: Seq[((Long, Boolean, Double, Double), Int)] = labeledNodes.zipWithIndex //appends an integer as an index to every labeledNodes in a way
  
  val intersections = ArrayBuffer[Intersection]()  
  
  val currentBuffer = ArrayBuffer[(Long, Double, Double)]()
  
  val way_length = labeledNodes.length //number of nodes in a way
  
  if (way_length == 1) {

    val intersect = new Intersection(labeledNodes(0)._1, labeledNodes(0)._3, labeledNodes(0)._4, ArrayBuffer((-1L, 0D, 0D)), ArrayBuffer((-1L, 0D, 0D))) //include lat and long info

    var result = Array((intersect.OSMId, intersect.latitude, intersect.longitude, intersect.inBuf.toArray, intersect.outBuf.toArray))
    (wayId, result) //return
  }
  else {
    indexedNodes.foreach{ case ((id, isIntersection, latitude, longitude), i) =&gt; // id is nodeId and isIntersection is the node's boolean label
      if (isIntersection) {
        val newEntry = new Intersection(id, latitude, longitude, currentBuffer.clone, ArrayBuffer[(Long, Double, Double)]())
        intersections += newEntry
        currentBuffer.clear
      }
      else {
        currentBuffer ++= Array((id, latitude, longitude))  //if the node is not an intersection append the nodeId to the current buffer 
      }
      
      // Reaches the end of the way while the outBuffer is not empty
      // Append the currentBuffer to the last existing intersection
      if (i == way_length - 1 &amp;&amp; !currentBuffer.isEmpty) {  
        if (intersections.isEmpty){
        intersections += new Intersection(-1, 0D, 0D, currentBuffer, ArrayBuffer[(Long, Double, Double)]()) 
        }
        else {
          intersections.last.outBuf ++= currentBuffer
        }
        currentBuffer.clear
      }
    }
    var result = intersections.map(i =&gt; (i.OSMId, i.latitude, i.longitude, i.inBuf.toArray, i.outBuf.toArray)).toArray  
    (wayId, result) 
  }
})
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>defined class Intersection
segmentedWays: org.apache.spark.sql.Dataset[(Long, Array[(Long, Double, Double, Array[(Long, Double, Double)], Array[(Long, Double, Double)])])] = [_1: bigint, _2: array&lt;struct&lt;_1:bigint,_2:double,_3:double,_4:array&lt;struct&lt;_1:bigint,_2:double,_3:double&gt;&gt;,_5:array&lt;struct&lt;_1:bigint,_2:double,_3:double&gt;&gt;&gt;&gt;]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val schema = &quot;array&lt;struct&lt;nodeId:bigint,latitude:double,longitude:double,inBuff:array&lt;struct&lt;nodeId:bigint,latitude:double,longitude:double&gt;&gt;,outBuff:array&lt;struct&lt;nodeId:bigint,latitude:double,longitude:double&gt;&gt;&gt;&gt;&quot;
segmentedWays.select($&quot;_1&quot;.alias(&quot;wayId&quot;), $&quot;_2&quot;.cast(schema).alias(&quot;nodeInfo&quot;)).printSchema()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>root
 |-- wayId: long (nullable = false)
 |-- nodeInfo: array (nullable = true)
 |    |-- element: struct (containsNull = true)
 |    |    |-- nodeId: long (nullable = true)
 |    |    |-- latitude: double (nullable = true)
 |    |    |-- longitude: double (nullable = true)
 |    |    |-- inBuff: array (nullable = true)
 |    |    |    |-- element: struct (containsNull = true)
 |    |    |    |    |-- nodeId: long (nullable = true)
 |    |    |    |    |-- latitude: double (nullable = true)
 |    |    |    |    |-- longitude: double (nullable = true)
 |    |    |-- outBuff: array (nullable = true)
 |    |    |    |-- element: struct (containsNull = true)
 |    |    |    |    |-- nodeId: long (nullable = true)
 |    |    |    |    |-- latitude: double (nullable = true)
 |    |    |    |    |-- longitude: double (nullable = true)

schema: String = array&lt;struct&lt;nodeId:bigint,latitude:double,longitude:double,inBuff:array&lt;struct&lt;nodeId:bigint,latitude:double,longitude:double&gt;&gt;,outBuff:array&lt;struct&lt;nodeId:bigint,latitude:double,longitude:double&gt;&gt;&gt;&gt;
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">//Unwrap the nested structure of the segmentedWays

val waySegmentDS = segmentedWays.flatMap(way =&gt; way._2.map(node =&gt; (way._1, node))) 
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>waySegmentDS: org.apache.spark.sql.Dataset[(Long, (Long, Double, Double, Array[(Long, Double, Double)], Array[(Long, Double, Double)]))] = [_1: bigint, _2: struct&lt;_1: bigint, _2: double ... 3 more fields&gt;]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">import scala.collection.immutable.Map

val intersectionVertices = waySegmentDS
  .map(way =&gt; 
   //nodeId     latitude   longitude      wayId      inBuff      outBuff
   (way._2._1, (way._2._2, way._2._3, Map(way._1 -&gt; (way._2._4, way._2._5))))) 
  .rdd
  //                     latitude, long, Map(wayId, inBuff, outBuff)
  .reduceByKey((a,b) =&gt; (a._1,     a._2, a._3 ++ b._3)) 

//intersectionVertices =  RDD[(nodeId, (latitude, longitude, wayMap(wayId -&gt; inBuff, outBuff)))]
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>import scala.collection.immutable.Map
intersectionVertices: org.apache.spark.rdd.RDD[(Long, (Double, Double, scala.collection.immutable.Map[Long,(Array[(Long, Double, Double)], Array[(Long, Double, Double)])]))] = ShuffledRDD[122] at reduceByKey at command-1211269020742696:9
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">intersectionVertices.count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res17: Long = 191991
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val edges = segmentedWays
  .filter(way =&gt; way._2.length &gt; 1) //ways with more than one nodes
  .flatMap{ case (wayId, nodes_info) =&gt; {  
             nodes_info.sliding(2) 
               .flatMap(segment =&gt; //segment is the pair of two nodes
                   List(Edge(segment(0)._1, segment(1)._1, wayId))
               )
   }}
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>edges: org.apache.spark.sql.Dataset[org.apache.spark.graphx.Edge[Long]] = [srcId: bigint, dstId: bigint ... 1 more field]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">edges.count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res19: Long = 237069
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">sc.setCheckpointDir(&quot;/_checkpoint&quot;) // just a directory in distributed file system
val edges_rdd = edges.rdd
intersectionVertices.checkpoint()
edges_rdd.checkpoint()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>edges_rdd: org.apache.spark.rdd.RDD[org.apache.spark.graphx.Edge[Long]] = MapPartitionsRDD[214] at rdd at command-1211269020742708:2
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val roadGraph = Graph(intersectionVertices, edges_rdd).cache
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>roadGraph: org.apache.spark.graphx.Graph[(Double, Double, scala.collection.immutable.Map[Long,(Array[(Long, Double, Double)], Array[(Long, Double, Double)])]),Long] = org.apache.spark.graphx.impl.GraphImpl@69447e5c
</code></pre>
</div>
</div>
<div class="cell markdown">
<h3 id="step-3---construction-of-a-weighted-road-graph"><a class="header" href="#step-3---construction-of-a-weighted-road-graph">Step 3 - Construction of a Weighted Road Graph</a></h3>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">import com.esri.core.geometry.GeometryEngine.geodesicDistanceOnWGS84
import com.esri.core.geometry.Point
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>import com.esri.core.geometry.GeometryEngine.geodesicDistanceOnWGS84
import com.esri.core.geometry.Point
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val weightedRoadGraph = roadGraph.mapTriplets{triplet =&gt; 
  def dist(lat1: Double, long1: Double, lat2: Double, long2: Double): Double = {
    val p1 = new Point(long1, lat1)
    val p2 = new Point(long2, lat2)
    geodesicDistanceOnWGS84(p1, p2)
  }
  
  val wayNodesInBuff = triplet.dstAttr._3(triplet.attr)._1 //dstAttr is the vertex attribute (latitude, longitude, wayMap(wayId -&gt; inBuff, outBuff))
  
  if (wayNodesInBuff.isEmpty) {
      (triplet.attr, dist(triplet.srcAttr._1, triplet.srcAttr._2, triplet.dstAttr._1, triplet.dstAttr._2))
  
  } else {
      var distance: Double = 0.0

      distance += dist(triplet.srcAttr._1, triplet.srcAttr._2, wayNodesInBuff(0)._2, wayNodesInBuff(0)._3 )
    
      if (wayNodesInBuff.length &gt; 1) {
      //accumulate the intermediate distances 
        distance += wayNodesInBuff.sliding(2).map{
        buff =&gt; dist(buff(0)._2, buff(0)._3, buff(1)._2, buff(1)._3)}
        .reduce(_ + _)
     }
    
      distance += dist(wayNodesInBuff.last._2, wayNodesInBuff.last._3, triplet.dstAttr._1, triplet.dstAttr._2)

      (triplet.attr, distance)
    }
  
}.cache
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>weightedRoadGraph: org.apache.spark.graphx.Graph[(Double, Double, scala.collection.immutable.Map[Long,(Array[(Long, Double, Double)], Array[(Long, Double, Double)])]),(Long, Double)] = org.apache.spark.graphx.impl.GraphImpl@1645750f
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">weightedRoadGraph.edges.count() //number of edges 
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res21: Long = 237069
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">weightedRoadGraph.edges.filter(edge =&gt; (edge.attr._2 &gt; 100.0)).count() //number of suffering edges with a distance tolerance of 100 meters 
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res22: Long = 137207
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">weightedRoadGraph.vertices.count() //number of vertices 
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res23: Long = 191991
</code></pre>
</div>
</div>
<div class="cell markdown">
<h3 id="step-4---construction-of-coarsened-road-graph"><a class="header" href="#step-4---construction-of-coarsened-road-graph">Step 4 - Construction of Coarsened Road Graph</a></h3>
<ul>
<li>The distance tolerance here is set to 100 meters.</li>
</ul>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">import org.apache.spark.graphx.{Edge =&gt; Edges}
val splittedEdges = weightedRoadGraph.triplets.flatMap{triplet =&gt; {
  def dist(lat1: Double, long1: Double, lat2: Double, long2: Double): Double = {
    val p1 = new Point(long1, lat1)
    val p2 = new Point(long2, lat2)
    geodesicDistanceOnWGS84(p1, p2)
  }
  val maxDist = 100
  var finalResult = Array[(Edges[(Long,  Double)], (Long, (Double, Double, Map[Long,(Array[(Long, Double, Double)], Array[(Long, Double, Double)])])), (Long, (Double, Double, Map[Long,(Array[(Long, Double, Double)], Array[(Long, Double, Double)])])))]()
  
  if(triplet.attr._2 &gt; maxDist){                            
    val wayId = triplet.attr._1
    var wayNodesBuff = triplet.dstAttr._3(wayId)._1 
    var wayNodesBuffSize = wayNodesBuff.length
    
    if(wayNodesBuffSize &gt; 0){
      var previousSrc = triplet.srcId

      var distance: Double = 0.0
      var currentBuff = Array[(Long, Double, Double)]()
      
      distance += dist(triplet.srcAttr._1, triplet.srcAttr._2, wayNodesBuff(0)._2, wayNodesBuff(0)._3) 
      
      var newVertex = (triplet.srcId, triplet.srcAttr)
      var previousVertex = newVertex
      
      if (distance &gt; maxDist){
        newVertex = (wayNodesBuff(0)._1, (wayNodesBuff(0)._2, wayNodesBuff(0)._3, Map(wayId -&gt; (Array[(Long, Double, Double)](), Array[(Long, Double, Double)]()))))
            
        finalResult +:= (Edges(previousSrc, wayNodesBuff(0)._1, (wayId, distance)), previousVertex, newVertex) 
        
        previousVertex = newVertex
        
        distance = 0
        previousSrc = wayNodesBuff(0)._1
      }
      else 
      {
        currentBuff +:= wayNodesBuff(0)
      }
         
      //loop through pairs of nodes in the way (in the buffer)
      if (wayNodesBuff.length &gt; 1){
      wayNodesBuff.sliding(2).foreach{segment =&gt; {
        
        val tmp_dst = distance
        distance += dist(segment(0)._2, segment(0)._3, segment(1)._2, segment(1)._3)
        
        if (distance &gt; maxDist)
        {
          if(segment(0)._1 != previousSrc){
              //      Vertex(nodeId,      (lat,                long,     Map(wayId-&gt;inBuff, outBuff)))
            newVertex = (segment(0)._1, (segment(0)._2, segment(0)._3, Map(wayId -&gt; (currentBuff, Array[(Long, Double, Double)]()))) )

            //adds the edge to the array
            finalResult +:= (Edges(previousSrc, segment(0)._1, (wayId, tmp_dst)), previousVertex, newVertex)

            previousVertex = newVertex
            distance -= tmp_dst
            previousSrc = segment(0)._1
            currentBuff = Array[(Long, Double, Double)]()
          }    
        }
        else 
        {
          currentBuff +:= segment(0)
        }
      }}}
      
      
      //from last node in the inBuff to the dst
      val tmp_dist = distance
      distance += dist(wayNodesBuff.last._2, wayNodesBuff.last._3, triplet.dstAttr._1, triplet.dstAttr._2)
      if (distance &gt; maxDist){
        if (wayNodesBuff.last._1 != previousSrc){
            newVertex = (wayNodesBuff.last._1, (wayNodesBuff.last._2, wayNodesBuff.last._3, Map(wayId -&gt; (currentBuff, Array[(Long, Double, Double)]()))))
            finalResult +:= (Edges(previousSrc, wayNodesBuff.last._1, (wayId, tmp_dist)), previousVertex, newVertex) 
            previousVertex = newVertex
            distance -= tmp_dist
            previousSrc = wayNodesBuff.last._1 
            currentBuff = Array[(Long, Double, Double)]()
            newVertex = (triplet.dstId, (triplet.dstAttr._1, triplet.dstAttr._2, Map(wayId -&gt; (currentBuff, triplet.dstAttr._3(wayId)._2))) )
        }
      }
      finalResult +:= (Edges(previousSrc, triplet.dstId, (wayId, distance)), previousVertex, newVertex)
      
    }
    // Distance &gt; threshold but no nodes in the way (buffer)
    else
    {
      finalResult +:= (Edges(triplet.srcId, triplet.dstId, triplet.attr), (triplet.srcId, triplet.srcAttr), (triplet.dstId, triplet.dstAttr))
    }
  }
  // Distance &lt; threshold
  else
  {
    finalResult +:= (Edges(triplet.srcId, triplet.dstId, triplet.attr), (triplet.srcId, triplet.srcAttr), (triplet.dstId, triplet.dstAttr))
  }
  
  // return
  finalResult
}}
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>import org.apache.spark.graphx.{Edge=&gt;Edges}
splittedEdges: org.apache.spark.rdd.RDD[(org.apache.spark.graphx.Edge[(Long, Double)], (Long, (Double, Double, scala.collection.immutable.Map[Long,(Array[(Long, Double, Double)], Array[(Long, Double, Double)])])), (Long, (Double, Double, scala.collection.immutable.Map[Long,(Array[(Long, Double, Double)], Array[(Long, Double, Double)])])))] = MapPartitionsRDD[245] at flatMap at command-1211269020742721:2
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">splittedEdges.count() 
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res28: Long = 734682
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Taking each edge and its reverse
val segmentedEdges = splittedEdges.flatMap{case(edge, srcVertex, dstVertex) =&gt; Array(edge)}
segmentedEdges.count() 
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>segmentedEdges: org.apache.spark.rdd.RDD[org.apache.spark.graphx.Edge[(Long, Double)]] = MapPartitionsRDD[246] at flatMap at command-1211269020742724:2
res29: Long = 734682
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Taking the individual vertices
val segmentedVertices = splittedEdges.flatMap{case(edge, srcVertex, dstVertex) =&gt; Array(srcVertex) ++ Array(dstVertex)}

segmentedVertices.map(node =&gt; node._1).distinct().count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>segmentedVertices: org.apache.spark.rdd.RDD[(Long, (Double, Double, scala.collection.immutable.Map[Long,(Array[(Long, Double, Double)], Array[(Long, Double, Double)])]))] = MapPartitionsRDD[240] at flatMap at command-1211269020742727:2
res27: Long = 685121
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Converting the vertices to a df
val verticesDF = segmentedVertices.toDF(&quot;nodeId&quot;,&quot;attr&quot;).select($&quot;nodeId&quot;,$&quot;attr._1&quot;.as(&quot;lat&quot;),$&quot;attr._2&quot;.as(&quot;long&quot;),explode($&quot;attr._3&quot;))
    .withColumnRenamed(&quot;key&quot;,&quot;wayId&quot;).withColumnRenamed(&quot;value&quot;,&quot;buffers&quot;)
    .select($&quot;nodeId&quot;,$&quot;lat&quot;,$&quot;long&quot;,$&quot;wayId&quot;,$&quot;buffers._1&quot;.as(&quot;inBuff&quot;),$&quot;buffers._2&quot;.as(&quot;outBuff&quot;))
  
verticesDF.show(1,false)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+----------+---------+------------------+---------+------+-------+
|nodeId    |lat      |long              |wayId    |inBuff|outBuff|
+----------+---------+------------------+---------+------+-------+
|5109322585|54.647108|25.128094200000003|137882502|[]    |[]     |
+----------+---------+------------------+---------+------+-------+
only showing top 1 row

verticesDF: org.apache.spark.sql.DataFrame = [nodeId: bigint, lat: double ... 4 more fields]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">//unique wayIds of the edges
val nodesWayId = splittedEdges.map{case(edge, srcVertex, dstVertex) =&gt; edge.attr._1}.toDF(&quot;nodesWayId&quot;).dropDuplicates() 
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>nodesWayId: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [nodesWayId: bigint]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Only vertices which have a wayId in their Map that is not included in any edge
// Dead end means there are no other intersection vertex in the way
val verticesWithDeadEndWays = verticesDF.join(nodesWayId, $&quot;nodesWayId&quot; === $&quot;wayId&quot;, &quot;leftanti&quot;) 
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>verticesWithDeadEndWays: org.apache.spark.sql.DataFrame = [nodeId: bigint, lat: double ... 4 more fields]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">//convert df to rdd to be joined later with the rest of the vertices
import scala.collection.mutable.WrappedArray
val verticesWithDeadEndWaysRDD = verticesWithDeadEndWays.rdd.map(row =&gt; (row.getLong(0),(row.getDouble(1),row.getDouble(2),Map(row.getLong(3)-&gt; (row.getAs[WrappedArray[(Long, Double, Double)]](4).array,row.getAs[WrappedArray[(Long, Double, Double)]](5).array)))))
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>import scala.collection.mutable.WrappedArray
verticesWithDeadEndWaysRDD: org.apache.spark.rdd.RDD[(Long, (Double, Double, scala.collection.immutable.Map[Long,(Array[(Long, Double, Double)], Array[(Long, Double, Double)])]))] = MapPartitionsRDD[264] at map at command-1211269020742731:3
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// for a node appearing in different ways, returns one vertex for each way
val verticesWithSharedWays = splittedEdges.flatMap{case(edge, srcVertex, dstVertex) =&gt; 
  {
    val srcVertex1 = (srcVertex._1,(srcVertex._2._1,srcVertex._2._2,Map(edge.attr._1 -&gt; srcVertex._2._3(edge.attr._1))))
    val dstVertex1 = (dstVertex._1,(dstVertex._2._1,dstVertex._2._2,Map(edge.attr._1 -&gt; dstVertex._2._3(edge.attr._1))))

    Array(srcVertex1) ++ Array(dstVertex1)
  }}.distinct()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>verticesWithSharedWays: org.apache.spark.rdd.RDD[(Long, (Double, Double, scala.collection.immutable.Map[Long,(Array[(Long, Double, Double)], Array[(Long, Double, Double)])]))] = MapPartitionsRDD[268] at distinct at command-1211269020742732:8
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">//union of verticesWithDeadEndWaysRDD and verticesWithSharedWays and reduced adding the maps 
val allVertices = verticesWithSharedWays.union(verticesWithDeadEndWaysRDD).reduceByKey((a,b) =&gt; (a._1, a._2, a._3 ++ b._3)) 
allVertices.count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>allVertices: org.apache.spark.rdd.RDD[(Long, (Double, Double, scala.collection.immutable.Map[Long,(Array[(Long, Double, Double)], Array[(Long, Double, Double)])]))] = ShuffledRDD[270] at reduceByKey at command-1211269020742733:2
res34: Long = 685121
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">dbutils.fs.mkdirs(&quot;/_checkpoint1&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res36: Boolean = true
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">sc.setCheckpointDir(&quot;/_checkpoint1&quot;) // just a directory in distributed file system
allVertices.checkpoint()
segmentedEdges.checkpoint()
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val coarsened_graph_100 = Graph(allVertices, segmentedEdges)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>coarsened_graph_100: org.apache.spark.graphx.Graph[(Double, Double, scala.collection.immutable.Map[Long,(Array[(Long, Double, Double)], Array[(Long, Double, Double)])]),(Long, Double)] = org.apache.spark.graphx.impl.GraphImpl@128b8420
</code></pre>
</div>
</div>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../../contents/000_5-sds-2-x-geo/033_01_OSMtoGraphXUppsalaTiny.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next" href="../../contents/000_5-sds-2-x-geo/033_03_LT_PageRank.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../../contents/000_5-sds-2-x-geo/033_01_OSMtoGraphXUppsalaTiny.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next" href="../../contents/000_5-sds-2-x-geo/033_03_LT_PageRank.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="../../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="../../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->


    </body>
</html>

<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>035_05_UndirectedG0 - sds-3.x/ScaDaMaLe</title>


        <!-- Custom HTML head -->

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="../../favicon.svg">
        <link rel="shortcut icon" href="../../favicon.png">
        <link rel="stylesheet" href="../../css/variables.css">
        <link rel="stylesheet" href="../../css/general.css">
        <link rel="stylesheet" href="../../css/chrome.css">
        <link rel="stylesheet" href="../../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../../highlight.css">
        <link rel="stylesheet" href="../../tomorrow-night.css">
        <link rel="stylesheet" href="../../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../../scroll-mdbook-outputs.css">

        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/000_5-sds-2-x-geo-changes.html">000_5-sds-2-x-geo-changes</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/001_CrashCourseGIS.html">001_CrashCourseGIS</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/031_GeospatialAnalyticsInMagellan.html">031_GeospatialAnalyticsInMagellan</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/031a_MagellanOSMIngestion.html">031a_MagellanOSMIngestion</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/032_NYtaxisInMagellan.html">032_NYtaxisInMagellan</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/032a_MSR_BeijingTaxiTrajectories_MagellanQueries.html">032a_MSR_BeijingTaxiTrajectories_MagellanQueries</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/032b_UberMapMatchingAndVisualization.html">032b_UberMapMatchingAndVisualization</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/032d_MobileSampleSQL.html">032d_MobileSampleSQL</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/032e_CallDetailRecords.html">032e_CallDetailRecords</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/032x_ComingAttractions.html">032x_ComingAttractions</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/033_00_Intro2PointsOnGraphs.html">033_00_Intro2PointsOnGraphs</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/033_01_OSMtoGraphXUppsalaTiny.html">033_01_OSMtoGraphXUppsalaTiny</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/033_02_OSMtoGraphX_LT.html">033_02_OSMtoGraphX_LT</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/033_03_LT_PageRank.html">033_03_LT_PageRank</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/034_01_MapMatching_with_GeoMatch_UppsalaTiny.html">034_01_MapMatching_with_GeoMatch_UppsalaTiny</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/034_02_MapMatching_on_a_Graph_UppsalaTiny.html">034_02_MapMatching_on_a_Graph_UppsalaTiny</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/034_03_MapMatching_on_a_Graph_LT.html">034_03_MapMatching_on_a_Graph_LT</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/034_04_MapMatching_on_a_G1_LT.html">034_04_MapMatching_on_a_G1_LT</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/034_05DistributionOfStates.html">034_05DistributionOfStates</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/034_06SimulatingArrivalTimesNHPP_Inversion.html">034_06SimulatingArrivalTimesNHPP_Inversion</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_01_Arcgis_coordinates_transformation.html">035_01_Arcgis_coordinates_transformation</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_02_Segmentation_municipalities_Magellan.html">035_02_Segmentation_municipalities_Magellan</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_03_Visualization_municipalities.html">035_03_Visualization_municipalities</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_04_MapMatching_intersections.html">035_04_MapMatching_intersections</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_05_UndirectedG0.html" class="active">035_05_UndirectedG0</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_06_ConnectedComponent_PageRank.html">035_06_ConnectedComponent_PageRank</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_07_PoissonRegression.html">035_07_PoissonRegression</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">sds-3.x/ScaDaMaLe</h1>

                    <div class="right-buttons">
                        <a href="../../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <div class="cell markdown">
<p>ScaDaMaLe Course <a href="https://lamastex.github.io/scalable-data-science/sds/3/x/">site</a> and <a href="https://lamastex.github.io/ScaDaMaLe/index.html">book</a></p>
</div>
<div class="cell markdown">
<h2 id="creating-g0-with-edges-in-the-two-directions"><a class="header" href="#creating-g0-with-edges-in-the-two-directions">Creating G0 with edges in the two directions.</a></h2>
<p>Virginia Jimenez Mohedano (<a href="https://www.linkedin.com/in/virginiajimenezmohedano/">LinkedIn</a>) and Raazesh Sainudiin (<a href="https://www.linkedin.com/in/raazesh-sainudiin-45955845/">LinkedIn</a>).</p>
<pre><code>This project was supported by UAB SENSMETRY through a Data Science Thesis Internship 
between 2022-01-17 and 2022-06-05 to Virginia J.M. and 
Databricks University Alliance with infrastructure credits from AWS to 
Raazesh Sainudiin, Department of Mathematics, Uppsala University, Sweden.
</code></pre>
<p>2022, Uppsala, Sweden</p>
</div>
<div class="cell markdown">
<h3 id="step-1---osm-to-graphx"><a class="header" href="#step-1---osm-to-graphx">Step 1 - OSM to GraphX</a></h3>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">import crosby.binary.osmosis.OsmosisReader

import org.apache.hadoop.mapreduce.{TaskAttemptContext, JobContext}
import org.apache.hadoop.fs.FileSystem
import org.apache.hadoop.conf.Configuration
import org.apache.hadoop.fs.Path

import org.openstreetmap.osmosis.core.container.v0_6.EntityContainer
import org.openstreetmap.osmosis.core.domain.v0_6._
import org.openstreetmap.osmosis.core.task.v0_6.Sink

import sqlContext.implicits._

import scala.collection.mutable.ArrayBuffer
import scala.collection.mutable.Map
import scala.collection.JavaConversions._

import org.apache.spark.sql.functions._
import org.apache.spark.graphx._
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>import crosby.binary.osmosis.OsmosisReader
import org.apache.hadoop.mapreduce.{TaskAttemptContext, JobContext}
import org.apache.hadoop.fs.FileSystem
import org.apache.hadoop.conf.Configuration
import org.apache.hadoop.fs.Path
import org.openstreetmap.osmosis.core.container.v0_6.EntityContainer
import org.openstreetmap.osmosis.core.domain.v0_6._
import org.openstreetmap.osmosis.core.task.v0_6.Sink
import sqlContext.implicits._
import scala.collection.mutable.ArrayBuffer
import scala.collection.mutable.Map
import scala.collection.JavaConversions._
import org.apache.spark.sql.functions._
import org.apache.spark.graphx._
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Read the parquet files for nodes and ways obtained from the osm-parquetizer.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">spark.conf.set(&quot;spark.sql.parquet.binaryAsString&quot;, true)

val nodes_df = spark.read.parquet(&quot;dbfs:/datasets/osm/lithuania/lithuania.osm.pbf.node.parquet&quot;)
val ways_df = spark.read.parquet(&quot;dbfs:/datasets/osm/lithuania/lithuania.osm.pbf.way.parquet&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>nodes_df: org.apache.spark.sql.DataFrame = [id: bigint, version: int ... 7 more fields]
ways_df: org.apache.spark.sql.DataFrame = [id: bigint, version: int ... 6 more fields]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val allowableWays2 = Seq(
  &quot;motorway&quot;,
  &quot;motorway_link&quot;,
  &quot;trunk&quot;,
  &quot;trunk_link&quot;,
  &quot;primary&quot;,
  &quot;primary_link&quot;,
  &quot;secondary&quot;,
  &quot;secondary_link&quot;,
  &quot;tertiary&quot;,
  &quot;tertiary_link&quot;,
  &quot;living_street&quot;,
  &quot;residential&quot;,
  &quot;road&quot;,
  &quot;construction&quot;,
  &quot;motorway_junction&quot;,
  &quot;unclassified&quot;
)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>allowableWays2: Seq[String] = List(motorway, motorway_link, trunk, trunk_link, primary, primary_link, secondary, secondary_link, tertiary, tertiary_link, living_street, residential, road, construction, motorway_junction, unclassified)
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">//convert the nodes to Dataset containing the fields of interest

case class NodeEntry(nodeId: Long, latitude: Double, longitude: Double, tags: Seq[String])

val nodeDS = nodes_df.map(node =&gt; 
  NodeEntry(node.getAs[Long](&quot;id&quot;),
       node.getAs[Double](&quot;latitude&quot;),
       node.getAs[Double](&quot;longitude&quot;),
       node.getAs[Seq[Row]](&quot;tags&quot;).map{case Row(key:String, value:String) =&gt; value}
)).cache()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>defined class NodeEntry
nodeDS: org.apache.spark.sql.Dataset[NodeEntry] = [nodeId: bigint, latitude: double ... 2 more fields]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">//convert the ways to Dataset containing the fields of interest

case class WayEntry(wayId: Long, tags: Array[String], nodes: Array[Long])

val wayDS2 = ways_df.flatMap(way =&gt; {
        val tagSet = way.getAs[Seq[Row]](&quot;tags&quot;).map{case Row(key:String, value:String) =&gt;  value}.toArray
        if (tagSet.intersect(allowableWays2).nonEmpty ){
            Array(WayEntry(way.getAs[Long](&quot;id&quot;),
            tagSet,
            way.getAs[Seq[Row]](&quot;nodes&quot;).map{case Row(index:Integer, nodeId:Long) =&gt;  nodeId}.toArray
            ))
        }
        else { Array[WayEntry]()}
}
).cache()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>defined class WayEntry
wayDS: org.apache.spark.sql.Dataset[WayEntry] = [wayId: bigint, tags: array&lt;string&gt; ... 1 more field]
wayDS2: org.apache.spark.sql.Dataset[WayEntry] = [wayId: bigint, tags: array&lt;string&gt; ... 1 more field]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">wayDS2.count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res4: Long = 162174
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">import org.apache.spark.sql.functions.explode
val nodeCounts2 = wayDS2
                    .select(explode('nodes).as(&quot;node&quot;))
                    .groupBy('node).count

//nodeCounts.show(5)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>import org.apache.spark.sql.functions.explode
nodeCounts: org.apache.spark.sql.DataFrame = [node: bigint, count: bigint]
nodeCounts2: org.apache.spark.sql.DataFrame = [node: bigint, count: bigint]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val intersectionNodes2 = nodeCounts2.filter('count &gt;= 2).select('node.alias(&quot;intersectionNode&quot;))
val true_intersections2 = intersectionNodes2
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>intersectionNodes: org.apache.spark.sql.DataFrame = [intersectionNode: bigint]
true_intersections: org.apache.spark.sql.DataFrame = [intersectionNode: bigint]
intersectionNodes2: org.apache.spark.sql.DataFrame = [intersectionNode: bigint]
true_intersections2: org.apache.spark.sql.DataFrame = [intersectionNode: bigint]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">intersectionNodes2.count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res7: Long = 203996
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val distinctNodesWays2 = wayDS2.flatMap(_.nodes).distinct
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>distinctNodesWays: org.apache.spark.sql.Dataset[Long] = [value: bigint]
distinctNodesWays2: org.apache.spark.sql.Dataset[Long] = [value: bigint]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">distinctNodesWays2.count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res10: Long = 1717461
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val wayNodes2 = nodeDS.as(&quot;nodes&quot;) //nodes that are in a way + nodes info from nodeDS
  .joinWith(distinctNodesWays2.as(&quot;ways&quot;), $&quot;ways.value&quot; === $&quot;nodes.nodeId&quot;)
  .map(_._1).cache
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>wayNodes: org.apache.spark.sql.Dataset[NodeEntry] = [nodeId: bigint, latitude: double ... 2 more fields]
wayNodes2: org.apache.spark.sql.Dataset[NodeEntry] = [nodeId: bigint, latitude: double ... 2 more fields]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">import org.apache.spark.sql.functions.{collect_list, map, udf}
import org.apache.spark.sql.functions._

// I assume that each &quot;nodes&quot; sequence contains at least one node
// We do not really need first and last elements from the sequence and when combining with original nodes, just we assign them &quot;true&quot;

val remove_first_and_last = udf((x: Seq[Long]) =&gt; x.drop(1).dropRight(1))

val nodes2 = wayDS2.
  select($&quot;wayId&quot;, $&quot;nodes&quot;).
  withColumn(&quot;node&quot;, explode($&quot;nodes&quot;)).
  drop(&quot;nodes&quot;)

val get_first_and_last = udf((x: Seq[Long]) =&gt; {val first = x(0); val last = x.reverse(0); Array(first, last)})

val first_and_last_nodes2 = wayDS2.
  select($&quot;wayId&quot;, get_first_and_last($&quot;nodes&quot;).as(&quot;nodes&quot;)).
  withColumn(&quot;node&quot;, explode($&quot;nodes&quot;)).
  drop(&quot;nodes&quot;)

val fake_intersections2 = first_and_last_nodes2.select($&quot;node&quot;).distinct().withColumnRenamed(&quot;node&quot;, &quot;value&quot;)

// Turn intersection set into a dataset to join (all values must be unique)
val intersections2 = intersectionNodes2.union(fake_intersections2).distinct

val wayNodesLocated2 = nodes2.join(wayNodes2, wayNodes2.col(&quot;nodeId&quot;) === nodes2.col(&quot;node&quot;)).select($&quot;wayId&quot;, $&quot;node&quot;, $&quot;latitude&quot;, $&quot;longitude&quot;)

case class MappedWay(wayId: Long, labels_located: Seq[Map[Long, (Boolean, Double, Double)]])

val maps2 = wayNodesLocated2.join(intersections2, 'node === 'intersectionNode, &quot;left_outer&quot;).
  //left outer joins returns all rows from the left DataFrame/Dataset regardless of match found on the right dataset
    select($&quot;wayId&quot;, $&quot;node&quot;, $&quot;intersectionNode&quot;.isNotNull.as(&quot;contains&quot;), $&quot;latitude&quot;, $&quot;longitude&quot;).
   groupBy(&quot;wayId&quot;).agg(collect_list(map($&quot;node&quot;, struct($&quot;contains&quot;.as(&quot;_1&quot;), $&quot;latitude&quot;.as(&quot;_2&quot;), $&quot;longitude&quot;.as(&quot;_3&quot;)))).as(&quot;labels_located&quot;)).as[MappedWay]  

val combine = udf((nodes: Seq[Long], labels_located: Seq[scala.collection.immutable.Map[Long, (Boolean, Double, Double)]]) =&gt; {
  // If labels does not have &quot;node&quot;, then it is either start/end - we assign label = true, latitude = 0, longitude = 0 for it, TO DO: revise it later, not sure
  val m = labels_located.map(_.toSeq).flatten.toMap

  nodes.map { node =&gt; (node, m.getOrElse(node, (true, 0D, 0D))) } //add structure

})


val strSchema = &quot;array&lt;struct&lt;nodeId:long, nodeInfo:struct&lt;label:boolean, latitude:double, longitude: double&gt;&gt;&gt;&quot;
val labeledWays2 = wayDS2.join(maps2, &quot;wayId&quot;)
                     .select($&quot;wayId&quot;, $&quot;tags&quot;, combine($&quot;nodes&quot;, $&quot;labels_located&quot;).as(&quot;labeledNodes&quot;).cast(strSchema))
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>import org.apache.spark.sql.functions.{collect_list, map, udf}
import org.apache.spark.sql.functions._
remove_first_and_last: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(&lt;function1&gt;,ArrayType(LongType,false),Some(List(ArrayType(LongType,false))))
nodes: org.apache.spark.sql.DataFrame = [wayId: bigint, node: bigint]
nodes2: org.apache.spark.sql.DataFrame = [wayId: bigint, node: bigint]
get_first_and_last: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(&lt;function1&gt;,ArrayType(LongType,false),Some(List(ArrayType(LongType,false))))
first_and_last_nodes: org.apache.spark.sql.DataFrame = [wayId: bigint, node: bigint]
first_and_last_nodes2: org.apache.spark.sql.DataFrame = [wayId: bigint, node: bigint]
fake_intersections: org.apache.spark.sql.DataFrame = [value: bigint]
fake_intersections2: org.apache.spark.sql.DataFrame = [value: bigint]
intersections: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [intersectionNode: bigint]
intersections2: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [intersectionNode: bigint]
wayNodesLocated: org.apache.spark.sql.DataFrame = [wayId: bigint, node: bigint ... 2 more fields]
wayNodesLocated2: org.apache.spark.sql.DataFrame = [wayId: bigint, node: bigint ... 2 more fields]
defined class MappedWay
maps: org.apache.spark.sql.Dataset[MappedWay] = [wayId: bigint, labels_located: array&lt;map&lt;bigint,struct&lt;_1:boolean,_2:double,_3:double&gt;&gt;&gt;]
maps2: org.apache.spark.sql.Dataset[MappedWay] = [wayId: bigint, labels_located: array&lt;map&lt;bigint,struct&lt;_1:boolean,_2:double,_3:double&gt;&gt;&gt;]
combine: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(&lt;function2&gt;,ArrayType(StructType(StructField(_1,LongType,false), StructField(_2,StructType(StructField(_1,BooleanType,false), StructField(_2,DoubleType,false), StructField(_3,DoubleType,false)),true)),true),Some(List(ArrayType(LongType,false), ArrayType(MapType(LongType,StructType(StructField(_1,BooleanType,false), StructField(_2,DoubleType,false), StructField(_3,DoubleType,false)),true),true))))
strSchema: String = array&lt;struct&lt;nodeId:long, nodeInfo:struct&lt;label:boolean, latitude:double, longitude: double&gt;&gt;&gt;
labeledWays: org.apache.spark.sql.DataFrame = [wayId: bigint, tags: array&lt;string&gt; ... 1 more field]
labeledWays2: org.apache.spark.sql.DataFrame = [wayId: bigint, tags: array&lt;string&gt; ... 1 more field]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">case class Intersection(OSMId: Long , latitude: Double, longitude: Double, inBuf: ArrayBuffer[(Long, Double, Double)], outBuf: ArrayBuffer[(Long, Double, Double)])

val segmentedWays2 = labeledWays2.map(way =&gt; {
  
  val labeledNodes = way.getAs[Seq[Row]](&quot;labeledNodes&quot;).map{case Row(k: Long, Row(v: Boolean, w:Double, x:Double)) =&gt; (k, v,w,x)}.toSeq //labeledNodes: (nodeid, label, lat, long)
  val wayId = way.getAs[Long](&quot;wayId&quot;)
  
  val indexedNodes: Seq[((Long, Boolean, Double, Double), Int)] = labeledNodes.zipWithIndex //appends an integer as an index to every labeledNodes in a way
  
  val intersections = ArrayBuffer[Intersection]()  
  
  val currentBuffer = ArrayBuffer[(Long, Double, Double)]()
  
  val way_length = labeledNodes.length //number of nodes in a way
  
  if (way_length == 1) {

    val intersect = new Intersection(labeledNodes(0)._1, labeledNodes(0)._3, labeledNodes(0)._4, ArrayBuffer((-1L, 0D, 0D)), ArrayBuffer((-1L, 0D, 0D))) //include lat and long info

    var result = Array((intersect.OSMId, intersect.latitude, intersect.longitude, intersect.inBuf.toArray, intersect.outBuf.toArray))
    (wayId, result) //return
  }
  else {
    indexedNodes.foreach{ case ((id, isIntersection, latitude, longitude), i) =&gt; // id is nodeId and isIntersection is the node label
      if (isIntersection) {
        val newEntry = new Intersection(id, latitude, longitude, currentBuffer.clone, ArrayBuffer[(Long, Double, Double)]())
        intersections += newEntry
        currentBuffer.clear
      }
      else {
        currentBuffer ++= Array((id, latitude, longitude))  //if the node is not an intersection append the nodeId to the current buffer 
      }
      
      // Reaches the end of the way while the outBuffer is not empty
      // Append the currentBuffer to the last intersection
      if (i == way_length - 1 &amp;&amp; !currentBuffer.isEmpty) {  
        if (intersections.isEmpty){
        intersections += new Intersection(-1, 0D, 0D, currentBuffer, ArrayBuffer[(Long, Double, Double)]()) 
        }
        else {
          intersections.last.outBuf ++= currentBuffer
        }
        currentBuffer.clear
      }
    }
    var result = intersections.map(i =&gt; (i.OSMId, i.latitude, i.longitude, i.inBuf.toArray, i.outBuf.toArray)).toArray  
    (wayId, result) 
  }
})
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>defined class Intersection
segmentedWays2: org.apache.spark.sql.Dataset[(Long, Array[(Long, Double, Double, Array[(Long, Double, Double)], Array[(Long, Double, Double)])])] = [_1: bigint, _2: array&lt;struct&lt;_1:bigint,_2:double,_3:double,_4:array&lt;struct&lt;_1:bigint,_2:double,_3:double&gt;&gt;,_5:array&lt;struct&lt;_1:bigint,_2:double,_3:double&gt;&gt;&gt;&gt;]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">segmentedWays2.count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res31: Long = 162174
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">//The nested structure of the segmentedWays is unwrapped
val waySegmentDS2 = segmentedWays2.flatMap(way =&gt; way._2.map(node =&gt; (way._1, node))) 

// for each (wayId, Array(IntersectionNode) =&gt; (wayId, IntersectionNode)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>waySegmentDS: org.apache.spark.sql.Dataset[(Long, (Long, Double, Double, Array[(Long, Double, Double)], Array[(Long, Double, Double)]))] = [_1: bigint, _2: struct&lt;_1: bigint, _2: double ... 3 more fields&gt;]
waySegmentDS2: org.apache.spark.sql.Dataset[(Long, (Long, Double, Double, Array[(Long, Double, Double)], Array[(Long, Double, Double)]))] = [_1: bigint, _2: struct&lt;_1: bigint, _2: double ... 3 more fields&gt;]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">import scala.collection.immutable.Map

//returns the intersection nodes with the ways where they appear mapped with the nodes in those ways (inBuff, outBuff) 
val intersectionVertices2 = waySegmentDS2
  .map(way =&gt; 
   //nodeId     latitude   longitude      wayId      inBuff      outBuff
   (way._2._1, (way._2._2, way._2._3, Map(way._1 -&gt; (way._2._4, way._2._5))))) 
  .rdd
  //                     latitude, long, Map(wayId, inBuff, outBuff)
  .reduceByKey((a,b) =&gt; (a._1,     a._2, a._3 ++ b._3)) 

//intersectionVertices =  RDD[(nodeId, (latitude, longitude, wayMap(wayId -&gt; inBuff, outBuff)))]
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>import scala.collection.immutable.Map
intersectionVertices: org.apache.spark.rdd.RDD[(Long, (Double, Double, scala.collection.immutable.Map[Long,(Array[(Long, Double, Double)], Array[(Long, Double, Double)])]))] = ShuffledRDD[86] at reduceByKey at command-3445861289894304:10
intersectionVertices2: org.apache.spark.rdd.RDD[(Long, (Double, Double, scala.collection.immutable.Map[Long,(Array[(Long, Double, Double)], Array[(Long, Double, Double)])]))] = ShuffledRDD[166] at reduceByKey at command-3445861289894304:17
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">intersectionVertices2.count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res34: Long = 232137
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">intersectionVertices2.map(vertex =&gt; (vertex._1, vertex._2)).toDF(&quot;id&quot;, &quot;Map&quot;).write.mode(&quot;overwrite&quot;).parquet(&quot;/_checkpoint/vertices_LT_initial_added_tags&quot;)
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val edges2 = segmentedWays2
  .filter(way =&gt; way._2.length &gt; 1) //ways with more than one intersections
  .flatMap{ case (wayId, nodes_info) =&gt; {  
             nodes_info.sliding(2) // For each way it takes nodes in pairs
               .flatMap(segment =&gt; //segment is the pair of two nodes
                   List(Edge(segment(0)._1, segment(1)._1, wayId))
               )
   }}
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>edges: org.apache.spark.sql.Dataset[org.apache.spark.graphx.Edge[Long]] = [srcId: bigint, dstId: bigint ... 1 more field]
edges2: org.apache.spark.sql.Dataset[org.apache.spark.graphx.Edge[Long]] = [srcId: bigint, dstId: bigint ... 1 more field]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val edges2_two_directions = segmentedWays2
  .filter(way =&gt; way._2.length &gt; 1) //ways with more than one intersections
  .flatMap{ case (wayId, nodes_info) =&gt; {  
             nodes_info.sliding(2) // For each way it takes nodes in pairs
               .flatMap(segment =&gt; //segment is the pair of two nodes
                   List(Edge(segment(0)._1, segment(1)._1, wayId),
                        Edge(segment(1)._1, segment(0)._1, wayId))
               )
   }}
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>edges_two_directions: org.apache.spark.sql.Dataset[org.apache.spark.graphx.Edge[Long]] = [srcId: bigint, dstId: bigint ... 1 more field]
edges2_two_directions: org.apache.spark.sql.Dataset[org.apache.spark.graphx.Edge[Long]] = [srcId: bigint, dstId: bigint ... 1 more field]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">edges2_two_directions.map(edge =&gt; (edge.srcId, edge.dstId)).toDF(&quot;src&quot;,&quot;dst&quot;).write.mode(&quot;overwrite&quot;).parquet(&quot;/_checkpoint/edges_LT_initial_two_directions_tags_added&quot;)
</code></pre>
</div>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../../contents/000_5-sds-2-x-geo/035_04_MapMatching_intersections.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next" href="../../contents/000_5-sds-2-x-geo/035_06_ConnectedComponent_PageRank.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../../contents/000_5-sds-2-x-geo/035_04_MapMatching_intersections.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next" href="../../contents/000_5-sds-2-x-geo/035_06_ConnectedComponent_PageRank.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="../../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="../../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->


    </body>
</html>

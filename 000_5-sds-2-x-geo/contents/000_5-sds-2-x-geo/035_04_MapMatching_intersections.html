<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>035_04_MapMatching_intersections - sds-3.x/ScaDaMaLe</title>


        <!-- Custom HTML head -->

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="../../favicon.svg">
        <link rel="shortcut icon" href="../../favicon.png">
        <link rel="stylesheet" href="../../css/variables.css">
        <link rel="stylesheet" href="../../css/general.css">
        <link rel="stylesheet" href="../../css/chrome.css">
        <link rel="stylesheet" href="../../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../../highlight.css">
        <link rel="stylesheet" href="../../tomorrow-night.css">
        <link rel="stylesheet" href="../../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../../scroll-mdbook-outputs.css">

        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/000_5-sds-2-x-geo-changes.html">000_5-sds-2-x-geo-changes</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/001_CrashCourseGIS.html">001_CrashCourseGIS</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/031_GeospatialAnalyticsInMagellan.html">031_GeospatialAnalyticsInMagellan</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/031a_MagellanOSMIngestion.html">031a_MagellanOSMIngestion</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/032_NYtaxisInMagellan.html">032_NYtaxisInMagellan</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/032a_MSR_BeijingTaxiTrajectories_MagellanQueries.html">032a_MSR_BeijingTaxiTrajectories_MagellanQueries</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/032b_UberMapMatchingAndVisualization.html">032b_UberMapMatchingAndVisualization</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/032d_MobileSampleSQL.html">032d_MobileSampleSQL</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/032e_CallDetailRecords.html">032e_CallDetailRecords</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/032x_ComingAttractions.html">032x_ComingAttractions</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/033_00_Intro2PointsOnGraphs.html">033_00_Intro2PointsOnGraphs</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/033_01_OSMtoGraphXUppsalaTiny.html">033_01_OSMtoGraphXUppsalaTiny</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/033_02_OSMtoGraphX_LT.html">033_02_OSMtoGraphX_LT</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/033_03_LT_PageRank.html">033_03_LT_PageRank</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/034_01_MapMatching_with_GeoMatch_UppsalaTiny.html">034_01_MapMatching_with_GeoMatch_UppsalaTiny</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/034_02_MapMatching_on_a_Graph_UppsalaTiny.html">034_02_MapMatching_on_a_Graph_UppsalaTiny</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/034_03_MapMatching_on_a_Graph_LT.html">034_03_MapMatching_on_a_Graph_LT</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/034_04_MapMatching_on_a_G1_LT.html">034_04_MapMatching_on_a_G1_LT</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/034_05DistributionOfStates.html">034_05DistributionOfStates</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/034_06SimulatingArrivalTimesNHPP_Inversion.html">034_06SimulatingArrivalTimesNHPP_Inversion</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_01_Arcgis_coordinates_transformation.html">035_01_Arcgis_coordinates_transformation</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_02_Segmentation_municipalities_Magellan.html">035_02_Segmentation_municipalities_Magellan</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_03_Visualization_municipalities.html">035_03_Visualization_municipalities</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_04_MapMatching_intersections.html" class="active">035_04_MapMatching_intersections</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_05_UndirectedG0.html">035_05_UndirectedG0</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_06_ConnectedComponent_PageRank.html">035_06_ConnectedComponent_PageRank</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_07_PoissonRegression.html">035_07_PoissonRegression</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">sds-3.x/ScaDaMaLe</h1>

                    <div class="right-buttons">
                        <a href="../../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <div class="cell markdown">
<p>ScaDaMaLe Course <a href="https://lamastex.github.io/scalable-data-science/sds/3/x/">site</a> and <a href="https://lamastex.github.io/ScaDaMaLe/index.html">book</a></p>
</div>
<div class="cell markdown">
<h2 id="map-matching-the-accident-with-their-closest-intersection-and-measuring-the-distance-between-them"><a class="header" href="#map-matching-the-accident-with-their-closest-intersection-and-measuring-the-distance-between-them">Map-matching the accident with their closest intersection and measuring the distance between them.</a></h2>
<p>Virginia Jimenez Mohedano (<a href="https://www.linkedin.com/in/virginiajimenezmohedano/">LinkedIn</a>) and Raazesh Sainudiin (<a href="https://www.linkedin.com/in/raazesh-sainudiin-45955845/">LinkedIn</a>).</p>
<pre><code>This project was supported by UAB SENSMETRY through a Data Science Thesis Internship 
between 2022-01-17 and 2022-06-05 to Virginia J.M. and 
Databricks University Alliance with infrastructure credits from AWS to 
Raazesh Sainudiin, Department of Mathematics, Uppsala University, Sweden.
</code></pre>
<p>2022, Uppsala, Sweden</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">import org.apache.spark.graphx._
import sqlContext.implicits._
import scala.collection.JavaConversions._
import org.cusp.bdi.gm.GeoMatch
import org.cusp.bdi.gm.geom.GMPoint
import org.cusp.bdi.gm.geom.GMLineString
import com.esri.arcgisruntime.geometry.{Point, SpatialReference, GeometryEngine}
import com.esri.arcgisruntime.geometry.GeometryEngine.project
import com.esri.arcgisruntime._

import com.esri.core.geometry.GeometryEngine.geodesicDistanceOnWGS84
import com.esri.core.geometry.{Point =&gt; Points}
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>import org.apache.spark.graphx._
import sqlContext.implicits._
import scala.collection.JavaConversions._
import org.cusp.bdi.gm.GeoMatch
import org.cusp.bdi.gm.geom.GMPoint
import org.cusp.bdi.gm.geom.GMLineString
import com.esri.arcgisruntime.geometry.{Point, SpatialReference, GeometryEngine}
import com.esri.arcgisruntime.geometry.GeometryEngine.project
import com.esri.arcgisruntime._
import com.esri.core.geometry.GeometryEngine.geodesicDistanceOnWGS84
import com.esri.core.geometry.{Point=&gt;Points}
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>In this notebook, we will find the intersections of the road network and extract their coordinates. Then, we load the accident data and use GeoMatch to match the accidents with their closest intersections. Later, when having the coordinates of both the intersections and the accidents, the distance between them is measured.</p>
</div>
<div class="cell markdown">
<h2 id="what-is-geomatch"><a class="header" href="#what-is-geomatch">What is GeoMatch</a></h2>
<p>GeoMatch is a novel, scalable, and efficient big-data pipeline for large-scale map matching on Apache Spark.</p>
<p>Read <a href="https://eprints.lancs.ac.uk/id/eprint/129165/1/GeoMatch_IEEE_BigData_preprint.pdf">GeoMatch: Efficient Large-Scale Map Matching on Apache Spark</a></p>
<p>The project is open source and all the relevant code can be found on the <a href="https://github.com/bdilab/GeoMatch">GeoMatch git repository</a>.</p>
<p>The jar library needs to be build from the git repository and uploaded to the cluster.</p>
</div>
<div class="cell markdown">
<h3 id="road-network"><a class="header" href="#road-network">Road Network</a></h3>
</div>
<div class="cell markdown">
<p>First, we want to obtain the intersections.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">spark.conf.set(&quot;spark.sql.parquet.binaryAsString&quot;, true)

val nodes_df = spark.read.parquet(&quot;dbfs:/datasets/osm/lithuania/lithuania.osm.pbf.node.parquet&quot;)
val ways_df = spark.read.parquet(&quot;dbfs:/datasets/osm/lithuania/lithuania.osm.pbf.way.parquet&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>nodes_df: org.apache.spark.sql.DataFrame = [id: bigint, version: int ... 7 more fields]
ways_df: org.apache.spark.sql.DataFrame = [id: bigint, version: int ... 6 more fields]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">//convert the nodes to Dataset containing the fields of interest

case class NodeEntry(nodeId: Long, latitude: Double, longitude: Double, tags: Seq[String])

val nodeDS = nodes_df.map(node =&gt; 
  NodeEntry(node.getAs[Long](&quot;id&quot;),
       node.getAs[Double](&quot;latitude&quot;),
       node.getAs[Double](&quot;longitude&quot;),
       node.getAs[Seq[Row]](&quot;tags&quot;).map{case Row(key:String, value:String) =&gt; value}
)).cache()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>defined class NodeEntry
nodeDS: org.apache.spark.sql.Dataset[NodeEntry] = [nodeId: bigint, latitude: double ... 2 more fields]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val allowableWays = Seq(
  &quot;motorway&quot;,
  &quot;motorway_link&quot;,
  &quot;trunk&quot;,
  &quot;trunk_link&quot;,
  &quot;primary&quot;,
  &quot;primary_link&quot;,
  &quot;secondary&quot;,
  &quot;secondary_link&quot;,
  &quot;tertiary&quot;,
  &quot;tertiary_link&quot;,
  &quot;living_street&quot;,
  &quot;residential&quot;,
  &quot;road&quot;,
  &quot;construction&quot;,
  &quot;motorway_junction&quot;
)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>allowableWays: Seq[String] = List(motorway, motorway_link, trunk, trunk_link, primary, primary_link, secondary, secondary_link, tertiary, tertiary_link, living_street, residential, road, construction, motorway_junction)
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">case class NodeEntry(nodeId: Long, latitude: Double, longitude: Double, tags: Seq[String])

val nodeDS = nodes_df.map(node =&gt; 
  NodeEntry(node.getAs[Long](&quot;id&quot;),
       node.getAs[Double](&quot;latitude&quot;),
       node.getAs[Double](&quot;longitude&quot;),
       node.getAs[Seq[Row]](&quot;tags&quot;).map{case Row(key:String, value:String) =&gt; value}
)).cache()

case class WayEntry(wayId: Long, tags: Array[String], nodes: Array[Long])

val wayDS = ways_df.flatMap(way =&gt; {
        val tagSet = way.getAs[Seq[Row]](&quot;tags&quot;).map{case Row(key:String, value:String) =&gt;  value}.toArray
        if (tagSet.intersect(allowableWays).nonEmpty ){
            Array(WayEntry(way.getAs[Long](&quot;id&quot;),
            tagSet,
            way.getAs[Seq[Row]](&quot;nodes&quot;).map{case Row(index:Integer, nodeId:Long) =&gt;  nodeId}.toArray
            ))
        }
        else { Array[WayEntry]()}
}
).cache()

import org.apache.spark.sql.functions.explode

val nodeCounts = wayDS
                    .select(explode('nodes).as(&quot;node&quot;))
                    .groupBy('node).count

val intersectionNodes = nodeCounts.filter('count &gt;= 2).select('node.alias(&quot;intersectionNode&quot;))
val intersections = intersectionNodes
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>defined class NodeEntry
nodeDS: org.apache.spark.sql.Dataset[NodeEntry] = [nodeId: bigint, latitude: double ... 2 more fields]
defined class WayEntry
wayDS: org.apache.spark.sql.Dataset[WayEntry] = [wayId: bigint, tags: array&lt;string&gt; ... 1 more field]
import org.apache.spark.sql.functions.explode
nodeCounts: org.apache.spark.sql.DataFrame = [node: bigint, count: bigint]
intersectionNodes: org.apache.spark.sql.DataFrame = [intersectionNode: bigint]
intersections: org.apache.spark.sql.DataFrame = [intersectionNode: bigint]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">intersections.show(10)
intersections.count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+----------------+
|intersectionNode|
+----------------+
|        32324770|
|        32325847|
|        34102506|
|      2287042206|
|        50124542|
|      2724174351|
|        33700245|
|      2802973888|
|       365309580|
|       135385293|
+----------------+
only showing top 10 rows

res4: Long = 162325
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>The next step is to obtain the coordinates of the intersection points and convert them into decimal degrees (needed for GeoMatch)</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val intersection_points = nodeDS.join(intersections, intersections(&quot;intersectionNode&quot;) === nodeDS(&quot;nodeId&quot;)).drop(&quot;tags&quot;, &quot;nodeId&quot;).select(&quot;intersectionNode&quot;, &quot;latitude&quot;, &quot;longitude&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>intersection_points: org.apache.spark.sql.DataFrame = [intersectionNode: bigint, latitude: double ... 1 more field]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">intersection_points.count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res4: Long = 162325
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">import org.apache.spark.sql.functions.{concat, lit}
val concat_coordinates = intersection_points.select($&quot;intersectionNode&quot;,concat($&quot;latitude&quot;,lit(&quot; &quot;),$&quot;longitude&quot;).alias(&quot;coordinates&quot;))
concat_coordinates.show(1, false)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+----------------+---------------------+
|intersectionNode|coordinates          |
+----------------+---------------------+
|32324770        |54.7129551 25.2697146|
+----------------+---------------------+
only showing top 1 row

import org.apache.spark.sql.functions.{concat, lit}
concat_coordinates: org.apache.spark.sql.DataFrame = [intersectionNode: bigint, coordinates: string]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val firstIntersectionStates = concat_coordinates.select(concat(lit(&quot;LineString:&quot;),$&quot;intersectionNode&quot;).alias(&quot;LineString&quot;),$&quot;coordinates&quot;)
firstIntersectionStates.show(1, false)
val firstIntersectionStates_rdd = firstIntersectionStates.rdd
firstIntersectionStates_rdd.take(1)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+-------------------+-----------------------------+
|LineString         |coordinates                  |
+-------------------+-----------------------------+
|LineString:15389886|54.7309125 25.239701200000003|
+-------------------+-----------------------------+
only showing top 1 row

firstIntersectionStates: org.apache.spark.sql.DataFrame = [LineString: string, coordinates: string]
firstIntersectionStates_rdd: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = MapPartitionsRDD[52] at rdd at command-2710632432421719:3
res6: Array[org.apache.spark.sql.Row] = Array([LineString:15389886,54.7309125 25.239701200000003])
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">if(!ArcGISRuntimeEnvironment.isInitialized())
    {
      ArcGISRuntimeEnvironment.setInstallDirectory(&quot;/dbfs/arcGISRuntime/arcgis-runtime-sdk-java-100.4.0/&quot;)
      ArcGISRuntimeEnvironment.initialize() 
    }
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>Initializing...
Java version : 1.8.0_282 (Azul Systems, Inc.) amd64
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">def project_to_meters(lon: String, lat: String): String = { 
    
    if(!ArcGISRuntimeEnvironment.isInitialized())
    {
      ArcGISRuntimeEnvironment.setInstallDirectory(&quot;/dbfs/arcGISRuntime/arcgis-runtime-sdk-java-100.4.0/&quot;)
      ArcGISRuntimeEnvironment.initialize() 
    }
  
    val initial_point = new Point(lon.toDouble, lat.toDouble, SpatialReference.create(4326))
    val reprojection = GeometryEngine.project(initial_point, SpatialReference.create(3035))
    reprojection.toString
}
spark.udf.register(&quot;project_to_meters&quot;, project_to_meters(_:String, _:String):String)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>project_to_meters: (lon: String, lat: String)String
res9: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(&lt;function2&gt;,StringType,Some(List(StringType, StringType)))
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val intersections_reprojected = firstIntersectionStates_rdd.map(
                                line =&gt; 
                                line.toString.replaceAll(&quot;\\[&quot;,&quot;&quot;).replaceAll(&quot;\\]&quot;,&quot;&quot;)).map(
                                      line =&gt; 
                                      {val parts = line.replaceAll(&quot;\&quot;&quot;,&quot;&quot;).split(&quot;,&quot;);
                                       val arrCoords = parts.slice(1,parts.length).map(
                                          xyStr =&gt; 
                                          {val xy = xyStr.split(&quot; &quot;);
                                          val reprojection = project_to_meters(xy(1).toString, xy(0).toString);
                                          val coords = reprojection.replaceAll(&quot;,&quot;,&quot;&quot;).replaceAll(&quot;\\[&quot;,&quot;&quot;).split(&quot; &quot;).slice(1,reprojection.length);
                                          val xy_new = coords(0).toString +&quot; &quot;+ coords(1).toString;xy_new});
                                       (parts(0).toString, arrCoords)})
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>intersections_reprojected: org.apache.spark.rdd.RDD[(String, Array[String])] = MapPartitionsRDD[54] at map at command-2710632432421722:3
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">intersections_reprojected.take(1)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res11: Array[(String, Array[String])] = Array((LineString:15389886,Array(5294624.872733 3617234.130316)))
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val intersections_unpacked = intersections_reprojected.map(item =&gt; item._1.toString + &quot;,&quot; + item._2(0).toString)
intersections_unpacked.take(1)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>intersections_unpacked: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[55] at map at command-2710632432421724:1
res10: Array[String] = Array(LineString:15389886,5294624.872733 3617234.130316)
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>The first rdd to be used in GeoMatch is formed with the intersections.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val rdd_first_set_intersections = intersections_unpacked.mapPartitions(_.map(line =&gt;
                                                                             {val parts = line.replaceAll(&quot;\&quot;&quot;,&quot;&quot;).split(',');
                                                                              val arrCoords = parts.slice(1, parts.length).map(xyStr =&gt; 
                                                                                                                               {val xy = xyStr.split(' ');
                                                                                                                                (xy(0).toDouble.toInt, xy(1).toDouble.toInt)});
                                                                              new GMPoint(parts(0), arrCoords(0))}))
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>rdd_first_set_intersections: org.apache.spark.rdd.RDD[org.cusp.bdi.gm.geom.GMPoint] = MapPartitionsRDD[56] at mapPartitions at command-2710632432421726:1
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">rdd_first_set_intersections.take(1)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res13: Array[org.cusp.bdi.gm.geom.GMPoint] = Array(GMPoint(LineString:15389886,(5294624,3617234)))
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Next, we need to obtain the set of points that are to be map matched. In this case the set of points corresponds to the accident events occuring in LT.</p>
</div>
<div class="cell markdown">
<p>The three events filtered are the ones corresponding to incorrect coordinates values so we dropped them.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val events = spark.read.format(&quot;parquet&quot;).load(&quot;dbfs:/FileStore/tables/LT_accV.parquet&quot;).rdd//.filter(line =&gt; (line(0) != &quot;LT20xyABCDEF&quot;) &amp;&amp; (line(0) != &quot;LT20xyABCDEF&quot;) &amp;&amp; (line(0) != &quot;LT20xyABCDEF&quot;)).map(line =&gt; line.toString)
events.take(1)
events.count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>events: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = MapPartitionsRDD[74] at rdd at command-2710632432421729:1
res13: Long = 11985
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val all_accidents = spark.read.format(&quot;parquet&quot;).load(&quot;dbfs:/FileStore/tables/LT_accV.parquet&quot;).toDF(&quot;PointId&quot;, &quot;longitude&quot;, &quot;latitude&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>all_accidents: org.apache.spark.sql.DataFrame = [PointId: string, longitude: string ... 1 more field]
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>The second rdd is formed with the accidents.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val rddSecondSet = events.mapPartitions(_.map(line =&gt; 
                                              {new GMPoint(line.getString(0), (line.getString(1).toDouble.toInt, line.getString(1).toDouble.toInt))}))
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>rddSecondSet: org.apache.spark.rdd.RDD[org.cusp.bdi.gm.geom.GMPoint] = MapPartitionsRDD[75] at mapPartitions at command-2710632432421732:1
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Implement Map-Matching using GeoMatch</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">//n(=dimension of the Hilber curve) should be a power of 2. , distance =  meters from an intersection
//distance too big to cover all the points far away from intersections.
val geoMatch = new GeoMatch(false, 256, 4000, (-1, -1, -1, -1))
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>geoMatch: org.cusp.bdi.gm.GeoMatch = GeoMatch(false,256,4000.0,(-1,-1,-1,-1))
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val resultRDD = geoMatch.spatialJoinKNN(rdd_first_set_intersections, rddSecondSet, 1, false)
//k is set to one to get the closest intersection
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>resultRDD: org.apache.spark.rdd.RDD[(org.cusp.bdi.gm.geom.GMPoint, scala.collection.mutable.ListBuffer[org.cusp.bdi.gm.geom.GMPoint])] = MapPartitionsRDD[88] at mapPartitions at GeoMatch.scala:94
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">//resultRDD.toDF(&quot;k&quot;, &quot;line&quot;).show(1, false)
</code></pre>
</div>
<div class="cell markdown">
<p>The output of the above command with IDs and locations anonymised is as follows:</p>
<pre><code>+----------------------------------+---------------------------------------------+
|k                                 |line                                         |
+----------------------------------+---------------------------------------------+
|[LT20xyABCDEF, [520xxxx, 361yyyy]]|[[LineString:924144ssss, [520zzzz, 361zzzz]]]|
+----------------------------------+---------------------------------------------+
only showing top 1 rows 
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val unmatched_events = resultRDD.filter(element =&gt; (element._2.isEmpty)).toDF(&quot;id&quot;, &quot;intersection&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>unmatched_events: org.apache.spark.sql.DataFrame = [id: struct&lt;_payload: string, _pointCoord: struct&lt;_1: int, _2: int&gt;&gt;, intersection: array&lt;struct&lt;_payload:string,_pointCoord:struct&lt;_1:int,_2:int&gt;&gt;&gt;]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">//no accidents unmatched
unmatched_events.count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res19: Long = 0
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">import org.apache.spark.sql.functions._
val intersections_df = intersections_unpacked.toDF(&quot;intersection&quot;)
val intersection_df2 = intersections_df.withColumn(&quot;all&quot;, split(col(&quot;intersection&quot;), &quot;,&quot;)).withColumn(&quot;intersection_id&quot;, $&quot;all&quot;(0)).withColumn(&quot;coordinates&quot;, $&quot;all&quot;(1)).drop(&quot;intersection&quot;, &quot;all&quot;)
val intersection_df3 = intersection_df2.withColumn(&quot;all&quot;, split(col(&quot;coordinates&quot;), &quot; &quot;)).withColumn(&quot;longitude&quot;, $&quot;all&quot;(0)).withColumn(&quot;latitude&quot;, $&quot;all&quot;(1)).drop(&quot;coordinates&quot;, &quot;all&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>import org.apache.spark.sql.functions._
intersections_df: org.apache.spark.sql.DataFrame = [intersection: string]
intersection_df2: org.apache.spark.sql.DataFrame = [intersection_id: string, coordinates: string]
intersection_df3: org.apache.spark.sql.DataFrame = [intersection_id: string, longitude: string ... 1 more field]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">intersection_df3.show(1,false) //intersections together with their coordinates
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+-------------------+--------------+--------------+
|intersection_id    |longitude     |latitude      |
+-------------------+--------------+--------------+
|LineString:15389886|5294624.872733|3617234.130316|
+-------------------+--------------+--------------+
only showing top 1 row
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Measure distance from each point to the nearest intersection</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val result = resultRDD.map(element =&gt;
                           {val accident = element._1
                           val intersection = element._2
                           (accident._payload, accident._pointCoord._1, accident._pointCoord._2, intersection(0)._payload, intersection(0)._pointCoord._1, intersection(0)._pointCoord._2)})
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>result: org.apache.spark.rdd.RDD[(String, Int, Int, String, Int, Int)] = MapPartitionsRDD[89] at map at command-2710632432421742:1
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">//result.take(1)
</code></pre>
</div>
<div class="cell markdown">
<p>The output of the above command with IDs and locations anonymised is as follows:</p>
<pre><code>Array[(String, Int, Int, String, Int, Int)] = Array((LT20xyABCDEF,520xxxx,361yyyy,LineString:92414ssss,520zzzz,361zzzz))
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val result_df = result.toDF(&quot;acc_id&quot;, &quot;acc_long&quot;, &quot;acc_lat&quot;, &quot;inters_id&quot;, &quot;inters_long&quot;, &quot;inters_lat&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>result_df: org.apache.spark.sql.DataFrame = [acc_id: string, acc_long: int ... 4 more fields]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">result_df.select(&quot;acc_id&quot;, &quot;inters_id&quot;).coalesce(1).write.parquet(&quot;dbfs:/datasets/lithuania/acc_inters_ids&quot;)
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">//result_df.show(1,false)
</code></pre>
</div>
<div class="cell markdown">
<p>The output of the above command with IDs and locations anonymised is as follows:</p>
<pre><code>+------------+--------+-------+---------------------+-----------+----------+
|acc_id      |acc_long|acc_lat|inters_id            |inters_long|inters_lat|
+------------+--------+-------+---------------------+-----------+----------+
|LT20xyABCDEF|520xxxx |361yyyy|LineString:92414sssss|520zzzz    |361zzzz   |
+------------+--------+-------+---------------------+-----------+----------+
only showing top 1 rows.
</code></pre>
</div>
<div class="cell markdown">
<p>To measure the geodesic distance we need to transform the coordinates to WGS84 system</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">def dist(lat1: String, long1: String, lat2: String, long2: String): Double = {
    val p1 = new Points(long1.toDouble, lat1.toDouble)
    val p2 = new Points(long2.toDouble, lat2.toDouble)
    geodesicDistanceOnWGS84(p1, p2)
  }
spark.udf.register(&quot;dist&quot;, dist(_:String, _:String, _:String, _:String):Double)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>dist: (lat1: String, long1: String, lat2: String, long2: String)Double
res30: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(&lt;function4&gt;,DoubleType,Some(List(StringType, StringType, StringType, StringType)))
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">def project_to_wgs(lon: Int, lat: Int): String = { 
    
    if(!ArcGISRuntimeEnvironment.isInitialized())
    {
      ArcGISRuntimeEnvironment.setInstallDirectory(&quot;/dbfs/arcGISRuntime/arcgis-runtime-sdk-java-100.4.0/&quot;)
      ArcGISRuntimeEnvironment.initialize() 
    }
  
    val initial_point = new Point(lon.toDouble, lat.toDouble, SpatialReference.create(3035))
    val reprojection = GeometryEngine.project(initial_point, SpatialReference.create(4326))
    reprojection.toString
}
spark.udf.register(&quot;project_to_wgs&quot;, project_to_wgs(_:Int, _:Int):String)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>project_to_wgs: (lon: Int, lat: Int)String
res21: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(&lt;function2&gt;,StringType,Some(List(IntegerType, IntegerType)))
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">def unpack_lat(str: String): String = {
        val lat = str.replaceAll(&quot;,&quot;,&quot;&quot;).replaceAll(&quot;\\[&quot;,&quot;&quot;).split(&quot; &quot;)(2)
        return lat
}
spark.udf.register(&quot;unpack_lat&quot;, unpack_lat(_:String): String)

def unpack_lon(str: String): String = {
        val lon = str.replaceAll(&quot;,&quot;,&quot;&quot;).replaceAll(&quot;\\[&quot;,&quot;&quot;).split(&quot; &quot;)(1)
        return lon
}
spark.udf.register(&quot;unpack_lon&quot;, unpack_lon(_:String): String)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>unpack_lat: (str: String)String
unpack_lon: (str: String)String
res25: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(&lt;function1&gt;,StringType,Some(List(StringType)))
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val result_wgs_packed = result_df.selectExpr(&quot;acc_id&quot;, &quot;inters_id&quot;, &quot;project_to_wgs(acc_long, acc_lat) as acc_coord_wgs&quot;, &quot;project_to_wgs(inters_long, inters_lat) as inters_coord_wgs&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>result_wgs_packed: org.apache.spark.sql.DataFrame = [acc_id: string, inters_id: string ... 2 more fields]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val result_wgs = result_wgs_packed.selectExpr(&quot;acc_id&quot;, &quot;inters_id&quot;, &quot;unpack_lon(acc_coord_wgs) as acc_long_wgs&quot;, &quot;unpack_lat(acc_coord_wgs) as acc_lat_wgs&quot;, &quot;unpack_lon(inters_coord_wgs) as inters_long_wgs&quot;, &quot;unpack_lat(inters_coord_wgs) as inters_lat_wgs&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>result_wgs: org.apache.spark.sql.DataFrame = [acc_id: string, inters_id: string ... 4 more fields]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">//result_wgs.show(1,false)
</code></pre>
</div>
<div class="cell markdown">
<p>The output of the above command with IDs and locations anonymised is as follows:</p>
<pre><code>+------------+---------------------+------------+-----------+---------------+--------------+
|acc_id      |inters_id            |acc_long_wgs|acc_lat_wgs|inters_long_wgs|inters_lat_wgs|
+------------+---------------------+------------+-----------+---------------+--------------+
|LT20xyABCDEF|LineString:92414sssss|23.xxxxxx   |54.yyyyyy  |23.xxxxxx      |54.yyyyyyy    |
+------------+---------------------+------------+-----------+---------------+--------------+
only showing top 1 rows.
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val acc_inters_distances = result_wgs.selectExpr(&quot;acc_id&quot;, &quot;dist(acc_lat_wgs, acc_long_wgs, inters_lat_wgs, inters_long_wgs) as distance_acc_inters&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>acc_inters_distances: org.apache.spark.sql.DataFrame = [acc_id: string, distance_acc_inters: double]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">//acc_inters_distances.sort(col(&quot;distance_acc_inters&quot;).desc).show(1,false)
</code></pre>
</div>
<div class="cell markdown">
<p>The output of the above command with IDs and locations anonymised is as follows:</p>
<pre><code>+------------+-------------------+
|acc_id      |distance_acc_inters|
+------------+-------------------+
|LT20xyABCDEF|3915.650145464729  |
+------------+-------------------+
only showing top 1 rows.
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">acc_inters_distances.coalesce(1).write.parquet(&quot;dbfs:/datasets/lithuania/acc_inters_distances&quot;)
</code></pre>
</div>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../../contents/000_5-sds-2-x-geo/035_03_Visualization_municipalities.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next" href="../../contents/000_5-sds-2-x-geo/035_05_UndirectedG0.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../../contents/000_5-sds-2-x-geo/035_03_Visualization_municipalities.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next" href="../../contents/000_5-sds-2-x-geo/035_05_UndirectedG0.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="../../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="../../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->


    </body>
</html>

<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>035_07_PoissonRegression - sds-3.x/ScaDaMaLe</title>


        <!-- Custom HTML head -->

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="../../favicon.svg">
        <link rel="shortcut icon" href="../../favicon.png">
        <link rel="stylesheet" href="../../css/variables.css">
        <link rel="stylesheet" href="../../css/general.css">
        <link rel="stylesheet" href="../../css/chrome.css">
        <link rel="stylesheet" href="../../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../../highlight.css">
        <link rel="stylesheet" href="../../tomorrow-night.css">
        <link rel="stylesheet" href="../../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../../scroll-mdbook-outputs.css">

        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/000_5-sds-2-x-geo-changes.html">000_5-sds-2-x-geo-changes</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/001_CrashCourseGIS.html">001_CrashCourseGIS</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/031_GeospatialAnalyticsInMagellan.html">031_GeospatialAnalyticsInMagellan</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/031a_MagellanOSMIngestion.html">031a_MagellanOSMIngestion</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/032_NYtaxisInMagellan.html">032_NYtaxisInMagellan</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/032a_MSR_BeijingTaxiTrajectories_MagellanQueries.html">032a_MSR_BeijingTaxiTrajectories_MagellanQueries</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/032b_UberMapMatchingAndVisualization.html">032b_UberMapMatchingAndVisualization</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/032d_MobileSampleSQL.html">032d_MobileSampleSQL</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/032e_CallDetailRecords.html">032e_CallDetailRecords</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/032x_ComingAttractions.html">032x_ComingAttractions</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/033_00_Intro2PointsOnGraphs.html">033_00_Intro2PointsOnGraphs</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/033_01_OSMtoGraphXUppsalaTiny.html">033_01_OSMtoGraphXUppsalaTiny</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/033_02_OSMtoGraphX_LT.html">033_02_OSMtoGraphX_LT</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/033_03_LT_PageRank.html">033_03_LT_PageRank</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/034_01_MapMatching_with_GeoMatch_UppsalaTiny.html">034_01_MapMatching_with_GeoMatch_UppsalaTiny</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/034_02_MapMatching_on_a_Graph_UppsalaTiny.html">034_02_MapMatching_on_a_Graph_UppsalaTiny</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/034_03_MapMatching_on_a_Graph_LT.html">034_03_MapMatching_on_a_Graph_LT</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/034_04_MapMatching_on_a_G1_LT.html">034_04_MapMatching_on_a_G1_LT</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/034_05DistributionOfStates.html">034_05DistributionOfStates</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/034_06SimulatingArrivalTimesNHPP_Inversion.html">034_06SimulatingArrivalTimesNHPP_Inversion</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_01_Arcgis_coordinates_transformation.html">035_01_Arcgis_coordinates_transformation</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_02_Segmentation_municipalities_Magellan.html">035_02_Segmentation_municipalities_Magellan</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_03_Visualization_municipalities.html">035_03_Visualization_municipalities</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_04_MapMatching_intersections.html">035_04_MapMatching_intersections</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_05_UndirectedG0.html">035_05_UndirectedG0</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_06_ConnectedComponent_PageRank.html">035_06_ConnectedComponent_PageRank</a></li><li class="chapter-item expanded affix "><a href="../../contents/000_5-sds-2-x-geo/035_07_PoissonRegression.html" class="active">035_07_PoissonRegression</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">sds-3.x/ScaDaMaLe</h1>

                    <div class="right-buttons">
                        <a href="../../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <div class="cell markdown">
<p>ScaDaMaLe Course <a href="https://lamastex.github.io/scalable-data-science/sds/3/x/">site</a> and <a href="https://lamastex.github.io/ScaDaMaLe/index.html">book</a></p>
</div>
<div class="cell markdown">
<h2 id="poisson-linear-regression-on-the-number-of-accidents"><a class="header" href="#poisson-linear-regression-on-the-number-of-accidents">Poisson Linear Regression on the number of accidents.</a></h2>
<p>Virginia Jimenez Mohedano (<a href="https://www.linkedin.com/in/virginiajimenezmohedano/">LinkedIn</a>) and Raazesh Sainudiin (<a href="https://www.linkedin.com/in/raazesh-sainudiin-45955845/">LinkedIn</a>).</p>
<pre><code>This project was supported by UAB SENSMETRY through a Data Science Thesis Internship 
between 2022-01-17 and 2022-06-05 to Virginia J.M. and 
Databricks University Alliance with infrastructure credits from AWS to 
Raazesh Sainudiin, Department of Mathematics, Uppsala University, Sweden.
</code></pre>
<p>2022, Uppsala, Sweden</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">import org.apache.spark.ml.regression._
import org.apache.spark.ml.feature._
import org.apache.spark.ml.evaluation._
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.types.IntegerType
import org.apache.spark.sql.functions._
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>import org.apache.spark.ml.regression._
import org.apache.spark.ml.feature._
import org.apache.spark.ml.evaluation._
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.types.IntegerType
import org.apache.spark.sql.functions._
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Accidents dataset
val dataset0 = spark.read.parquet(&quot;dbfs:/datasets/lithuania/dataset_poissonReg.parquet&quot;)
val distances = spark.read.parquet(&quot;dbfs:/datasets/lithuania/acc_inters_distances.parquet&quot;)
val pageRank = spark.read.parquet(&quot;dbfs:/datasets/lithuania/acc_inters_pagerank_2&quot;)

// Dataset with pagerank info
val dataset1 = dataset0.join(distances, dataset0(&quot;id&quot;) === distances(&quot;acc_id&quot;)).drop(&quot;acc_id&quot;,&quot;number_of_lanes&quot;).join(pageRank, $&quot;id&quot; === $&quot;acc_id&quot;).drop(&quot;id&quot;,&quot;acc_id&quot;,&quot;inters_id&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>dataset0: org.apache.spark.sql.DataFrame = [id: string, date: string ... 5 more fields]
distances: org.apache.spark.sql.DataFrame = [acc_id: string, distance_acc_inters: double]
pageRank: org.apache.spark.sql.DataFrame = [acc_id: string, inters_id: string ... 1 more field]
dataset1: org.apache.spark.sql.DataFrame = [date: string, time: string ... 6 more fields]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">dataset1.count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res66: Long = 10273
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">//dataset1.show(1,false)
</code></pre>
</div>
<div class="cell markdown">
<p>The output of the above command with date anonymised is as follows:</p>
<pre><code>+----------+----+-------+-----+-----+-----------------+-------------------+------------------+
|      date|time|weather|light|urban|surface_condition|distance_acc_inters|          pageRank|
+----------+----+-------+-----+-----+-----------------+-------------------+------------------+
|20xx-mm-dd|1545|     01|   01|   01|               01|   71.4226418463424|0.8232438315921039|
+----------+----+-------+-----+-----+-----------------+-------------------+------------------+
only showing top 1 row.
</code></pre>
</div>
<div class="cell markdown">
<h1 id="individual-feature-analysis"><a class="header" href="#individual-feature-analysis">Individual feature analysis</a></h1>
<h2 id="dataset-grouped-in-general"><a class="header" href="#dataset-grouped-in-general">Dataset grouped in general</a></h2>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Rounding and grouping by features
val dataset_rounded = dataset1.withColumn(&quot;distance_rounded&quot;,round($&quot;distance_acc_inters&quot;,-1)).withColumn(&quot;pagerank_rounded&quot;,round($&quot;pageRank&quot;,1))
val dataset_grouped_general = dataset_rounded.groupBy(&quot;weather&quot;,&quot;light&quot;,&quot;distance_rounded&quot;,&quot;urban&quot;,&quot;surface_condition&quot;).count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>dataset_rounded: org.apache.spark.sql.DataFrame = [date: string, time: string ... 8 more fields]
dataset_grouped_general: org.apache.spark.sql.DataFrame = [weather: string, light: string ... 4 more fields]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">dataset_grouped_general.count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res5: Long = 1826
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">dataset_grouped_general.show()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+-------+-----+----------------+-----+-----------------+-----+
|weather|light|distance_rounded|urban|surface_condition|count|
+-------+-----+----------------+-----+-----------------+-----+
|     01|   03|            60.0|   01|               04|   18|
|     01|   01|          1320.0|   02|               01|    2|
|     02|   02|            10.0|   01|               04|   12|
|     01|   01|           240.0|   02|               04|    3|
|     01|   01|           380.0|   02|               04|    1|
|     01|   01|          1370.0|   02|               01|    3|
|     01|   05|            90.0|   02|               02|    3|
|     01|   05|           180.0|   01|               02|    1|
|     02|   03|           190.0|   01|               04|    3|
|     01|   03|            40.0|   02|               04|    2|
|     01|   02|           250.0|   01|               02|    1|
|     02|   01|           360.0|   01|               04|    1|
|     01|   01|           670.0|   01|               01|    1|
|     03|   03|           120.0|   01|               04|    1|
|     02|   02|           100.0|   02|               04|    1|
|     02|   02|            60.0|   01|               04|   11|
|     05|   05|           280.0|   01|               02|    1|
|     01|   01|           170.0|   01|               01|   37|
|     01|   01|           820.0|   02|               01|    5|
|     01|   01|           540.0|   02|               02|    2|
+-------+-----+----------------+-----+-----------------+-----+
only showing top 20 rows
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Transforming string into indexes (e.g. (01, 05, 99) -&gt; (0, 1, 2))
// original: val strIndexer = new StringIndexer().setInputCols(Array(&quot;weather&quot;,&quot;light&quot;)).setOutputCols(Array(&quot;weather_index&quot;,&quot;light_index&quot;))
// Multiple StringIndexers because of Spark 2
val strIndexer1 = new StringIndexer().setInputCol(&quot;weather&quot;).setOutputCol(&quot;weather_index&quot;).setStringOrderType(&quot;alphabetAsc&quot;) 
val strIndexer2 = new StringIndexer().setInputCol(&quot;light&quot;).setOutputCol(&quot;light_index&quot;).setStringOrderType(&quot;alphabetAsc&quot;) 
val strIndexer3 = new StringIndexer().setInputCol(&quot;urban&quot;).setOutputCol(&quot;urban_index&quot;).setStringOrderType(&quot;alphabetAsc&quot;) 
val strIndexer4 = new StringIndexer().setInputCol(&quot;surface_condition&quot;).setOutputCol(&quot;surface_index&quot;).setStringOrderType(&quot;alphabetAsc&quot;) 
val indexed1 = strIndexer1.fit(dataset_grouped_general).transform(dataset_grouped_general)
val indexed2 = strIndexer2.fit(indexed1).transform(indexed1)
val indexed3 = strIndexer3.fit(indexed2).transform(indexed2)
val indexed4 = strIndexer4.fit(indexed3).transform(indexed3)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>strIndexer1: org.apache.spark.ml.feature.StringIndexer = strIdx_449260d64c9d
strIndexer2: org.apache.spark.ml.feature.StringIndexer = strIdx_3297edaab880
strIndexer3: org.apache.spark.ml.feature.StringIndexer = strIdx_44f0eafecde9
strIndexer4: org.apache.spark.ml.feature.StringIndexer = strIdx_32c1693975b0
indexed1: org.apache.spark.sql.DataFrame = [weather: string, light: string ... 5 more fields]
indexed2: org.apache.spark.sql.DataFrame = [weather: string, light: string ... 6 more fields]
indexed3: org.apache.spark.sql.DataFrame = [weather: string, light: string ... 7 more fields]
indexed4: org.apache.spark.sql.DataFrame = [weather: string, light: string ... 8 more fields]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Transforming indexes into one hot encoding (e.g. (0, 1, 2) -&gt; ([1,0,0], [0,1,0], [0,0,1]))
// called OneHotEncoder in Spark 3
val encoder = new OneHotEncoderEstimator().setInputCols(Array(&quot;weather_index&quot;,&quot;light_index&quot;,&quot;urban_index&quot;,&quot;surface_index&quot;)).setOutputCols(Array(&quot;weather_onehot&quot;,&quot;light_onehot&quot;,&quot;urban_onehot&quot;,&quot;surface_onehot&quot;)).setDropLast(false)
val encoded = encoder.fit(indexed4).transform(indexed4).select(&quot;weather_onehot&quot;,&quot;light_onehot&quot;,&quot;urban_onehot&quot;,&quot;surface_onehot&quot;,&quot;distance_rounded&quot;,&quot;count&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>encoder: org.apache.spark.ml.feature.OneHotEncoderEstimator = oneHotEncoder_e5bdee3e096c
encoded: org.apache.spark.sql.DataFrame = [weather_onehot: vector, light_onehot: vector ... 4 more fields]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">indexed4.orderBy($&quot;count&quot;.desc).select(&quot;weather&quot;, &quot;light&quot;,&quot;urban&quot;, &quot;surface_condition&quot;, &quot;distance_rounded&quot;, &quot;count&quot;).show()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+-------+-----+-----+-----------------+----------------+-----+
|weather|light|urban|surface_condition|distance_rounded|count|
+-------+-----+-----+-----------------+----------------+-----+
|     01|   01|   01|               01|            10.0|  661|
|     01|   01|   01|               01|             0.0|  654|
|     01|   01|   01|               01|            20.0|  457|
|     01|   01|   01|               01|            30.0|  401|
|     01|   01|   01|               01|            40.0|  359|
|     01|   01|   01|               01|            50.0|  329|
|     01|   01|   01|               01|            60.0|  259|
|     01|   01|   01|               01|            70.0|  249|
|     01|   01|   01|               01|            90.0|  183|
|     01|   01|   01|               01|            80.0|  172|
|     01|   01|   01|               04|            10.0|  150|
|     01|   01|   02|               01|            10.0|  122|
|     01|   01|   01|               01|           110.0|  120|
|     01|   01|   01|               01|           100.0|  118|
|     01|   01|   02|               01|             0.0|  113|
|     01|   01|   01|               04|             0.0|  102|
|     01|   01|   01|               01|           120.0|  100|
|     01|   03|   01|               04|            10.0|   98|
|     01|   03|   01|               01|            10.0|   96|
|     01|   01|   01|               04|            20.0|   90|
+-------+-----+-----+-----------------+----------------+-----+
only showing top 20 rows
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val encodedAll = encoder.fit(indexed4).transform(indexed4)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>encodedAll: org.apache.spark.sql.DataFrame = [weather: string, light: string ... 12 more fields]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">encodedAll.printSchema
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>root
 |-- weather: string (nullable = true)
 |-- light: string (nullable = true)
 |-- distance_rounded: double (nullable = true)
 |-- urban: string (nullable = true)
 |-- surface_condition: string (nullable = true)
 |-- count: long (nullable = false)
 |-- weather_index: double (nullable = false)
 |-- light_index: double (nullable = false)
 |-- urban_index: double (nullable = false)
 |-- surface_index: double (nullable = false)
 |-- weather_onehot: vector (nullable = true)
 |-- light_onehot: vector (nullable = true)
 |-- urban_onehot: vector (nullable = true)
 |-- surface_onehot: vector (nullable = true)
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">encoded.orderBy($&quot;count&quot;.desc).show() 
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+--------------+-------------+-------------+--------------+----------------+-----+
|weather_onehot| light_onehot| urban_onehot|surface_onehot|distance_rounded|count|
+--------------+-------------+-------------+--------------+----------------+-----+
| (6,[0],[1.0])|(5,[0],[1.0])|(2,[0],[1.0])| (4,[0],[1.0])|            10.0|  661|
| (6,[0],[1.0])|(5,[0],[1.0])|(2,[0],[1.0])| (4,[0],[1.0])|             0.0|  654|
| (6,[0],[1.0])|(5,[0],[1.0])|(2,[0],[1.0])| (4,[0],[1.0])|            20.0|  457|
| (6,[0],[1.0])|(5,[0],[1.0])|(2,[0],[1.0])| (4,[0],[1.0])|            30.0|  401|
| (6,[0],[1.0])|(5,[0],[1.0])|(2,[0],[1.0])| (4,[0],[1.0])|            40.0|  359|
| (6,[0],[1.0])|(5,[0],[1.0])|(2,[0],[1.0])| (4,[0],[1.0])|            50.0|  329|
| (6,[0],[1.0])|(5,[0],[1.0])|(2,[0],[1.0])| (4,[0],[1.0])|            60.0|  259|
| (6,[0],[1.0])|(5,[0],[1.0])|(2,[0],[1.0])| (4,[0],[1.0])|            70.0|  249|
| (6,[0],[1.0])|(5,[0],[1.0])|(2,[0],[1.0])| (4,[0],[1.0])|            90.0|  183|
| (6,[0],[1.0])|(5,[0],[1.0])|(2,[0],[1.0])| (4,[0],[1.0])|            80.0|  172|
| (6,[0],[1.0])|(5,[0],[1.0])|(2,[0],[1.0])| (4,[3],[1.0])|            10.0|  150|
| (6,[0],[1.0])|(5,[0],[1.0])|(2,[1],[1.0])| (4,[0],[1.0])|            10.0|  122|
| (6,[0],[1.0])|(5,[0],[1.0])|(2,[0],[1.0])| (4,[0],[1.0])|           110.0|  120|
| (6,[0],[1.0])|(5,[0],[1.0])|(2,[0],[1.0])| (4,[0],[1.0])|           100.0|  118|
| (6,[0],[1.0])|(5,[0],[1.0])|(2,[1],[1.0])| (4,[0],[1.0])|             0.0|  113|
| (6,[0],[1.0])|(5,[0],[1.0])|(2,[0],[1.0])| (4,[3],[1.0])|             0.0|  102|
| (6,[0],[1.0])|(5,[0],[1.0])|(2,[0],[1.0])| (4,[0],[1.0])|           120.0|  100|
| (6,[0],[1.0])|(5,[2],[1.0])|(2,[0],[1.0])| (4,[3],[1.0])|            10.0|   98|
| (6,[0],[1.0])|(5,[2],[1.0])|(2,[0],[1.0])| (4,[0],[1.0])|            10.0|   96|
| (6,[0],[1.0])|(5,[0],[1.0])|(2,[0],[1.0])| (4,[3],[1.0])|            20.0|   90|
+--------------+-------------+-------------+--------------+----------------+-----+
only showing top 20 rows
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">encodedAll.select(&quot;light&quot;,&quot;light_index&quot;,&quot;light_onehot&quot;,&quot;count&quot;).orderBy($&quot;count&quot;.desc).show()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+-----+-----------+-------------+-----+
|light|light_index| light_onehot|count|
+-----+-----------+-------------+-----+
|   01|        0.0|(5,[0],[1.0])|  661|
|   01|        0.0|(5,[0],[1.0])|  654|
|   01|        0.0|(5,[0],[1.0])|  457|
|   01|        0.0|(5,[0],[1.0])|  401|
|   01|        0.0|(5,[0],[1.0])|  359|
|   01|        0.0|(5,[0],[1.0])|  329|
|   01|        0.0|(5,[0],[1.0])|  259|
|   01|        0.0|(5,[0],[1.0])|  249|
|   01|        0.0|(5,[0],[1.0])|  183|
|   01|        0.0|(5,[0],[1.0])|  172|
|   01|        0.0|(5,[0],[1.0])|  150|
|   01|        0.0|(5,[0],[1.0])|  122|
|   01|        0.0|(5,[0],[1.0])|  120|
|   01|        0.0|(5,[0],[1.0])|  118|
|   01|        0.0|(5,[0],[1.0])|  113|
|   01|        0.0|(5,[0],[1.0])|  102|
|   01|        0.0|(5,[0],[1.0])|  100|
|   03|        2.0|(5,[2],[1.0])|   98|
|   03|        2.0|(5,[2],[1.0])|   96|
|   01|        0.0|(5,[0],[1.0])|   90|
+-----+-----------+-------------+-----+
only showing top 20 rows
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Transforming grouping all features into a feature column
val assembler = new VectorAssembler().setInputCols(Array(&quot;weather_onehot&quot;,&quot;light_onehot&quot;,&quot;urban_onehot&quot;,&quot;surface_onehot&quot;,&quot;distance_rounded&quot;)).setOutputCol(&quot;features&quot;)
val assembled = assembler.transform(encoded).select($&quot;count&quot;, $&quot;features&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>assembler: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_d07c57e0650f
assembled: org.apache.spark.sql.DataFrame = [count: bigint, features: vector]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">//CrossValidation to find the best parameter
import org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder}

val pr = new GeneralizedLinearRegression().setFamily(&quot;poisson&quot;).setLink(&quot;log&quot;).setMaxIter(50).setLabelCol(&quot;count&quot;)

val paramGrid = new ParamGridBuilder()
     //.addGrid(pr.regParam, Array(0.5, 0.3, 0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00001))
     //.addGrid(pr.regParam, Array(5, 4, 3, 2, 1, 0.5, 0.3, 0.1, 0.05, 0.01))
     //.addGrid(pr.regParam, Array(3.25, 3.2, 3.15, 3.1, 3.05, 3))
     //.addGrid(pr.regParam, Array(0.01, 0.1, 1.0, 10.0))
     //.addGrid(pr.regParam, Array(0.08, 0.09, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5))
     .addGrid(pr.regParam, Array(0.005, 0.01, 0.02, 0.03, 0.1, 0.5))
     .build()

val cv = new CrossValidator()
     .setEstimator(pr)
     .setEvaluator(new RegressionEvaluator().setLabelCol(&quot;count&quot;))
     .setEstimatorParamMaps(paramGrid)
     .setNumFolds(5)

val model = cv.fit(assembled)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>import org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder}
pr: org.apache.spark.ml.regression.GeneralizedLinearRegression = glm_41b9fdc53532
paramGrid: Array[org.apache.spark.ml.param.ParamMap] =
Array({
	glm_41b9fdc53532-regParam: 0.005
}, {
	glm_41b9fdc53532-regParam: 0.01
}, {
	glm_41b9fdc53532-regParam: 0.02
}, {
	glm_41b9fdc53532-regParam: 0.03
}, {
	glm_41b9fdc53532-regParam: 0.1
}, {
	glm_41b9fdc53532-regParam: 0.5
})
cv: org.apache.spark.ml.tuning.CrossValidator = cv_2032b2f9c9f1
model: org.apache.spark.ml.tuning.CrossValidatorModel = cv_2032b2f9c9f1
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">model.bestModel.explainParams
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res15: String =
family: The name of family which is a description of the error distribution to be used in the model. Supported options: binomial, gamma, gaussian, poisson, tweedie. (default: gaussian, current: poisson)
featuresCol: features column name (default: features)
fitIntercept: whether to fit an intercept term (default: true)
labelCol: label column name (default: label, current: count)
link: The name of link function which provides the relationship between the linear predictor and the mean of the distribution function. Supported options: cloglog, probit, logit, inverse, sqrt, identity, log (current: log)
linkPower: The index in the power link function. Only applicable to the Tweedie family. (undefined)
linkPredictionCol: link prediction (linear predictor) column name (undefined)
maxIter: maximum number of iterations (&gt;= 0) (default: 25, current: 50)
offsetCol: The offset column name. If this is not set or empty, we treat all instance offsets as 0.0 (undefined)
predictionCol: prediction column name (default: prediction)
regParam: regularization parameter (&gt;= 0) (default: 0.0, current: 0.005)
solver: The solver algorithm for optimization. Supported options: irls. (Default irls) (default: irls)
tol: the convergence tolerance for iterative algorithms (&gt;= 0) (default: 1.0E-6)
variancePower: The power in the variance function of the Tweedie distribution which characterizes the relationship between the variance and mean of the distribution. Only applicable to the Tweedie family. Supported values: 0 and [1, Inf). (default: 0.0)
weightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0 (undefined)
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">model.bestModel.extractParamMap()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res16: org.apache.spark.ml.param.ParamMap =
{
	glm_41b9fdc53532-family: poisson,
	glm_41b9fdc53532-featuresCol: features,
	glm_41b9fdc53532-fitIntercept: true,
	glm_41b9fdc53532-labelCol: count,
	glm_41b9fdc53532-link: log,
	glm_41b9fdc53532-maxIter: 50,
	glm_41b9fdc53532-predictionCol: prediction,
	glm_41b9fdc53532-regParam: 0.005,
	glm_41b9fdc53532-solver: irls,
	glm_41b9fdc53532-tol: 1.0E-6,
	glm_41b9fdc53532-variancePower: 0.0
}
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Doing regression
val glr = new GeneralizedLinearRegression().setFamily(&quot;poisson&quot;).setLink(&quot;log&quot;).setMaxIter(50).setRegParam(0.03).setLabelCol(&quot;count&quot;)
val glrModel = glr.fit(assembled)
// Analyzing coefficients
glrModel.summary
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>glr: org.apache.spark.ml.regression.GeneralizedLinearRegression = glm_63902e85457c
glrModel: org.apache.spark.ml.regression.GeneralizedLinearRegressionModel = glm_63902e85457c
res17: org.apache.spark.ml.regression.GeneralizedLinearRegressionTrainingSummary =
Coefficients:
          Feature Estimate Std Error  T Value P Value
      (Intercept)   1.1875    0.0620  19.1405  0.0000
weather_onehot_01   1.0084    0.0305  33.0618  0.0000
weather_onehot_02   0.3323    0.0351   9.4682  0.0000
weather_onehot_03  -0.2708    0.0402  -6.7382  0.0000
weather_onehot_04  -0.5509    0.0412 -13.3569  0.0000
weather_onehot_05  -0.2413    0.0437  -5.5202  0.0000
weather_onehot_06  -0.2777    0.0456  -6.0906  0.0000
  light_onehot_01   1.3814    0.0283  48.8072  0.0000
  light_onehot_02  -0.4006    0.0338 -11.8536  0.0000
  light_onehot_03   0.0814    0.0319   2.5563  0.0106
  light_onehot_04  -0.7292    0.0392 -18.6025  0.0000
  light_onehot_05  -0.3332    0.0331 -10.0542  0.0000
  urban_onehot_01   0.4389    0.0386  11.3662  0.0000
  urban_onehot_02  -0.4389    0.0386 -11.3662  0.0000
surface_onehot_01   1.1096    0.0322  34.4532  0.0000
surface_onehot_02  -0.7582    0.0358 -21.1723  0.0000
surface_onehot_03  -0.3160    0.0463  -6.8223  0.0000
surface_onehot_04  -0.0354    0.0331  -1.0699  0.2846
 distance_rounded  -0.0053    0.0001 -80.1873  0.0000

(Dispersion parameter for poisson family taken to be 1.0000)
    Null deviance: 42906.6423 on 1807 degrees of freedom
Residual deviance: 12410.4474 on 1807 degrees of freedom
AIC: 17313.6105
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Doing regression
val glr = new GeneralizedLinearRegression().setFamily(&quot;poisson&quot;).setLink(&quot;log&quot;).setMaxIter(50).setRegParam(0.02).setLabelCol(&quot;count&quot;)
val glrModel = glr.fit(assembled)
// Analyzing coefficients
glrModel.summary
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>glr: org.apache.spark.ml.regression.GeneralizedLinearRegression = glm_c845bf98c162
glrModel: org.apache.spark.ml.regression.GeneralizedLinearRegressionModel = glm_c845bf98c162
res18: org.apache.spark.ml.regression.GeneralizedLinearRegressionTrainingSummary =
Coefficients:
          Feature Estimate Std Error  T Value P Value
      (Intercept)   1.0036    0.0746  13.4593  0.0000
weather_onehot_01   1.0983    0.0353  31.1433  0.0000
weather_onehot_02   0.4306    0.0400  10.7762  0.0000
weather_onehot_03  -0.2717    0.0465  -5.8421  0.0000
weather_onehot_04  -0.6467    0.0483 -13.3841  0.0000
weather_onehot_05  -0.2720    0.0512  -5.3083  0.0000
weather_onehot_06  -0.3385    0.0540  -6.2664  0.0000
  light_onehot_01   1.4559    0.0332  43.8319  0.0000
  light_onehot_02  -0.4052    0.0388 -10.4311  0.0000
  light_onehot_03   0.1274    0.0366   3.4775  0.0005
  light_onehot_04  -0.8548    0.0458 -18.6550  0.0000
  light_onehot_05  -0.3233    0.0381  -8.4862  0.0000
  urban_onehot_01   0.4525    0.0468   9.6705  0.0000
  urban_onehot_02  -0.4525    0.0468  -9.6705  0.0000
surface_onehot_01   1.1823    0.0381  30.9995  0.0000
surface_onehot_02  -0.7847    0.0420 -18.6969  0.0000
surface_onehot_03  -0.4152    0.0550  -7.5549  0.0000
surface_onehot_04   0.0176    0.0390   0.4503  0.6525
 distance_rounded  -0.0054    0.0001 -81.1834  0.0000

(Dispersion parameter for poisson family taken to be 1.0000)
    Null deviance: 42906.6423 on 1807 degrees of freedom
Residual deviance: 12070.2322 on 1807 degrees of freedom
AIC: 16973.3953
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Doing regression
val glr = new GeneralizedLinearRegression().setFamily(&quot;poisson&quot;).setLink(&quot;log&quot;).setMaxIter(50).setRegParam(0.01).setLabelCol(&quot;count&quot;)
val glrModel = glr.fit(assembled)
// Analyzing coefficients
glrModel.summary
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>glr: org.apache.spark.ml.regression.GeneralizedLinearRegression = glm_09f4354ad483
glrModel: org.apache.spark.ml.regression.GeneralizedLinearRegressionModel = glm_09f4354ad483
res19: org.apache.spark.ml.regression.GeneralizedLinearRegressionTrainingSummary =
Coefficients:
          Feature Estimate Std Error  T Value P Value
      (Intercept)   0.7123    0.1027   6.9326  0.0000
weather_onehot_01   1.2356    0.0458  26.9979  0.0000
weather_onehot_02   0.5884    0.0502  11.7268  0.0000
weather_onehot_03  -0.2477    0.0587  -4.2194  0.0000
weather_onehot_04  -0.8054    0.0627 -12.8365  0.0000
weather_onehot_05  -0.3138    0.0660  -4.7522  0.0000
weather_onehot_06  -0.4571    0.0713  -6.4106  0.0000
  light_onehot_01   1.5553    0.0445  34.9383  0.0000
  light_onehot_02  -0.3954    0.0498  -7.9416  0.0000
  light_onehot_03   0.2003    0.0474   4.2223  0.0000
  light_onehot_04  -1.0659    0.0596 -17.8914  0.0000
  light_onehot_05  -0.2943    0.0490  -6.0091  0.0000
  urban_onehot_01   0.4679    0.0654   7.1519  0.0000
  urban_onehot_02  -0.4679    0.0654  -7.1519  0.0000
surface_onehot_01   1.2977    0.0515  25.1760  0.0000
surface_onehot_02  -0.7882    0.0553 -14.2425  0.0000
surface_onehot_03  -0.6214    0.0734  -8.4680  0.0000
surface_onehot_04   0.1118    0.0524   2.1344  0.0328
 distance_rounded  -0.0055    0.0001 -82.4092  0.0000

(Dispersion parameter for poisson family taken to be 1.0000)
    Null deviance: 42906.6423 on 1807 degrees of freedom
Residual deviance: 11713.8989 on 1807 degrees of freedom
AIC: 16617.0621
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Doing regression // may be use this...
val glr = new GeneralizedLinearRegression().setFamily(&quot;poisson&quot;).setLink(&quot;log&quot;).setMaxIter(100).setRegParam(0.005).setLabelCol(&quot;count&quot;)
val glrModel = glr.fit(assembled)
// Analyzing coefficients
glrModel.summary
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>glr: org.apache.spark.ml.regression.GeneralizedLinearRegression = glm_c14aefc3d082
glrModel: org.apache.spark.ml.regression.GeneralizedLinearRegressionModel = glm_c14aefc3d082
res20: org.apache.spark.ml.regression.GeneralizedLinearRegressionTrainingSummary =
Coefficients:
          Feature Estimate Std Error  T Value P Value
      (Intercept)   0.4569    0.1426   3.2055  0.0013
weather_onehot_01   1.3471    0.0604  22.2845  0.0000
weather_onehot_02   0.7180    0.0642  11.1779  0.0000
weather_onehot_03  -0.2006    0.0735  -2.7312  0.0063
weather_onehot_04  -0.9428    0.0805 -11.7141  0.0000
weather_onehot_05  -0.3348    0.0833  -4.0188  0.0001
weather_onehot_06  -0.5868    0.0926  -6.3380  0.0000
  light_onehot_01   1.6265    0.0608  26.7452  0.0000
  light_onehot_02  -0.3733    0.0652  -5.7215  0.0000
  light_onehot_03   0.2596    0.0631   4.1133  0.0000
  light_onehot_04  -1.2524    0.0772 -16.2213  0.0000
  light_onehot_05  -0.2604    0.0645  -4.0372  0.0001
  urban_onehot_01   0.4766    0.0919   5.1829  0.0000
  urban_onehot_02  -0.4766    0.0919  -5.1829  0.0000
surface_onehot_01   1.4060    0.0706  19.9158  0.0000
surface_onehot_02  -0.7482    0.0739 -10.1186  0.0000
surface_onehot_03  -0.8661    0.0979  -8.8439  0.0000
surface_onehot_04   0.2082    0.0713   2.9201  0.0035
 distance_rounded  -0.0055    0.0001 -83.1794  0.0000

(Dispersion parameter for poisson family taken to be 1.0000)
    Null deviance: 42906.6423 on 1807 degrees of freedom
Residual deviance: 11530.8466 on 1807 degrees of freedom
AIC: 16434.0097
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Doing regression // may be use this...
val glr = new GeneralizedLinearRegression().setFamily(&quot;poisson&quot;).setLink(&quot;log&quot;).setMaxIter(50).setRegParam(0.005).setLabelCol(&quot;count&quot;)
val glrModel = glr.fit(assembled)
// Analyzing coefficients
glrModel.summary
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>glr: org.apache.spark.ml.regression.GeneralizedLinearRegression = glm_f2f6e11bce23
glrModel: org.apache.spark.ml.regression.GeneralizedLinearRegressionModel = glm_f2f6e11bce23
res21: org.apache.spark.ml.regression.GeneralizedLinearRegressionTrainingSummary =
Coefficients:
          Feature Estimate Std Error  T Value P Value
      (Intercept)   0.4569    0.1426   3.2055  0.0013
weather_onehot_01   1.3471    0.0604  22.2845  0.0000
weather_onehot_02   0.7180    0.0642  11.1779  0.0000
weather_onehot_03  -0.2006    0.0735  -2.7312  0.0063
weather_onehot_04  -0.9428    0.0805 -11.7141  0.0000
weather_onehot_05  -0.3348    0.0833  -4.0188  0.0001
weather_onehot_06  -0.5868    0.0926  -6.3380  0.0000
  light_onehot_01   1.6265    0.0608  26.7452  0.0000
  light_onehot_02  -0.3733    0.0652  -5.7215  0.0000
  light_onehot_03   0.2596    0.0631   4.1133  0.0000
  light_onehot_04  -1.2524    0.0772 -16.2213  0.0000
  light_onehot_05  -0.2604    0.0645  -4.0372  0.0001
  urban_onehot_01   0.4766    0.0919   5.1829  0.0000
  urban_onehot_02  -0.4766    0.0919  -5.1829  0.0000
surface_onehot_01   1.4060    0.0706  19.9158  0.0000
surface_onehot_02  -0.7482    0.0739 -10.1186  0.0000
surface_onehot_03  -0.8661    0.0979  -8.8439  0.0000
surface_onehot_04   0.2082    0.0713   2.9201  0.0035
 distance_rounded  -0.0055    0.0001 -83.1794  0.0000

(Dispersion parameter for poisson family taken to be 1.0000)
    Null deviance: 42906.6423 on 1807 degrees of freedom
Residual deviance: 11530.8466 on 1807 degrees of freedom
AIC: 16434.0097
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Sorting results and adding explanation
val coefficient_names = Array(&quot;Weather: Clear&quot;, &quot;Weather: Rain&quot;, &quot;Weather: Snow&quot;, &quot;Weather: Fog&quot;, &quot;Weather: Hail&quot;, &quot;Weather: Severe winds&quot;, &quot;Light: Daylight&quot;, &quot;Light: Twilight&quot;, &quot;Light: Darkness street lights lit&quot;, &quot;Light: Darkness street lights unlit&quot;, &quot;Light: Darkness no street lights&quot;, &quot;Urban area: Yes&quot;, &quot;Urban Area: No&quot;, &quot;Surface:  Dry&quot;, &quot;Surface conditions: Snow&quot;, &quot;Surface conditions: Slippery&quot;, &quot;Surface conditions: Wet&quot;, &quot;Distance to intersection&quot;);
val coefficients = glrModel.coefficients.toArray;
val results = (coefficient_names zip coefficients).sortBy(- _._2);
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>coefficient_names: Array[String] = Array(Weather: Clear, Weather: Rain, Weather: Snow, Weather: Fog, Weather: Hail, Weather: Severe winds, Light: Daylight, Light: Twilight, Light: Darkness street lights lit, Light: Darkness street lights unlit, Light: Darkness no street lights, Urban area: Yes, Urban Area: No, Surface:  Dry, Surface conditions: Snow, Surface conditions: Slippery, Surface conditions: Wet, Distance to intersection)
coefficients: Array[Double] = Array(1.3470664632390563, 0.7179669262323152, -0.20064300667145904, -0.9427572969514967, -0.3348377398187767, -0.5867953460297699, 1.6264583126311356, -0.37327339515034913, 0.25961345332790997, -1.2524419437239054, -0.2603564270848369, 0.476556192651841, -0.47655619265183025, 1.4060213301843612, -0.7481546633939465, -0.8660526185248044, 0.20818595173449747, -0.005535693920436917)
results: Array[(String, Double)] = Array((Light: Daylight,1.6264583126311356), (Surface:  Dry,1.4060213301843612), (Weather: Clear,1.3470664632390563), (Weather: Rain,0.7179669262323152), (Urban area: Yes,0.476556192651841), (Light: Darkness street lights lit,0.25961345332790997), (Surface conditions: Wet,0.20818595173449747), (Distance to intersection,-0.005535693920436917), (Weather: Snow,-0.20064300667145904), (Light: Darkness no street lights,-0.2603564270848369), (Weather: Hail,-0.3348377398187767), (Light: Twilight,-0.37327339515034913), (Urban Area: No,-0.47655619265183025), (Weather: Severe winds,-0.5867953460297699), (Surface conditions: Snow,-0.7481546633939465), (Surface conditions: Slippery,-0.8660526185248044), (Weather: Fog,-0.9427572969514967), (Light: Darkness street lights unlit,-1.2524419437239054))
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Printing results
for((name,value) &lt;- results)
{
  println(name + &quot;: &quot; + value)
}
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>Light: Daylight: 1.6264583126311356
Surface:  Dry: 1.4060213301843612
Weather: Clear: 1.3470664632390563
Weather: Rain: 0.7179669262323152
Urban area: Yes: 0.476556192651841
Light: Darkness street lights lit: 0.25961345332790997
Surface conditions: Wet: 0.20818595173449747
Distance to intersection: -0.005535693920436917
Weather: Snow: -0.20064300667145904
Light: Darkness no street lights: -0.2603564270848369
Weather: Hail: -0.3348377398187767
Light: Twilight: -0.37327339515034913
Urban Area: No: -0.47655619265183025
Weather: Severe winds: -0.5867953460297699
Surface conditions: Snow: -0.7481546633939465
Surface conditions: Slippery: -0.8660526185248044
Weather: Fog: -0.9427572969514967
Light: Darkness street lights unlit: -1.2524419437239054
</code></pre>
</div>
</div>
<div class="cell markdown">
<h2 id="dataset-grouped-by-month"><a class="header" href="#dataset-grouped-by-month">Dataset grouped by month</a></h2>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Grouping by month
val dataset_grouped_month = dataset_rounded.withColumn(&quot;month&quot;,substring(col(&quot;date&quot;),1,7)).groupBy(&quot;weather&quot;,&quot;light&quot;,&quot;distance_rounded&quot;,&quot;urban&quot;,&quot;surface_condition&quot;,&quot;month&quot;).count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>dataset_grouped_month: org.apache.spark.sql.DataFrame = [weather: string, light: string ... 5 more fields]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Doing all the steps
val indexed1_month = strIndexer1.fit(dataset_grouped_month).transform(dataset_grouped_month)
val indexed2_month = strIndexer2.fit(indexed1_month).transform(indexed1_month)
val indexed3_month = strIndexer3.fit(indexed2_month).transform(indexed2_month)
val indexed4_month = strIndexer4.fit(indexed3_month).transform(indexed3_month)
val encoded_month = encoder.fit(indexed4_month).transform(indexed4_month).select(&quot;weather_onehot&quot;,&quot;light_onehot&quot;,&quot;urban_onehot&quot;,&quot;surface_onehot&quot;,&quot;distance_rounded&quot;,&quot;count&quot;)
val assembled_month = assembler.transform(encoded_month).select($&quot;count&quot;, $&quot;features&quot;)
val glr_month = new GeneralizedLinearRegression().setFamily(&quot;poisson&quot;).setLink(&quot;log&quot;).setMaxIter(50).setRegParam(0.005).setLabelCol(&quot;count&quot;)
val glrModel_month = glr_month.fit(assembled_month)
val coefficients_month = glrModel_month.coefficients.toArray;
val results_month = (coefficient_names zip coefficients_month).sortBy(- _._2);
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Printing results
for((name,value) &lt;- results_month)
{
  println(name + &quot;: &quot; + value)
}
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>Light: Daylight: 0.5623282770331778
Surface:  Dry: 0.4056304643240561
Urban area: Yes: 0.27651985478282864
Weather: Clear: 0.171680640166019
Weather: Rain: 0.04571149327911539
Distance to intersection: -0.0012496110475531071
Weather: Hail: -0.006464683263122493
Weather: Snow: -0.015211594561228423
Light: Darkness no street lights: -0.02432984947036485
Light: Darkness street lights lit: -0.030012104359405916
Weather: Fog: -0.09400517317140901
Surface conditions: Slippery: -0.09972393291767397
Weather: Severe winds: -0.10171068244941438
Surface conditions: Wet: -0.14527962265900163
Surface conditions: Snow: -0.16062690874739757
Light: Twilight: -0.21826494432123064
Urban Area: No: -0.27651985478280566
Light: Darkness street lights unlit: -0.2897213788821447
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">glrModel_month.summary
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res30: org.apache.spark.ml.regression.GeneralizedLinearRegressionTrainingSummary =
Coefficients:
          Feature Estimate Std Error  T Value P Value
      (Intercept)   0.0989    0.1447   0.6833  0.4944
weather_onehot_01   0.1717    0.0626   2.7430  0.0061
weather_onehot_02   0.0457    0.0659   0.6938  0.4878
weather_onehot_03  -0.0152    0.0759  -0.2003  0.8412
weather_onehot_04  -0.0940    0.0869  -1.0820  0.2793
weather_onehot_05  -0.0065    0.0863  -0.0749  0.9403
weather_onehot_06  -0.1017    0.1013  -1.0044  0.3152
  light_onehot_01   0.5623    0.0612   9.1863  0.0000
  light_onehot_02  -0.2183    0.0656  -3.3255  0.0009
  light_onehot_03  -0.0300    0.0636  -0.4719  0.6370
  light_onehot_04  -0.2897    0.0819  -3.5390  0.0004
  light_onehot_05  -0.0243    0.0651  -0.3737  0.7087
  urban_onehot_01   0.2765    0.0920   3.0049  0.0027
  urban_onehot_02  -0.2765    0.0920  -3.0049  0.0027
surface_onehot_01   0.4056    0.0742   5.4658  0.0000
surface_onehot_02  -0.1606    0.0775  -2.0723  0.0382
surface_onehot_03  -0.0997    0.1172  -0.8510  0.3947
surface_onehot_04  -0.1453    0.0747  -1.9451  0.0518
 distance_rounded  -0.0012    0.0001 -23.9449  0.0000

(Dispersion parameter for poisson family taken to be 1.0000)
   Null deviance: 11326.9327 on 6368 degrees of freedom
Residual deviance: 7306.2897 on 6368 degrees of freedom
AIC: 21928.7784
</code></pre>
</div>
</div>
<div class="cell markdown">
<h2 id="dataset-grouped-by-day"><a class="header" href="#dataset-grouped-by-day">Dataset grouped by day</a></h2>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Grouping by day
val dataset_grouped_day = dataset_rounded.groupBy(&quot;weather&quot;,&quot;light&quot;,&quot;distance_rounded&quot;,&quot;urban&quot;,&quot;surface_condition&quot;,&quot;date&quot;).count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>dataset_grouped_day: org.apache.spark.sql.DataFrame = [weather: string, light: string ... 5 more fields]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Doing all the steps
val indexed1_day = strIndexer1.fit(dataset_grouped_day).transform(dataset_grouped_day)
val indexed2_day = strIndexer2.fit(indexed1_day).transform(indexed1_day)
val indexed3_day = strIndexer3.fit(indexed2_day).transform(indexed2_day)
val indexed4_day = strIndexer4.fit(indexed3_day).transform(indexed3_day)
val encoded_day = encoder.fit(indexed4_day).transform(indexed4_day).select(&quot;weather_onehot&quot;,&quot;light_onehot&quot;,&quot;urban_onehot&quot;,&quot;surface_onehot&quot;,&quot;distance_rounded&quot;,&quot;count&quot;)
val assembled_day = assembler.transform(encoded_day).select($&quot;count&quot;, $&quot;features&quot;)
val glr_day = new GeneralizedLinearRegression().setFamily(&quot;poisson&quot;).setLink(&quot;log&quot;).setMaxIter(10).setRegParam(0.3).setLabelCol(&quot;count&quot;)
val glrModel_day = glr_day.fit(assembled_day)
val coefficients_day = glrModel_day.coefficients.toArray;
val results_day = (coefficient_names zip coefficients_day).sortBy(- _._2);
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Printing results
for((name,value) &lt;- results_day)
{
  println(name + &quot;: &quot; + value)
}
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>Light: Daylight: 0.027949186006437664
Surface:  Dry: 0.024533366742833455
Urban area: Yes: 0.01977720359248019
Weather: Clear: 0.006331686971903564
Distance to intersection: -1.1992730742822068E-4
Surface conditions: Slippery: -1.8964818599701529E-4
Weather: Severe winds: -5.76416264665067E-4
Weather: Hail: -6.123269851679737E-4
Weather: Fog: -8.835249668022383E-4
Weather: Snow: -0.001350789643218188
Light: Darkness street lights unlit: -0.0022390087563577783
Weather: Rain: -0.00290862911205009
Surface conditions: Snow: -0.004932534826253334
Light: Darkness no street lights: -0.006119182190514435
Light: Darkness street lights lit: -0.00906486462823428
Light: Twilight: -0.010526130431331129
Surface conditions: Wet: -0.01941118373058309
Urban Area: No: -0.019777203592480055
</code></pre>
</div>
</div>
<div class="cell markdown">
<h2 id="just-light"><a class="header" href="#just-light">Just light</a></h2>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Doing all the steps
val dataset_grouped_light = dataset_rounded.groupBy(&quot;light&quot;).count()
val indexed_light = strIndexer2.fit(dataset_grouped_light).transform(dataset_grouped_light)
val encoder_light = new OneHotEncoderEstimator().setInputCols(Array(&quot;light_index&quot;)).setOutputCols(Array(&quot;light_onehot&quot;)).setDropLast(false)
val encoded_light = encoder_light.fit(indexed_light).transform(indexed_light).select(&quot;light_onehot&quot;,&quot;count&quot;)
val assembler_light = new VectorAssembler().setInputCols(Array(&quot;light_onehot&quot;)).setOutputCol(&quot;features&quot;)
val assembled_light = assembler_light.transform(encoded_light).select($&quot;count&quot;, $&quot;features&quot;)
val glr_light = new GeneralizedLinearRegression().setFamily(&quot;poisson&quot;).setLink(&quot;log&quot;).setMaxIter(10).setRegParam(0.3).setLabelCol(&quot;count&quot;)
val glrModel_light = glr_light.fit(assembled_light)
glrModel_light.summary
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>dataset_grouped_light: org.apache.spark.sql.DataFrame = [light: string, count: bigint]
indexed_light: org.apache.spark.sql.DataFrame = [light: string, count: bigint ... 1 more field]
encoder_light: org.apache.spark.ml.feature.OneHotEncoderEstimator = oneHotEncoder_ec81b8e54627
encoded_light: org.apache.spark.sql.DataFrame = [light_onehot: vector, count: bigint]
assembler_light: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_9f3ca194a390
assembled_light: org.apache.spark.sql.DataFrame = [count: bigint, features: vector]
glr_light: org.apache.spark.ml.regression.GeneralizedLinearRegression = glm_fdacf33318aa
glrModel_light: org.apache.spark.ml.regression.GeneralizedLinearRegressionModel = glm_fdacf33318aa
res34: org.apache.spark.ml.regression.GeneralizedLinearRegressionTrainingSummary =
Coefficients:
        Feature Estimate Std Error  T Value P Value
    (Intercept)   7.6558    0.0122 627.7315  0.0000
light_onehot_01   0.9015    0.0129  70.0368  0.0000
light_onehot_02  -0.2332    0.0143 -16.2947  0.0000
light_onehot_03  -0.0981    0.0141  -6.9427  0.0000
light_onehot_04  -0.3701    0.0145 -25.5212  0.0000
light_onehot_05  -0.2002    0.0143 -14.0310  0.0000

(Dispersion parameter for poisson family taken to be 1.0000)
   Null deviance: 15678.9980 on -1 degrees of freedom
Residual deviance: 4666.8292 on -1 degrees of freedom
AIC: 4722.9211
</code></pre>
</div>
</div>
<div class="cell markdown">
<h2 id="just-distance"><a class="header" href="#just-distance">Just distance</a></h2>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Doing all the steps
val dataset_grouped_distance = dataset_rounded.groupBy(&quot;distance_rounded&quot;).count()
val assembler_distance = new VectorAssembler().setInputCols(Array(&quot;distance_rounded&quot;)).setOutputCol(&quot;features&quot;)
val assembled_distance = assembler_distance.transform(dataset_grouped_distance).select($&quot;count&quot;, $&quot;features&quot;)
val glr_distance = new GeneralizedLinearRegression().setFamily(&quot;poisson&quot;).setLink(&quot;log&quot;).setMaxIter(10).setRegParam(0.3).setLabelCol(&quot;count&quot;)
val glrModel_distance = glr_distance.fit(assembled_distance)
glrModel_distance.summary
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>dataset_grouped_distance: org.apache.spark.sql.DataFrame = [distance_rounded: double, count: bigint]
assembler_distance: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_007e7fa35bfe
assembled_distance: org.apache.spark.sql.DataFrame = [count: bigint, features: vector]
glr_distance: org.apache.spark.ml.regression.GeneralizedLinearRegression = glm_2fe978b3bb68
glrModel_distance: org.apache.spark.ml.regression.GeneralizedLinearRegressionModel = glm_2fe978b3bb68
res36: org.apache.spark.ml.regression.GeneralizedLinearRegressionTrainingSummary =
Coefficients:
         Feature Estimate Std Error   T Value P Value
     (Intercept)   6.7026    0.0127  527.4419  0.0000
distance_rounded  -0.0070    0.0001 -109.2103  0.0000

(Dispersion parameter for poisson family taken to be 1.0000)
   Null deviance: 44053.5339 on 198 degrees of freedom
Residual deviance: 4631.6038 on 198 degrees of freedom
AIC: 5420.1342
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">dataset_grouped_distance.show(false)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+----------------+-----+
|distance_rounded|count|
+----------------+-----+
|170.0           |119  |
|810.0           |3    |
|720.0           |12   |
|160.0           |143  |
|70.0            |502  |
|1350.0          |5    |
|0.0             |1389 |
|650.0           |18   |
|2770.0          |1    |
|390.0           |24   |
|840.0           |7    |
|2270.0          |1    |
|1130.0          |6    |
|2060.0          |1    |
|1020.0          |7    |
|410.0           |30   |
|800.0           |12   |
|2430.0          |1    |
|180.0           |86   |
|430.0           |20   |
+----------------+-----+
only showing top 20 rows
</code></pre>
</div>
</div>
<div class="cell markdown">
<h1 id="including-pagerank"><a class="header" href="#including-pagerank">Including PageRank</a></h1>
</div>
<div class="cell code" execution_count="1" scrolled="true">
<pre><code class="language-scala">// Doing all the steps
val dataset_grouped_general_pagerank = dataset_rounded.groupBy(&quot;weather&quot;,&quot;light&quot;,&quot;distance_rounded&quot;,&quot;pagerank_rounded&quot;,&quot;urban&quot;,&quot;surface_condition&quot;).count()
val indexed1_pagerank = strIndexer1.fit(dataset_grouped_general_pagerank).transform(dataset_grouped_general_pagerank)
val indexed2_pagerank = strIndexer2.fit(indexed1_pagerank).transform(indexed1_pagerank)
val indexed3_pagerank = strIndexer3.fit(indexed2_pagerank).transform(indexed2_pagerank)
val indexed4_pagerank = strIndexer4.fit(indexed3_pagerank).transform(indexed3_pagerank)

val encoded_pagerank = encoder.fit(indexed4_pagerank).transform(indexed4_pagerank).select(&quot;weather_onehot&quot;,&quot;light_onehot&quot;,&quot;urban_onehot&quot;,&quot;surface_onehot&quot;,&quot;distance_rounded&quot;,&quot;pagerank_rounded&quot;,&quot;count&quot;)

val assembler_pagerank = new VectorAssembler().setInputCols(Array(&quot;weather_onehot&quot;,&quot;light_onehot&quot;,&quot;urban_onehot&quot;,&quot;surface_onehot&quot;,&quot;distance_rounded&quot;,&quot;pagerank_rounded&quot;)).setOutputCol(&quot;features&quot;)
val assembled_pagerank = assembler_pagerank.transform(encoded_pagerank).select($&quot;count&quot;, $&quot;features&quot;)

val glr_pagerank = new GeneralizedLinearRegression().setFamily(&quot;poisson&quot;).setLink(&quot;log&quot;).setMaxIter(50).setRegParam(0.005).setLabelCol(&quot;count&quot;)
val glrModel_pagerank = glr_pagerank.fit(assembled_pagerank)
// Analyzing coefficients
glrModel_pagerank.summary
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>dataset_grouped_general_pagerank: org.apache.spark.sql.DataFrame = [weather: string, light: string ... 5 more fields]
indexed1_pagerank: org.apache.spark.sql.DataFrame = [weather: string, light: string ... 6 more fields]
indexed2_pagerank: org.apache.spark.sql.DataFrame = [weather: string, light: string ... 7 more fields]
indexed3_pagerank: org.apache.spark.sql.DataFrame = [weather: string, light: string ... 8 more fields]
indexed4_pagerank: org.apache.spark.sql.DataFrame = [weather: string, light: string ... 9 more fields]
encoded_pagerank: org.apache.spark.sql.DataFrame = [weather_onehot: vector, light_onehot: vector ... 5 more fields]
assembler_pagerank: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_359bb84c0fd6
assembled_pagerank: org.apache.spark.sql.DataFrame = [count: bigint, features: vector]
glr_pagerank: org.apache.spark.ml.regression.GeneralizedLinearRegression = glm_25d8fe385c90
glrModel_pagerank: org.apache.spark.ml.regression.GeneralizedLinearRegressionModel = glm_25d8fe385c90
res39: org.apache.spark.ml.regression.GeneralizedLinearRegressionTrainingSummary =
Coefficients:
          Feature Estimate Std Error  T Value P Value
      (Intercept)   0.3866    0.1453   2.6617  0.0078
weather_onehot_01   0.2915    0.0623   4.6782  0.0000
weather_onehot_02   0.0622    0.0656   0.9482  0.3430
weather_onehot_03   0.0060    0.0758   0.0794  0.9367
weather_onehot_04  -0.1749    0.0861  -2.0309  0.0423
weather_onehot_05  -0.0683    0.0858  -0.7963  0.4259
weather_onehot_06  -0.1165    0.1009  -1.1549  0.2481
  light_onehot_01   0.7548    0.0612  12.3418  0.0000
  light_onehot_02  -0.2576    0.0656  -3.9281  0.0001
  light_onehot_03  -0.0044    0.0635  -0.0693  0.9447
  light_onehot_04  -0.4067    0.0812  -5.0098  0.0000
  light_onehot_05  -0.0861    0.0650  -1.3250  0.1852
  urban_onehot_01   0.2711    0.0920   2.9465  0.0032
  urban_onehot_02  -0.2711    0.0920  -2.9465  0.0032
surface_onehot_01   0.5846    0.0738   7.9171  0.0000
surface_onehot_02  -0.3471    0.0771  -4.5041  0.0000
surface_onehot_03  -0.1442    0.1154  -1.2498  0.2114
surface_onehot_04  -0.0933    0.0744  -1.2543  0.2097
 distance_rounded  -0.0016    0.0001 -29.9758  0.0000
 pagerank_rounded  -0.2553    0.0130 -19.5737  0.0000

(Dispersion parameter for poisson family taken to be 1.0000)
   Null deviance: 15623.3418 on 5276 degrees of freedom
Residual deviance: 9219.4191 on 5276 degrees of freedom
AIC: 21726.7106
</code></pre>
</div>
</div>
<div class="cell markdown">
<h2 id="just-pagerank"><a class="header" href="#just-pagerank">Just PageRank</a></h2>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Doing all the steps
val dataset_grouped_pagerank = dataset1.withColumn(&quot;pagerank_rounded&quot;,round($&quot;pageRank&quot;,2)).groupBy(&quot;pagerank_rounded&quot;).count()
val assembler_pagerank = new VectorAssembler().setInputCols(Array(&quot;pagerank_rounded&quot;)).setOutputCol(&quot;features&quot;)
val assembled_pagerank = assembler_pagerank.transform(dataset_grouped_pagerank).select($&quot;count&quot;, $&quot;features&quot;)
val glr_pagerank = new GeneralizedLinearRegression().setFamily(&quot;poisson&quot;).setLink(&quot;log&quot;).setMaxIter(50).setRegParam(0.005).setLabelCol(&quot;count&quot;)
val glrModel_pagerank = glr_pagerank.fit(assembled_pagerank)
glrModel_pagerank.summary
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>dataset_grouped_pagerank: org.apache.spark.sql.DataFrame = [pagerank_rounded: double, count: bigint]
assembler_pagerank: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_1562d58b948e
assembled_pagerank: org.apache.spark.sql.DataFrame = [count: bigint, features: vector]
glr_pagerank: org.apache.spark.ml.regression.GeneralizedLinearRegression = glm_58640c3b7cb9
glrModel_pagerank: org.apache.spark.ml.regression.GeneralizedLinearRegressionModel = glm_58640c3b7cb9
res69: org.apache.spark.ml.regression.GeneralizedLinearRegressionTrainingSummary =
Coefficients:
         Feature Estimate Std Error  T Value P Value
     (Intercept)   4.7703    0.0246 194.1037  0.0000
pagerank_rounded  -0.5405    0.0207 -26.1011  0.0000

(Dispersion parameter for poisson family taken to be 1.0000)
    Null deviance: 9765.4028 on 160 degrees of freedom
Residual deviance: 9054.1338 on 160 degrees of freedom
AIC: 9902.4787
</code></pre>
</div>
</div>
<div class="cell markdown">
<h3 id="pagerank-by-month"><a class="header" href="#pagerank-by-month">PageRank by month</a></h3>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Doing all the steps
val dataset_grouped_pagerank_month = dataset1.withColumn(&quot;pagerank_rounded&quot;,round($&quot;pageRank&quot;,2)).withColumn(&quot;month&quot;,substring(col(&quot;date&quot;),1,7)).groupBy(&quot;pagerank_rounded&quot;,&quot;month&quot;).count()
val assembler_pagerank_month = new VectorAssembler().setInputCols(Array(&quot;pagerank_rounded&quot;)).setOutputCol(&quot;features&quot;)
val assembled_pagerank_month = assembler_pagerank_month.transform(dataset_grouped_pagerank_month).select($&quot;count&quot;, $&quot;features&quot;)
val glr_pagerank_month = new GeneralizedLinearRegression().setFamily(&quot;poisson&quot;).setLink(&quot;log&quot;).setMaxIter(10).setRegParam(0.3).setLabelCol(&quot;count&quot;)
val glrModel_pagerank_month = glr_pagerank_month.fit(assembled_pagerank_month)
glrModel_pagerank_month.summary
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>dataset_grouped_pagerank_month: org.apache.spark.sql.DataFrame = [pagerank_rounded: double, month: string ... 1 more field]
assembler_pagerank_month: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_c5b019f8644b
assembled_pagerank_month: org.apache.spark.sql.DataFrame = [count: bigint, features: vector]
glr_pagerank_month: org.apache.spark.ml.regression.GeneralizedLinearRegression = glm_ceb92ebc8613
glrModel_pagerank_month: org.apache.spark.ml.regression.GeneralizedLinearRegressionModel = glm_ceb92ebc8613
res73: org.apache.spark.ml.regression.GeneralizedLinearRegressionTrainingSummary =
Coefficients:
         Feature Estimate Std Error T Value P Value
     (Intercept)   0.9549    0.0196 48.7928  0.0000
pagerank_rounded  -0.0493    0.0154 -3.2041  0.0014

(Dispersion parameter for poisson family taken to be 1.0000)
    Null deviance: 4460.9515 on 4172 degrees of freedom
Residual deviance: 4443.2036 on 4172 degrees of freedom
AIC: 15391.4472
</code></pre>
</div>
</div>
<div class="cell markdown">
<h2 id="pagerank-and-distance"><a class="header" href="#pagerank-and-distance">PageRank and distance</a></h2>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Doing all the steps
val dataset_grouped_general_pagerank_distance = dataset_rounded.groupBy(&quot;distance_rounded&quot;,&quot;pagerank_rounded&quot;).count()
val assembler_pagerank_distance = new VectorAssembler().setInputCols(Array(&quot;distance_rounded&quot;,&quot;pagerank_rounded&quot;)).setOutputCol(&quot;features&quot;)
val assembled_pagerank_distance = assembler_pagerank_distance.transform(dataset_grouped_general_pagerank_distance).select($&quot;count&quot;, $&quot;features&quot;)

val glr_pagerank_distance = new GeneralizedLinearRegression().setFamily(&quot;poisson&quot;).setLink(&quot;log&quot;).setMaxIter(50).setRegParam(0.005).setLabelCol(&quot;count&quot;)
val glrModel_pagerank_distance = glr_pagerank_distance.fit(assembled_pagerank_distance)
// Analyzing coefficients
glrModel_pagerank_distance.summary
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>dataset_grouped_general_pagerank_distance: org.apache.spark.sql.DataFrame = [distance_rounded: double, pagerank_rounded: double ... 1 more field]
assembler_pagerank_distance: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_ad4c5c9a1dd5
assembled_pagerank_distance: org.apache.spark.sql.DataFrame = [count: bigint, features: vector]
glr_pagerank_distance: org.apache.spark.ml.regression.GeneralizedLinearRegression = glm_bf18561f042e
glrModel_pagerank_distance: org.apache.spark.ml.regression.GeneralizedLinearRegressionModel = glm_bf18561f042e
res75: org.apache.spark.ml.regression.GeneralizedLinearRegressionTrainingSummary =
Coefficients:
         Feature Estimate Std Error  T Value P Value
     (Intercept)   3.9437    0.0266 148.0558  0.0000
distance_rounded  -0.0075    0.0001 -82.4530  0.0000
pagerank_rounded  -0.0292    0.0202  -1.4467  0.1480

(Dispersion parameter for poisson family taken to be 1.0000)
    Null deviance: 28944.5937 on 977 degrees of freedom
Residual deviance: 13190.1748 on 977 degrees of freedom
AIC: 16120.2376
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">dataset_grouped_general_pagerank_distance.count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res77: Long = 980
</code></pre>
</div>
</div>
<div class="cell markdown">
<h1 id="grouped-feature-analysis"><a class="header" href="#grouped-feature-analysis">Grouped feature analysis</a></h1>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// Column values explained
val dataset2 = dataset1.withColumn(&quot;weather_explained&quot;, when($&quot;weather&quot; === &quot;01&quot;, &quot;Weather: Clear&quot;).when($&quot;weather&quot; === &quot;02&quot;, &quot;Weather: Rain&quot;).when($&quot;weather&quot; === &quot;03&quot;, &quot;Weather: Snow&quot;).when($&quot;weather&quot; === &quot;04&quot;, &quot;Weather: Fog&quot;).when($&quot;weather&quot; === &quot;05&quot;, &quot;Weather: Hail&quot;).when($&quot;weather&quot; === &quot;06&quot;, &quot;Weather: Severe winds&quot;)).withColumn(&quot;light_explained&quot;, when($&quot;light&quot; === &quot;01&quot;, &quot;Light: Daylight&quot;).when($&quot;light&quot; === &quot;02&quot;, &quot;Light: Twilight&quot;).when($&quot;light&quot; === &quot;03&quot;, &quot;Light: Darkness street lights lit&quot;).when($&quot;light&quot; === &quot;04&quot;, &quot;Light: Darkness street lights unlit&quot;).when($&quot;light&quot; === &quot;05&quot;, &quot;Light: Darkness no street lights&quot;)).withColumn(&quot;urban_explained&quot;, when($&quot;urban&quot; === &quot;01&quot;, &quot;Urban Area: No&quot;).when($&quot;urban&quot; === &quot;02&quot;, &quot;Urban Area: No&quot;)).withColumn(&quot;surface_explained&quot;, when($&quot;surface_condition&quot; === &quot;01&quot;, &quot;Surface: Dry&quot;).when($&quot;surface_condition&quot; === &quot;02&quot;, &quot;Surface: Snow&quot;).when($&quot;surface_condition&quot; === &quot;03&quot;, &quot;Surface: Slippery&quot;).when($&quot;surface_condition&quot; === &quot;04&quot;, &quot;Surface: Wet&quot;))
dataset2.show()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+----------+----+-------+-----+-----+-----------------+-------------------+-------------------+-----------------+--------------------+---------------+-----------------+
|      date|time|weather|light|urban|surface_condition|distance_acc_inters|          pageRank3|weather_explained|     light_explained|urban_explained|surface_explained|
+----------+----+-------+-----+-----+-----------------+-------------------+-------------------+-----------------+--------------------+---------------+-----------------+
|2019-02-04|0900|     03|   01|   01|               02|  8.468333215455965| 1.2842425279855638|    Weather: Snow|     Light: Daylight| Urban Area: No|    Surface: Snow|
|2019-04-08|1545|     01|   01|   01|               01|   71.4226418463424| 0.4088802902500498|   Weather: Clear|     Light: Daylight| Urban Area: No|     Surface: Dry|
|2019-04-20|0037|     01|   03|   01|               01|  5.821136911776573| 1.8277684271925088|   Weather: Clear|Light: Darkness s...| Urban Area: No|     Surface: Dry|
|2019-07-05|1945|     01|   01|   02|               01| 305.58515800316945|0.40518914213955115|   Weather: Clear|     Light: Daylight| Urban Area: No|     Surface: Dry|
|2019-07-19|1841|     01|   01|   01|               01|  66.41492453005965| 0.8318381122604184|   Weather: Clear|     Light: Daylight| Urban Area: No|     Surface: Dry|
|2019-07-20|1137|     01|   01|   01|               01|  223.9469478590693| 1.2842425279855638|   Weather: Clear|     Light: Daylight| Urban Area: No|     Surface: Dry|
|2019-08-21|1559|     02|   01|   01|               04| 147.47766658082287| 0.5935098377369848|    Weather: Rain|     Light: Daylight| Urban Area: No|     Surface: Wet|
|2019-09-02|0856|     01|   01|   02|               01|  432.2910978729382| 1.2842425279855638|   Weather: Clear|     Light: Daylight| Urban Area: No|     Surface: Dry|
|2019-09-23|1928|     01|   02|   01|               01|  72.25367772991889| 0.3844077184864608|   Weather: Clear|     Light: Twilight| Urban Area: No|     Surface: Dry|
|2019-10-10|0701|     02|   02|   01|               04|  62.31538588865796| 1.2631860026730954|    Weather: Rain|     Light: Twilight| Urban Area: No|     Surface: Wet|
|2019-11-11|1754|     01|   05|   02|               04|   188.479708322116| 1.3757429662531127|   Weather: Clear|Light: Darkness n...| Urban Area: No|     Surface: Wet|
|2017-04-12|1258|     01|   01|   01|               01| 63.949699402760665| 0.6072002240075746|   Weather: Clear|     Light: Daylight| Urban Area: No|     Surface: Dry|
|2017-05-04|2103|     01|   01|   02|               01| 49.948394028394716| 1.2842425279855638|   Weather: Clear|     Light: Daylight| Urban Area: No|     Surface: Dry|
|2017-09-12|1704|     02|   01|   02|               04|  51.07458691449452| 0.9181997704510707|    Weather: Rain|     Light: Daylight| Urban Area: No|     Surface: Wet|
|2017-06-11|2335|     01|   03|   01|               04|  51.87865568464353|  2.369287330476644|   Weather: Clear|Light: Darkness s...| Urban Area: No|     Surface: Wet|
|2017-04-08|2113|     01|   05|   02|               01|  976.4733516796357| 0.3800046844511643|   Weather: Clear|Light: Darkness n...| Urban Area: No|     Surface: Dry|
|2017-08-21|1540|     01|   01|   01|               01|  42.11951375810313| 1.2842425279855638|   Weather: Clear|     Light: Daylight| Urban Area: No|     Surface: Dry|
|2017-10-31|0847|     01|   01|   01|               01| 15.318848854000429|  1.060463767722192|   Weather: Clear|     Light: Daylight| Urban Area: No|     Surface: Dry|
|2017-04-24|0733|     01|   01|   02|               01|   76.1581647669748| 1.1255108382462593|   Weather: Clear|     Light: Daylight| Urban Area: No|     Surface: Dry|
|2017-09-26|0809|     01|   01|   01|               01|  5.009736800229386| 0.9956983340635517|   Weather: Clear|     Light: Daylight| Urban Area: No|     Surface: Dry|
+----------+----+-------+-----+-----+-----------------+-------------------+-------------------+-----------------+--------------------+---------------+-----------------+
only showing top 20 rows

dataset2: org.apache.spark.sql.DataFrame = [date: string, time: string ... 10 more fields]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val grouped = dataset2.withColumn(&quot;grouped&quot;,concat($&quot;weather&quot;,$&quot;light&quot;,$&quot;urban&quot;,$&quot;surface_condition&quot;)).withColumn(&quot;grouped_explained&quot;,concat($&quot;weather_explained&quot;,$&quot;light_explained&quot;,$&quot;urban_explained&quot;,$&quot;surface_explained&quot;)).withColumn(&quot;distance_rounded&quot;,round($&quot;distance_acc_inters&quot;,-1)).select(&quot;grouped&quot;,&quot;grouped_explained&quot;,&quot;distance_rounded&quot;).groupBy(&quot;grouped&quot;,&quot;grouped_explained&quot;,&quot;distance_rounded&quot;).count()
grouped.show()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+--------+--------------------+----------------+-----+
| grouped|   grouped_explained|distance_rounded|count|
+--------+--------------------+----------------+-----+
|03050202|Weather: SnowLigh...|           510.0|    1|
|01010201|Weather: ClearLig...|           170.0|   19|
|01010201|Weather: ClearLig...|          1950.0|    1|
|01020102|Weather: ClearLig...|            20.0|    2|
|01050201|Weather: ClearLig...|           870.0|    2|
|03010202|Weather: SnowLigh...|            60.0|    1|
|05010104|Weather: HailLigh...|             0.0|    1|
|01010204|Weather: ClearLig...|             0.0|   20|
|03050202|Weather: SnowLigh...|           160.0|    1|
|01010201|Weather: ClearLig...|           370.0|    9|
|02010104|Weather: RainLigh...|          2530.0|    1|
|01050201|Weather: ClearLig...|           150.0|    2|
|01010204|Weather: ClearLig...|          3920.0|    1|
|03010202|Weather: SnowLigh...|           160.0|    1|
|01010104|Weather: ClearLig...|           530.0|    1|
|01010201|Weather: ClearLig...|            60.0|   40|
|01010101|Weather: ClearLig...|           800.0|    3|
|01020201|Weather: ClearLig...|          1400.0|    1|
|01010204|Weather: ClearLig...|           570.0|    1|
|03050202|Weather: SnowLigh...|           390.0|    1|
+--------+--------------------+----------------+-----+
only showing top 20 rows

grouped: org.apache.spark.sql.DataFrame = [grouped: string, grouped_explained: string ... 2 more fields]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">grouped.count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res54: Long = 1826
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="true">
<pre><code class="language-scala">// Doing all the steps
val strIndexer_grouped = new StringIndexer().setInputCol(&quot;grouped&quot;).setOutputCol(&quot;grouped_index&quot;).setStringOrderType(&quot;alphabetAsc&quot;) 
val indexed_grouped = strIndexer_grouped.fit(grouped).transform(grouped)
val encoder_grouped = new OneHotEncoderEstimator().setInputCols(Array(&quot;grouped_index&quot;)).setOutputCols(Array(&quot;onehot&quot;)).setDropLast(false)
val encoded_grouped = encoder_grouped.fit(indexed_grouped).transform(indexed_grouped).select(&quot;onehot&quot;,&quot;distance_rounded&quot;,&quot;count&quot;)
val assembler_grouped = new VectorAssembler().setInputCols(Array(&quot;onehot&quot;,&quot;distance_rounded&quot;)).setOutputCol(&quot;features&quot;)
val assembled_grouped = assembler_grouped.transform(encoded_grouped).select($&quot;count&quot;, $&quot;features&quot;)
val glr_grouped = new GeneralizedLinearRegression().setFamily(&quot;poisson&quot;).setLink(&quot;log&quot;).setMaxIter(10).setRegParam(0.3).setLabelCol(&quot;count&quot;)
val glrModel_grouped = glr_grouped.fit(assembled_grouped)
glrModel_grouped.summary
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>strIndexer_grouped: org.apache.spark.ml.feature.StringIndexer = strIdx_cf9acfc5aed6
indexed_grouped: org.apache.spark.sql.DataFrame = [grouped: string, grouped_explained: string ... 3 more fields]
encoder_grouped: org.apache.spark.ml.feature.OneHotEncoderEstimator = oneHotEncoder_1401e11b2769
encoded_grouped: org.apache.spark.sql.DataFrame = [onehot: vector, distance_rounded: double ... 1 more field]
assembler_grouped: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_c3b27adfe90f
assembled_grouped: org.apache.spark.sql.DataFrame = [count: bigint, features: vector]
glr_grouped: org.apache.spark.ml.regression.GeneralizedLinearRegression = glm_dfa7b094a5de
glrModel_grouped: org.apache.spark.ml.regression.GeneralizedLinearRegressionModel = glm_dfa7b094a5de
res55: org.apache.spark.ml.regression.GeneralizedLinearRegressionTrainingSummary =
Coefficients:
         Feature Estimate Std Error  T Value P Value
     (Intercept)   2.6588    0.0124 214.7331  0.0000
 onehot_01010101   1.0617    0.0149  71.2573  0.0000
 onehot_01010102  -0.0258    0.0162  -1.5903  0.1118
 onehot_01010103  -0.0084    0.0166  -0.5048  0.6137
 onehot_01010104   0.1476    0.0159   9.2841  0.0000
 onehot_01010201   0.2658    0.0157  16.9190  0.0000
 onehot_01010202  -0.0494    0.0161  -3.0747  0.0021
 onehot_01010203  -0.0035    0.0166  -0.2121  0.8320
 onehot_01010204  -0.0165    0.0160  -1.0359  0.3002
 onehot_01020101   0.0064    0.0161   0.3969  0.6914
 onehot_01020102  -0.0302    0.0164  -1.8429  0.0654
 onehot_01020103  -0.0058    0.0166  -0.3510  0.7256
 onehot_01020104  -0.0175    0.0162  -1.0823  0.2791
 onehot_01020201  -0.0424    0.0161  -2.6279  0.0086
 onehot_01020202  -0.0323    0.0164  -1.9724  0.0486
 onehot_01020204  -0.0367    0.0163  -2.2505  0.0244
 onehot_01030101   0.0729    0.0161   4.5418  0.0000
 onehot_01030102  -0.0324    0.0163  -1.9883  0.0468
 onehot_01030103  -0.0024    0.0167  -0.1452  0.8845
 onehot_01030104   0.0545    0.0161   3.3782  0.0007
 onehot_01030201  -0.0301    0.0164  -1.8374  0.0662
 onehot_01030202  -0.0153    0.0165  -0.9235  0.3557
 onehot_01030204  -0.0189    0.0165  -1.1458  0.2519
 onehot_01040101  -0.0372    0.0163  -2.2858  0.0223
 onehot_01040102  -0.0158    0.0165  -0.9572  0.3385
 onehot_01040104  -0.0316    0.0164  -1.9286  0.0538
 onehot_01040201  -0.0183    0.0165  -1.1074  0.2681
 onehot_01040202  -0.0068    0.0166  -0.4065  0.6844
 onehot_01040204  -0.0082    0.0166  -0.4948  0.6207
 onehot_01050101  -0.0281    0.0161  -1.7461  0.0808
 onehot_01050102  -0.0290    0.0164  -1.7662  0.0774
 onehot_01050103  -0.0014    0.0167  -0.0816  0.9350
 onehot_01050104  -0.0442    0.0162  -2.7312  0.0063
 onehot_01050201  -0.0106    0.0160  -0.6660  0.5054
 onehot_01050202  -0.0397    0.0162  -2.4525  0.0142
 onehot_01050204  -0.0417    0.0161  -2.5959  0.0094
 onehot_02010101  -0.0012    0.0167  -0.0709  0.9435
 onehot_02010102  -0.0031    0.0166  -0.1877  0.8511
 onehot_02010104   0.0201    0.0161   1.2492  0.2116
 onehot_02010201  -0.0001    0.0167  -0.0079  0.9937
 onehot_02010202  -0.0031    0.0166  -0.1854  0.8529
 onehot_02010204  -0.0378    0.0160  -2.3549  0.0185
 onehot_02020101  -0.0083    0.0166  -0.4972  0.6190
 onehot_02020102  -0.0011    0.0167  -0.0676  0.9461
 onehot_02020104  -0.0297    0.0162  -1.8287  0.0674
 onehot_02020202  -0.0024    0.0167  -0.1453  0.8845
 onehot_02020204  -0.0349    0.0163  -2.1334  0.0329
 onehot_02030104   0.0202    0.0161   1.2521  0.2106
 onehot_02030204  -0.0148    0.0165  -0.8964  0.3700
 onehot_02040102  -0.0022    0.0167  -0.1332  0.8940
 onehot_02040104  -0.0221    0.0165  -1.3435  0.1791
 onehot_02040204  -0.0062    0.0166  -0.3750  0.7077
 onehot_02050104  -0.0371    0.0163  -2.2751  0.0229
 onehot_02050202  -0.0034    0.0166  -0.2064  0.8365
 onehot_02050204  -0.0507    0.0161  -3.1468  0.0017
 onehot_03010101  -0.0058    0.0166  -0.3510  0.7256
 onehot_03010102  -0.0333    0.0163  -2.0450  0.0409
 onehot_03010104  -0.0209    0.0165  -1.2710  0.2037
 onehot_03010202  -0.0260    0.0164  -1.5885  0.1122
 onehot_03010204  -0.0036    0.0166  -0.2194  0.8264
 onehot_03020102  -0.0216    0.0165  -1.3133  0.1891
 onehot_03020104  -0.0142    0.0165  -0.8589  0.3904
 onehot_03020202  -0.0213    0.0165  -1.2928  0.1961
 onehot_03020204  -0.0085    0.0166  -0.5131  0.6079
 onehot_03030102  -0.0307    0.0164  -1.8750  0.0608
 onehot_03030104  -0.0246    0.0164  -1.4992  0.1338
 onehot_03030204  -0.0037    0.0166  -0.2210  0.8251
 onehot_03040102  -0.0069    0.0166  -0.4148  0.6783
 onehot_03040104  -0.0021    0.0167  -0.1276  0.8985
 onehot_03040202   0.0000    0.0167   0.0012  0.9991
 onehot_03040204  -0.0019    0.0167  -0.1119  0.9109
 onehot_03050102  -0.0219    0.0165  -1.3304  0.1834
 onehot_03050104  -0.0044    0.0166  -0.2644  0.7914
 onehot_03050202  -0.0291    0.0164  -1.7771  0.0755
 onehot_03050204  -0.0087    0.0166  -0.5235  0.6006
 onehot_04010101  -0.0098    0.0166  -0.5892  0.5557
 onehot_04010102  -0.0037    0.0166  -0.2210  0.8251
 onehot_04010104  -0.0191    0.0165  -1.1580  0.2469
 onehot_04010201  -0.0120    0.0166  -0.7231  0.4696
 onehot_04010202  -0.0021    0.0167  -0.1284  0.8978
 onehot_04010204  -0.0099    0.0166  -0.5961  0.5511
 onehot_04020101  -0.0046    0.0166  -0.2763  0.7823
 onehot_04020104  -0.0097    0.0166  -0.5852  0.5584
 onehot_04020201  -0.0022    0.0167  -0.1335  0.8938
 onehot_04020202  -0.0040    0.0166  -0.2376  0.8122
 onehot_04020204  -0.0062    0.0166  -0.3743  0.7082
 onehot_04030101  -0.0058    0.0166  -0.3510  0.7256
 onehot_04030102  -0.0001    0.0167  -0.0070  0.9944
 onehot_04030104  -0.0212    0.0165  -1.2878  0.1978
 onehot_04040101  -0.0037    0.0166  -0.2210  0.8251
 onehot_04040102  -0.0035    0.0166  -0.2121  0.8320
 onehot_04040104  -0.0004    0.0167  -0.0239  0.9809
 onehot_04050101  -0.0052    0.0166  -0.3149  0.7528
 onehot_04050102  -0.0052    0.0166  -0.3139  0.7536
 onehot_04050104  -0.0066    0.0166  -0.3961  0.6921
 onehot_04050201  -0.0121    0.0166  -0.7335  0.4633
 onehot_04050202  -0.0047    0.0166  -0.2835  0.7768
 onehot_04050204  -0.0150    0.0165  -0.9071  0.3643
 onehot_05010102  -0.0036    0.0166  -0.2177  0.8276
 onehot_05010104  -0.0201    0.0165  -1.2185  0.2230
 onehot_05010202  -0.0039    0.0166  -0.2329  0.8159
 onehot_05010204  -0.0143    0.0165  -0.8627  0.3883
 onehot_05020102  -0.0064    0.0166  -0.3835  0.7013
 onehot_05020104  -0.0149    0.0165  -0.9011  0.3675
 onehot_05020204  -0.0090    0.0166  -0.5432  0.5870
 onehot_05030102  -0.0165    0.0165  -0.9970  0.3188
 onehot_05030104  -0.0222    0.0164  -1.3504  0.1769
 onehot_05030204  -0.0068    0.0166  -0.4065  0.6844
 onehot_05040104  -0.0119    0.0166  -0.7152  0.4745
 onehot_05050102  -0.0011    0.0167  -0.0644  0.9487
 onehot_05050104  -0.0080    0.0166  -0.4814  0.6302
 onehot_05050202  -0.0098    0.0166  -0.5906  0.5548
 onehot_05050204  -0.0256    0.0164  -1.5543  0.1201
 onehot_06010101  -0.0022    0.0167  -0.1332  0.8940
 onehot_06010102  -0.0167    0.0165  -1.0090  0.3130
 onehot_06010104  -0.0022    0.0167  -0.1332  0.8940
 onehot_06010201  -0.0063    0.0166  -0.3764  0.7066
 onehot_06010202  -0.0012    0.0167  -0.0740  0.9410
 onehot_06020102  -0.0037    0.0166  -0.2210  0.8251
 onehot_06020201  -0.0035    0.0166  -0.2121  0.8320
 onehot_06020202  -0.0012    0.0167  -0.0709  0.9435
 onehot_06030101  -0.0082    0.0166  -0.4909  0.6235
 onehot_06030102  -0.0082    0.0166  -0.4909  0.6235
 onehot_06030104  -0.0030    0.0167  -0.1795  0.8575
 onehot_06040102  -0.0033    0.0166  -0.1954  0.8451
 onehot_06040104  -0.0037    0.0166  -0.2210  0.8251
 onehot_06050102  -0.0044    0.0166  -0.2638  0.7920
 onehot_06050202  -0.0093    0.0166  -0.5593  0.5759
 onehot_06050204  -0.0035    0.0166  -0.2121  0.8320
distance_rounded  -0.0038    0.0001 -64.7431  0.0000

(Dispersion parameter for poisson family taken to be 1.0000)
    Null deviance: 42906.6423 on 1696 degrees of freedom
Residual deviance: 25578.5740 on 1696 degrees of freedom
AIC: 30703.7371
</code></pre>
</div>
</div>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../../contents/000_5-sds-2-x-geo/035_06_ConnectedComponent_PageRank.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../../contents/000_5-sds-2-x-geo/035_06_ConnectedComponent_PageRank.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

            </nav>

        </div>




        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="../../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="../../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->


    </body>
</html>


<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>SDS-2.x, Scalable Data Engineering Science &#8212; Scalable Data Science &amp; Distributed Machine Learning</title>
    
  <link rel="stylesheet" href="../../../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
  
  <img src="../../../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Scalable Data Science & Distributed Machine Learning</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/000_ScaDaMaLe.html">
   Introduction
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction to Apache Spark Core
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/001_whySpark.html">
   Why Apache Spark?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html">
   databricks community edition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#essentials-of-databricks-cloud-dbc-in-a-big-hurry">
   Essentials of Databricks Cloud (DBC) in a Big Hurry
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#dbc-essentials-what-is-databricks-cloud">
   DBC Essentials: What is Databricks Cloud?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#dbc-essentials-shard-cluster-notebook-and-dashboard">
   DBC Essentials: Shard, Cluster, Notebook and Dashboard
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#dbc-essentials-team-state-collaboration-elastic-resources">
   DBC Essentials: Team, State, Collaboration, Elastic Resources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#you-should-all-have-databricks-community-edition-account-by-now">
   You Should All Have databricks community edition account by now!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#import-course-content-now">
   Import Course Content Now!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#cloud-free-computing-environment-optional-but-recommended">
   Cloud-free Computing Environment (Optional but recommended)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_01_multiLingualNotebooks.html">
   Notebooks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_01_multiLingualNotebooks.html#further-reference-homework-recurrrent-points-of-reference">
   Further Reference / Homework / Recurrrent Points of Reference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html">
   Introduction to Scala through Scala Notebook
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#scala-in-your-own-computer">
   Scala in your own computer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#scala-resources">
   Scala Resources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#introduction-to-scala">
   Introduction to Scala
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#let-s-get-our-hands-dirty-in-scala">
   Letâ€™s get our hands dirty in Scala
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#scala-types">
   Scala Types
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#expressions">
   Expressions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#blocks">
   Blocks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#functions">
   Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#methods">
   Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#classes">
   Classes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#case-classes">
   Case Classes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#objects">
   Objects
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#traits">
   Traits
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#main-method">
   Main Method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#what-i-try-not-do-while-learning-a-new-language">
   What I try not do while learning a new language?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html">
   Scala Resources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html#let-s-continue-to-get-our-hands-dirty-in-scala">
   Letâ€™s continue to get our hands dirty in Scala
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html#scala-type-hierarchy">
   Scala Type Hierarchy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html#scala-collections">
   Scala Collections
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html#exercise-in-functional-programming">
   Exercise in Functional Programming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html#lazy-evaluation">
   Lazy Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html#recursions">
   Recursions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/004_RDDsTransformationsActions.html">
   Introduction to Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/004_RDDsTransformationsActions.html#spark-cluster-overview">
   Spark Cluster Overview:
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/005_RDDsTransformationsActionsHOMEWORK.html">
   HOMEWORK notebook - RDDs Transformations and Actions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html">
   Piped RDDs and Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#from-a-local-collection">
   From a Local Collection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#glom">
   glom
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#checkpointing">
   Checkpointing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#pipe-rdds-to-system-commands">
   Pipe RDDs to System Commands
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#mappartitions">
   mapPartitions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#foreachpartition">
   foreachPartition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#numerically-rigorous-bayesian-ab-testing">
   Numerically Rigorous Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#usage-instructions-for-isit1or2coins">
   Usage instructions for IsIt1or2Coins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006_WordCount.html">
   Word Count on US State of the Union (SoU) Addresses
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction to Apache Spark SQL
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007_SparkSQLIntroBasics.html">
   Introduction to Spark SQL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007_SparkSQLIntroBasics.html#overview">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007_SparkSQLIntroBasics.html#datasets-and-dataframes">
   Datasets and DataFrames
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007_SparkSQLIntroBasics.html#getting-started-in-spark-2-x">
   Getting Started in Spark 2.x
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007a_SparkSQLProgGuide_HW.html">
   Spark Sql Programming Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007b_SparkSQLProgGuide_HW.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007b_SparkSQLProgGuide_HW.html#id1">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007c_SparkSQLProgGuide_HW.html">
   Getting Started - Exercise
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007d_SparkSQLProgGuide_HW.html">
   Data Sources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007d_SparkSQLProgGuide_HW.html#id1">
   Data Sources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007e_SparkSQLProgGuide_HW.html">
   Performance Tuning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007f_SparkSQLProgGuide_HW.html">
   Distributed SQL Engine
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007f_SparkSQLProgGuide_HW.html#id1">
   Distributed SQL Engine
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html#sql-pivoting-since-spark-2-4">
   SQL Pivoting since Spark 2.4
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html#load-data">
   Load Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-in-sql">
   Pivoting in SQL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-with-multiple-aggregate-expressions">
   Pivoting with Multiple Aggregate Expressions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-with-multiple-grouping-columns">
   Pivoting with Multiple Grouping Columns
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-with-multiple-pivot-columns">
   Pivoting with Multiple Pivot Columns
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html">
   Diamonds ML Pipeline Workflow - DataFrame ETL and EDA Part
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#step-1-load-data-as-dataframe">
   Step 1. Load data as DataFrame
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#step-2-understand-the-data">
   Step 2. Understand the data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#let-us-run-through-some-basic-inteactive-sql-queries-next">
   Let us run through some basic inteactive SQL queries next
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#why-do-we-need-to-know-these-interactive-sql-queries">
   Why do we need to know these interactive SQL queries?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#we-will-continue-later-with-ml-pipelines-to-do-prediction-with-a-fitted-model-from-this-dataset">
   We will continue later with ML pipelines to do prediction with a fitted model from this dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html">
   Power Plant ML Pipeline Application - DataFrame Part
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-1-business-understanding">
   Step 1: Business Understanding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-2-load-your-data">
   Step 2: Load Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#use-this-for-other-smallish-datasets-you-want-to-import-to-your-ce">
   USE THIS FOR OTHER SMALLish DataSets you want to import to your CE
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-3-explore-your-data">
   Step 3: Explore Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-4-visualize-your-data">
   Step 4: Visualize Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/010_wikipediaClickStream_01ETLEDA.html">
   Wiki Clickstream Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/010_wikipediaClickStream_01ETLEDA.html#wikipedia-logo">
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_LoadExtract.html">
   Old Bailey Online Data Analysis in Apache Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_LoadExtract.html#analysing-the-full-old-bailey-online-sessions-papers-dataset">
   Analysing the Full Old Bailey Online Sessions Papers Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html">
   Piped RDDs and Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#from-a-local-collection">
   From a Local Collection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#glom">
   glom
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#checkpointing">
   Checkpointing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#pipe-rdds-to-system-commands">
   Pipe RDDs to System Commands
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#mappartitions">
   mapPartitions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#foreachpartition">
   foreachPartition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#numerically-rigorous-bayesian-ab-testing">
   Numerically Rigorous Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#usage-instructions-for-isit1or2coins">
   Usage instructions for IsIt1or2Coins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#parsing-the-output-from-isit1or2coins">
   Parsing the output from
   <code class="docutils literal notranslate">
    <span class="pre">
     IsIt1or2Coins
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#providing-case-classes-for-input-and-output-for-easy-spark-communication">
   Providing case classes for input and output for easy spark communication
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/035_LDA_CornellMovieDialogs.html">
   Topic Modeling of Movie Dialogs with Latent Dirichlet Allocation
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Distribute Deep Learning with Horovod
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_7-sds-3-x-ddl/00_DDL_Introduction.html">
   Introduction to Distributed Deep Learning (DDL) with Horovod over Tensorflow/keras and Pytorch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_7-sds-3-x-ddl/0x_mnist-tensorflow-keras.html">
   Distributed deep learning training using TensorFlow and Keras with HorovodRunner
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_7-sds-3-x-ddl/0y_mnist-pytorch.html">
   Distributed deep learning training using PyTorch with HorovodRunner for MNIST
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  WASP AI-Track Student Projects
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/035_LDA_CornellMovieDialogs.html">
   Topic Modeling of Movie Dialogs with Latent Dirichlet Allocation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-01_group-TheTwoCultures/00_download_data.html">
   The two cultures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-01_group-TheTwoCultures/01_load_data.html">
   Preprocessing and loading the relevant data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-01_group-TheTwoCultures/02_logisticregression.html">
   The two cultures - Classifying threads with logistic regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-01_group-TheTwoCultures/03_word2vec.html">
   Classification using Word2Vec
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-01_group-TheTwoCultures/04_LDA.html">
   Topic Modeling with LDA
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-02_group-LiUUmeaSceneGraphMotifs/01_Loading_GQA-JSON.html">
   Reading GQA JSON files
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-02_group-LiUUmeaSceneGraphMotifs/02_SceneGraphMotifs.html">
   Exploring the GQA Scene Graph Dataset Structure and Properties
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-02_group-LiUUmeaSceneGraphMotifs/02_SceneGraphMotifs.html#general-discussion">
   General discussion
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-03_group-GuangyiZhang/01_triads.html">
   Signed Triads in Social Media
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-04_group-DistributedLinearAlgebra/01_DistributedSVD.html">
   Distributed singular value decomposition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-04_group-DistributedLinearAlgebra/02_CollaborativeFiltering.html">
   Music Recommendation System
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-05_group-LundDirichletAnalysts/01_Wikipedia_LDA_Analysis.html">
   Wikipedia analysis using Latent Dirichlet Allocation (LDA)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-05_group-LundDirichletAnalysts/01_Wikipedia_LDA_Analysis.html#folders-and-files">
   Folders and Files
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-05_group-LundDirichletAnalysts/01_Wikipedia_LDA_Analysis.html#downloading">
   Downloading
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-05_group-LundDirichletAnalysts/01_Wikipedia_LDA_Analysis.html#extracting-and-filtering">
   Extracting and Filtering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-05_group-LundDirichletAnalysts/01_Wikipedia_LDA_Analysis.html#prepare-for-lda">
   Prepare for LDA
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-05_group-LundDirichletAnalysts/01_Wikipedia_LDA_Analysis.html#lda">
   LDA
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-05_group-LundDirichletAnalysts/01_Wikipedia_LDA_Analysis.html#looking-at-the-model">
   Looking at the model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-06_group-ParticleClustering/00_Introduction.html">
   Unsupervised clustering of particle physics data with distributed training
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-06_group-ParticleClustering/00_Introduction.html#introduction">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-06_group-ParticleClustering/00_Introduction.html#background">
   Background
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-06_group-ParticleClustering/00_Introduction.html#the-uclusted-algorithm">
   The UClusted algorithm
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-06_group-ParticleClustering/00_Introduction.html#motivation">
   Motivation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-06_group-ParticleClustering/00_Introduction.html#our-contribution">
   Our contribution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-06_group-ParticleClustering/01_data_and_preprocessing.html">
   Important!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-06_group-ParticleClustering/01_data_and_preprocessing.html#important-continued-from-above">
   Important (continued from above)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-06_group-ParticleClustering/04_evaluate.html">
   Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-07_group-MathAtKTH/01_Coding_Motifs.html">
   Motif Finding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-07_group-MathAtKTH/01_Coding_Motifs.html#application">
   Application
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-07_group-MathAtKTH/02_Data_Processing.html">
   Data Processing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-07_group-MathAtKTH/03_graph_string_converter.html">
   Intro
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-07_group-MathAtKTH/03_graph_string_converter.html#examples">
   Examples
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-08_group-DistributedEnsemble/00_Introduction.html">
   Lit
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-08_group-DistributedEnsemble/00_Introduction.html#docs">
   Docs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-08_group-DistributedEnsemble/model_2.html">
   MLP with auto-inferred
   <code class="docutils literal notranslate">
    <span class="pre">
     shapes
    </span>
   </code>
   param
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-08_group-DistributedEnsemble/project.html">
   ScaDaMaLe project: Distributed ensembles
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-08_group-DistributedEnsemble/project.html#imports">
   Imports
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-08_group-DistributedEnsemble/project.html#data">
   Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-08_group-DistributedEnsemble/project.html#distributed-ensemble-of-neural-networks">
   Distributed ensemble of neural networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-08_group-DistributedEnsemble/project.html#distributed-ensembles-prediction-api">
   Distributed ensembles prediction API
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-08_group-DistributedEnsemble/project.html#application-example-distributed-predictions">
   Application example: Distributed predictions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-08_group-DistributedEnsemble/project.html#application-example-out-of-distribution-detection">
   Application example: Out of distribution detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/01_Introduction.html">
   Topic Modeling with SARS-Cov-2 Genome ðŸ§¬
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/02_Data_Processing.html">
   Extract (overlapping [since yet do not know which parts corresponds to coding regions]) 3-mers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/03_LDA.html">
   Load processed data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/03_LDA.html#format-data-for-apache-spark-mllib-clustering-lda-adapted-from-the-lda-course-tutorial-034lda20newsgroupssmall">
   Format data for apache.spark.mllib.clustering.LDA (adapted from the LDA course tutorial â€˜034
   <em>
    LDA
   </em>
   20NewsGroupsSmallâ€™)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/03_LDA.html#visualise-results">
   Visualise Results
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/04_Classification_CountVector.html">
   Load processed data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/04_Classification_CountVector.html#format-data">
   Format data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/04_Classification_CountVector.html#classification">
   Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/04_Classification_CountVector.html#evaluation">
   Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/05_Classification.html">
   Load processed data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/05_Classification.html#explore-data">
   Explore data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/05_Classification.html#classification">
   Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/05_Classification.html#evaluation">
   Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/06_Results.html">
   Results and Conclusion
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-10_group-Geosmus/01_Introduction.html">
   Twitter Streaming Using Geolocation and Emoji Based Sentiment Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-10_group-Geosmus/02_ClusteringEmoticonsBasedOnTweets.html">
   Clustering emoticons based on tweets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-10_group-Geosmus/03_Dynamic_Tweet_Maps.html">
   Dynamic Tweet Maps
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-10_group-Geosmus/04_conclusion.html">
   Conclusion
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-10_group-Geosmus/05_appendix_get-cc-data.html">
   Notebook for collecting tweets with country codes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-10_group-Geosmus/07_a_appendix_extendedTwitterUtils2run.html">
   Note, this notebook has been edited slightly from the one supplied by Raaz.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-10_group-Geosmus/07_a_appendix_extendedTwitterUtils2run.html#scadamale-scalable-data-science-and-distributed-machine-learning">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-10_group-Geosmus/07_a_appendix_extendedTwitterUtils2run.html#extended-spark-streaming-twitter-twitterutils">
   Extended spark.streaming.twitter.TwitterUtils
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-10_group-Geosmus/07_b_appendix_TTTDFfunctions.html">
   Note, this notebook has been edited slightly from the one supplied by Raaz.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-10_group-Geosmus/07_b_appendix_TTTDFfunctions.html#scadamale-scalable-data-science-and-distributed-machine-learning">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-11_group-Sketchings/00_QuantileEstimation.html">
   Anomaly Detection with Iterative Quantile Estimation and T-digest
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/00_ProjectDescriptionAndPlanning.html">
   Project Description and Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/01_DownloadFilesPeriodicallyScript.html">
   Download Files Periodically
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/01_StreamToFile.html">
   Stream to parquet file
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/021_DataPreprocess_Explain.html">
   Loading data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/021_DataPreprocess_Explain.html#preprocessing">
   Preprocessing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/02_DataPreprocess.html">
   Loading data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/02_DataPreprocess.html#preprocessing">
   Preprocessing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html">
   This notebook is for explosive analysis of features in data.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html#statistics-of-invariant-features">
   Statistics of invariant features
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html#correlation-between-invariant-features">
   Correlation between invariant features
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html#correlation-between-new-case-per-million-total-case-new-death-per-million-total-death-per-million-reproduction-rate-and-stringency-index">
   Correlation between new case per million, total case, new death per million, total death per million, reproduction rate and stringency index.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/04_DataVisualize.html">
   Show reproduction rate of selected countries i.e. Sweden, Germany, Danmark, Finland, Norway
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/04_DataVisualize.html#visualize-total-cases-total-deaths-new-cases-and-new-deaths-during-pandemic">
   Visualize total cases, total deaths, new cases and new deaths during pandemic
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/04_DataVisualize.html#total-deaths">
   Total Deaths
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/04_DataVisualize.html#new-cases">
   New Cases
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/04_DataVisualize.html#new-deaths">
   New Deaths
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/05_Clustering.html">
   Clustering of country features in the Covid 19 dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/06_DataPredicton_LR.html">
   Prediction with Linear Regression (LR) Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/07_DataPredicton_ARIMA.html">
   Prediction with Time Series model - ARIMA
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/08_DataPrediction_GP.html">
   Prediction with time series model - Gaussian Processes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-13_group-Genomics/01_1000genomes.html">
   Genomics Analysis with Glow and Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-13_group-Genomics/01_1000genomes.html#load-libs-and-define-helper-functions">
   Load libs and define helper functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-13_group-Genomics/01_1000genomes.html#read-data">
   Read data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-13_group-Genomics/01_1000genomes.html#pca">
   PCA
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-13_group-Genomics/01_1000genomes.html#predicting-ethinicity">
   Predicting Ethinicity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-13_group-Genomics/01_1000genomes.html#filtering-of-snps-based-on-chi-squared-test">
   Filtering of SNPs based on chi-squared test
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-14_group-NullHypothesisEvaluationCriteria/distributed_combinatorial_bandit.html">
   Distributional combinatorial bandits
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-15_group-FinancialDataStreams/00_video.html">
   Reinforcement Learning for Intraday Trading
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-15_group-FinancialDataStreams/01_rl_intraday_trading.html">
   Reinforcement Learning for Intraday Trading
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html">
   Reinforcement Learning for Intraday Trading - Distributed model tuning with Elephas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html#elephas">
   Elephas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html#notes-to-the-elephas-training">
   Notes to the elephas training
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html#id1">
   Notes to the elephas training
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-15_group-FinancialDataStreams/03_resources.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-15_group-FinancialDataStreams/03_resources.html#environment">
   Environment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-15_group-FinancialDataStreams/03_resources.html#rl-algorithms">
   RL-Algorithms
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-15_group-FinancialDataStreams/03_resources.html#scalable-dl">
   Scalable DL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-15_group-FinancialDataStreams/03_resources.html#spark-scalability-monitoring">
   Spark scalability monitoring
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-15_group-FinancialDataStreams/03_resources.html#raaz-to-group">
   Raaz to groupâ€¦
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-16_group-IntrusionDetection/00_Introduction.html">
   Problem Definition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-16_group-IntrusionDetection/00_Introduction.html#loading-and-preprocessing-data">
   Loading and Preprocessing Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Intro.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Intro.html#problem-description">
   Problem description
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-19_group-Featuring/01_FundamentalMatrix.html">
   Link to our video explaining the 1) theory, 2) preprocessing the dataset, 3) algorithm and 4) results
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-19_group-Featuring/01_FundamentalMatrix.html#https-drive-google-com-drive-folders-1zewj6jsjeuu9f8q5xy-avwxq3yj9oi7z-usp-sharing">
   https://drive.google.com/drive/folders/1zEWj6JsJEUu9f8Q5Xy_avwxQ3yJ9oI7Z?usp=sharing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-19_group-Featuring/01_FundamentalMatrix.html#problem-formulation">
   Problem formulation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-19_group-Featuring/01_FundamentalMatrix.html#results">
   Results
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-20_group-Generalization/02_CNNs.html">
   The data set
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-20_group-Generalization/02_CNNs.html#mixup-data-generator">
   MixUp data generator
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-20_group-Generalization/02_CNNs.html#training-function">
   Training function
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-20_group-Generalization/02_CNNs.html#connection-between-mixup-performance-and-generalization">
   Connection between MixUp performance and generalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-20_group-Generalization/02_CNNs.html#directly-training-on-mixup-data">
   Directly training on MixUp data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-20_group-Generalization/02_CNNs.html#conclusions">
   Conclusions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-21_group-GraphSpectralAnalysis/00_introduction.html">
   Graph Spectral Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-21_group-GraphSpectralAnalysis/01_preprocess_data.html">
   Preprocess the data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-21_group-GraphSpectralAnalysis/02_generate_graphs.html">
   Generate random graphs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-21_group-GraphSpectralAnalysis/03_compute_rsvd.html">
   Compute RSVD
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-21_group-GraphSpectralAnalysis/04_analyse_eigenvalues.html">
   Analyse the eigenvalue spectrum
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Voluntary Student Projects
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/030_Spark_GDELT_project.html">
   Plugging into GDELT Streams - TODO - IN PROGRESS
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/030_Spark_GDELT_project.html#this-is-just-dipping-our-pinky-toe-in-this-ocean-of-information">
   This is just dipping our pinky toe in this ocean of information!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/030_Spark_GDELT_project.html#download-from-gdelt-project">
   Download from gdelt-project
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../_sources/000_0-sds-3-x-projects/student-project-18_group-ProjectRL/sds-2-x-dl/062_DLbyABr_06-GenerativeNetworks.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://lamastex.github.io/ScaDaMaLe/index.html"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://lamastex.github.io/ScaDaMaLe/index.html/issues/new?title=Issue%20on%20page%20%2F000_0-sds-3-x-projects/student-project-18_group-ProjectRL/sds-2-x-dl/062_DLbyABr_06-GenerativeNetworks.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   SDS-2.x, Scalable Data Engineering Science
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#generative-networks">
   Generative Networks
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#concept">
     Concept:
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#does-it-contain-enough-information-to-do-the-reverse">
     Does it contain enough information to do the reverse?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mechanically-how-could-this-work">
     Mechanically, How Could This Work?
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#pretty-cool-so-we-re-all-done-now-right-now-quite">
       Pretty cool. So weâ€™re all done now, right? Now quiteâ€¦
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-goal-is-to-generate-a-variety-of-new-output-from-a-variety-of-new-inputs">
       The Goal is to Generate a Variety of New Output From a Variety of New Inputs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#two-principal-approaches-architectures-2015">
       Two principal approaches / architectures (2015-)
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#variational-autoencoder-vae">
     Variational Autoencoder (VAE)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generative-adversarial-network-gan">
     Generative Adversarial Network (GAN)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#sample-generated-digits-epoch-1">
       Sample generated digits: epoch 1
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#sample-generated-digits-epoch-10">
       Sample generated digits: epoch 10
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#generator-discriminator-loss">
       Generator/Discriminator Loss
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#which-strategy-to-use">
     Which Strategy to Use?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#where-next">
   Where Next?
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="sds-2-x-scalable-data-engineering-science">
<h1><a class="reference external" href="https://lamastex.github.io/scalable-data-science/sds/2/x/">SDS-2.x, Scalable Data Engineering Science</a><a class="headerlink" href="#sds-2-x-scalable-data-engineering-science" title="Permalink to this headline">Â¶</a></h1>
<p>This is a 2019 augmentation and update of <a class="reference external" href="https://www.linkedin.com/in/adbreind">Adam
Breindel</a>â€™s initial notebooks.</p>
</div>
<div class="section" id="generative-networks">
<h1>Generative Networks<a class="headerlink" href="#generative-networks" title="Permalink to this headline">Â¶</a></h1>
<div class="section" id="concept">
<h2>Concept:<a class="headerlink" href="#concept" title="Permalink to this headline">Â¶</a></h2>
<p>If a set of network weights can convert an image of the numeral 8 or a
cat &lt;br/&gt;into the classification â€œ8â€ or â€œcatâ€ â€¦</p>
</div>
<div class="section" id="does-it-contain-enough-information-to-do-the-reverse">
<h2>Does it contain enough information to do the reverse?<a class="headerlink" href="#does-it-contain-enough-information-to-do-the-reverse" title="Permalink to this headline">Â¶</a></h2>
<p>I.e., can we ask a network what â€œ8â€ looks like and get a picture?</p>
<p>Letâ€™s think about this for a second. Clearly the classifications have
far fewer bits of entropy than the source imagesâ€™ theoretical limit.</p>
<ul class="simple">
<li><p>Cat (in cat-vs-dog) has just 1 bit, where perhaps a 256x256
grayscale image has up to 512k bits.</p></li>
<li><p>8 (in MNIST) has <span class="math notranslate nohighlight">\({log \_2 10}\)</span> or a little over 3 bits, where a
28x28 grayscale image has over 6000 bits.</p></li>
</ul>
<p>So at first, this would seem difficult or impossible.</p>
<p><strong>But</strong> â€¦ letâ€™s do a thought experiment.</p>
<ul class="simple">
<li><p>Children can do this easily</p></li>
<li><p>We could create a lookup table of, say, digit -&gt; image trivially,
and use that as a first approximation</p></li>
</ul>
<p>Those approaches seem like cheating. But letâ€™s think about how they
work.</p>
<p>If a child (or adult) draws a cat (or number 8), they are probably not
drawing any specific cat (or 8). They are drawing a general
approximation of a cat based on</p>
<ol class="simple">
<li><p>All of the cats theyâ€™ve seen</p></li>
<li><p>What they remember as the key elements of a cat (4 legs, tail,
pointy ears)</p></li>
<li><p>A lookup table substitutes one specific cat or 8 â€¦ and, especially
in the case of the 8, that may be fine. The only thing we â€œloseâ€ is
the diversity of things that all mapped to cat (or 8) â€“ and
discarding that information was exactly our goal when building a
classifier</p></li>
</ol>
<p>The â€œ8â€ is even simpler: we learn that a number is an idea, not a
specific instance, so anything that another human recognizes as 8 is
good enough. We are not even trying to make a particular shape, just one
that represents our encoded information that distinguishes 8 from other
possible symbols in the context and the eye of the viewer.</p>
<p>This should remind you a bit of the KL Divergence we talked about at the
start: we are providing just enough information (entropy or surprise) to
distinguish the cat or â€œ8â€ from the other items that a human receiver
might be expecting to see.</p>
<p>And where do our handwritten â€œpixelsâ€ come from? No image in particular
â€“ they are totally synthetic based on a probability distribution.</p>
<p><em>These considerations make it sound more likely that a computer could
perform the same task.</em></p>
<p>But what would the weights really represent? what could they generate?</p>
<p><strong>The weights we learn in classification represent the distinguishing
features of a class, across all training examples of the class, modified
to overlap minimally with features of other classes.</strong> KL divergence
again.</p>
<p>To be concrete, if we trained a model on just a few dozen MNIST images
using pixels, it would probably learn the 3 or 4 â€œmagicâ€ pixels that
<em>happened</em> to distinguish the 8s in that dataset. Trying to generate
from that information would yield strong confidence about those magic
pixels, but would look like dots to us humans.</p>
<p>On the other hand, if we trained on a very large number of MNIST images
â€“ say we use the convnet this time â€“ the modelâ€™s weights should
represent general filters of masks for features that distinguish an 8.
And if we try to reverse the process by amplifying just those filters,
we should get a blurry statistical distribution of those very features.
The approximate shape of the Platonic â€œ8â€!</p>
</div>
<div class="section" id="mechanically-how-could-this-work">
<h2>Mechanically, How Could This Work?<a class="headerlink" href="#mechanically-how-could-this-work" title="Permalink to this headline">Â¶</a></h2>
<p>Letâ€™s start with a simpler model called an auto-encoder.</p>
<p>An autoencoderâ€™s job is to take a large representation of a record and
find weights that represent that record in a smaller encoding, subject
to the constraint that the decoded version should match the original as
closely as possible.</p>
<p>A bit like training a JPEG encoder to compress images by scoring it with
the loss between the original image and the decompressed version of the
lossy compressed image.</p>
<p>&lt;img src=â€http://i.imgur.com/oTRvlB6.pngâ€ width=450&gt;</p>
<p>One nice aspect of this is that it is <em>unsupervised</em> â€“ i.e., we do not
need any ground-truth or human-generated labels in order to find the
error and train. The error is always the difference between the output
and the input, and the goal is to minimize this over many examples, thus
minimize in the general case.</p>
<p>We can do this with a simple multilayer perceptron network. Or, we can
get fancier and do this with a convolutional network. In reverse, the
convolution (typically called â€œtransposed convolutionâ€ or
â€œdeconvolutionâ€) is an upsampling operation across space (in images) or
space &amp; time (in audio/video).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
<span class="kn">import</span> <span class="nn">sklearn.datasets</span>
<span class="kn">import</span> <span class="nn">datetime</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">train_libsvm</span> <span class="o">=</span> <span class="s2">&quot;/dbfs/databricks-datasets/mnist-digits/data-001/mnist-digits-train.txt&quot;</span>
<span class="n">test_libsvm</span> <span class="o">=</span> <span class="s2">&quot;/dbfs/databricks-datasets/mnist-digits/data-001/mnist-digits-test.txt&quot;</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">load_svmlight_file</span><span class="p">(</span><span class="n">train_libsvm</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">784</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">load_svmlight_file</span><span class="p">(</span><span class="n">test_libsvm</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">784</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mean_squared_error&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;mean_squared_error&#39;</span><span class="p">,</span> <span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">])</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">today</span><span class="p">()</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">)):</span>
	<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">: </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">scores</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>

<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;Start: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">start</span><span class="p">))</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">today</span><span class="p">()</span>
<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;End: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">end</span><span class="p">))</span>
<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;Elapse: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">end</span><span class="o">-</span><span class="n">start</span><span class="p">))</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;model loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ax</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="mi">61</span><span class="p">],</span> <span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">encode_decode</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="mi">61</span><span class="p">],</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ax</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">encode_decode</span><span class="p">,</span> <span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Any ideas about those black dots in the upper right?</p>
<div class="section" id="pretty-cool-so-we-re-all-done-now-right-now-quite">
<h3>Pretty cool. So weâ€™re all done now, right? Now quiteâ€¦<a class="headerlink" href="#pretty-cool-so-we-re-all-done-now-right-now-quite" title="Permalink to this headline">Â¶</a></h3>
<p>The problem with the autoencoder is itâ€™s â€œtoo goodâ€ at its task.</p>
<p>It is optimized to compress exactly the input record set, so it is
trained only to create records it has seen. If the middle layer, or
information bottleneck, is tight enough, the coded records use all of
the information space in the middle layer.</p>
<p>So any value in the middle layer decodes to exactly one already-seen
exemplar.</p>
<p>In our example, and most autoencoders, there is more space in the middle
layer but the coded values are not distributed in any sensible way. So
we can decode a random vector and weâ€™ll probably just get garbage.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">30</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">t</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>

<span class="k">with</span> <span class="n">K</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    <span class="n">display</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
    
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="the-goal-is-to-generate-a-variety-of-new-output-from-a-variety-of-new-inputs">
<h3>The Goal is to Generate a Variety of New Output From a Variety of New Inputs<a class="headerlink" href="#the-goal-is-to-generate-a-variety-of-new-output-from-a-variety-of-new-inputs" title="Permalink to this headline">Â¶</a></h3>
<p>â€¦ Where the Class/Category is Common (i.e., all 8s or Cats)</p>
<p>Some considerations:</p>
<ul class="simple">
<li><p>Is â€œgenerative contentâ€ something new? Or something true?</p>
<ul>
<li><p>In a Platonic sense, maybe, but in reality itâ€™s literally a
probabilistic guess based on the training data!</p></li>
<li><p>E.g., law enforcement photo enhancment</p></li>
</ul>
</li>
<li><p>How do we train?</p>
<ul>
<li><p>If we score directly against the training data (like in the
autoencoder), the network will be very conservative, generating
only examples that it has seen.</p></li>
<li><p>In extreme cases, it will always generate a single (or small
number) of examples, since those score well. This is known as
<strong>mode collapse</strong>, since the network learns to locate the modes
in the input distribution.</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="two-principal-approaches-architectures-2015">
<h3>Two principal approaches / architectures (2015-)<a class="headerlink" href="#two-principal-approaches-architectures-2015" title="Permalink to this headline">Â¶</a></h3>
<p><strong>Generative Adversarial Networks (GAN)</strong> and <strong>Variational Autoencoders
(VAE)</strong></p>
</div>
</div>
<div class="section" id="variational-autoencoder-vae">
<h2>Variational Autoencoder (VAE)<a class="headerlink" href="#variational-autoencoder-vae" title="Permalink to this headline">Â¶</a></h2>
<p>Our autoencoder was able to generate images, but the problem was that
arbitrary input vectors donâ€™t map to anything meaningful. As discussed,
this is partly by design â€“ the training of the VAE is for effectively
for compressing a specific input dataset.</p>
<p>What we would like, is that if we start with a valid input vector and
move a bit on some direction, we get a plausible output that is also
changed in some way.</p>
<hr class="docutils" />
<blockquote>
<div><p><strong>ASIDE: Manifold Hypothesis</strong></p>
</div></blockquote>
<blockquote>
<div><p>The manifold hypothesis is that the interesting, relevant, or critical
subspaces in the space of all vector inputs are actually low(er)
dimensional manifolds. A manifold is a space where each point has a
neighborhood that behaves like (is homeomorphic to) <span class="math notranslate nohighlight">\({\\Bbb R^n}\)</span>. So
we would like to be able to move a small amount and have only a small
amount of change, not a sudden discontinuous change.</p>
</div></blockquote>
<hr class="docutils" />
<p>The key feature of Variational Autoencoders is that we add a constraint
on the encoded representation of our data: namely, that it follows a
Gaussian distribution. Since the Gaussian is determined by its mean and
variance (or standard deviation), we can model it as a k-variate
Gaussian with these two parameters (<span class="math notranslate nohighlight">\({\\mu}\)</span> and <span class="math notranslate nohighlight">\({\\sigma}\)</span>) for each
value of k.</p>
<p>&lt;img src=â€http://i.imgur.com/OFLDweH.jpgâ€ width=600&gt; &lt;div
style=â€text-align: rightâ€&gt;&lt;sup&gt;(credit to Miram Shiffman,
http://blog.fastforwardlabs.com/2016/08/22/under-the-hood-of-the-variational-autoencoder-in.html)&lt;/sup&gt;&lt;/div&gt;</p>
<p>&lt;img src=â€http://i.imgur.com/LbvJI5q.jpgâ€&gt; &lt;div
style=â€text-align: rightâ€&gt;&lt;sup&gt;(credit to Kevin Franz,
http://kvfrans.com/variational-autoencoders-explained/)&lt;/sup&gt;&lt;/div&gt;</p>
<p>One challenge is how to balance accurate reproduction of the input
(traditional autoencoder loss) with the requirement that we match a
Gaussian distribution. We can force the network to optimize both of
these goals by creating a custom error function that sums up two
components:</p>
<ul class="simple">
<li><p>How well we match the input, calculated as binary crossentropy or
MSE loss</p></li>
<li><p>How well we match a Gaussian, calculated as KL divergence from the
Gaussian distribution</p></li>
</ul>
<p>We can easily implement a custom loss function and pass it as a
parameter to the optimizer in Keras.</p>
<p>The Keras source examples folder contains an elegant simple
implementation, which weâ€™ll discuss below. Itâ€™s a little more complex
than the code weâ€™ve seen so far, but weâ€™ll clarify the innovations:</p>
<ul class="simple">
<li><p>Custom loss functions that combined KL divergence and cross-entropy
loss</p></li>
<li><p>Custom â€œLambdaâ€ layer that provides the sampling from the encoded
distribution</p></li>
</ul>
<p>Overall itâ€™s probably simpler than you might expect. Letâ€™s start it
(since it takes a few minutes to train) and discuss the code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span>

<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Lambda</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">objectives</span>
<span class="kn">from</span> <span class="nn">keras.datasets</span> <span class="kn">import</span> <span class="n">mnist</span>
<span class="kn">import</span> <span class="nn">sklearn.datasets</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">original_dim</span> <span class="o">=</span> <span class="mi">784</span>
<span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">intermediate_dim</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">nb_epoch</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">epsilon_std</span> <span class="o">=</span> <span class="mf">1.0</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">batch_shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">original_dim</span><span class="p">))</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">intermediate_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">z_mean</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">)(</span><span class="n">h</span><span class="p">)</span>
<span class="n">z_log_var</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">)(</span><span class="n">h</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">sampling</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="n">z_mean</span><span class="p">,</span> <span class="n">z_log_var</span> <span class="o">=</span> <span class="n">args</span>
    <span class="n">epsilon</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">random_normal</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">),</span> <span class="n">mean</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span>
                              <span class="n">stddev</span><span class="o">=</span><span class="n">epsilon_std</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">z_mean</span> <span class="o">+</span> <span class="n">K</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">z_log_var</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">epsilon</span>

<span class="c1"># note that &quot;output_shape&quot; isn&#39;t necessary with the TensorFlow backend</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="n">sampling</span><span class="p">,</span> <span class="n">output_shape</span><span class="o">=</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,))([</span><span class="n">z_mean</span><span class="p">,</span> <span class="n">z_log_var</span><span class="p">])</span>

<span class="c1"># we instantiate these layers separately so as to reuse them later</span>
<span class="n">decoder_h</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">intermediate_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)</span>
<span class="n">decoder_mean</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">original_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)</span>
<span class="n">h_decoded</span> <span class="o">=</span> <span class="n">decoder_h</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
<span class="n">x_decoded_mean</span> <span class="o">=</span> <span class="n">decoder_mean</span><span class="p">(</span><span class="n">h_decoded</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">vae_loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_decoded_mean</span><span class="p">):</span>
    <span class="n">xent_loss</span> <span class="o">=</span> <span class="n">original_dim</span> <span class="o">*</span> <span class="n">objectives</span><span class="o">.</span><span class="n">binary_crossentropy</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_decoded_mean</span><span class="p">)</span>
    <span class="n">kl_loss</span> <span class="o">=</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">z_log_var</span> <span class="o">-</span> <span class="n">K</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">z_mean</span><span class="p">)</span> <span class="o">-</span> <span class="n">K</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">z_log_var</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">xent_loss</span> <span class="o">+</span> <span class="n">kl_loss</span>

<span class="n">vae</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_decoded_mean</span><span class="p">)</span>
<span class="n">vae</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">vae_loss</span><span class="p">)</span>

<span class="n">train_libsvm</span> <span class="o">=</span> <span class="s2">&quot;/dbfs/databricks-datasets/mnist-digits/data-001/mnist-digits-train.txt&quot;</span>
<span class="n">test_libsvm</span> <span class="o">=</span> <span class="s2">&quot;/dbfs/databricks-datasets/mnist-digits/data-001/mnist-digits-test.txt&quot;</span>

<span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">load_svmlight_file</span><span class="p">(</span><span class="n">train_libsvm</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">784</span><span class="p">)</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">load_svmlight_file</span><span class="p">(</span><span class="n">test_libsvm</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">784</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>

<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">x_train</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])))</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">x_test</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])))</span>

<span class="n">vae</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="n">nb_epoch</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">x_test</span><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># build a model to project inputs on the latent space</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">z_mean</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 60000 samples, validate on 10000 samples
Epoch 1/50
 - 7s - loss: 190.9768 - val_loss: 173.1796
Epoch 2/50
 - 7s - loss: 170.5004 - val_loss: 168.3274
Epoch 3/50
 - 7s - loss: 166.9483 - val_loss: 165.7523
Epoch 4/50
 - 7s - loss: 164.8370 - val_loss: 164.2769
Epoch 5/50
 - 7s - loss: 163.3543 - val_loss: 162.8434
Epoch 6/50
 - 7s - loss: 162.1008 - val_loss: 161.5877
Epoch 7/50
 - 7s - loss: 161.0557 - val_loss: 160.8535
Epoch 8/50
 - 7s - loss: 160.0666 - val_loss: 159.8321
Epoch 9/50
 - 7s - loss: 159.1418 - val_loss: 159.0197
Epoch 10/50
 - 7s - loss: 158.3370 - val_loss: 158.1361
Epoch 11/50
 - 7s - loss: 157.6069 - val_loss: 157.9401
Epoch 12/50
 - 7s - loss: 156.9792 - val_loss: 156.8949
Epoch 13/50
 - 7s - loss: 156.4237 - val_loss: 156.6119
Epoch 14/50
 - 7s - loss: 155.9121 - val_loss: 156.3393
Epoch 15/50
 - 7s - loss: 155.4880 - val_loss: 156.1204
Epoch 16/50
 - 7s - loss: 155.0392 - val_loss: 156.1275
Epoch 17/50
 - 7s - loss: 154.6869 - val_loss: 155.0182
Epoch 18/50
 - 7s - loss: 154.3163 - val_loss: 154.7265
Epoch 19/50
 - 7s - loss: 154.0314 - val_loss: 154.6318
Epoch 20/50
 - 7s - loss: 153.7218 - val_loss: 154.3242
Epoch 21/50
 - 7s - loss: 153.4679 - val_loss: 154.4581
Epoch 22/50
 - 7s - loss: 153.1870 - val_loss: 153.9840
Epoch 23/50
 - 7s - loss: 152.9839 - val_loss: 153.8052
Epoch 24/50
 - 7s - loss: 152.7605 - val_loss: 153.9252
Epoch 25/50
 - 7s - loss: 152.5473 - val_loss: 153.7088
Epoch 26/50
 - 7s - loss: 152.3364 - val_loss: 153.6085
Epoch 27/50
 - 7s - loss: 152.1534 - val_loss: 153.2579
Epoch 28/50
 - 7s - loss: 152.0203 - val_loss: 153.1721
Epoch 29/50
 - 7s - loss: 151.8157 - val_loss: 153.1620
Epoch 30/50
 - 7s - loss: 151.6618 - val_loss: 153.1152
Epoch 31/50
 - 7s - loss: 151.5067 - val_loss: 152.8042
Epoch 32/50
 - 7s - loss: 151.3810 - val_loss: 152.8947
Epoch 33/50
 - 7s - loss: 151.2489 - val_loss: 152.5349
Epoch 34/50
 - 7s - loss: 151.0784 - val_loss: 152.9623
Epoch 35/50
 - 7s - loss: 150.9885 - val_loss: 152.5544
Epoch 36/50
 - 7s - loss: 150.8500 - val_loss: 152.6461
Epoch 37/50
 - 7s - loss: 150.7122 - val_loss: 152.0259
Epoch 38/50
 - 7s - loss: 150.6166 - val_loss: 152.8115
Epoch 39/50
 - 7s - loss: 150.4893 - val_loss: 152.0757
Epoch 40/50
 - 7s - loss: 150.4013 - val_loss: 152.3985
Epoch 41/50
 - 7s - loss: 150.3099 - val_loss: 151.8574
Epoch 42/50
 - 7s - loss: 150.1686 - val_loss: 151.9436
Epoch 43/50
 - 7s - loss: 150.1139 - val_loss: 152.1689
Epoch 44/50
 - 7s - loss: 150.0130 - val_loss: 151.7565
Epoch 45/50
 - 7s - loss: 149.8982 - val_loss: 151.7926
Epoch 46/50
 - 7s - loss: 149.8157 - val_loss: 152.5258
Epoch 47/50
 - 7s - loss: 149.7415 - val_loss: 151.6356
Epoch 48/50
 - 7s - loss: 149.6592 - val_loss: 151.9871
Epoch 49/50
 - 7s - loss: 149.5619 - val_loss: 151.6842
Epoch 50/50
 - 7s - loss: 149.4900 - val_loss: 151.6131
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># display a 2D plot of the digit classes in the latent space</span>
<span class="n">x_test_encoded</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">((</span><span class="mi">8</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_test_encoded</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x_test_encoded</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_test</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">display</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># build a digit generator that can sample from the learned distribution</span>
<span class="n">decoder_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,))</span>
<span class="n">_h_decoded</span> <span class="o">=</span> <span class="n">decoder_h</span><span class="p">(</span><span class="n">decoder_input</span><span class="p">)</span>
<span class="n">_x_decoded_mean</span> <span class="o">=</span> <span class="n">decoder_mean</span><span class="p">(</span><span class="n">_h_decoded</span><span class="p">)</span>
<span class="n">generator</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">decoder_input</span><span class="p">,</span> <span class="n">_x_decoded_mean</span><span class="p">)</span>

<span class="c1"># display a 2D manifold of the digits</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">15</span>  <span class="c1"># figure with 15x15 digits</span>
<span class="n">digit_size</span> <span class="o">=</span> <span class="mi">28</span>
<span class="n">figure</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">digit_size</span> <span class="o">*</span> <span class="n">n</span><span class="p">,</span> <span class="n">digit_size</span> <span class="o">*</span> <span class="n">n</span><span class="p">))</span>
<span class="c1"># linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian</span>
<span class="c1"># to produce values of the latent variables z, since the prior of the latent space is Gaussian</span>
<span class="n">grid_x</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
<span class="n">grid_y</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">yi</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">grid_x</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">xi</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">grid_y</span><span class="p">):</span>
        <span class="n">z_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">xi</span><span class="p">,</span> <span class="n">yi</span><span class="p">]])</span>
        <span class="n">x_decoded</span> <span class="o">=</span> <span class="n">generator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">z_sample</span><span class="p">)</span>
        <span class="n">digit</span> <span class="o">=</span> <span class="n">x_decoded</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">digit_size</span><span class="p">,</span> <span class="n">digit_size</span><span class="p">)</span>
        <span class="n">figure</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">digit_size</span><span class="p">:</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">digit_size</span><span class="p">,</span>
               <span class="n">j</span> <span class="o">*</span> <span class="n">digit_size</span><span class="p">:</span> <span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">digit_size</span><span class="p">]</span> <span class="o">=</span> <span class="n">digit</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">((</span><span class="mi">7</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">figure</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Greys_r&#39;</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Note that it is blurry, and â€œmanipulableâ€ by moving through the latent
space!</p>
<hr class="docutils" />
<blockquote>
<div><p>It is <em>not</em> intuitively obvious where the calculation of the KL
divergence comes from, and in general there is not a simple analytic
way to derive KL divergence for arbitrary distributions. Because we
have assumptions about Gaussians here, this is a special case â€“ the
derivation is included in the Auto-Encoding Variational Bayes paper
(2014; https://arxiv.org/pdf/1312.6114.pdf)</p>
</div></blockquote>
</div>
<hr class="docutils" />
<div class="section" id="generative-adversarial-network-gan">
<h2>Generative Adversarial Network (GAN)<a class="headerlink" href="#generative-adversarial-network-gan" title="Permalink to this headline">Â¶</a></h2>
<p>The GAN, popularized recently by Ian Goodfellowâ€™s work, consists of
<strong>two networks</strong>:</p>
<ol class="simple">
<li><p>Generator network (that initially generates output from noise)</p></li>
<li><p>Discriminator network (trained with real data, to simply distinguish
2 class: real and fake)</p>
<ul class="simple">
<li><p>The discriminator is also sometimes called the â€œAâ€ or
adversarial network</p></li>
</ul>
</li>
</ol>
<p>The basic procedure for building a GAN is to train both neworks in
tandem according to the following simple procedure:</p>
<ol class="simple">
<li><p>Generate bogus output from â€œGâ€</p></li>
<li><p>Train â€œDâ€ with real and bogus data, labeled properly</p></li>
<li><p>Train â€œGâ€ to target the â€œreal/true/1â€ label by</p>
<ul class="simple">
<li><p>taking the â€œstackedâ€ G + D model</p></li>
<li><p>feeding noise in at the start (G) end</p></li>
<li><p>and backpropagating from the real/true/1 distribution at the
output (D) end</p></li>
</ul>
</li>
</ol>
<p>As always, there are lots of variants! But this is the core idea, as
illustrated in the following code.</p>
<p>Zackory Ericksonâ€™s example is so elegant and clear, Iâ€™ve used included
it from https://github.com/Zackory/Keras-MNIST-GAN</p>
<p>Once again, weâ€™ll start it running first, since it takes a while to
train.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Input</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers.core</span> <span class="kn">import</span> <span class="n">Reshape</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Flatten</span>
<span class="kn">from</span> <span class="nn">keras.layers.advanced_activations</span> <span class="kn">import</span> <span class="n">LeakyReLU</span>
<span class="kn">from</span> <span class="nn">keras.layers.convolutional</span> <span class="kn">import</span> <span class="n">Convolution2D</span><span class="p">,</span> <span class="n">UpSampling2D</span>
<span class="kn">from</span> <span class="nn">keras.layers.normalization</span> <span class="kn">import</span> <span class="n">BatchNormalization</span>
<span class="kn">from</span> <span class="nn">keras.regularizers</span> <span class="kn">import</span> <span class="n">l1</span><span class="p">,</span> <span class="n">l1_l2</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">initializers</span>
<span class="kn">import</span> <span class="nn">sklearn.datasets</span>

<span class="n">K</span><span class="o">.</span><span class="n">set_image_data_format</span><span class="p">(</span><span class="s1">&#39;channels_last&#39;</span><span class="p">)</span>

<span class="c1"># Deterministic output.</span>
<span class="c1"># Tired of seeing the same results every time? Remove the line below.</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>

<span class="c1"># The results are a little better when the dimensionality of the random vector is only 10.</span>
<span class="c1"># The dimensionality has been left at 100 for consistency with other GAN implementations.</span>
<span class="n">randomDim</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">train_libsvm</span> <span class="o">=</span> <span class="s2">&quot;/dbfs/databricks-datasets/mnist-digits/data-001/mnist-digits-train.txt&quot;</span>
<span class="n">test_libsvm</span> <span class="o">=</span> <span class="s2">&quot;/dbfs/databricks-datasets/mnist-digits/data-001/mnist-digits-test.txt&quot;</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">load_svmlight_file</span><span class="p">(</span><span class="n">train_libsvm</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">784</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">load_svmlight_file</span><span class="p">(</span><span class="n">test_libsvm</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">784</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">-</span> <span class="mf">127.5</span><span class="p">)</span><span class="o">/</span><span class="mf">127.5</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">60000</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>

<span class="c1"># Function for initializing network weights</span>
<span class="k">def</span> <span class="nf">initNormal</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">initializers</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">stddev</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>

<span class="c1"># Optimizer</span>
<span class="n">adam</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.0002</span><span class="p">,</span> <span class="n">beta_1</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">generator</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">generator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="n">randomDim</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializers</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">stddev</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)))</span>
<span class="n">generator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
<span class="n">generator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">))</span>
<span class="n">generator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
<span class="n">generator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1024</span><span class="p">))</span>
<span class="n">generator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
<span class="n">generator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">))</span>
<span class="n">generator</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">adam</span><span class="p">)</span>

<span class="n">discriminator</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">discriminator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializers</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">stddev</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)))</span>
<span class="n">discriminator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
<span class="n">discriminator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">))</span>
<span class="n">discriminator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">))</span>
<span class="n">discriminator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
<span class="n">discriminator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">))</span>
<span class="n">discriminator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">))</span>
<span class="n">discriminator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
<span class="n">discriminator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">))</span>
<span class="n">discriminator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
<span class="n">discriminator</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">adam</span><span class="p">)</span>

<span class="c1"># Combined network</span>
<span class="n">discriminator</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">ganInput</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">randomDim</span><span class="p">,))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">ganInput</span><span class="p">)</span>
<span class="n">ganOutput</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">gan</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">ganInput</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">ganOutput</span><span class="p">)</span>
<span class="n">gan</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">adam</span><span class="p">)</span>

<span class="n">dLosses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">gLosses</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Plot the loss from each batch</span>
<span class="k">def</span> <span class="nf">plotLoss</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">dLosses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Discriminitive loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">gLosses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Generative loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;/dbfs/FileStore/gan_loss_epoch_</span><span class="si">%d</span><span class="s1">.png&#39;</span> <span class="o">%</span> <span class="n">epoch</span><span class="p">)</span>

<span class="c1"># Create a wall of generated MNIST images</span>
<span class="k">def</span> <span class="nf">plotGeneratedImages</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">examples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)):</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="n">examples</span><span class="p">,</span> <span class="n">randomDim</span><span class="p">])</span>
    <span class="n">generatedImages</span> <span class="o">=</span> <span class="n">generator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">noise</span><span class="p">)</span>
    <span class="n">generatedImages</span> <span class="o">=</span> <span class="n">generatedImages</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">examples</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">generatedImages</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">dim</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dim</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">generatedImages</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray_r&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;/dbfs/FileStore/gan_generated_image_epoch_</span><span class="si">%d</span><span class="s1">.png&#39;</span> <span class="o">%</span> <span class="n">epoch</span><span class="p">)</span>

<span class="c1"># Save the generator and discriminator networks (and weights) for later use</span>
<span class="k">def</span> <span class="nf">saveModels</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
    <span class="n">generator</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;/tmp/gan_generator_epoch_</span><span class="si">%d</span><span class="s1">.h5&#39;</span> <span class="o">%</span> <span class="n">epoch</span><span class="p">)</span>
    <span class="n">discriminator</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;/tmp/gan_discriminator_epoch_</span><span class="si">%d</span><span class="s1">.h5&#39;</span> <span class="o">%</span> <span class="n">epoch</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batchSize</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
    <span class="n">batchCount</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">batchSize</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epochs:&#39;</span><span class="p">,</span> <span class="n">epochs</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Batch size:&#39;</span><span class="p">,</span> <span class="n">batchSize</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Batches per epoch:&#39;</span><span class="p">,</span> <span class="n">batchCount</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="mi">15</span><span class="p">,</span> <span class="s1">&#39;Epoch </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">e</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="mi">15</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batchCount</span><span class="p">):</span>
            <span class="c1"># Get a random set of input noise and images</span>
            <span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="n">batchSize</span><span class="p">,</span> <span class="n">randomDim</span><span class="p">])</span>
            <span class="n">imageBatch</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="n">batchSize</span><span class="p">)]</span>

            <span class="c1"># Generate fake MNIST images</span>
            <span class="n">generatedImages</span> <span class="o">=</span> <span class="n">generator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">noise</span><span class="p">)</span>
            <span class="c1"># print np.shape(imageBatch), np.shape(generatedImages)</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">imageBatch</span><span class="p">,</span> <span class="n">generatedImages</span><span class="p">])</span>

            <span class="c1"># Labels for generated and real data</span>
            <span class="n">yDis</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">batchSize</span><span class="p">)</span>
            <span class="c1"># One-sided label smoothing</span>
            <span class="n">yDis</span><span class="p">[:</span><span class="n">batchSize</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.9</span>

            <span class="c1"># Train discriminator</span>
            <span class="n">discriminator</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">dloss</span> <span class="o">=</span> <span class="n">discriminator</span><span class="o">.</span><span class="n">train_on_batch</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">yDis</span><span class="p">)</span>

            <span class="c1"># Train generator</span>
            <span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="n">batchSize</span><span class="p">,</span> <span class="n">randomDim</span><span class="p">])</span>
            <span class="n">yGen</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batchSize</span><span class="p">)</span>
            <span class="n">discriminator</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">gloss</span> <span class="o">=</span> <span class="n">gan</span><span class="o">.</span><span class="n">train_on_batch</span><span class="p">(</span><span class="n">noise</span><span class="p">,</span> <span class="n">yGen</span><span class="p">)</span>

        <span class="c1"># Store loss of most recent batch from this epoch</span>
        <span class="n">dLosses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dloss</span><span class="p">)</span>
        <span class="n">gLosses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gloss</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">e</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">e</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">plotGeneratedImages</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
            <span class="n">saveModels</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>

    <span class="c1"># Plot losses from every epoch</span>
    <span class="n">plotLoss</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>

<span class="n">train</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:From /databricks/python/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
(&#39;Epochs:&#39;, 10)
(&#39;Batch size:&#39;, 128)
(&#39;Batches per epoch:&#39;, 468)
(&#39;---------------&#39;, &#39;Epoch 1&#39;, &#39;---------------&#39;)
(&#39;---------------&#39;, &#39;Epoch 2&#39;, &#39;---------------&#39;)
(&#39;---------------&#39;, &#39;Epoch 3&#39;, &#39;---------------&#39;)
(&#39;---------------&#39;, &#39;Epoch 4&#39;, &#39;---------------&#39;)
(&#39;---------------&#39;, &#39;Epoch 5&#39;, &#39;---------------&#39;)
(&#39;---------------&#39;, &#39;Epoch 6&#39;, &#39;---------------&#39;)
(&#39;---------------&#39;, &#39;Epoch 7&#39;, &#39;---------------&#39;)
(&#39;---------------&#39;, &#39;Epoch 8&#39;, &#39;---------------&#39;)
(&#39;---------------&#39;, &#39;Epoch 9&#39;, &#39;---------------&#39;)
(&#39;---------------&#39;, &#39;Epoch 10&#39;, &#39;---------------&#39;)
</pre></div>
</div>
</div></blockquote>
<div class="section" id="sample-generated-digits-epoch-1">
<h3>Sample generated digits: epoch 1<a class="headerlink" href="#sample-generated-digits-epoch-1" title="Permalink to this headline">Â¶</a></h3>
<p>&lt;img src=â€/files/gan<em>generated</em>image<em>epoch</em>1.pngâ€ width=800&gt;</p>
</div>
<div class="section" id="sample-generated-digits-epoch-10">
<h3>Sample generated digits: epoch 10<a class="headerlink" href="#sample-generated-digits-epoch-10" title="Permalink to this headline">Â¶</a></h3>
<p>&lt;img src=â€/files/gan<em>generated</em>image<em>epoch</em>10.pngâ€ width=800&gt;</p>
</div>
<div class="section" id="generator-discriminator-loss">
<h3>Generator/Discriminator Loss<a class="headerlink" href="#generator-discriminator-loss" title="Permalink to this headline">Â¶</a></h3>
</div>
</div>
<div class="section" id="which-strategy-to-use">
<h2>Which Strategy to Use?<a class="headerlink" href="#which-strategy-to-use" title="Permalink to this headline">Â¶</a></h2>
<p>This is definitely an area of active research, so youâ€™ll want to
experiment with both of these approaches.</p>
<p>GANs typically produce â€œsharper picturesâ€ â€“ the adversarial loss is
better than the combined MSE/XE + KL loss used in VAEs, but then again,
thatâ€™s partly by design.</p>
<p>VAEs are â€“ as seen above â€“ blurrier but more manipulable. One way of
thinking about the multivariate Gaussian representation is that VAEs are
trained to find some â€œmeaningâ€ in variation along each dimensin. And, in
fact, with specific training it is possible to get them to associate
specific meanings like color, translation, rotation, etc. to those
dimensions.</p>
</div>
</div>
<div class="section" id="where-next">
<h1>Where Next?<a class="headerlink" href="#where-next" title="Permalink to this headline">Â¶</a></h1>
<p>Keep an eye on Medium articles and others at sites like
towardsdatascience:</p>
<p>Here is one which caught my eve in 2019:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://towardsdatascience.com/aifortrading-2edd6fac689d">AI for
trading</a></p></li>
</ul>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./000_0-sds-3-x-projects/student-project-18_group-ProjectRL/sds-2-x-dl"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By ScaDaMaLe Team<br/>
        
            &copy; Copyright 2020 Creative Commons Zero v1.0 Universal.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>

<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Anomaly Detection with Iterative Quantile Estimation and T-digest &#8212; Scalable Data Science &amp; Distributed Machine Learning</title>
    
  <link rel="stylesheet" href="../../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Project Description and Introduction" href="../student-project-12_group-CovidPandemic/00_ProjectDescriptionAndPlanning.html" />
    <link rel="prev" title="ScaDaMaLe, Scalable Data Science and Distributed Machine Learning" href="../student-project-10_group-Geosmus/07_b_appendix_TTTDFfunctions.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Scalable Data Science & Distributed Machine Learning</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/000_ScaDaMaLe.html">
   Introduction
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction to Apache Spark Core
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_1-sds-3-x/001_whySpark.html">
   Why Apache Spark?
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/002_00_loginToDatabricks.html">
     Login to databricks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/002_00_loginToDatabricks.html#import-course-content-now">
     Import Course Content Now!
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/002_00_loginToDatabricks.html#cloud-free-computing-environment">
     Cloud-free Computing Environment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/002_01_multiLingualNotebooks.html">
     Multi-lingual Notebooks
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_1-sds-3-x/003_00_scalaCrashCourse.html">
   Scala Crash Course
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/003_01_scalaCrashCourse.html">
     Scala Crash Course Continued
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_1-sds-3-x/004_RDDsTransformationsActions.html">
   Introduction to Spark
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/005_RDDsTransformationsActionsHOMEWORK.html">
     HOMEWORK on RDD Transformations and Actions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html">
     Piped RDDs and Bayesian AB Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#from-a-local-collection">
     From a Local Collection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#glom">
     glom
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#checkpointing">
     Checkpointing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#pipe-rdds-to-system-commands">
     Pipe RDDs to System Commands
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#mappartitions">
     mapPartitions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#foreachpartition">
     foreachPartition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#numerically-rigorous-bayesian-ab-testing">
     Numerically Rigorous Bayesian AB Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#usage-instructions-for-isit1or2coins">
     Usage instructions for IsIt1or2Coins
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006_WordCount.html">
     Word Count on US State of the Union (SoU) Addresses
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction to Apache Spark SQL
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/007_SparkSQLIntroBasics.html">
   Introduction to Spark SQL
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_1-sds-3-x/007_SparkSQLIntroBasics.html#getting-started-in-spark-2-x">
   Getting Started in Spark 2.x
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007a_SparkSQLProgGuide_HW.html">
     Spark Sql Programming Guide
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007b_SparkSQLProgGuide_HW.html">
     Getting Started
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007b_SparkSQLProgGuide_HW.html#id1">
     Getting Started
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007c_SparkSQLProgGuide_HW.html">
     Getting Started - Exercise
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007d_SparkSQLProgGuide_HW.html">
     Data Sources
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007d_SparkSQLProgGuide_HW.html#id1">
     Data Sources
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007e_SparkSQLProgGuide_HW.html">
     Performance Tuning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007f_SparkSQLProgGuide_HW.html">
     Distributed SQL Engine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007f_SparkSQLProgGuide_HW.html#id1">
     Distributed SQL Engine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html">
     ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html#sql-pivoting-since-spark-2-4">
     SQL Pivoting since Spark 2.4
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html#load-data">
     Load Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-in-sql">
     Pivoting in SQL
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-with-multiple-aggregate-expressions">
     Pivoting with Multiple Aggregate Expressions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-with-multiple-grouping-columns">
     Pivoting with Multiple Grouping Columns
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-with-multiple-pivot-columns">
     Pivoting with Multiple Pivot Columns
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Extract Transform and Load
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html">
   Diamonds ML Pipeline Workflow - DataFrame ETL and EDA Part
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#step-1-load-data-as-dataframe">
   Step 1. Load data as DataFrame
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#step-2-understand-the-data">
   Step 2. Understand the data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#let-us-run-through-some-basic-inteactive-sql-queries-next">
   Let us run through some basic inteactive SQL queries next
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#why-do-we-need-to-know-these-interactive-sql-queries">
   Why do we need to know these interactive SQL queries?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#we-will-continue-later-with-ml-pipelines-to-do-prediction-with-a-fitted-model-from-this-dataset">
   We will continue later with ML pipelines to do prediction with a fitted model from this dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html">
   Power Plant ML Pipeline Application - DataFrame Part
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-1-business-understanding">
   Step 1: Business Understanding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-2-load-your-data">
   Step 2: Load Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#use-this-for-other-smallish-datasets-you-want-to-import-to-your-ce">
   USE THIS FOR OTHER SMALLish DataSets you want to import to your CE
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-3-explore-your-data">
   Step 3: Explore Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-4-visualize-your-data">
   Step 4: Visualize Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/010_wikipediaClickStream_01ETLEDA.html">
   Wiki Clickstream Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/010_wikipediaClickStream_01ETLEDA.html#wikipedia-logo">
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_LoadExtract.html">
   Old Bailey Online Data Analysis in Apache Spark
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_LoadExtract.html#analysing-the-full-old-bailey-online-sessions-papers-dataset">
   Analysing the Full Old Bailey Online Sessions Papers Dataset
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html">
     Piped RDDs and Bayesian AB Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#from-a-local-collection">
     From a Local Collection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#glom">
     glom
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#checkpointing">
     Checkpointing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#pipe-rdds-to-system-commands">
     Pipe RDDs to System Commands
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#mappartitions">
     mapPartitions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#foreachpartition">
     foreachPartition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#numerically-rigorous-bayesian-ab-testing">
     Numerically Rigorous Bayesian AB Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#usage-instructions-for-isit1or2coins">
     Usage instructions for IsIt1or2Coins
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#parsing-the-output-from-isit1or2coins">
     Parsing the output from
     <code class="docutils literal notranslate">
      <span class="pre">
       IsIt1or2Coins
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#providing-case-classes-for-input-and-output-for-easy-spark-communication">
     Providing case classes for input and output for easy spark communication
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/035_LDA_CornellMovieDialogs.html">
   Topic Modeling of Movie Dialogs with Latent Dirichlet Allocation
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Trends in Money and News
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_9-sds-3-x-trends/000_TrendsInFinancialStocksAndNewsEvents.html">
   Trends in Financial Stocks and News Events
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/00a_FX1M.html">
     Historical FX-1-M Financial Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/00b_yfinance.html">
     yfinance Stock Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/000a_finance_utils.html">
     Utilities Needed for Financial Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/000b_gdelt_utils.html">
     Utilities Needed for Mass Media Data
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_9-sds-3-x-trends/01_trend_calculus_showcase.html">
   Finding trends in oil price data.
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/02_streamable_trend_calculus.html">
     Streaming Trend Calculus with Maximum Necessary Reversals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/03_streamable_trend_calculus_estimators.html">
     Markov Model for Trend Calculus
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_9-sds-3-x-trends/030_Spark_GDELT_project_001.html">
   Plugging into GDELT Mass Media Streams
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/030a_gdelt_EOI_detection.html">
     Detecting Events of Interest to OIL/GAS Price Trends
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/030b_gdelt_POI_detection.html">
     Detecting Persons of Interest to OIL/GAS Price Trends
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Distributed Deep Learning with Horovod
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_7-sds-3-x-ddl/00_DDL_Introduction.html">
   Introduction to Distributed Deep Learning (DDL) with Horovod over Tensorflow/keras and Pytorch
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_7-sds-3-x-ddl/0x_mnist-tensorflow-keras.html">
     Distributed deep learning training using TensorFlow and Keras with HorovodRunner
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_7-sds-3-x-ddl/0y_mnist-pytorch.html">
     Distributed deep learning training using PyTorch with HorovodRunner for MNIST
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  WASP AI-Track Student Projects
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-01_group-TheTwoCultures/00_download_data.html">
   The two cultures
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-01_group-TheTwoCultures/01_load_data.html">
     Preprocessing and loading the relevant data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-01_group-TheTwoCultures/02_logisticregression.html">
     The two cultures - Classifying threads with logistic regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-01_group-TheTwoCultures/03_word2vec.html">
     Classification using Word2Vec
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-01_group-TheTwoCultures/04_LDA.html">
     Topic Modeling with LDA
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-02_group-LiUUmeaSceneGraphMotifs/01_SceneGraphMotifs.html">
   Exploring the GQA Scene Graph Dataset Structure and Properties
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-03_group-GuangyiZhang/01_triads.html">
   Signed Triads in Social Media
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-04_group-DistributedLinearAlgebra/01_DistributedSVD.html">
   Distributed Linear Algebra
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-04_group-DistributedLinearAlgebra/02_CollaborativeFiltering.html">
     Music Recommendation System
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-05_group-LundDirichletAnalysts/01_Wikipedia_LDA_Analysis.html">
   Wikipedia analysis using Latent Dirichlet Allocation (LDA)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-06_group-ParticleClustering/00_Introduction.html">
   Unsupervised clustering of particle physics data with distributed training
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-06_group-ParticleClustering/00_Introduction.html#introduction">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-06_group-ParticleClustering/00_Introduction.html#background">
   Background
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-06_group-ParticleClustering/00_Introduction.html#the-uclusted-algorithm">
   The UClusted algorithm
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-06_group-ParticleClustering/00_Introduction.html#motivation">
   Motivation
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-06_group-ParticleClustering/00_Introduction.html#our-contribution">
   Our contribution
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-06_group-ParticleClustering/01_data_and_preprocessing.html">
     Important!
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-06_group-ParticleClustering/01_data_and_preprocessing.html#important-continued-from-above">
     Important (continued from above)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-06_group-ParticleClustering/04_evaluate.html">
     Evaluation
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-07_group-MathAtKTH/01_Coding_Motifs.html">
   Motif Finding
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-07_group-MathAtKTH/01_Coding_Motifs.html#application">
   Application
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-07_group-MathAtKTH/02_Data_Processing.html">
     Data Processing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-07_group-MathAtKTH/03_graph_string_converter.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-07_group-MathAtKTH/03_graph_string_converter.html#examples">
     Examples
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-08_group-DistributedEnsemble/00_project.html">
   Distributed ensembles
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-08_group-DistributedEnsemble/00_project.html#distributed-ensembles-prediction-api">
   Distributed ensembles prediction API
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-08_group-DistributedEnsemble/00_project.html#application-example-distributed-predictions">
   Application example: Distributed predictions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-08_group-DistributedEnsemble/00_project.html#application-example-out-of-distribution-detection">
   Application example: Out of distribution detection
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-09_group-TopicModeling/01_Introduction.html">
   Topic Modeling with SARS-Cov-2 Genome ðŸ§¬
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/02_Data_Processing.html">
     Data Processing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/03_LDA.html">
     LDA - Extract Features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/04_Classification_CountVector.html">
     Classification CountVector
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/05_Classification.html">
     Load processed data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/05_Classification.html#explore-data">
     Explore data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/05_Classification.html#classification">
     Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/05_Classification.html#evaluation">
     Evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/06_Results.html">
     Results and Conclusion
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-10_group-Geosmus/01_Introduction.html">
   Twitter Streaming Using Geolocation and Emoji Based Sentiment Analysis
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/02_ClusteringEmoticonsBasedOnTweets.html">
     Clustering emoticons based on tweets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/03_Dynamic_Tweet_Maps.html">
     Dynamic Tweet Maps
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/04_conclusion.html">
     Conclusion
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/05_appendix_get-cc-data.html">
     Notebook for collecting tweets with country codes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/07_a_appendix_extendedTwitterUtils2run.html">
     ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/07_a_appendix_extendedTwitterUtils2run.html#extended-spark-streaming-twitter-twitterutils">
     Extended spark.streaming.twitter.TwitterUtils
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/07_b_appendix_TTTDFfunctions.html">
     ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Anomaly Detection with Iterative Quantile Estimation and T-digest
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-12_group-CovidPandemic/00_ProjectDescriptionAndPlanning.html">
   Project Description and Introduction
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/01_DownloadFilesPeriodicallyScript.html">
     Download Files Periodically
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/01_StreamToFile.html">
     Stream to parquet file
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/021_DataPreprocess_Explain.html">
     Loading data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/021_DataPreprocess_Explain.html#preprocessing">
     Preprocessing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/02_DataPreprocess.html">
     Loading data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/02_DataPreprocess.html#preprocessing">
     Preprocessing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html">
     This notebook is for explosive analysis of features in data.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html#statistics-of-invariant-features">
     Statistics of invariant features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html#correlation-between-invariant-features">
     Correlation between invariant features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html#correlation-between-new-case-per-million-total-case-new-death-per-million-total-death-per-million-reproduction-rate-and-stringency-index">
     Correlation between new case per million, total case, new death per million, total death per million, reproduction rate and stringency index.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/04_DataVisualize.html">
     Show reproduction rate of selected countries i.e. Sweden, Germany, Danmark, Finland, Norway
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/04_DataVisualize.html#visualize-total-cases-total-deaths-new-cases-and-new-deaths-during-pandemic">
     Visualize total cases, total deaths, new cases and new deaths during pandemic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/04_DataVisualize.html#total-deaths">
     Total Deaths
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/04_DataVisualize.html#new-cases">
     New Cases
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/04_DataVisualize.html#new-deaths">
     New Deaths
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/05_Clustering.html">
     Clustering of country features in the Covid 19 dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/06_DataPredicton_LR.html">
     Prediction with Linear Regression (LR) Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/07_DataPredicton_ARIMA.html">
     Prediction with Time Series model - ARIMA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/08_DataPrediction_GP.html">
     Prediction with time series model - Gaussian Processes
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-13_group-Genomics/01_1000genomes.html">
   Genomics Analysis with Glow and Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-13_group-Genomics/01_1000genomes.html#load-libs-and-define-helper-functions">
   Load libs and define helper functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-13_group-Genomics/01_1000genomes.html#read-data">
   Read data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-13_group-Genomics/01_1000genomes.html#pca">
   PCA
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-13_group-Genomics/01_1000genomes.html#predicting-ethinicity">
   Predicting Ethinicity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-13_group-Genomics/01_1000genomes.html#filtering-of-snps-based-on-chi-squared-test">
   Filtering of SNPs based on chi-squared test
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-14_group-NullHypothesisEvaluationCriteria/00_distributed_combinatorial_bandit.html">
   Distributional combinatorial bandits
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/00_video.html">
   Reinforcement Learning for Intraday Trading
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/01_rl_intraday_trading.html">
     Reinforcement Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/01_rl_intraday_trading.html#summary-and-outlook">
     Summary and Outlook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html">
     Reinforcement Learning - Distributed model tuning with Elephas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html#elephas">
     Elephas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html#notes-to-the-elephas-training">
     Notes to the elephas training
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/03_resources.html">
     Resources
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-16_group-IntrusionDetection/00_Introduction.html">
   Intrusion Detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-16_group-IntrusionDetection/00_Introduction.html#preparing-the-dataframe-for-training-classifers">
   Preparing the DataFrame for training classifers
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-17_group-TowardsScalableTDA/00_introduction.html">
   Density Estimation via Voronoi Diagrams in High Dimensions
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-17_group-TowardsScalableTDA/03_robotics_dataset.html">
     Robotics Dataset
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-18_group-ProjectRL/00_Problem_Description.html">
   Recommender System
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-18_group-ProjectRL/01_The_ALS_method.html">
     <span class="xref myst">
      The Alternating Least Squares method (ALS)
     </span>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-18_group-ProjectRL/01_The_ALS_method.html#on-a-small-dataset">
     <span class="xref myst">
      On a small dataset
     </span>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-18_group-ProjectRL/01_The_ALS_method.html#on-a-large-dataset-netflix-dataset">
     <span class="xref myst">
      On a large dataset - Netflix dataset
     </span>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-18_group-ProjectRL/02_Extensions.html">
     Extensions
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-19_group-Featuring/01_FundamentalMatrix.html">
   Fundamental Matrix
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-20_group-Generalization/01_Background.html">
   MixUp and Generalization
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-20_group-Generalization/02_Random_Forest.html">
     Random Forests and MixUp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-20_group-Generalization/03_CNN_MNIST.html">
     CNN for MNIST
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-20_group-Generalization/04_CNN_Intel_Image.html">
     CNN for Intel Image Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-20_group-Generalization/05_Horovod_test.html">
     CNNs and MixUp with Horovod
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-21_group-GraphSpectralAnalysis/00_introduction.html">
   Graph Spectral Analysis
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-21_group-GraphSpectralAnalysis/01_preprocess_data.html">
     Preprocess the data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-21_group-GraphSpectralAnalysis/02_generate_graphs.html">
     Generate random graphs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-21_group-GraphSpectralAnalysis/03_compute_rsvd.html">
     Compute RSVD
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-21_group-GraphSpectralAnalysis/04_analyse_eigenvalues.html">
     Analyse the eigenvalue spectrum
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-22_group-SwapWithDDP/00_Introduction.html">
   SWAP
   <em>
    With
   </em>
   DDP
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-22_group-SwapWithDDP/01_SWAP_with_DDP.html">
     SWAP
     <em>
      With
     </em>
     DDP
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/000_0-sds-3-x-projects/student-project-11_group-Sketchings/00_QuantileEstimation.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://lamastex.github.io/ScaDaMaLe/index.html"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://lamastex.github.io/ScaDaMaLe/index.html/issues/new?title=Issue%20on%20page%20%2F000_0-sds-3-x-projects/student-project-11_group-Sketchings/00_QuantileEstimation.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#links-to-videos">
   Links to videos
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#iterative-method-vs-t-digest">
   7.1 Iterative method vs t-digest
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sketching-with-the-iterative-method">
   7.2 Sketching with the iterative method
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#alternative-approaches">
   7.3 Alternative approaches
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="anomaly-detection-with-iterative-quantile-estimation-and-t-digest">
<h1>Anomaly Detection with Iterative Quantile Estimation and T-digest<a class="headerlink" href="#anomaly-detection-with-iterative-quantile-estimation-and-t-digest" title="Permalink to this headline">Â¶</a></h1>
<p>Project group 11</p>
<p>Alexander Karlsson, Alvin Jin and George Osipov</p>
<p>13 January 2021</p>
<div class="section" id="links-to-videos">
<h2>Links to videos<a class="headerlink" href="#links-to-videos" title="Permalink to this headline">Â¶</a></h2>
<p>Link:
https://liuonline-my.sharepoint.com/:f:/g/personal/geoos58<em>liu</em>se/El8VTHoZPVpDqpkdkpmJK8IB0Bd-YZw0t5-WRKeTXsqckA?e=faazbx
(expires 28/02/2020).</p>
<p>The folder contains both the original recording (1x, ~25min) and the
<em>recommended</em> sped-up recording (1.25x, ~20min). The latter is shorter
and more fun.</p>
<ol class="simple">
<li><p>Introduction</p></li>
</ol>
<hr class="docutils" />
<p>Anomaly detection is often implemented as a threshold detector where
scalar valued scores (often computed from a higher dimensional sample)
above a set threshold are classified as detections. It is often desired
that the number of false alarms, i.e. non-anomalous samples that have
higher score than the threshold, should be constant. This requires an
adaptive threshold if the distribution of the scores varies with time.
In this project we will look at two aspects of anomaly detection 1. How
to calulate the threshold or quantile for a fixed distribution 2. How to
apply this quantile to distributions that change over time using a
simple filter</p>
<p>For quantile estimation (QE) we will use t-digest and compare it to a
more naive approach which will be presented later. A problem for both
these methods are data streams that arise from distributions that change
over time. Assume that each sample received a time <span class="math notranslate nohighlight">\(t\)</span> can be written as</p>
<div class="math notranslate nohighlight">
\[  x(t) = f(t) + w(t), 
\]</div>
<p>where <span class="math notranslate nohighlight">\(f(t)\)</span> is a trend value that varies with time and <span class="math notranslate nohighlight">\(w(t)\)</span> is a
random variable with a distribution that may also vary with time. We are
interested in finding anomalies in <span class="math notranslate nohighlight">\(w(t)\)</span>. If we were to estimate a
quantile from samples obtained from a time interval <span class="math notranslate nohighlight">\(T_s\)</span>, the anomalies
would depend on both <span class="math notranslate nohighlight">\(f(t)\)</span> and <span class="math notranslate nohighlight">\(w(t)\)</span>, e.g. if <span class="math notranslate nohighlight">\(f(t)\)</span> is a linearly
increasing function and <span class="math notranslate nohighlight">\(w(t)\)</span> is constant, most of the anomalous
samples would be the more recent ones. This could be mitigated by taking
samples from a small enough interval such that <span class="math notranslate nohighlight">\(f(t)\)</span> and <span class="math notranslate nohighlight">\(w(t)\)</span> can be
considered constant during that time. This approach requires a
continuous update of the estimated quantile, which we denote <span class="math notranslate nohighlight">\(q[n]\)</span>,
where <span class="math notranslate nohighlight">\(n\)</span> is the index of the time interval at time <span class="math notranslate nohighlight">\(nT_s\)</span>. In some
cases this may be a sufficently accurate solution. However, assume now
that <span class="math notranslate nohighlight">\(w(t)\)</span> is constant but will occasionally change to a distribution
with higher mean, i.e. this change is now the anomaly we are trying to
detect. If we use the same target quantile in all time steps, these
anomalies would go undetected. A compromise is to filter the stream of
estimated quantiles <span class="math notranslate nohighlight">\(q[1],q[2],...,q[n]\)</span> in a manner that preserves
scalability. The data stream we will look at will have the following
form. Each time step yields <span class="math notranslate nohighlight">\(N\)</span> samples with Gaussian distribution with
standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span>=1 and mean</p>
<div class="math notranslate nohighlight">
\[  \mu[n]=\frac{n}{1000}, 
\]</div>
<p>and with 5<span class="math notranslate nohighlight">\(\%\)</span> probability, 1<span class="math notranslate nohighlight">\(\%\)</span> of the data will have mean</p>
<div class="math notranslate nohighlight">
\[  \mu[n]=\frac{n}{1000} + 2. 
\]</div>
<ol class="simple">
<li><p>QE with t-digest</p></li>
</ol>
<hr class="docutils" />
<p>With t-digest the distribution is estimated using a set of clusters
where each cluster is represented by a mean value and weight (the number
of samples assigned to the cluster). Clusters at the tail ends of the
distribution will have smaller weights. This is determined by a
non-decreasing function referred to as a scale function and will result
in an error in the QE that is relative to the quantile rather than an
absolute error, which is the fundamental idea with t-digest. Any
quantile can be estimated by interpolating between cluster points. The
algorithm is explained in detail in [Dunning]. The clusters can be
computed in a scalable manner which makes the algorithm suitable for
large datasets.</p>
<ol class="simple">
<li><p>Naive QE</p></li>
</ol>
<hr class="docutils" />
<p>A simpler and perhaps more naive approach for empirical QE is to
estimate the desired quantile as the the <span class="math notranslate nohighlight">\(k\)</span>â€™th ordered statistic, i.e.
the value <span class="math notranslate nohighlight">\(q=x_k\)</span> for which <span class="math notranslate nohighlight">\(k\)</span> samples are smaller or equal to <span class="math notranslate nohighlight">\(q\)</span>,
e.g. the 95â€™th percentile from 1000 samples would then be estimated as
the 950â€™th ordered statistic. If the data is i.i.d. the estimated
quantile will then be a random variable with pdf [Rohling]</p>
<div class="math notranslate nohighlight">
\[  p(x_k)= k  {N\choose k} \left[ P(x) \right]^{k-1} \left[ 1-P(x) \right]^{N-k} p(x), 
\]</div>
<p>where <span class="math notranslate nohighlight">\(x_k\)</span> is the <span class="math notranslate nohighlight">\(k\)</span>â€™th ordered statistic, <span class="math notranslate nohighlight">\(P(x)\)</span> is the cdf of the
random variable <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(p(x)\)</span> is the pdf.</p>
<p>However, if the data is distributed, sorting becomes problematic. We
therefore present an iterative, and more scalable, method of finding the
desired quantile (or rather, the ordered statistic). We start with a
random guess <span class="math notranslate nohighlight">\(\hat{q}\)</span> (e.g. the mean) and count the number of samples
that are larger than <span class="math notranslate nohighlight">\(\hat{q}\)</span>. This can be done in a distributed
fashion where each node reports on the number of samples greater than
<span class="math notranslate nohighlight">\(\hat{q}\)</span> as well as the total number of samples in each node. These
number are then aggregated at the master node and the ratio yields an
estimate of a quantile for <span class="math notranslate nohighlight">\(\hat{q}\)</span>. If this is larger than the desired
quantile, <span class="math notranslate nohighlight">\(\hat{q}\)</span> should be decreased and vice versa. One then
proceeds by iteratively changing <span class="math notranslate nohighlight">\(\hat{q}\)</span> until the desired quantile is
found. The search can be made efficient using the following steps</p>
<ol class="simple">
<li><p>Choose an integer <span class="math notranslate nohighlight">\(k\)</span> that correspends to the desired quantile, e.g.
<span class="math notranslate nohighlight">\(k\)</span>=950 for <span class="math notranslate nohighlight">\(N\)</span>=1000 (95â€™th percentile).</p></li>
<li><p>Arbitrarily choose an initial guess of <span class="math notranslate nohighlight">\(\hat{q}\)</span>.</p></li>
<li><p>Count the number of samples that are greater than <span class="math notranslate nohighlight">\(\hat{q}\)</span>, call
this <span class="math notranslate nohighlight">\(M\)</span>. If <span class="math notranslate nohighlight">\(M &gt; N-k\)</span> increase <span class="math notranslate nohighlight">\(\hat{q}\)</span> by 1, then by 2,4,8,16
etc. until <span class="math notranslate nohighlight">\(M &lt; N-k\)</span> (or reverse this process if <span class="math notranslate nohighlight">\(M\)</span> is initially
lower than <span class="math notranslate nohighlight">\(N-k\)</span> ). We now have an upper limit (U) and a lower
limit (L) for the desired quantile, <span class="math notranslate nohighlight">\(\hat{q}_U\)</span> and <span class="math notranslate nohighlight">\(\hat{q}_L\)</span>. Let
<span class="math notranslate nohighlight">\(d\)</span> = <span class="math notranslate nohighlight">\(\hat{q}_U\)</span> - <span class="math notranslate nohighlight">\(\hat{q}_L\)</span>.</p></li>
<li><p>Let <span class="math notranslate nohighlight">\(\hat{q} = \hat{q}_L\)</span>. In each iteration update
<span class="math notranslate nohighlight">\(\hat{q} \leftarrow \hat{q} + ud/2\)</span> and then <span class="math notranslate nohighlight">\(d \leftarrow d/2\)</span>
where <span class="math notranslate nohighlight">\(u\)</span> is +1 if <span class="math notranslate nohighlight">\(M &gt; N-k\)</span> and -1 otherwise. Stop iterating when
<span class="math notranslate nohighlight">\(M=N-k\)</span>.</p></li>
</ol>
<p>This approach will converge to a solution in time proportional to
log<span class="math notranslate nohighlight">\(_2(N)\)</span>. For other types of iterative searches for finding an
emperical quantile see [MÃ¶ller].</p>
<ol class="simple">
<li><p>Filtering Time Varying Quantiles</p></li>
</ol>
<hr class="docutils" />
<p>An interesting problem with both the presented method for QE and
t-digest is how to balance new and old estimates. One approach is to
make one new estimate for each new batch. This will fail however if one
batch suddenly contains a larger burst of â€œoutliersâ€ as these might then
go undetected due to the temporary change of the statistics.</p>
<p>Another is to estimate the desired quantiles from one batch and then
keep this estimate in the proceeding batches. This will also fail if the
distribution varies slowly, i.e. with time the calculated parameters
will correspond to different quantiles than what was originally desired.
One could mitigate this effect by averaging or updating new estimates
with older. However if we estimate the quantiles based on all samples
from the beginning up until time <span class="math notranslate nohighlight">\(n\)</span> we need to weight them properly,
otherwise we may still have large errors due to distributions that
change with time.</p>
<p>A simple tradeoff is to introduce a filter with some forget rate <span class="math notranslate nohighlight">\(T\)</span>,
i.e. samples that are older than <span class="math notranslate nohighlight">\(T\)</span> no longer effect the current
estimate while the more recent estimates are weighted together. A basic
approach is an equally weighted sliding window of size <span class="math notranslate nohighlight">\(T\)</span> where</p>
<div class="math notranslate nohighlight">
\[  \bar{q}[n]= \frac{1}{T}\sum_{i=0}^{T-1}q[n-i] 
\]</div>
<p>is the weighted estimate and <span class="math notranslate nohighlight">\(q[n]\)</span> is the quantile estimated from
batch/time <span class="math notranslate nohighlight">\(n\)</span>. This requires storing <span class="math notranslate nohighlight">\(T\)</span> samples in a memory and
writing (i.e. replacing the oldest sample with the newest) in each time
step, which may or may not be an issue. Another is to have a filter with
exponential decay where each sample <span class="math notranslate nohighlight">\(q[i]\)</span> for <span class="math notranslate nohighlight">\(i=0,...,n\)</span> is weighted
by a factor <span class="math notranslate nohighlight">\(ce^{-(n-i)/\tau}\)</span> for <span class="math notranslate nohighlight">\(\tau&gt;0\)</span> and</p>
<div class="math notranslate nohighlight">
\[  c= \left[\sum_{i=0}^{\infty}e^{-i/\tau}\right]^{-1} = 1 - e^{-1/\tau}. 
\]</div>
<p>The weights of previous samples at time <span class="math notranslate nohighlight">\(n=100\)</span> for two different values
of <span class="math notranslate nohighlight">\(\tau\)</span> are shown below</p>
<p><img alt="Im1" src="https://raw.githubusercontent.com/gosip/wasp-scadamale-sketching/main/impRe.jpg" /></p>
<p>This can be simply implemented with the filter</p>
<div class="math notranslate nohighlight">
\[  \bar{q}[n]= \bar{q}[n-1]e^{-1/\tau} + cq[n] = \sum_{i=0}^{n}cq[i]e^{(i-n)/\tau}. 
\]</div>
<p>The sum of <span class="math notranslate nohighlight">\(n\)</span> weights is</p>
<div class="math notranslate nohighlight">
\[  \sum_{i=0}^{n} ce^{-i/\tau} = c\frac{1 - e^{-n/\tau}}{1-e^{-1/\tau}} = 1 - e^{-n/\tau} 
\]</div>
<p>which can be approximated as one, e.g. if <span class="math notranslate nohighlight">\(n=5\tau\)</span> the weights mass is
greater than 0.99. If we regard <span class="math notranslate nohighlight">\(q[n]\)</span> as a random variable with
expected value <span class="math notranslate nohighlight">\(\mu\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2\)</span> that have been
approximately constant for a duration of <span class="math notranslate nohighlight">\(L\gg\tau\)</span> samples the filter
will be asymptotically unbiased</p>
<div class="math notranslate nohighlight">
\[  \mathbf{E}\left[q[n] \right] = \mathbf{E}\left[\sum_{i=0}^{n}cq[i]e^{(i-n)/\tau}  \right] = \mathbf{E}\left[q[i] \right] \sum_{i=0}^{n}ce^{-i/\tau} = \mu(1 - e^{-n/\tau})\approx \mu. 
\]</div>
<p>Assuming for the sake of analysis that <span class="math notranslate nohighlight">\(\mu=0\)</span> and that <span class="math notranslate nohighlight">\(q[n]\)</span> is
uncorrelated, i.e. <span class="math notranslate nohighlight">\(\mathbf{E}\left[q[j]q[i] \right]= \sigma^2\)</span> if <span class="math notranslate nohighlight">\(j=i\)</span>
and <span class="math notranslate nohighlight">\(\mathbf{E}\left[q[j]q[i] \right]= 0\)</span> otherwise, we get the variance
as</p>
<div class="math notranslate nohighlight">
\[  \text{var}\left[q[n] \right] =  \mathbf{E}\left[\left(\sum_{i=0}^{n}cq[i]e^{(i-n)/\tau}  \right)^2\right] = \mathbf{E}\left[q[i]^2 \right]  \sum_{i=0}^{n}c^2e^{-2i/\tau}  = \sigma^2c^2\frac{(1 - e^{-2n/\tau})}{(1 - e^{-2/\tau})}   = \sigma^2\frac{(1 - e^{-1/\tau})^2(1 - e^{-2n/\tau})}{(1 - e^{-1/\tau})(1 + e^{-1/\tau})} \approx \sigma^2\frac{(1 - e^{-1/\tau})}{(1 + e^{-1/\tau})} = \gamma\sigma^2
\]</div>
<p>i.e. a reduction by a factor <span class="math notranslate nohighlight">\(\gamma\)</span>. This can be compared to the
factor <span class="math notranslate nohighlight">\(1/T\)</span> which is the reduction in variance from a rectangular
sliding window of length <span class="math notranslate nohighlight">\(T\)</span>, e.g. if <span class="math notranslate nohighlight">\(T=100\)</span> we get the same steady
state reduction in variance if <span class="math notranslate nohighlight">\(\tau=50\)</span>. The value of <span class="math notranslate nohighlight">\(\gamma\)</span> as a
function of <span class="math notranslate nohighlight">\(\tau\)</span> is shown below</p>
<p><img alt="Im2" src="https://raw.githubusercontent.com/gosip/wasp-scadamale-sketching/main/gammagainRe.jpg" /></p>
<p>The transfer function for this filter in <span class="math notranslate nohighlight">\(z\)</span>-domain is</p>
<div class="math notranslate nohighlight">
\[  H(z) = \frac{\bar{Q}(z)}{Q(z)} = \frac{1-e^{-1/\tau}}{1 - e^{-1/\tau}z^{-1}}. 
\]</div>
<p>The frequency response, obtained by letting <span class="math notranslate nohighlight">\(z=e^{j2\pi\nu}\)</span> where the
normalized frequency is <span class="math notranslate nohighlight">\(\nu = T_sf\)</span>, <span class="math notranslate nohighlight">\(f\)</span> is the frequency and <span class="math notranslate nohighlight">\(T_s\)</span> is
the time between samples, is shown below</p>
<p><img alt="Im3" src="https://raw.githubusercontent.com/gosip/wasp-scadamale-sketching/main/fresp2.jpg" /></p>
<p>The figure shows the tradeoff between supressing (in magnitude) higher
frequencies and following changes (i.e. keeping phase). The trend that
the filter should follow should be slow enough such that it can be
approximated as constant for a duration of <span class="math notranslate nohighlight">\(L\gg\tau\)</span>, i.e. depending of
the frequency of the desired trend, the sampling rate, <span class="math notranslate nohighlight">\(1/T_s\)</span>, needs to
be high enough to satisfy this. If the flow of samples is constant this
will in turn limit the number of samples in each batch and the smallest
quantile that can be estimated.</p>
<ol class="simple">
<li><p>Implementation</p></li>
</ol>
<hr class="docutils" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="o">//</span> <span class="n">neccessary</span> <span class="n">imports</span>
<span class="kn">import</span> <span class="nn">org.isarnproject.sketches.java.TDigest</span>
<span class="kn">import</span> <span class="nn">org.isarnproject.sketches.spark.tdigest._</span>
<span class="kn">import</span> <span class="nn">scala.util.Random</span>
<span class="kn">import</span> <span class="nn">scala.util.Random._</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.functions._</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span>
<span class="kn">import</span> <span class="nn">scala.math._</span>
<span class="kn">import</span> <span class="nn">org.apache.commons.math3.distribution.NormalDistribution</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>import org.isarnproject.sketches.java.TDigest
import org.isarnproject.sketches.spark.tdigest._
import scala.util.Random
import scala.util.Random._
import org.apache.spark.sql.functions._
import org.apache.spark.sql.Dataset
import scala.math._
import org.apache.commons.math3.distribution.NormalDistribution
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="o">//</span> <span class="n">Define</span> <span class="mi">2</span><span class="o">-</span><span class="n">Gaussian</span> <span class="n">mixture</span> <span class="n">model</span>
<span class="o">//</span> <span class="n">This</span> <span class="n">code</span> <span class="ow">is</span> <span class="n">taken</span> <span class="kn">from</span> <span class="p">[</span><span class="mi">041</span><span class="n">_SketchingWithTDigest</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">myMixtureOf2Normals</span><span class="p">(</span> <span class="n">normalLocation</span><span class="p">:</span> <span class="n">Double</span><span class="p">,</span> <span class="n">abnormalLocation</span><span class="p">:</span> <span class="n">Double</span><span class="p">,</span> <span class="n">normalWeight</span><span class="p">:</span> <span class="n">Double</span><span class="p">,</span> <span class="n">r</span><span class="p">:</span> <span class="n">Random</span><span class="p">)</span> <span class="p">:</span> <span class="n">Double</span> <span class="o">=</span> <span class="p">{</span>
  <span class="n">val</span> <span class="n">sample</span> <span class="o">=</span> <span class="k">if</span> <span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">nextDouble</span> <span class="o">&lt;=</span> <span class="n">normalWeight</span><span class="p">)</span> <span class="p">{</span><span class="n">r</span><span class="o">.</span><span class="n">nextGaussian</span><span class="o">+</span><span class="n">normalLocation</span> <span class="p">}</span> 
               <span class="k">else</span> <span class="p">{</span><span class="n">r</span><span class="o">.</span><span class="n">nextGaussian</span> <span class="o">+</span> <span class="n">abnormalLocation</span><span class="p">}</span> 
  <span class="k">return</span> <span class="n">sample</span>
   <span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>myMixtureOf2Normals: (normalLocation: Double, abnormalLocation: Double, normalWeight: Double, r: scala.util.Random)Double
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>%%scala
// Define the naive QE function
def itrQuantEstimator[D](data:Dataset[D], target: Int): Double = {
  // find an interval
  var x = 0.0
  var x_old = 0.0
  var qfound=false
  var step = 1.0
  var Na_old = data.filter($&quot;value&quot;&gt;x).count() 
  var Na = Na_old
  var scale=1.0
  if (Na_old &lt; 10){scale= (-1)}
  step = step*scale  
  var Nitr = 0
  while (qfound == false){
    // updata iteretion count
    Nitr = Nitr + 1
    // update x
    x = x + step
    // update step
    step = step*2
    Na = data.filter($&quot;value&quot;&gt;x).count()
    if (Na*scale &lt; target*scale){
      qfound = true}
    else{
      Na_old=Na
      x_old=x
    }
  }

  // set upper and lower limit
  var UL = x_old
  var LL=x
  if (x_old &lt; x){UL = x; LL=x_old }

  // Find the quantile for current batch
  var Int = UL - LL
  qfound = false
  x=LL
  scale=1
  while (qfound == false){
    // updata iteretion count
    Nitr = Nitr + 1
    // update x
    Int = Int/2
    x = x + scale*Int
    Na = data.filter($&quot;value&quot;&gt;x).count()
    if (Na == target){
      qfound = true}
    else if (Na &lt; target){
           // decrease x
      scale= -1
    }
    else if(Na &gt; target){
    // increase x
      scale= 1
    }
  
  }
  return x
}
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>itrQuantEstimator: [D](data: org.apache.spark.sql.Dataset[D], target: Int)Double
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>%%scala
// Estimate quantiles in loop 

val N = 100000 // samples per batch

// Naive QE parameters
val Nmk = 10 // integer &quot;N - k&quot;

// t-digest parameters
val targetQ = 1.0 - Nmk.toDouble/N.toDouble
val comp = 0.2 // Compression parameter
val Nc = 25 // Number of bins
val udf_tDigest = TDigestAggregator.udf[Double](comp,Nc)

// filter parameters
val tau = 20.0
val c = 1.0 - exp(-1.0/tau)
var q_tf = 0.0 //filterd t-digets quantile estimate
var q_nf = 0.0 //filterd naive quantile estimate

// loop parameters
val T = 500 // time or number of batches
var resMap = scala.collection.mutable.Map[Int,(Int,Double,Double,Double,Double,Double,Double,Double,Double,Double,Double)]() // create an empty map for storing results
var q_true = 0.0 // true quantile
var Na_true = 0.0 // true number of 
var rr = 0.0 // realisation of anomalies
var Na_t1 = 0.0 // number of anomalies using t-digest estimate from first batch 
var Na_tf = 0.0 // number of anomalies using filtered t-digest estimate from current batch 
var Na_n1 = 0.0 // number of anomalies using naive estimate from first batch 
var Na_nf = 0.0 // number of anomalies using filtered naive estimate from current batch 
var q_t1 = 0.0 // first QE with t-digets
var q_n1 = 0.0 // first QE with naive QE
var q_t = 0.0 // t-digest quantile estimate
var q_n = 0.0 // naive quantile estimate

// data parameters
var mu1=0.0
var mu2=0.0
var wN=1.0
val seed = 10L
val r = new Random(seed) // create random instace with &quot;seed&quot;


// Start loop
for( t &lt;- 1 to T){
  //get batch of data
  rr=r.nextFloat
  if( rr &lt; 0.95 )
  {wN=1.0} // All data is normal
  else
  {wN=0.99} // 1% of data is anomalous
  mu1=t.toDouble/1000.0 
  mu2=mu1 + 2
  val data = sc.parallelize(Vector.fill(N){myMixtureOf2Normals(mu1, mu2, wN, r)}).toDF.as[Double]
  
  
  //do t-digest
  val agg = data.agg(udf_tDigest($&quot;value&quot;))
  val td = agg.first.getAs[TDigest](0) 
  q_t = td.cdfInverse(targetQ)
  
  if( t == 1 ){q_t1 = q_t} // save first quantile estimate  
  if( t == 1 ){q_tf = q_t}else{q_tf = q_t*c + exp(-1.0/tau)*resMap(t-1)._5}   // if first batch use no filter weight
  Na_t1 = data.filter($&quot;value&quot;&gt;q_t1).count()
  Na_tf = data.filter($&quot;value&quot;&gt;q_tf).count()
  
  //do naive QE
  q_n = itrQuantEstimator(data,Nmk)
  
  if( t == 1 ){q_n1 = q_n} // save first quantile estimate  
  if( t == 1 ){q_nf = q_n}else{q_nf = q_n*c + exp(-1.0/tau)*resMap(t-1)._9}   // if first batch use no filter weight
  Na_n1 = data.filter($&quot;value&quot;&gt;q_n1).count()
  Na_nf = data.filter($&quot;value&quot;&gt;q_nf).count()
  
  //get true quantile and true number of anomalies (ignoring anomalies) 
  val normalDataDistribution = new NormalDistribution(mu1, 1);
  q_true = normalDataDistribution.inverseCumulativeProbability(targetQ)

  val abnormalDataDistribution = new NormalDistribution(mu2, 1);
  var cdf_N = normalDataDistribution.cumulativeProbability(q_true)
  var cdf_A = abnormalDataDistribution.cumulativeProbability(q_true)

  Na_true = N*wN*(1.0-cdf_N) + N*(1.0-wN)*(1.0-cdf_A)

  
  // save results
  resMap += (t -&gt; (t,q_true,Na_true,q_t,q_tf,Na_t1,Na_tf,q_n,q_nf,Na_n1,Na_nf))
  println(&quot;Batch Number: &quot;+ t)

}

// Put results into dataframe for presentation
val resL = resMap.toList.map(_._2) // convert to list and extract data
val resS = resL.sortBy(x =&gt; x._1) // sort
val res_all = resS.toDF(&quot;Time index, n&quot;,&quot;true quantile&quot;,&quot;true number of anomalies&quot;,&quot;QE with t-digest&quot;,&quot;filtered QE with t-digest&quot;,&quot;number of anomalies with fix t-digest quantile&quot;,&quot;number of anomalies with filtered t-digest quantile&quot;,&quot;Naive QE&quot;,&quot;filtered naive QE&quot;,&quot;number of anomalies with fix naive QE&quot;,&quot;number of anomalies with filtered naive QE&quot;) // convert to DF
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Batch Number: 1
Batch Number: 2
Batch Number: 3
Batch Number: 4
Batch Number: 5
Batch Number: 6
Batch Number: 7
Batch Number: 8
Batch Number: 9
Batch Number: 10
Batch Number: 11
Batch Number: 12
Batch Number: 13
Batch Number: 14
Batch Number: 15
Batch Number: 16
Batch Number: 17
Batch Number: 18
Batch Number: 19
Batch Number: 20
Batch Number: 21
Batch Number: 22
Batch Number: 23
Batch Number: 24
Batch Number: 25
Batch Number: 26
Batch Number: 27
Batch Number: 28
Batch Number: 29
Batch Number: 30
output truncated to 30 lines...
</pre></div>
</div>
</div>
</div>
<ol class="simple">
<li><p>Results</p></li>
</ol>
<hr class="docutils" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="o">//</span> <span class="n">Plot</span> <span class="n">estimated</span> <span class="ow">and</span> <span class="n">true</span> <span class="n">quantiles</span>
<span class="n">display</span><span class="p">(</span><span class="n">res_all</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table>
<thead>
<tr class="header">
<th>Time index, n</th>
<th>true quantile</th>
<th>true number of anomalies</th>
<th>QE with t-digest</th>
<th>filtered QE with t-digest</th>
<th>number of anomalies with fix t-digest quantile</th>
<th>number of anomalies with filtered t-digest quantile</th>
<th>Naive QE</th>
<th>filtered naive QE</th>
<th>number of anomalies with fix naive QE</th>
<th>...</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1.0</td>
<td>3.7200164854557087</td>
<td>9.999999999998899</td>
<td>3.83177124781981</td>
<td>3.83177124781981</td>
<td>10.0</td>
<td>10.0</td>
<td>3.8125</td>
<td>3.8125</td>
<td>10.0</td>
<td>...</td>
</tr>
<tr class="even">
<td>2.0</td>
<td>3.7210164854557086</td>
<td>9.999999999998899</td>
<td>3.708080772285753</td>
<td>3.825738792144233</td>
<td>2.0</td>
<td>2.0</td>
<td>3.6875</td>
<td>3.806403678062589</td>
<td>3.0</td>
<td>...</td>
</tr>
<tr class="odd">
<td>3.0</td>
<td>3.722016485455709</td>
<td>9.999999999998899</td>
<td>3.773951823511478</td>
<td>3.8232131118806505</td>
<td>8.0</td>
<td>8.0</td>
<td>3.7890625</td>
<td>3.8055579388286414</td>
<td>8.0</td>
<td>...</td>
</tr>
<tr class="even">
<td>4.0</td>
<td>3.723016485455709</td>
<td>9.999999999998899</td>
<td>3.52861076733272</td>
<td>3.808845185993609</td>
<td>3.0</td>
<td>3.0</td>
<td>3.52734375</td>
<td>3.7919892727274016</td>
<td>3.0</td>
<td>...</td>
</tr>
<tr class="odd">
<td>5.0</td>
<td>3.7240164854557087</td>
<td>9.999999999998899</td>
<td>3.785518110416313</td>
<td>3.807707511092989</td>
<td>7.0</td>
<td>7.0</td>
<td>3.7890625</td>
<td>3.791846532337131</td>
<td>7.0</td>
<td>...</td>
</tr>
<tr class="even">
<td>6.0</td>
<td>3.7250164854557086</td>
<td>9.999999999998899</td>
<td>3.7485411099008963</td>
<td>3.8048219316566287</td>
<td>5.0</td>
<td>6.0</td>
<td>3.75</td>
<td>3.7898056528723996</td>
<td>6.0</td>
<td>...</td>
</tr>
<tr class="odd">
<td>7.0</td>
<td>3.726016485455709</td>
<td>9.999999999998899</td>
<td>3.6989399177046245</td>
<td>3.799658004901166</td>
<td>4.0</td>
<td>4.0</td>
<td>3.703125</td>
<td>3.785578187547159</td>
<td>4.0</td>
<td>...</td>
</tr>
<tr class="even">
<td>8.0</td>
<td>3.727016485455709</td>
<td>9.999999999998899</td>
<td>3.7769226304826367</td>
<td>3.7985491876065827</td>
<td>9.0</td>
<td>9.0</td>
<td>3.78125</td>
<td>3.785367099349615</td>
<td>9.0</td>
<td>...</td>
</tr>
<tr class="odd">
<td>9.0</td>
<td>3.7280164854557087</td>
<td>9.999999999998899</td>
<td>3.676113548571056</td>
<td>3.7925779310291974</td>
<td>6.0</td>
<td>7.0</td>
<td>3.6796875</td>
<td>3.7802130444708</td>
<td>6.0</td>
<td>...</td>
</tr>
<tr class="even">
<td>10.0</td>
<td>3.7290164854557086</td>
<td>9.999999999998899</td>
<td>3.813854665682245</td>
<td>3.793615609622972</td>
<td>9.0</td>
<td>11.0</td>
<td>3.8125</td>
<td>3.7817876978730793</td>
<td>10.0</td>
<td>...</td>
</tr>
<tr class="odd">
<td>...</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table></div></div>
</div>
<p>We see that the filtered quantiles are not affected by the bursts of
anomalies, seen as spikes in the instantaneous estimates. We also note
that the difference between quantiles using the t-digest and naive
method is small. The number of iterations in each time step for the
naive method varied between 4 and 18 with a mean of 10 iterations. This
can be reduced by using the estimated quantile in step <span class="math notranslate nohighlight">\(n-1\)</span> as the
initial guess in step <span class="math notranslate nohighlight">\(n\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="o">//</span> <span class="n">Plot</span> <span class="n">number</span> <span class="n">of</span> <span class="n">anomalies</span> <span class="ow">and</span> <span class="n">true</span> <span class="n">number</span> <span class="n">of</span> <span class="n">anomalies</span> 
<span class="n">display</span><span class="p">(</span><span class="n">res_all</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table>
<thead>
<tr class="header">
<th>Time index, n</th>
<th>true quantile</th>
<th>true number of anomalies</th>
<th>QE with t-digest</th>
<th>filtered QE with t-digest</th>
<th>number of anomalies with fix t-digest quantile</th>
<th>number of anomalies with filtered t-digest quantile</th>
<th>Naive QE</th>
<th>filtered naive QE</th>
<th>number of anomalies with fix naive QE</th>
<th>...</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1.0</td>
<td>3.7200164854557087</td>
<td>9.999999999998899</td>
<td>3.83177124781981</td>
<td>3.83177124781981</td>
<td>10.0</td>
<td>10.0</td>
<td>3.8125</td>
<td>3.8125</td>
<td>10.0</td>
<td>...</td>
</tr>
<tr class="even">
<td>2.0</td>
<td>3.7210164854557086</td>
<td>9.999999999998899</td>
<td>3.708080772285753</td>
<td>3.825738792144233</td>
<td>2.0</td>
<td>2.0</td>
<td>3.6875</td>
<td>3.806403678062589</td>
<td>3.0</td>
<td>...</td>
</tr>
<tr class="odd">
<td>3.0</td>
<td>3.722016485455709</td>
<td>9.999999999998899</td>
<td>3.773951823511478</td>
<td>3.8232131118806505</td>
<td>8.0</td>
<td>8.0</td>
<td>3.7890625</td>
<td>3.8055579388286414</td>
<td>8.0</td>
<td>...</td>
</tr>
<tr class="even">
<td>4.0</td>
<td>3.723016485455709</td>
<td>9.999999999998899</td>
<td>3.52861076733272</td>
<td>3.808845185993609</td>
<td>3.0</td>
<td>3.0</td>
<td>3.52734375</td>
<td>3.7919892727274016</td>
<td>3.0</td>
<td>...</td>
</tr>
<tr class="odd">
<td>5.0</td>
<td>3.7240164854557087</td>
<td>9.999999999998899</td>
<td>3.785518110416313</td>
<td>3.807707511092989</td>
<td>7.0</td>
<td>7.0</td>
<td>3.7890625</td>
<td>3.791846532337131</td>
<td>7.0</td>
<td>...</td>
</tr>
<tr class="even">
<td>6.0</td>
<td>3.7250164854557086</td>
<td>9.999999999998899</td>
<td>3.7485411099008963</td>
<td>3.8048219316566287</td>
<td>5.0</td>
<td>6.0</td>
<td>3.75</td>
<td>3.7898056528723996</td>
<td>6.0</td>
<td>...</td>
</tr>
<tr class="odd">
<td>7.0</td>
<td>3.726016485455709</td>
<td>9.999999999998899</td>
<td>3.6989399177046245</td>
<td>3.799658004901166</td>
<td>4.0</td>
<td>4.0</td>
<td>3.703125</td>
<td>3.785578187547159</td>
<td>4.0</td>
<td>...</td>
</tr>
<tr class="even">
<td>8.0</td>
<td>3.727016485455709</td>
<td>9.999999999998899</td>
<td>3.7769226304826367</td>
<td>3.7985491876065827</td>
<td>9.0</td>
<td>9.0</td>
<td>3.78125</td>
<td>3.785367099349615</td>
<td>9.0</td>
<td>...</td>
</tr>
<tr class="odd">
<td>9.0</td>
<td>3.7280164854557087</td>
<td>9.999999999998899</td>
<td>3.676113548571056</td>
<td>3.7925779310291974</td>
<td>6.0</td>
<td>7.0</td>
<td>3.6796875</td>
<td>3.7802130444708</td>
<td>6.0</td>
<td>...</td>
</tr>
<tr class="even">
<td>10.0</td>
<td>3.7290164854557086</td>
<td>9.999999999998899</td>
<td>3.813854665682245</td>
<td>3.793615609622972</td>
<td>9.0</td>
<td>11.0</td>
<td>3.8125</td>
<td>3.7817876978730793</td>
<td>10.0</td>
<td>...</td>
</tr>
<tr class="odd">
<td>...</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table></div></div>
</div>
<p>If a fixed quantile is used the number of anomalies will increase with
time due to the changing statistics of the data distribution. By
properly filtering the estimates, the number of anomalies are kept at a
constant level (10 in this case) in time slots with the normal
distribution while still detecting the bursts of outliers (seen as
spikes with 52.7 calculated anomaleties) in time slots with the abnormal
distribution. The emperical mean relative errors for the quantile
defined as</p>
<div class="math notranslate nohighlight">
\[  \varepsilon_q  = \frac{1}{T}\sum_{n=1}^{T}\frac{|q[n] - \hat{q}[n]|}{q[n]}
\]</div>
<p>was 0.0052 with the naive QE and 0.0054 with t-digest, using the
filtered quantiles. The corresponding error for the number of anomalies
(this is ideally <span class="math notranslate nohighlight">\(N-k = 10\)</span> in normal batches and 52.7 in abnormal
batches), was 0.23 with naive QE and 0.24 with t-digest, i.e. both
methods perform equally in this case.</p>
<ol class="simple">
<li><p>Discussion</p></li>
</ol>
</div>
<hr class="docutils" />
<div class="section" id="iterative-method-vs-t-digest">
<h2>7.1 Iterative method vs t-digest<a class="headerlink" href="#iterative-method-vs-t-digest" title="Permalink to this headline">Â¶</a></h2>
<p>One difference between the iterative method and t-digest is that the
latter is updated with a single sample at a time, while the former must
store the whole batch of <span class="math notranslate nohighlight">\(N\)</span> samples, and thus might require more space.
On the other hand, the iterative method has a simple implementation that
relies only on the basic arithmetic operations, while t-digest requires
evaluations of scale functions which contain relatively expensive
operations such as log and sin<span class="math notranslate nohighlight">\(^{-1}\)</span>. This could suggest that iterative
method can be implemented to work faster than t-digest. Developing an
efficient implementation and comparing these methods in terms of time
complexity would be an interesting future research direction.</p>
</div>
<div class="section" id="sketching-with-the-iterative-method">
<h2>7.2 Sketching with the iterative method<a class="headerlink" href="#sketching-with-the-iterative-method" title="Permalink to this headline">Â¶</a></h2>
<p>Another difference is that the t-digest outputs a sketch â€“ a compressed
object that can be used to obtain estimates of different statistics of
the original data stream, e.g. estimates of several different quantiles.
On the other hand, the iterative method in the form presented above can
only be used to estimate one quantile. A way to obtain a data sketch
with the iterative method is to fix a step size <span class="math notranslate nohighlight">\(\alpha\)</span> and to maintain
<span class="math notranslate nohighlight">\(\frac{1}{\alpha}\)</span> quantiles for <span class="math notranslate nohighlight">\(\alpha\)</span>, <span class="math notranslate nohighlight">\(2\alpha\)</span>, <span class="math notranslate nohighlight">\(3\alpha\)</span>, â€¦ If
we want to get an estimate of a quantile that is not stored in the
sketch, we can take two values from the sketch such that the desired
quantile falls between them and then iterpolate (e.g. linearly). The
space complexity of this sketch is <span class="math notranslate nohighlight">\(O(\frac{1}{\alpha})\)</span>, i.e. it
depends linearly on the desired level of accuracy. Having in mind that
our target application is anomaly detection, one could modify this
solution to better correspond to the task at hand: instead of evenly
spacing the quantiles, one could be more fine-grained towards the
endpoints of the interval [0,1] and have larger bins in the middle.</p>
</div>
<div class="section" id="alternative-approaches">
<h2>7.3 Alternative approaches<a class="headerlink" href="#alternative-approaches" title="Permalink to this headline">Â¶</a></h2>
<p>An alternative approach to quantile estimation is KLL (see
https://arxiv.org/pdf/1603.05346.pdf). It is a data-agnostic method,
i.e. no prior distribution is assumed on the data stream. The data
points are only assumed to be pairwise comparable. In this model, KLL is
provably optimal. The basic idea of the algorithm is the following. The
data is processes by <em>compactors</em>, which are subroutines that have
arrays of given capacity. A compactor collects elements until the
maximum capacity is reached, then it sorts the elements and removes
either the odd-indexed ones or the even-indexed ones (deciding
randomly). Afterwards, the compactor passed the remaining elements to
another compactor. The full algorithm is a chain of compactors. By
choosing appropriate capacities for compactors at each level, KLL
achieves provably optimal worst-case performance.</p>
<p>One might be interested in comparing KLL with t-digest and the iterative
method empirically. It would also be interesting to mathematically
analyze t-digest and the naive QE in the distribution-agnostic model of
KLL.</p>
<ol class="simple">
<li><p>References</p></li>
</ol>
<hr class="docutils" />
<p>[Rohling] H. Rohling, â€œRadar CFAR Thresholding in Clutter and Multiple
Target Situations,â€ in IEEE Transactions on Aerospace and Electronic
Systems, vol. AES-19, no. 4, pp. 608-621, July 1983, doi:
10.1109/TAES.1983.309350.</p>
<p>[MÃ¶ller] MÃ¶ller, E., Grieszbach, G., Shack, B., &amp; Witte, H. (2000).
Statistical properties and control algorithms of recursive quantile
estimators. Biometrical Journal, 42(6), 729â€“746.</p>
<p>[Dunning] Dunning, T., &amp; Ertl, O. (2019). Computing extremely accurate
quantiles using t-digests. arXiv preprint arXiv:1902.04023.</p>
<p>[041<em>SketchingWithTDigest]
https://lamastex.github.io/scalable-data-science/sds/2/2/db/041</em>SketchingWithTDigest/</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./000_0-sds-3-x-projects/student-project-11_group-Sketchings"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="../student-project-10_group-Geosmus/07_b_appendix_TTTDFfunctions.html" title="previous page">ScaDaMaLe, Scalable Data Science and Distributed Machine Learning</a>
    <a class='right-next' id="next-link" href="../student-project-12_group-CovidPandemic/00_ProjectDescriptionAndPlanning.html" title="next page">Project Description and Introduction</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By ScaDaMaLe Team<br/>
        
            &copy; Copyright 2020 Creative Commons Zero v1.0 Universal.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>

<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Distributed ensembles &#8212; Scalable Data Science &amp; Distributed Machine Learning</title>
    
  <link rel="stylesheet" href="../../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Topic Modeling with SARS-Cov-2 Genome ðŸ§¬" href="../student-project-09_group-TopicModeling/01_Introduction.html" />
    <link rel="prev" title="Intro" href="../student-project-07_group-MathAtKTH/03_graph_string_converter.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Scalable Data Science & Distributed Machine Learning</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/000_ScaDaMaLe.html">
   Introduction
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction to Apache Spark Core
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_1-sds-3-x/001_whySpark.html">
   Why Apache Spark?
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/002_00_loginToDatabricks.html">
     Login to databricks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/002_00_loginToDatabricks.html#import-course-content-now">
     Import Course Content Now!
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/002_00_loginToDatabricks.html#cloud-free-computing-environment">
     Cloud-free Computing Environment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/002_01_multiLingualNotebooks.html">
     Multi-lingual Notebooks
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_1-sds-3-x/003_00_scalaCrashCourse.html">
   Scala Crash Course
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/003_01_scalaCrashCourse.html">
     Scala Crash Course Continued
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_1-sds-3-x/004_RDDsTransformationsActions.html">
   Introduction to Spark
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/005_RDDsTransformationsActionsHOMEWORK.html">
     HOMEWORK on RDD Transformations and Actions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html">
     Piped RDDs and Bayesian AB Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#from-a-local-collection">
     From a Local Collection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#glom">
     glom
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#checkpointing">
     Checkpointing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#pipe-rdds-to-system-commands">
     Pipe RDDs to System Commands
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#mappartitions">
     mapPartitions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#foreachpartition">
     foreachPartition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#numerically-rigorous-bayesian-ab-testing">
     Numerically Rigorous Bayesian AB Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#usage-instructions-for-isit1or2coins">
     Usage instructions for IsIt1or2Coins
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006_WordCount.html">
     Word Count on US State of the Union (SoU) Addresses
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction to Apache Spark SQL
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/007_SparkSQLIntroBasics.html">
   Introduction to Spark SQL
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_1-sds-3-x/007_SparkSQLIntroBasics.html#getting-started-in-spark-2-x">
   Getting Started in Spark 2.x
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007a_SparkSQLProgGuide_HW.html">
     Spark Sql Programming Guide
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007b_SparkSQLProgGuide_HW.html">
     Getting Started
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007b_SparkSQLProgGuide_HW.html#id1">
     Getting Started
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007c_SparkSQLProgGuide_HW.html">
     Getting Started - Exercise
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007d_SparkSQLProgGuide_HW.html">
     Data Sources
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007d_SparkSQLProgGuide_HW.html#id1">
     Data Sources
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007e_SparkSQLProgGuide_HW.html">
     Performance Tuning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007f_SparkSQLProgGuide_HW.html">
     Distributed SQL Engine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007f_SparkSQLProgGuide_HW.html#id1">
     Distributed SQL Engine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html">
     ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html#sql-pivoting-since-spark-2-4">
     SQL Pivoting since Spark 2.4
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html#load-data">
     Load Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-in-sql">
     Pivoting in SQL
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-with-multiple-aggregate-expressions">
     Pivoting with Multiple Aggregate Expressions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-with-multiple-grouping-columns">
     Pivoting with Multiple Grouping Columns
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-with-multiple-pivot-columns">
     Pivoting with Multiple Pivot Columns
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Extract Transform and Load
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html">
   Diamonds ML Pipeline Workflow - DataFrame ETL and EDA Part
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#step-1-load-data-as-dataframe">
   Step 1. Load data as DataFrame
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#step-2-understand-the-data">
   Step 2. Understand the data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#let-us-run-through-some-basic-inteactive-sql-queries-next">
   Let us run through some basic inteactive SQL queries next
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#why-do-we-need-to-know-these-interactive-sql-queries">
   Why do we need to know these interactive SQL queries?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#we-will-continue-later-with-ml-pipelines-to-do-prediction-with-a-fitted-model-from-this-dataset">
   We will continue later with ML pipelines to do prediction with a fitted model from this dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html">
   Power Plant ML Pipeline Application - DataFrame Part
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-1-business-understanding">
   Step 1: Business Understanding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-2-load-your-data">
   Step 2: Load Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#use-this-for-other-smallish-datasets-you-want-to-import-to-your-ce">
   USE THIS FOR OTHER SMALLish DataSets you want to import to your CE
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-3-explore-your-data">
   Step 3: Explore Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-4-visualize-your-data">
   Step 4: Visualize Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/010_wikipediaClickStream_01ETLEDA.html">
   Wiki Clickstream Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/010_wikipediaClickStream_01ETLEDA.html#wikipedia-logo">
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_LoadExtract.html">
   Old Bailey Online Data Analysis in Apache Spark
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_LoadExtract.html#analysing-the-full-old-bailey-online-sessions-papers-dataset">
   Analysing the Full Old Bailey Online Sessions Papers Dataset
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html">
     Piped RDDs and Bayesian AB Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#from-a-local-collection">
     From a Local Collection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#glom">
     glom
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#checkpointing">
     Checkpointing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#pipe-rdds-to-system-commands">
     Pipe RDDs to System Commands
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#mappartitions">
     mapPartitions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#foreachpartition">
     foreachPartition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#numerically-rigorous-bayesian-ab-testing">
     Numerically Rigorous Bayesian AB Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#usage-instructions-for-isit1or2coins">
     Usage instructions for IsIt1or2Coins
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#parsing-the-output-from-isit1or2coins">
     Parsing the output from
     <code class="docutils literal notranslate">
      <span class="pre">
       IsIt1or2Coins
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#providing-case-classes-for-input-and-output-for-easy-spark-communication">
     Providing case classes for input and output for easy spark communication
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/035_LDA_CornellMovieDialogs.html">
   Topic Modeling of Movie Dialogs with Latent Dirichlet Allocation
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Trends in Money and News
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_9-sds-3-x-trends/000_TrendsInFinancialStocksAndNewsEvents.html">
   Trends in Financial Stocks and News Events
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/00a_FX1M.html">
     Historical FX-1-M Financial Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/00b_yfinance.html">
     yfinance Stock Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/000a_finance_utils.html">
     Utilities Needed for Financial Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/000b_gdelt_utils.html">
     Utilities Needed for Mass Media Data
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_9-sds-3-x-trends/01_trend_calculus_showcase.html">
   Finding trends in oil price data.
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/02_streamable_trend_calculus.html">
     Streaming Trend Calculus with Maximum Necessary Reversals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/03_streamable_trend_calculus_estimators.html">
     Markov Model for Trend Calculus
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_9-sds-3-x-trends/030_Spark_GDELT_project_001.html">
   Plugging into GDELT Mass Media Streams
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/030a_gdelt_EOI_detection.html">
     Detecting Events of Interest to OIL/GAS Price Trends
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/030b_gdelt_POI_detection.html">
     Detecting Persons of Interest to OIL/GAS Price Trends
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Distributed Deep Learning with Horovod
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_7-sds-3-x-ddl/00_DDL_Introduction.html">
   Introduction to Distributed Deep Learning (DDL) with Horovod over Tensorflow/keras and Pytorch
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_7-sds-3-x-ddl/0x_mnist-tensorflow-keras.html">
     Distributed deep learning training using TensorFlow and Keras with HorovodRunner
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_7-sds-3-x-ddl/0y_mnist-pytorch.html">
     Distributed deep learning training using PyTorch with HorovodRunner for MNIST
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  WASP AI-Track Student Projects
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-01_group-TheTwoCultures/00_download_data.html">
   The two cultures
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-01_group-TheTwoCultures/01_load_data.html">
     Preprocessing and loading the relevant data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-01_group-TheTwoCultures/02_logisticregression.html">
     The two cultures - Classifying threads with logistic regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-01_group-TheTwoCultures/03_word2vec.html">
     Classification using Word2Vec
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-01_group-TheTwoCultures/04_LDA.html">
     Topic Modeling with LDA
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-02_group-LiUUmeaSceneGraphMotifs/01_SceneGraphMotifs.html">
   Exploring the GQA Scene Graph Dataset Structure and Properties
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-03_group-GuangyiZhang/01_triads.html">
   Signed Triads in Social Media
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-04_group-DistributedLinearAlgebra/01_DistributedSVD.html">
   Distributed Linear Algebra
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-04_group-DistributedLinearAlgebra/02_CollaborativeFiltering.html">
     Music Recommendation System
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-05_group-LundDirichletAnalysts/01_Wikipedia_LDA_Analysis.html">
   Wikipedia analysis using Latent Dirichlet Allocation (LDA)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-06_group-ParticleClustering/00_Introduction.html">
   Unsupervised clustering of particle physics data with distributed training
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-06_group-ParticleClustering/00_Introduction.html#introduction">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-06_group-ParticleClustering/00_Introduction.html#background">
   Background
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-06_group-ParticleClustering/00_Introduction.html#the-uclusted-algorithm">
   The UClusted algorithm
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-06_group-ParticleClustering/00_Introduction.html#motivation">
   Motivation
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-06_group-ParticleClustering/00_Introduction.html#our-contribution">
   Our contribution
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-06_group-ParticleClustering/01_data_and_preprocessing.html">
     Important!
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-06_group-ParticleClustering/01_data_and_preprocessing.html#important-continued-from-above">
     Important (continued from above)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-06_group-ParticleClustering/04_evaluate.html">
     Evaluation
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-07_group-MathAtKTH/01_Coding_Motifs.html">
   Motif Finding
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-07_group-MathAtKTH/01_Coding_Motifs.html#application">
   Application
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-07_group-MathAtKTH/02_Data_Processing.html">
     Data Processing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-07_group-MathAtKTH/03_graph_string_converter.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-07_group-MathAtKTH/03_graph_string_converter.html#examples">
     Examples
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Distributed ensembles
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="#distributed-ensembles-prediction-api">
   Distributed ensembles prediction API
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="#application-example-distributed-predictions">
   Application example: Distributed predictions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="#application-example-out-of-distribution-detection">
   Application example: Out of distribution detection
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-09_group-TopicModeling/01_Introduction.html">
   Topic Modeling with SARS-Cov-2 Genome ðŸ§¬
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/02_Data_Processing.html">
     Extract (overlapping [since yet do not know which parts corresponds to coding regions]) 3-mers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/03_LDA.html">
     Load processed data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/03_LDA.html#format-data-for-apache-spark-mllib-clustering-lda-adapted-from-the-lda-course-tutorial-034lda20newsgroupssmall">
     Format data for apache.spark.mllib.clustering.LDA (adapted from the LDA course tutorial â€˜034
     <em>
      LDA
     </em>
     20NewsGroupsSmallâ€™)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/03_LDA.html#visualise-results">
     Visualise Results
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/04_Classification_CountVector.html">
     Load processed data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/04_Classification_CountVector.html#format-data">
     Format data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/04_Classification_CountVector.html#classification">
     Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/04_Classification_CountVector.html#evaluation">
     Evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/05_Classification.html">
     Load processed data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/05_Classification.html#explore-data">
     Explore data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/05_Classification.html#classification">
     Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/05_Classification.html#evaluation">
     Evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/06_Results.html">
     Results and Conclusion
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-10_group-Geosmus/01_Introduction.html">
   Twitter Streaming Using Geolocation and Emoji Based Sentiment Analysis
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/02_ClusteringEmoticonsBasedOnTweets.html">
     Clustering emoticons based on tweets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/03_Dynamic_Tweet_Maps.html">
     Dynamic Tweet Maps
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/04_conclusion.html">
     Conclusion
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/05_appendix_get-cc-data.html">
     Notebook for collecting tweets with country codes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/07_a_appendix_extendedTwitterUtils2run.html">
     ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/07_a_appendix_extendedTwitterUtils2run.html#extended-spark-streaming-twitter-twitterutils">
     Extended spark.streaming.twitter.TwitterUtils
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/07_b_appendix_TTTDFfunctions.html">
     ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-11_group-Sketchings/00_QuantileEstimation.html">
   Anomaly Detection with Iterative Quantile Estimation and T-digest
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-12_group-CovidPandemic/00_ProjectDescriptionAndPlanning.html">
   Project Description and Introduction
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/01_DownloadFilesPeriodicallyScript.html">
     Download Files Periodically
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/01_StreamToFile.html">
     Stream to parquet file
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/021_DataPreprocess_Explain.html">
     Loading data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/021_DataPreprocess_Explain.html#preprocessing">
     Preprocessing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/02_DataPreprocess.html">
     Loading data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/02_DataPreprocess.html#preprocessing">
     Preprocessing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html">
     This notebook is for explosive analysis of features in data.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html#statistics-of-invariant-features">
     Statistics of invariant features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html#correlation-between-invariant-features">
     Correlation between invariant features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html#correlation-between-new-case-per-million-total-case-new-death-per-million-total-death-per-million-reproduction-rate-and-stringency-index">
     Correlation between new case per million, total case, new death per million, total death per million, reproduction rate and stringency index.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/04_DataVisualize.html">
     Show reproduction rate of selected countries i.e. Sweden, Germany, Danmark, Finland, Norway
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/04_DataVisualize.html#visualize-total-cases-total-deaths-new-cases-and-new-deaths-during-pandemic">
     Visualize total cases, total deaths, new cases and new deaths during pandemic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/04_DataVisualize.html#total-deaths">
     Total Deaths
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/04_DataVisualize.html#new-cases">
     New Cases
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/04_DataVisualize.html#new-deaths">
     New Deaths
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/05_Clustering.html">
     Clustering of country features in the Covid 19 dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/06_DataPredicton_LR.html">
     Prediction with Linear Regression (LR) Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/07_DataPredicton_ARIMA.html">
     Prediction with Time Series model - ARIMA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/08_DataPrediction_GP.html">
     Prediction with time series model - Gaussian Processes
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-13_group-Genomics/01_1000genomes.html">
   Genomics Analysis with Glow and Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-13_group-Genomics/01_1000genomes.html#load-libs-and-define-helper-functions">
   Load libs and define helper functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-13_group-Genomics/01_1000genomes.html#read-data">
   Read data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-13_group-Genomics/01_1000genomes.html#pca">
   PCA
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-13_group-Genomics/01_1000genomes.html#predicting-ethinicity">
   Predicting Ethinicity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-13_group-Genomics/01_1000genomes.html#filtering-of-snps-based-on-chi-squared-test">
   Filtering of SNPs based on chi-squared test
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-14_group-NullHypothesisEvaluationCriteria/00_distributed_combinatorial_bandit.html">
   Distributional combinatorial bandits
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/00_video.html">
   Reinforcement Learning for Intraday Trading
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/01_rl_intraday_trading.html">
     Reinforcement Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/01_rl_intraday_trading.html#summary-and-outlook">
     Summary and Outlook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html">
     Reinforcement Learning - Distributed model tuning with Elephas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html#elephas">
     Elephas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html#notes-to-the-elephas-training">
     Notes to the elephas training
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/03_resources.html">
     Resources
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-16_group-IntrusionDetection/00_Introduction.html">
   Intrusion Detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-16_group-IntrusionDetection/00_Introduction.html#preparing-the-dataframe-for-training-classifers">
   Preparing the DataFrame for training classifers
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-17_group-TowardsScalableTDA/00_introduction.html">
   Density Estimation via Voronoi Diagrams in High Dimensions
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-17_group-TowardsScalableTDA/03_robotics_dataset.html">
     Robotics Dataset
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-18_group-ProjectRL/00_Problem_Description.html">
   Recommender System
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-18_group-ProjectRL/01_The_ALS_method.html">
     <span class="xref myst">
      The Alternating Least Squares method (ALS)
     </span>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-18_group-ProjectRL/01_The_ALS_method.html#on-a-small-dataset">
     <span class="xref myst">
      On a small dataset
     </span>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-18_group-ProjectRL/01_The_ALS_method.html#on-a-large-dataset-netflix-dataset">
     <span class="xref myst">
      On a large dataset - Netflix dataset
     </span>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-18_group-ProjectRL/02_Extensions.html">
     Extensions
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-19_group-Featuring/01_FundamentalMatrix.html">
   Fundamental Matrix
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-20_group-Generalization/01_Background.html">
   MixUp and Generalization
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-20_group-Generalization/02_Random_Forest.html">
     Random Forests and MixUp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-20_group-Generalization/03_CNN_MNIST.html">
     CNN for MNIST
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-20_group-Generalization/04_CNN_Intel_Image.html">
     CNN for Intel Image Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-20_group-Generalization/05_Horovod_test.html">
     CNNs and MixUp with Horovod
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-21_group-GraphSpectralAnalysis/00_introduction.html">
   Graph Spectral Analysis
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-21_group-GraphSpectralAnalysis/01_preprocess_data.html">
     Preprocess the data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-21_group-GraphSpectralAnalysis/02_generate_graphs.html">
     Generate random graphs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-21_group-GraphSpectralAnalysis/03_compute_rsvd.html">
     Compute RSVD
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-21_group-GraphSpectralAnalysis/04_analyse_eigenvalues.html">
     Analyse the eigenvalue spectrum
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-22_group-SwapWithDDP/00_Introduction.html">
   SWAP
   <em>
    With
   </em>
   DDP
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-22_group-SwapWithDDP/01_SWAP_with_DDP.html">
     SWAP
     <em>
      With
     </em>
     DDP
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/000_0-sds-3-x-projects/student-project-08_group-DistributedEnsemble/00_project.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://lamastex.github.io/ScaDaMaLe/index.html"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://lamastex.github.io/ScaDaMaLe/index.html/issues/new?title=Issue%20on%20page%20%2F000_0-sds-3-x-projects/student-project-08_group-DistributedEnsemble/00_project.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Distributed ensembles
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#introduction">
     Introduction
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#why-ensembles">
       Why ensembles?
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
       Distributed ensembles
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#imports">
     Imports
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data">
     Data
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#distributed-ensemble-of-neural-networks">
     Distributed ensemble of neural networks
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#distributed-ensembles-prediction-api">
   Distributed ensembles prediction API
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#application-example-distributed-predictions">
   Application example: Distributed predictions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#making-distributed-predictions">
     Making distributed predictions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#application-example-out-of-distribution-detection">
   Application example: Out of distribution detection
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#references">
     References
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="distributed-ensembles">
<h1>Distributed ensembles<a class="headerlink" href="#distributed-ensembles" title="Permalink to this headline">Â¶</a></h1>
<p><em>Amanda Olmin, Amirhossein Ahmadian and Jakob Lindqvist</em></p>
<p><a class="reference external" href="https://www.youtube.com/watch?v=zbYewn3nDtk">Video presentation</a></p>
<p>Python version: python 3.7</p>
<p><strong>Library dependencies</strong> - PySpark - PyTorch - toolz - matplotlib</p>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">Â¶</a></h2>
<p>In this project, we create a distributed ensemble of neural networks
that we can train and make predictions with in a distributed fashion,
and we also apply this model to the out-of-distribution detection
problem [2] (detecting inputs that are highly dissimilar from the
training data).</p>
<div class="section" id="why-ensembles">
<h3>Why ensembles?<a class="headerlink" href="#why-ensembles" title="Permalink to this headline">Â¶</a></h3>
<p>Ensembles of neural networks - often have better predictive performance
than single ensemble members [1] - have shown to provide reliable
uncertainty estimates</p>
<p>The latter quality is beneficial in itself but is especially useful when
it comes to tasks such as out-of-distribution detection, where a modelâ€™s
uncertainty estimates can be used to determine if a sample is
in-distribution or not. We demonstrate this in the experiments below.</p>
</div>
<div class="section" id="id1">
<h3>Distributed ensembles<a class="headerlink" href="#id1" title="Permalink to this headline">Â¶</a></h3>
<p>In Spark, it is common to distribute <em>data</em> over several worker nodes.
In this way, the same function is performed on several nodes on
different parts of the data. The result from each node is then
communicated and aggregated to a final function output. Similarily, we
can train a neural network (a single ensemble member) in a distributed
way by distributing the data that we use to train it. This can for
example be done using the built-in MLP and MLPC classes in Pyspark
[3]. However, this approach requires continuous communication between
nodes to update model weights (possibly at every iteration) since every
node keeps its own version of the model weights. The approach therefore
scales badly as - the number of model parameters grow (more information
to communicate between nodes) - when the complexity of the training
algorithm increases, e.g. we wish to use a stochastic training algorithm</p>
<p>In this regard, the communication becomes a bottleneck. Asynchronous
updating can reduce the amount of communication, but might also hurt
model performance [4].</p>
<p>Considering that the ensemble members are independent models, they never
need to communicate during the training phase. Hence, training ensemble
members in a way that requires the otherwise independent training
processes to integrate or synchronize, would cause unnecessary costs,
for example since the training processes all need to communicate through
the driver node. The same holds for prediction; no communication is
needed between ensemble members except at the very end when the
predictions are aggregated.</p>
<p>To avoid unnecessary communication, we distribute the <em>ensemble members</em>
and train them on separate worker nodes such that we - are able to train
several ensemble members in parallell (limited by the number of nodes in
our cluster) and independently - avoid communication between worker
nodes</p>
<p>To achieve this, we implement our own training processes below. In
addition, we implement our own MLP class with the help of PyTorch. MLP
objects and their training data are then distributed on worker nodes
using Spark. This is not only to avoid distributing the training data
over several nodes during training but also to package the ensemble
members in a way that makes it possible for us to send them between the
driver and the worker nodes prior to and at the end of training.</p>
<img src="files/shared_uploads/amanda.olmin@liu.se/distributed_fig_small.png"/></div>
</div>
<div class="section" id="imports">
<h2>Imports<a class="headerlink" href="#imports" title="Permalink to this headline">Â¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">randrange</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="c1"># External libs added to cluster</span>
<span class="kn">from</span> <span class="nn">pyspark.mllib.random</span> <span class="kn">import</span> <span class="n">RandomRDDs</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">StringIndexer</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">VectorAssembler</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">pyspark.rdd</span> <span class="kn">import</span> <span class="n">PipelinedRDD</span>
<span class="kn">from</span> <span class="nn">toolz.itertoolz</span> <span class="kn">import</span> <span class="n">partition_all</span>
<span class="kn">from</span> <span class="nn">toolz.itertoolz</span> <span class="kn">import</span> <span class="n">cons</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="data">
<h2>Data<a class="headerlink" href="#data" title="Permalink to this headline">Â¶</a></h2>
<p>We introduce the functions that we use to load the data for the
experiments that we conduct. We split the available training data
between ensemble members using sampling with or without replacement. The
number of training data points that we can distribute to each ensemble
member is only limited by the memory available to each worker node.</p>
<p><strong>TOY DATA</strong></p>
<p>We create a function for generating data consisting of Gaussian
clusters. The function takes as input, user defined means and variances
for each cluster in the data as well as the total number of observations
and a vector of intended class proportions. It also comes with an option
to split the final RDD into train and test sets.</p>
<p>We will use this data later on to demonstrate our distributed ensembles
framework as well as to generate out-of-distribution data for OOD
detection.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_gaussian_RDD</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="n">variances</span><span class="p">,</span> <span class="n">num_observations</span><span class="p">,</span> <span class="n">class_proportions</span><span class="p">,</span> <span class="n">train_test_split</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Create toy Gaussian classification data</span>
<span class="sd">  Let C := number of clusters/classes and P := number of data features</span>
<span class="sd">  </span>
<span class="sd">  Args: </span>
<span class="sd">    means (np.array[float]): mean vector of shape (C, P)</span>
<span class="sd">    variances (np.array[float]): vector of variances, shape (C, P)</span>
<span class="sd">    num_observations (scalar[int]): the total number of observations in the final data set</span>
<span class="sd">    class_proportions (np.array[float]): vector of class proportions, length C</span>
<span class="sd">    train_test_split: whether to split the data into train/test sets or not</span>
<span class="sd">    </span>
<span class="sd">  Returns:</span>
<span class="sd">    Gaussian data, RDD of tuples (list(features), int(label))</span>
<span class="sd">  &quot;&quot;&quot;</span>
  
  <span class="k">assert</span> <span class="n">means</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">variances</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="k">assert</span> <span class="n">means</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">variances</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
  <span class="k">assert</span> <span class="n">class_proportions</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span>
    
  <span class="n">num_classes</span> <span class="o">=</span> <span class="n">means</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">num_features</span> <span class="o">=</span> <span class="n">means</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
  
  <span class="n">data_rdd</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">emptyRDD</span><span class="p">()</span> 
  <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_classes</span><span class="p">):</span>
    
    <span class="c1"># Generate standard normal data</span>
    <span class="n">class_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_observations</span> <span class="o">*</span> <span class="n">class_proportions</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
    <span class="n">class_rdd</span> <span class="o">=</span> <span class="n">RandomRDDs</span><span class="o">.</span><span class="n">normalVectorRDD</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="n">numRows</span><span class="o">=</span><span class="n">class_size</span><span class="p">,</span> <span class="n">numCols</span><span class="o">=</span><span class="n">num_features</span><span class="p">,</span> <span class="n">numPartitions</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1">#, seed=123)</span>

    <span class="c1"># Map to true distribution</span>
    <span class="n">class_rdd_transformed</span> <span class="o">=</span> <span class="n">class_rdd</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="n">means</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+</span> <span class="p">(</span><span class="n">variances</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:]</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="n">v</span><span class="p">)</span>
    
    <span class="c1"># Add labels</span>
    <span class="n">class_rdd_w_label</span> <span class="o">=</span> <span class="n">class_rdd_transformed</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">k</span><span class="p">))</span> 
    
    <span class="n">data_rdd</span> <span class="o">=</span> <span class="n">data_rdd</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">class_rdd_w_label</span><span class="p">)</span>
    
  <span class="c1"># We will shuffle and repartition the data</span>
  <span class="n">num_partitions</span> <span class="o">=</span> <span class="mi">10</span>
  <span class="n">shuffled_rdd</span> <span class="o">=</span>  <span class="n">data_rdd</span><span class="o">.</span><span class="n">sortBy</span><span class="p">(</span><span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="n">randrange</span><span class="p">(</span><span class="n">num_observations</span><span class="p">))</span><span class="o">.</span><span class="n">repartition</span><span class="p">(</span><span class="n">num_partitions</span><span class="p">)</span>
  <span class="n">final_rdd</span> <span class="o">=</span> <span class="n">shuffled_rdd</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="nb">tuple</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">int</span><span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">])))</span>
  
  <span class="k">if</span> <span class="n">train_test_split</span><span class="p">:</span>
    <span class="n">train_rdd</span><span class="p">,</span> <span class="n">test_rdd</span> <span class="o">=</span> <span class="n">final_rdd</span><span class="o">.</span><span class="n">randomSplit</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="n">seed</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">final_rdd</span> <span class="o">=</span> <span class="p">(</span><span class="n">train_rdd</span><span class="p">,</span> <span class="n">test_rdd</span><span class="p">)</span>
    
  <span class="k">return</span> <span class="n">final_rdd</span>                                   
</pre></div>
</div>
</div>
</div>
<p><strong>FIRE WALL DATA</strong></p>
<p>We will also consider some real data. The dataset that we will use
consits of traffic from a firewall tracking record. We have accessed it
through the UCI Machine Learning repository [4]:
https://archive.ics.uci.edu/ml/datasets/Internet+Firewall+Data.</p>
<ul class="simple">
<li><p>Number of data points: 65,532.</p></li>
<li><p>Number of features: 11 (all numerical).</p></li>
<li><p>Number of classes: 4 (allow/deny/drop/reset both).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">load_firewall_data</span><span class="p">(</span><span class="n">train_test_split</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">file_location</span><span class="o">=</span><span class="s2">&quot;/FileStore/shared_uploads/amanda.olmin@liu.se/fire_wall_data.csv&quot;</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Load and preprocess firewall data</span>
<span class="sd">  Args:</span>
<span class="sd">     file_location: file location from which to load the data</span>
<span class="sd">     train_test_split: whether to split the data into train/test sets or not</span>
<span class="sd">  </span>
<span class="sd">  Returns:</span>
<span class="sd">     Firewall data, RDD of tuples (list(features), int(label))</span>
<span class="sd">  &quot;&quot;&quot;</span>
  
  <span class="c1"># File location and type</span>
  <span class="c1"># file_location = &quot;/FileStore/shared_uploads/amanda.olmin@liu.se/fire_wall_data.csv&quot; </span>
  <span class="n">file_type</span> <span class="o">=</span> <span class="s2">&quot;csv&quot;</span>

  <span class="c1"># CSV options</span>
  <span class="n">infer_schema</span> <span class="o">=</span> <span class="s2">&quot;true&quot;</span>
  <span class="n">first_row_is_header</span> <span class="o">=</span> <span class="s2">&quot;true&quot;</span>
  <span class="n">delimiter</span> <span class="o">=</span> <span class="s2">&quot;,&quot;</span>

  <span class="c1"># Load the data from file</span>
  <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">file_type</span><span class="p">)</span> \
      <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;inferSchema&quot;</span><span class="p">,</span> <span class="n">infer_schema</span><span class="p">)</span> \
      <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span> <span class="n">first_row_is_header</span><span class="p">)</span> \
      <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;sep&quot;</span><span class="p">,</span> <span class="n">delimiter</span><span class="p">)</span> \
      <span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file_location</span><span class="p">)</span>
  
  <span class="c1"># Preprocess data</span>
  <span class="n">col_num</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Source Port&quot;</span><span class="p">,</span> <span class="s2">&quot;Destination Port&quot;</span><span class="p">,</span> <span class="s2">&quot;NAT Source Port&quot;</span><span class="p">,</span> <span class="s2">&quot;NAT Destination Port&quot;</span><span class="p">,</span> <span class="s2">&quot;Bytes&quot;</span><span class="p">,</span> <span class="s2">&quot;Bytes Sent&quot;</span><span class="p">,</span> <span class="s2">&quot;Bytes Received&quot;</span><span class="p">,</span> <span class="s2">&quot;Packets&quot;</span><span class="p">,</span> <span class="s2">&quot;Elapsed Time (sec)&quot;</span><span class="p">,</span> <span class="s2">&quot;pkts_sent&quot;</span><span class="p">,</span> <span class="s2">&quot;pkts_received&quot;</span><span class="p">]</span>

  <span class="c1"># Index qualitative variable</span>
  <span class="n">indexer</span> <span class="o">=</span> <span class="n">StringIndexer</span><span class="p">(</span><span class="n">inputCol</span> <span class="o">=</span> <span class="s2">&quot;Action&quot;</span><span class="p">,</span> <span class="n">outputCol</span> <span class="o">=</span> <span class="s2">&quot;label&quot;</span><span class="p">)</span>

  <span class="c1"># Scale numerical features</span>
  <span class="n">va</span> <span class="o">=</span> <span class="n">VectorAssembler</span><span class="p">(</span><span class="n">inputCols</span> <span class="o">=</span> <span class="n">col_num</span><span class="p">,</span> <span class="n">outputCol</span> <span class="o">=</span> <span class="s2">&quot;numerical_features&quot;</span><span class="p">)</span> 
  <span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">(</span><span class="n">inputCol</span> <span class="o">=</span> <span class="s2">&quot;numerical_features&quot;</span><span class="p">,</span> <span class="n">outputCol</span> <span class="o">=</span> <span class="s2">&quot;features&quot;</span><span class="p">)</span>
  
  <span class="c1"># Apply pipeline </span>
  <span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">indexer</span><span class="p">,</span> <span class="n">va</span><span class="p">,</span> <span class="n">scaler</span><span class="p">])</span>
  <span class="n">final_df</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">)</span> 
  
  <span class="c1"># Convert to RDD</span>
  <span class="n">final_rdd</span> <span class="o">=</span> <span class="n">final_df</span><span class="o">.</span><span class="n">rdd</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="nb">tuple</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">int</span><span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">])))</span>
  
  <span class="k">if</span> <span class="n">train_test_split</span><span class="p">:</span>
    <span class="n">train_rdd</span><span class="p">,</span> <span class="n">test_rdd</span> <span class="o">=</span> <span class="n">final_rdd</span><span class="o">.</span><span class="n">randomSplit</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="n">seed</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">final_rdd</span> <span class="o">=</span> <span class="p">(</span><span class="n">train_rdd</span><span class="p">,</span> <span class="n">test_rdd</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">final_rdd</span>
</pre></div>
</div>
</div>
</div>
<p>** RDD partition **</p>
<p>Below, we provide a function that partitions an RDD. We will use it to
distribute data between ensemble members.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_partitioned_rdd</span><span class="p">(</span><span class="n">input_rdd</span><span class="p">,</span> <span class="n">partition_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Partition RDD </span>
<span class="sd">  </span>
<span class="sd">  Args:</span>
<span class="sd">    input_rdd: RDD to be partitioned</span>
<span class="sd">  </span>
<span class="sd">  Returns:</span>
<span class="sd">    Partitioned RDD</span>
<span class="sd">  &quot;&quot;&quot;</span>
  
  <span class="k">return</span> <span class="n">input_rdd</span><span class="o">.</span><span class="n">mapPartitions</span><span class="p">(</span><span class="k">lambda</span> <span class="n">partition</span><span class="p">:</span> <span class="n">partition_all</span><span class="p">(</span><span class="n">partition_size</span><span class="p">,</span> <span class="n">partition</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="distributed-ensemble-of-neural-networks">
<h2>Distributed ensemble of neural networks<a class="headerlink" href="#distributed-ensemble-of-neural-networks" title="Permalink to this headline">Â¶</a></h2>
<p><strong>PyTorch Model</strong></p>
<p>To implement the ensemble members, we first write an ordinary
feedforward (MLP) neural network class using PyTorch, which has a
Softmax output and Tanh activation functions. The number of layers and
neurons in each layer is passed as an argument to the constructor of
this class. Moreover, any instance of this network class (parameters and
structure) can be easily stored in and loaded from a state dictionary
(state_dict) object.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#Feedforward network for classification</span>
<span class="k">class</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">shape</span><span class="p">):</span>
    <span class="c1">#shape: number of neurons in each layer (including the input and output layers)</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MLP</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    
    <span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]))</span>
    
    <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="o">=</span><span class="n">shape</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_nlayers</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
  
  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
    
    <span class="n">y</span><span class="o">=</span><span class="n">x</span>
    
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">):</span>
      <span class="k">if</span> <span class="n">i</span><span class="o">&lt;</span><span class="bp">self</span><span class="o">.</span><span class="n">_nlayers</span><span class="o">-</span><span class="mi">2</span><span class="p">:</span>
        <span class="n">y</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">layer</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">y</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">layer</span><span class="p">(</span><span class="n">y</span><span class="p">),</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">y</span>
  
  <span class="c1">#constructing an instance of this class based on a state dictionary (network parameters)</span>
  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">from_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">):</span>
    <span class="n">net_shape</span> <span class="o">=</span> <span class="n">MLP</span><span class="o">.</span><span class="n">shape_from_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
    <span class="n">net</span><span class="o">=</span><span class="n">MLP</span><span class="p">(</span><span class="n">net_shape</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">net</span>

  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">shape_from_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Infer MLP layer shapes from state_dict&quot;&quot;&quot;</span>
    <span class="n">iter_</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">input_size</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">iter_</span><span class="p">)</span>
    <span class="n">bias_tensors</span> <span class="o">=</span> <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">key_val</span><span class="p">:</span> <span class="n">key_val</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;bias&quot;</span><span class="p">)</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">iter_</span><span class="p">)</span>
    <span class="n">shapes</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">key_val</span><span class="p">:</span> <span class="n">key_val</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">bias_tensors</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">cons</span><span class="p">(</span><span class="n">input_size</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">shapes</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Functions for training and testing networks</strong></p>
<p>Here we have some functions that are used to train/test each individual
network in the ensemble. The <em>Train</em> function takes the initial weights
of a network, trains it on a set of input-taraget data based on
stochastic gradient optimization and cross-entropy loss, and returns the
state dictionary of the trained network. PyTorchâ€™s backpropagation and
optimization tools are used to implement this function as usual. The
<em>Predict</em> function simply takes the state dictionary corresponding to a
network as well as a data point (or batch of data), and returns the
output (probabilities) of the network at that point.</p>
<p>We note that Spark can automatically distribute these functions on the
nodes, and thus writing them for a distributed ensemble is not basically
different from a local setup.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#utility class for pytorch data loader</span>
<span class="k">class</span> <span class="nc">DataSet</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>

  <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

  <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ind</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>

<span class="c1">#The main training function (is run on worker nodes)</span>
<span class="k">def</span> <span class="nf">Train</span><span class="p">(</span><span class="n">net_params</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
  <span class="c1">#net_params: initial parameters of the feedforward network (state dictionary) </span>
  <span class="c1">#x,y: training data (pytorch tensors)</span>

  <span class="n">n_epochs</span><span class="o">=</span><span class="mi">100</span>
  <span class="n">batchsize</span><span class="o">=</span><span class="mi">10</span>
  
  <span class="n">net</span><span class="o">=</span><span class="n">MLP</span><span class="o">.</span><span class="n">from_state_dict</span><span class="p">(</span><span class="n">net_params</span><span class="p">)</span>
  
  <span class="n">train_data</span> <span class="o">=</span> <span class="n">DataSet</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
  <span class="n">dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batchsize</span><span class="p">)</span>
  
  <span class="n">opt</span><span class="o">=</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
  <span class="n">loss</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
      
      <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
      
      <span class="n">xb</span><span class="p">,</span><span class="n">yb</span><span class="o">=</span><span class="n">batch</span>
      
      <span class="n">yhat</span><span class="o">=</span><span class="n">net</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span>
      <span class="n">err</span><span class="o">=</span><span class="n">loss</span><span class="p">(</span><span class="n">yhat</span><span class="p">,</span><span class="n">yb</span><span class="p">)</span>
      <span class="n">err</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
  
      <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
  
  <span class="n">err</span><span class="o">=</span><span class="n">loss</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="n">y</span><span class="p">)</span>
  <span class="n">lossval</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">err</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
  
  <span class="c1">#returns parameters of the trained network and loss</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span><span class="n">lossval</span><span class="p">)</span>

<span class="c1">#Get the output of a feedforward network given an input tensor</span>
<span class="k">def</span> <span class="nf">Predict</span><span class="p">(</span><span class="n">net_params</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
  <span class="c1">#net_params: parameters (state dictionary) of the network</span>
  <span class="c1">#x: input (pytorch tensor)</span>
  <span class="n">net</span> <span class="o">=</span> <span class="n">MLP</span><span class="o">.</span><span class="n">from_state_dict</span><span class="p">(</span><span class="n">net_params</span><span class="p">)</span>
  <span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
  <span class="k">return</span> <span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1">#Reshaping and converting the tuples stored in a dataset RDD into input and target tensors</span>
<span class="k">def</span> <span class="nf">Totensor</span><span class="p">(</span><span class="n">d</span><span class="p">):</span>
  <span class="c1">#d: the dataset (list of tuples)</span>
  
  <span class="n">x</span><span class="o">=</span><span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">d</span><span class="p">]</span>
  <span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">d</span><span class="p">]</span>
  <span class="n">x</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
  <span class="n">y</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
  
  <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">make_prediction</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">Predict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Creating an ensemble of networks, and training them in parallel</strong></p>
<p>We now use the class and functions defined above to create an ensemble
of feedforward neural networks, and train it in a distributed fashion,
where each network is trained on a single worker independently from the
other ones. Firstly, several networks are initialized using the MLP
class with a random number of hidden layers and neurons, and random
initial weights. Using randomness helps to increase the diversity in the
ensemble (without which, the outputs of ensemble members could get
correlated with each other).</p>
<p>As mentioned before, the training data is partioned into equal size
parts, and each of the networks in the ensemble is assigned one part.
Since the dataset is assumed to be an RDD (to let it be huge), an
iterator object is needed which collects one part of the data RDD
(transfers it from the cloud to the driver node) in each call. Note that
we here implicitly assume that each part of the data (but not the whole
dataset) fits into the memory of a single machine.</p>
<p>After constructing the network object and loading data for each member
of the ensemble, the state dictionary of the network and its
corresponding training data are packed into a tuple, and appended to a
list. The list of state_dict/data tuples is then parallelized to obtain
an Spark RDD. We found out that it is difficult to directly put the
PyTorch neural network objects in an RDD, apparently becasue Spark does
not know by default how to encode these objects and transfer them
between nodes. Therefore, we use the state dictionary instead, which
contains all the necessary information about a network.</p>
<p>Finally, the network training function (<em>Train</em> defined above) is
applied to each element of the model/data RDD, in the form of a <em>map</em>
operation. This tells Spark to run the function on each element in
parallel (on worker machines) independently.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_ensemble</span><span class="p">(</span><span class="n">n_models</span><span class="p">,</span> <span class="n">inputdims</span><span class="p">,</span> <span class="n">nclasses</span><span class="p">,</span> <span class="n">max_layers</span><span class="p">,</span> <span class="n">min_neurons</span><span class="p">,</span> <span class="n">max_neurons</span><span class="p">,</span> <span class="n">data_iterator</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Constructing and training a distributed ensemble of feedforward networks</span>
<span class="sd">  </span>
<span class="sd">    Args:</span>
<span class="sd">      n_models: number of the ensemble memebrs</span>
<span class="sd">      inputdims: number of features dimesnions</span>
<span class="sd">      nclasses: number of the classes</span>
<span class="sd">      max_layers: maximum allowed number of hidden layers for the networks</span>
<span class="sd">      min_neurons,max_neurons: the valid range for the number of neurons in each hidden layer</span>
<span class="sd">      data_iterator: a Python iterator over the parts of the training data (one part per each member of the ensemble)</span>

<span class="sd">    Returns: a list of state dictionaries of the trained networks</span>
<span class="sd">  &quot;&quot;&quot;</span>
  
  <span class="c1"># initialization</span>
  <span class="n">model_data</span><span class="o">=</span><span class="p">[]</span> <span class="c1"># pairs of model parameters and their training data</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_models</span><span class="p">):</span>
    <span class="c1"># pick random number of hidden layers and neurons for each network</span>
    <span class="n">nhidden</span><span class="o">=</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_layers</span><span class="p">)</span>
    <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">inputdims</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nhidden</span><span class="p">):</span>
      <span class="n">shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">min_neurons</span><span class="p">,</span> <span class="n">max_neurons</span><span class="p">))</span>
    <span class="n">shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nclasses</span><span class="p">)</span>
    
    <span class="n">net</span><span class="o">=</span><span class="n">MLP</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    
    <span class="c1">#fetch the next part of data</span>
    <span class="n">d</span><span class="o">=</span><span class="nb">next</span><span class="p">(</span><span class="n">data_iterator</span><span class="p">)</span>
    <span class="n">x</span><span class="o">=</span><span class="n">d</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">y</span><span class="o">=</span><span class="n">d</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
  
    <span class="n">model_data</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">))</span>

  <span class="c1"># distribute the array</span>
  <span class="n">model_data_par</span><span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">model_data</span><span class="p">)</span>
  <span class="c1"># execute the train function on the worker nodes</span>
  <span class="n">models_trained</span> <span class="o">=</span> <span class="n">model_data_par</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">Train</span><span class="p">(</span><span class="o">*</span><span class="n">t</span><span class="p">))</span>
  
  <span class="c1">#transfer the trained models and loss values to the driver</span>
  <span class="n">models_trained</span><span class="o">=</span><span class="n">models_trained</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
  
  <span class="c1">#print the training loss values</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;training losses:&quot;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">([</span><span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">models_trained</span><span class="p">])</span>

  <span class="c1"># return the state dicts</span>
  <span class="k">return</span> <span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">models_trained</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>** Utility functions for saving and loading the ensemble model from
the disk **</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">save_models_distr</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">dir_</span><span class="p">,</span> <span class="n">model_names</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="n">dir_</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">dir_</span><span class="p">)</span>
  <span class="n">dir_</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  
  <span class="k">if</span> <span class="n">model_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">model_names</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;m</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">.pt&quot;</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">models</span><span class="o">.</span><span class="n">count</span><span class="p">())]</span>
  <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">model_names</span><span class="p">)</span> <span class="o">==</span> <span class="n">models</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
  <span class="n">model_paths</span> <span class="o">=</span> <span class="p">[</span><span class="n">dir_</span> <span class="o">/</span> <span class="n">model_name</span> <span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">model_names</span><span class="p">]</span>
  <span class="n">model_paths</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">model_paths</span><span class="p">)</span>
  <span class="n">models</span><span class="o">.</span><span class="n">zip</span><span class="p">(</span><span class="n">model_paths</span><span class="p">)</span><span class="o">.</span><span class="n">foreach</span><span class="p">(</span><span class="k">lambda</span> <span class="n">dict_and_path</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="o">*</span><span class="n">dict_and_path</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">save_models</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">dir_</span><span class="p">,</span> <span class="n">model_names</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="n">dir_</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">dir_</span><span class="p">)</span>
  <span class="n">dir_</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  
  <span class="k">if</span> <span class="n">model_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">model_names</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;m</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">.pt&quot;</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">models</span><span class="p">))]</span>
  <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">model_names</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">models</span><span class="p">)</span>
  <span class="n">model_paths</span> <span class="o">=</span> <span class="p">[</span><span class="n">dir_</span> <span class="o">/</span> <span class="n">model_name</span> <span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">model_names</span><span class="p">]</span>
  <span class="k">for</span> <span class="n">state_dict</span><span class="p">,</span> <span class="n">path</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">model_paths</span><span class="p">):</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>
  
<span class="k">def</span> <span class="nf">load_models</span><span class="p">(</span><span class="n">model_names</span><span class="p">,</span> <span class="n">dir_</span><span class="p">):</span>
  <span class="n">dir_</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">dir_</span><span class="p">)</span>
  <span class="n">model_paths</span> <span class="o">=</span> <span class="p">[</span><span class="n">dir_</span> <span class="o">/</span> <span class="n">model_name</span> <span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">model_names</span><span class="p">]</span>
  <span class="n">state_dicts</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">model_paths</span><span class="p">]</span>
  <span class="k">return</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">state_dicts</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="distributed-ensembles-prediction-api">
<h1>Distributed ensembles prediction API<a class="headerlink" href="#distributed-ensembles-prediction-api" title="Permalink to this headline">Â¶</a></h1>
<p>From the training process we get a distributed iterator <code class="docutils literal notranslate"><span class="pre">models</span></code> over
the trained models. (NB. the <code class="docutils literal notranslate"><span class="pre">train_ensemble</span></code> function actually collects
the trained models for convenience.) Internally this is an iterator over
<code class="docutils literal notranslate"><span class="pre">torch.state_dicts</span></code> holding the paramâ€™s of each model respectively.</p>
<p>There are different ways in which we can do predictions:</p>
<ul class="simple">
<li><p>Distributed predictions with <code class="docutils literal notranslate"><span class="pre">ens_preds(models,</span> <span class="pre">test_x)</span></code>, which maps
the combined model and test data to predictions for each data point.
This iterator can be collected to a list of the predictions for each
ensemble member, or further processed in a distributed and
functional manner. This is the most flexible variant since it
preserves the prediction of every member on every datapoint. It is
also the most expensive (if we do collect all the data).</p></li>
<li><p>Reduced/aggregated predictions with
<code class="docutils literal notranslate"><span class="pre">ens_preds_reduced(models,</span> <span class="pre">test_x,</span> <span class="pre">red_fn)</span></code>. Working with an
ensemble, we are often concerned with some aggregate of the membersâ€™
predictions, eg., the average prediction. For this we provide an
reducing version of <code class="docutils literal notranslate"><span class="pre">ens_preds</span></code> where the user need only supply the
reduce function <code class="docutils literal notranslate"><span class="pre">red_fn</span></code>, describing how to combine the predictions
of two ensemble members. For instance, if you would like to get the
average probability vector of a classifier ensemble for every data
point you would use:
<code class="docutils literal notranslate"><span class="pre">python</span>&#160;&#160; <span class="pre">avg_prob_vecs</span> <span class="pre">=</span> <span class="pre">ens_preds_reduced(models,</span> <span class="pre">x,</span> <span class="pre">lambda</span> <span class="pre">x,</span> <span class="pre">y:</span> <span class="pre">(x+y)/2)</span></code>
Internally, this simply calls <code class="docutils literal notranslate"><span class="pre">.reduce(red_fn)</span></code> on the iterator
returned from <code class="docutils literal notranslate"><span class="pre">ens_preds</span></code>. This is merely a convenience function.</p></li>
<li><p>Metrics per ensemble member. If the number of test samples is large,
we will collect a lot of predictions over the cluster. If we know
that we only want an aggregate metric for each member across the
whole test data, we use the <code class="docutils literal notranslate"><span class="pre">ens_metrics</span></code> method for aggregation on
the worker nodes.
<code class="docutils literal notranslate"><span class="pre">python</span>&#160;&#160; <span class="pre">avg_acc_per_member</span> <span class="pre">=</span> <span class="pre">ens_metrics(models,</span> <span class="pre">test_input,</span> <span class="pre">test_true_labels,</span> <span class="pre">&lt;list</span> <span class="pre">of</span> <span class="pre">metric</span> <span class="pre">functions&gt;)</span></code>
Note that each metric function must be on the form: f: R^(N x D_x)
x R^(N) â€“&gt; T</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ens_preds</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">test_x</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Distributed ensemble predictions</span>
<span class="sd">  Takes a set of models and test data and makes distributed predictions</span>
<span class="sd">  Let N := number of data points and D_x := the dimension of a single datapoint x</span>
<span class="sd">  </span>
<span class="sd">  Args:</span>
<span class="sd">    models (list[state_dict]): set of models represented as a list (state_dict, shape)</span>
<span class="sd">    test_x (torch.Tensor): Tensor of size (N, D_x)</span>
<span class="sd">  </span>
<span class="sd">  Returns:</span>
<span class="sd">    Distributed iterator over the predictions. E.g. an iterator over probability vectors in the case of a classifier ens.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">pred_iter</span> <span class="o">=</span> <span class="n">_pred_models_iter</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">test_x</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">pred_iter</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">Predict</span><span class="p">(</span><span class="o">*</span><span class="n">t</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">ens_preds_reduced</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">test_x</span><span class="p">,</span> <span class="n">red_fn</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Reduced/aggregated ensemble predictions</span>
<span class="sd">  Takes a set of models and test data and makes distributed predictions and reduces them with a provided `red_fn`</span>
<span class="sd">  Let N := number of data points and D_x := the dimension of a single datapoint x</span>
<span class="sd">  </span>
<span class="sd">  Args:</span>
<span class="sd">    models (list[state_dict]): set of models represented as a list (state_dict, shape)</span>
<span class="sd">    test_x (torch.Tensor): Tensor of size (N, D_x)</span>
<span class="sd">    red_fn function: f: R^D_x x R^D_x --&gt; R^D_x</span>
<span class="sd">  </span>
<span class="sd">  Returns:</span>
<span class="sd">    Single reduced/aggregated prediction of the whole ensemble</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="n">ens_preds</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">test_x</span><span class="p">)</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">red_fn</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">ens_metrics</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span><span class="p">,</span> <span class="n">metrics</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Distributed ensemble metrics</span>
<span class="sd">  Takes a set of models and test data, predicts probability vectors and calculates the provided metrics</span>
<span class="sd">  given true labels `test_y`</span>
<span class="sd">  Let N := number of data points and D_x := the dimension of a single datapoint x</span>
<span class="sd">  </span>
<span class="sd">  Args:</span>
<span class="sd">    models (list[state_dict]): set of models represented as a list (state_dict, shape)</span>
<span class="sd">    test_x (torch.Tensor): Tensor of size (N, D_x)</span>
<span class="sd">    test_y (torch.Tensor): Tensor of size (N). NB: hard labels</span>
<span class="sd">    metrics (list[functions]): List of functions where each funcion f: R^(N x D_x) x R^(N) --&gt; T, where T is a generic output type.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="n">ens_preds</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">test_x</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">prob_vecs</span><span class="p">:</span> <span class="p">[</span><span class="n">metric</span><span class="p">(</span><span class="n">prob_vecs</span><span class="p">,</span> <span class="n">test_y</span><span class="p">)</span> <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">metrics</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">_pred_models_iter</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">test_x</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Helper function to generate a distributed iterator over models and test data</span>
<span class="sd">  NB: the same `test_x` is given to all elements in the iterator</span>
<span class="sd">  </span>
<span class="sd">  Args:</span>
<span class="sd">    models (list[state_dict]): set of models represented as a list (state_dict, shape)</span>
<span class="sd">    test_x (torch.Tensor): Tensor of size (N, D_x)</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">PipelinedRDD</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">models</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">model</span><span class="p">:</span> <span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_x</span><span class="p">))</span>
  <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
    <span class="n">models_and_data</span> <span class="o">=</span> <span class="p">[(</span><span class="n">params</span><span class="p">,</span> <span class="n">test_x</span><span class="p">)</span> <span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">models</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">models_and_data</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;&#39;models&#39; must be an RDD or a list&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">avg_accuracy</span><span class="p">(</span><span class="n">prob_vecs</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Example metrics function: average accuracy</span>
<span class="sd">  Let N := number of data points and C := the number of classes</span>
<span class="sd">  </span>
<span class="sd">  Args:</span>
<span class="sd">    prob_vecs (torch.Tensor): Tensor of size (N, C)</span>
<span class="sd">    labels (torch.Tensor): Tensor of size (N), hard labels, with classes corresponding to indices 0, ..., C-1</span>
<span class="sd">  </span>
<span class="sd">  Returns:</span>
<span class="sd">    torch.Tensor: Tensor of size (N), average accuracy over all datapoints.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">hard_preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">prob_vecs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">hard_preds</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">entropy</span><span class="p">(</span><span class="n">prob_vecs</span><span class="p">):</span>
  <span class="k">return</span> <span class="o">-</span> <span class="p">(</span><span class="n">prob_vecs</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">prob_vecs</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">avg_entropy</span><span class="p">(</span><span class="n">prob_vec_1</span><span class="p">,</span> <span class="n">prob_vec_2</span><span class="p">):</span>
  <span class="n">e_1</span> <span class="o">=</span> <span class="n">entropy</span><span class="p">(</span><span class="n">prob_vec_1</span><span class="p">)</span>
  <span class="n">e_2</span> <span class="o">=</span> <span class="n">entropy</span><span class="p">(</span><span class="n">prob_vec_2</span><span class="p">)</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">e_1</span> <span class="o">+</span> <span class="n">e_2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="application-example-distributed-predictions">
<h1>Application example: Distributed predictions<a class="headerlink" href="#application-example-distributed-predictions" title="Permalink to this headline">Â¶</a></h1>
<p>Letâ€™s first demonstrate our distributed ensembles with a simple toy
example. Weâ€™ll create gaussian toy data with three slightly overlapping
clusters:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)])</span>
<span class="n">variances</span> <span class="o">=</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">num_observations</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">class_proportions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">3</span><span class="p">])</span>
<span class="n">data_train</span><span class="p">,</span> <span class="n">data_test</span> <span class="o">=</span> <span class="n">create_gaussian_RDD</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="n">variances</span><span class="p">,</span> <span class="n">num_observations</span><span class="p">,</span> <span class="n">class_proportions</span><span class="p">,</span> <span class="n">train_test_split</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now weâ€™ll create and distributedly train a classifier ensemble and save
it to file. This is not necessary, we can â€“ in fact â€“ make predictions
with the trained ensemble without ever collecting it from the worker
nodes, but in most use cases it will be convenient to save the ensemble
on disk.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data_iterator</span><span class="o">=</span><span class="n">get_partitioned_rdd</span><span class="p">(</span><span class="n">data_train</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">Totensor</span><span class="p">)</span><span class="o">.</span><span class="n">toLocalIterator</span><span class="p">()</span>
<span class="n">n_models</span><span class="o">=</span><span class="mi">5</span> <span class="c1"># ensemble size</span>
<span class="n">inputdims</span><span class="o">=</span><span class="mi">2</span> <span class="c1"># features dimensions</span>
<span class="n">nclasses</span><span class="o">=</span><span class="mi">3</span> <span class="c1"># number of classes</span>
<span class="n">max_layers</span><span class="o">=</span><span class="mi">2</span>
<span class="n">min_neurons</span><span class="o">=</span><span class="mi">2</span>
<span class="n">max_neurons</span><span class="o">=</span><span class="mi">5</span>

<span class="n">models_trained</span> <span class="o">=</span> <span class="n">train_ensemble</span><span class="p">(</span><span class="n">n_models</span><span class="p">,</span> <span class="n">inputdims</span><span class="p">,</span> <span class="n">nclasses</span><span class="p">,</span> <span class="n">max_layers</span><span class="p">,</span> <span class="n">min_neurons</span><span class="p">,</span> <span class="n">max_neurons</span><span class="p">,</span> <span class="n">data_iterator</span><span class="p">)</span>
<span class="n">saved_models_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;saved_models/gaussian&quot;</span><span class="p">)</span>
<span class="n">save_models</span><span class="p">(</span><span class="n">models_trained</span><span class="p">,</span> <span class="n">saved_models_dir</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>training losses:
[0.6597320437431335, 0.6314507126808167, 0.6506103277206421, 0.6424266695976257, 0.657072901725769]
</pre></div>
</div>
</div>
</div>
<div class="section" id="making-distributed-predictions">
<h2>Making distributed predictions<a class="headerlink" href="#making-distributed-predictions" title="Permalink to this headline">Â¶</a></h2>
<p>With the trained ensemble we can make predictions and calculate metrics,
all in a distributed manner.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">test_xx</span><span class="p">,</span> <span class="n">test_yy</span> <span class="o">=</span> <span class="n">Totensor</span><span class="p">(</span><span class="n">data_test</span><span class="o">.</span><span class="n">collect</span><span class="p">())</span>
<span class="n">model_names</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;m</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">.pt&quot;</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_models</span><span class="p">)]</span>
<span class="n">models</span> <span class="o">=</span> <span class="n">load_models</span><span class="p">(</span><span class="n">model_names</span><span class="p">,</span> <span class="n">saved_models_dir</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="n">avg_prob_vecs</span> <span class="o">=</span> <span class="n">ens_preds_reduced</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">test_xx</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># (A single) Average prob. vec for all data points.</span>
<span class="n">avg_acc</span> <span class="o">=</span> <span class="n">ens_metrics</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">test_xx</span><span class="p">,</span> <span class="n">test_yy</span><span class="p">,</span> <span class="p">[</span><span class="n">avg_accuracy</span><span class="p">])</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span> <span class="c1"># Average acc. for each ens. over all data points</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Average accuracy for each ensemble member: </span><span class="si">{</span><span class="p">[</span><span class="n">acc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">acc</span> <span class="ow">in</span> <span class="n">avg_acc</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Average accuracy for the whole ensemble: </span><span class="si">{</span><span class="n">avg_accuracy</span><span class="p">(</span><span class="n">avg_prob_vecs</span><span class="p">,</span> <span class="n">test_yy</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Average accuracy for each ensemble member: [0.9240759015083313, 0.9240759015083313, 0.9160839319229126, 0.9110888838768005, 0.9220778942108154]
Average accuracy for the whole ensemble: 0.9210789203643799
</pre></div>
</div>
</div>
</div>
<p>We can also make use of the uncertainty description provided by the
ensemble. Weâ€™ll plot the test data, each point coloured the predicted
distribution, which will illustrate the certain predictions with
distinct colur and uncertain with muddied colours.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">preds</span> <span class="o">=</span> <span class="n">avg_prob_vecs</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">hard_preds</span> <span class="o">=</span> <span class="n">avg_prob_vecs</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">every_nth</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">train_xx</span><span class="p">,</span> <span class="n">train_yy</span> <span class="o">=</span> <span class="n">Totensor</span><span class="p">(</span><span class="n">data_train</span><span class="o">.</span><span class="n">collect</span><span class="p">())</span>

<span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax_1</span><span class="p">,</span> <span class="n">ax_2</span><span class="p">))</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="c1"># For the train data we use the true labels to simulate a completely certain prediction.</span>
<span class="n">color_map</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span> <span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="mi">2</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]}</span>
<span class="n">ax_1</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">train_xx</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">train_xx</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="p">[</span><span class="n">color_map</span><span class="p">[</span><span class="n">class_</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span> <span class="k">for</span> <span class="n">class_</span> <span class="ow">in</span> <span class="n">train_yy</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Train&quot;</span><span class="p">)</span>
<span class="n">ax_2</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">test_xx</span><span class="p">[::</span><span class="n">every_nth</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">test_xx</span><span class="p">[::</span><span class="n">every_nth</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">preds</span><span class="p">[::</span><span class="n">every_nth</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Test&quot;</span><span class="p">)</span>
<span class="n">ax_1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Train&quot;</span><span class="p">)</span>
<span class="n">ax_2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Test&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="application-example-out-of-distribution-detection">
<h1>Application example: Out of distribution detection<a class="headerlink" href="#application-example-out-of-distribution-detection" title="Permalink to this headline">Â¶</a></h1>
<p>Our distributed ensemble can be used for out of distribution (OOD)
detection. A simple way is to measure the entropy of the combined
ensemble prediction; high entropy signals weird data, not seen in the
training distribution.</p>
<p>â€œReal worldâ€ out of distribution data can be hard to come by, but a
typical example would be images in different contexts. E.g. scenic
vistas or pathology scans may share the same feature space but have very
different distribution. For the data we have collected, no such OOD set
exists, so we will showcase it with an OOD set of gaussian noise. Of
course, noise that is very far from the in distribution (ID) data will
saturate the classifiers softmax for one element, actually yielding very
confident, low entropy, nonsense predictions.</p>
<p>Regardless, letâ€™s see how to do this with the distributed ensemble.
First, we train it and again, save the trained parameters to file</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data_train</span><span class="p">,</span> <span class="n">data_test</span> <span class="o">=</span> <span class="n">load_firewall_data</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">data_iterator</span><span class="o">=</span><span class="n">get_partitioned_rdd</span><span class="p">(</span><span class="n">data_train</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">Totensor</span><span class="p">)</span><span class="o">.</span><span class="n">toLocalIterator</span><span class="p">()</span>

<span class="n">n_models</span><span class="o">=</span><span class="mi">10</span>
<span class="n">models_trained</span><span class="o">=</span><span class="n">train_ensemble</span><span class="p">(</span><span class="n">n_models</span><span class="p">,</span>
                              <span class="n">inputdims</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span>
                              <span class="n">nclasses</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                              <span class="n">max_layers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                              <span class="n">min_neurons</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                              <span class="n">max_neurons</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
                              <span class="n">data_iterator</span><span class="o">=</span><span class="n">data_iterator</span><span class="p">)</span> 
<span class="n">saved_models_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;saved_models/firewall&quot;</span><span class="p">)</span>
<span class="n">save_models</span><span class="p">(</span><span class="n">models_trained</span><span class="p">,</span> <span class="n">saved_models_dir</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>training losses:
[0.7487057447433472, 0.750811755657196, 0.7578539252281189, 0.7506877183914185, 0.7623474597930908, 0.7521470785140991, 0.7517384886741638, 0.7481321692466736, 0.750828742980957, 0.7547193765640259]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gen_ood_data</span><span class="p">(</span><span class="n">test_x</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">):</span>
  <span class="n">num_test_samples</span><span class="p">,</span> <span class="n">dim_x</span> <span class="o">=</span> <span class="n">test_x</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
  <span class="n">random_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">dim_x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim_x</span><span class="p">)</span>
  <span class="n">random_cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">dim_x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim_x</span><span class="p">)</span> <span class="o">*</span> <span class="mi">10</span>
  <span class="n">ood_x</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">Totensor</span><span class="p">(</span><span class="n">create_gaussian_RDD</span><span class="p">(</span><span class="n">random_mean</span><span class="p">,</span> <span class="n">random_cov</span><span class="p">,</span> <span class="n">num_test_samples</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]),</span> <span class="n">train_test_split</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">())</span>
  <span class="k">return</span> <span class="n">ood_x</span>

  
<span class="n">data</span> <span class="o">=</span> <span class="n">data_test</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="n">batch</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">batch_size</span><span class="p">]</span>
<span class="n">test_xx</span><span class="p">,</span> <span class="n">test_yy</span> <span class="o">=</span> <span class="n">Totensor</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
<span class="n">ood_x</span> <span class="o">=</span> <span class="n">gen_ood_data</span><span class="p">(</span><span class="n">test_xx</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>

<span class="n">models_p</span> <span class="o">=</span> <span class="n">load_models</span><span class="p">(</span><span class="n">model_names</span><span class="p">,</span> <span class="n">saved_models_dir</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>

<span class="c1"># We can either calculate the average entropy of the ensemble members</span>
<span class="n">avg_entropy_id</span> <span class="o">=</span> <span class="n">ens_preds</span><span class="p">(</span><span class="n">models_p</span><span class="p">,</span> <span class="n">test_xx</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">entropy</span><span class="p">)</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">avg_entropy_ood</span> <span class="o">=</span> <span class="n">ens_preds</span><span class="p">(</span><span class="n">models_p</span><span class="p">,</span> <span class="n">ood_x</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">entropy</span><span class="p">)</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="c1"># ... or we the entropy of the average ensemble prediction.</span>
<span class="n">entropy_avg_id</span> <span class="o">=</span> <span class="n">entropy</span><span class="p">(</span><span class="n">ens_preds_reduced</span><span class="p">(</span><span class="n">models_p</span><span class="p">,</span> <span class="n">test_xx</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">entropy_avg_ood</span> <span class="o">=</span> <span class="n">entropy</span><span class="p">(</span><span class="n">ens_preds_reduced</span><span class="p">(</span><span class="n">models_p</span><span class="p">,</span> <span class="n">ood_x</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="c1"># Set entropy measure</span>
<span class="n">entropy_id</span> <span class="o">=</span> <span class="n">avg_entropy_id</span>
<span class="n">entropy_ood</span> <span class="o">=</span> <span class="n">avg_entropy_ood</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Comparison of the entropy of the ensemble classifier on
in-distribution and OOD data</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">entropy_hist</span><span class="p">(</span><span class="n">id_</span><span class="p">,</span> <span class="n">ood</span><span class="p">,</span> <span class="n">n_bins</span><span class="p">,</span> <span class="n">upper_x_bound</span><span class="p">):</span>
  <span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax_1</span><span class="p">,</span> <span class="n">ax_2</span><span class="p">))</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">_plot_hist</span><span class="p">(</span><span class="n">ax_1</span><span class="p">,</span> <span class="n">id_</span><span class="p">,</span> <span class="n">n_bins</span><span class="p">,</span> <span class="s2">&quot;ID&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="n">upper_x_bound</span><span class="p">)</span>
  <span class="n">_plot_hist</span><span class="p">(</span><span class="n">ax_2</span><span class="p">,</span> <span class="n">ood</span><span class="p">,</span> <span class="n">n_bins</span><span class="p">,</span> <span class="s2">&quot;OOD&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">upper_x_bound</span><span class="p">)</span>
  <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Entropy histogram&quot;</span><span class="p">)</span>
  <span class="n">ax_2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;entropy&quot;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">_plot_hist</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">counts</span><span class="p">,</span> <span class="n">n_bins</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">color</span><span class="p">,</span> <span class="n">upper_x_bound</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">n_bins</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xbound</span><span class="p">(</span><span class="n">lower</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">upper</span> <span class="o">=</span> <span class="n">upper_x_bound</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;rel freq&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
  
<span class="n">n_bins</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">entropy_bound</span> <span class="o">=</span> <span class="mf">0.15</span>
<span class="n">entropy_hist</span><span class="p">(</span><span class="n">entropy_id</span><span class="p">,</span> <span class="n">entropy_ood</span><span class="p">,</span> <span class="n">n_bins</span><span class="p">,</span> <span class="n">entropy_bound</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Evaluation of the OOD detection in terms of ROC curve and area under
this curve (AUROC)</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">is_ood</span><span class="p">(</span><span class="n">entropies</span><span class="p">,</span> <span class="n">cut_off_entropy</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">entropies</span> <span class="o">&gt;</span> <span class="n">cut_off_entropy</span>

<span class="k">def</span> <span class="nf">fpr_and_tpr</span><span class="p">(</span><span class="n">id_</span><span class="p">,</span> <span class="n">ood</span><span class="p">,</span> <span class="n">res</span><span class="p">):</span>
  <span class="n">max_entropy</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">id_</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">ood</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
  <span class="c1"># max_entropy = id_.max()</span>
  <span class="n">thresholds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">max_entropy</span><span class="p">,</span> <span class="n">max_entropy</span> <span class="o">/</span> <span class="n">res</span><span class="p">)</span>
  <span class="n">roc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([(</span><span class="n">fpr</span><span class="p">(</span><span class="n">id_</span><span class="p">,</span> <span class="n">th</span><span class="p">),</span> <span class="n">tpr</span><span class="p">(</span><span class="n">ood</span><span class="p">,</span> <span class="n">th</span><span class="p">))</span> <span class="k">for</span> <span class="n">th</span> <span class="ow">in</span> <span class="n">thresholds</span><span class="p">])</span>
  <span class="n">roc</span> <span class="o">=</span> <span class="n">roc</span><span class="p">[</span><span class="n">roc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">argsort</span><span class="p">()]</span>
  <span class="n">fprs</span><span class="p">,</span> <span class="n">tprs</span> <span class="o">=</span> <span class="p">(</span><span class="n">roc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">roc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
  <span class="k">return</span> <span class="n">fprs</span><span class="p">,</span> <span class="n">tprs</span>

<span class="k">def</span> <span class="nf">fpr</span><span class="p">(</span><span class="n">id_</span><span class="p">,</span> <span class="n">th</span><span class="p">):</span>
  <span class="n">id_pred</span> <span class="o">=</span> <span class="n">is_ood</span><span class="p">(</span><span class="n">id_</span><span class="p">,</span> <span class="n">th</span><span class="p">)</span>
  <span class="n">fp</span> <span class="o">=</span> <span class="n">id_pred</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
  <span class="n">tn</span> <span class="o">=</span> <span class="n">id_pred</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">fp</span>
  <span class="k">return</span> <span class="n">fp</span> <span class="o">/</span> <span class="p">(</span><span class="n">tn</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">tpr</span><span class="p">(</span><span class="n">ood</span><span class="p">,</span> <span class="n">th</span><span class="p">):</span>
  <span class="n">ood_pred</span> <span class="o">=</span> <span class="n">is_ood</span><span class="p">(</span><span class="n">ood</span><span class="p">,</span> <span class="n">th</span><span class="p">)</span>
  <span class="n">tp</span> <span class="o">=</span> <span class="n">ood_pred</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
  <span class="n">fn</span> <span class="o">=</span> <span class="n">ood_pred</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">tp</span>
  <span class="k">return</span> <span class="n">tp</span> <span class="o">/</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span>

<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span> <span class="o">=</span> <span class="n">fpr_and_tpr</span><span class="p">(</span><span class="n">avg_entropy_id</span><span class="p">,</span> <span class="n">avg_entropy_ood</span><span class="p">,</span> <span class="n">res</span> <span class="o">=</span> <span class="mi">100</span><span class="p">)</span>
<span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;FPR&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;TPR&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;ROC&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;AUROC: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">trapz</span><span class="p">(</span><span class="n">tpr</span><span class="p">,</span> <span class="n">fpr</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AUROC: 0.6480554090292237
</pre></div>
</div>
</div>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">Â¶</a></h2>
<p>[1] Lakshminarayanan, B., Pritzel, A., &amp; Blundell, C. (2017). Simple
and scalable predictive uncertainty estimation using deep ensembles. In
Advances in neural information processing systems (pp. 6402-6413).</p>
<p>[2] Ovadia, Y., Fertig, E., Ren, J., Nado, Z., Sculley, D., Nowozin,
S., â€¦ &amp; Snoek, J. (2019). Can you trust your modelâ€™s uncertainty?
Evaluating predictive uncertainty under dataset shift. In Advances in
Neural Information Processing Systems (pp. 13991-14002).</p>
<p>[3] Apache Spark. (2021, 01, 11). Classification and Regression
[https://spark.apache.org/docs/latest/ml-classification-regression.html].</p>
<p>[4] Chen, J., Pan, X., Monga, R., Bengio, S., &amp; Jozefowicz, R. (2016).
Revisiting distributed synchronous SGD. arXiv preprint arXiv:1604.00981.</p>
<p>[5] Dua, D. and Graff, C. (2019). UCI Machine Learning Repository
[http://archive.ics.uci.edu/ml]. Irvine, CA: University of California,
School of Information and Computer Science.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./000_0-sds-3-x-projects/student-project-08_group-DistributedEnsemble"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="../student-project-07_group-MathAtKTH/03_graph_string_converter.html" title="previous page">Intro</a>
    <a class='right-next' id="next-link" href="../student-project-09_group-TopicModeling/01_Introduction.html" title="next page">Topic Modeling with SARS-Cov-2 Genome ðŸ§¬</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By ScaDaMaLe Team<br/>
        
            &copy; Copyright 2020 Creative Commons Zero v1.0 Universal.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>
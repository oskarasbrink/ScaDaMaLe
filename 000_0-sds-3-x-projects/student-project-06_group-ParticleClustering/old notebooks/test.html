
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>&lt;no title&gt; &#8212; Scalable Data Science &amp; Distributed Machine Learning</title>
    
  <link rel="stylesheet" href="../../../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
  
  <img src="../../../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Scalable Data Science & Distributed Machine Learning</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/000_ScaDaMaLe.html">
   Introduction
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction to Apache Spark Core
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/001_whySpark.html">
   Why Apache Spark?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html">
   databricks community edition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#essentials-of-databricks-cloud-dbc-in-a-big-hurry">
   Essentials of Databricks Cloud (DBC) in a Big Hurry
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#dbc-essentials-what-is-databricks-cloud">
   DBC Essentials: What is Databricks Cloud?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#dbc-essentials-shard-cluster-notebook-and-dashboard">
   DBC Essentials: Shard, Cluster, Notebook and Dashboard
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#dbc-essentials-team-state-collaboration-elastic-resources">
   DBC Essentials: Team, State, Collaboration, Elastic Resources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#you-should-all-have-databricks-community-edition-account-by-now">
   You Should All Have databricks community edition account by now!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#import-course-content-now">
   Import Course Content Now!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#cloud-free-computing-environment-optional-but-recommended">
   Cloud-free Computing Environment (Optional but recommended)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_01_multiLingualNotebooks.html">
   Notebooks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_01_multiLingualNotebooks.html#further-reference-homework-recurrrent-points-of-reference">
   Further Reference / Homework / Recurrrent Points of Reference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html">
   Introduction to Scala through Scala Notebook
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#scala-in-your-own-computer">
   Scala in your own computer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#scala-resources">
   Scala Resources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#introduction-to-scala">
   Introduction to Scala
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#let-s-get-our-hands-dirty-in-scala">
   Let’s get our hands dirty in Scala
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#scala-types">
   Scala Types
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#expressions">
   Expressions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#blocks">
   Blocks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#functions">
   Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#methods">
   Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#classes">
   Classes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#case-classes">
   Case Classes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#objects">
   Objects
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#traits">
   Traits
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#main-method">
   Main Method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#what-i-try-not-do-while-learning-a-new-language">
   What I try not do while learning a new language?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html">
   Scala Resources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html#let-s-continue-to-get-our-hands-dirty-in-scala">
   Let’s continue to get our hands dirty in Scala
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html#scala-type-hierarchy">
   Scala Type Hierarchy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html#scala-collections">
   Scala Collections
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html#exercise-in-functional-programming">
   Exercise in Functional Programming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html#lazy-evaluation">
   Lazy Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html#recursions">
   Recursions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/004_RDDsTransformationsActions.html">
   Introduction to Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/004_RDDsTransformationsActions.html#spark-cluster-overview">
   Spark Cluster Overview:
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/005_RDDsTransformationsActionsHOMEWORK.html">
   HOMEWORK notebook - RDDs Transformations and Actions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html">
   Piped RDDs and Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#from-a-local-collection">
   From a Local Collection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#glom">
   glom
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#checkpointing">
   Checkpointing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#pipe-rdds-to-system-commands">
   Pipe RDDs to System Commands
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#mappartitions">
   mapPartitions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#foreachpartition">
   foreachPartition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#numerically-rigorous-bayesian-ab-testing">
   Numerically Rigorous Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#usage-instructions-for-isit1or2coins">
   Usage instructions for IsIt1or2Coins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006_WordCount.html">
   Word Count on US State of the Union (SoU) Addresses
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction to Apache Spark SQL
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007_SparkSQLIntroBasics.html">
   Introduction to Spark SQL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007_SparkSQLIntroBasics.html#overview">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007_SparkSQLIntroBasics.html#datasets-and-dataframes">
   Datasets and DataFrames
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007_SparkSQLIntroBasics.html#getting-started-in-spark-2-x">
   Getting Started in Spark 2.x
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007a_SparkSQLProgGuide_HW.html">
   Spark Sql Programming Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007b_SparkSQLProgGuide_HW.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007b_SparkSQLProgGuide_HW.html#id1">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007c_SparkSQLProgGuide_HW.html">
   Getting Started - Exercise
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007d_SparkSQLProgGuide_HW.html">
   Data Sources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007d_SparkSQLProgGuide_HW.html#id1">
   Data Sources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007e_SparkSQLProgGuide_HW.html">
   Performance Tuning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007f_SparkSQLProgGuide_HW.html">
   Distributed SQL Engine
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007f_SparkSQLProgGuide_HW.html#id1">
   Distributed SQL Engine
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html#sql-pivoting-since-spark-2-4">
   SQL Pivoting since Spark 2.4
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html#load-data">
   Load Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-in-sql">
   Pivoting in SQL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-with-multiple-aggregate-expressions">
   Pivoting with Multiple Aggregate Expressions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-with-multiple-grouping-columns">
   Pivoting with Multiple Grouping Columns
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-with-multiple-pivot-columns">
   Pivoting with Multiple Pivot Columns
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html">
   Diamonds ML Pipeline Workflow - DataFrame ETL and EDA Part
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#step-1-load-data-as-dataframe">
   Step 1. Load data as DataFrame
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#step-2-understand-the-data">
   Step 2. Understand the data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#let-us-run-through-some-basic-inteactive-sql-queries-next">
   Let us run through some basic inteactive SQL queries next
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#why-do-we-need-to-know-these-interactive-sql-queries">
   Why do we need to know these interactive SQL queries?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#we-will-continue-later-with-ml-pipelines-to-do-prediction-with-a-fitted-model-from-this-dataset">
   We will continue later with ML pipelines to do prediction with a fitted model from this dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html">
   Power Plant ML Pipeline Application - DataFrame Part
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-1-business-understanding">
   Step 1: Business Understanding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-2-load-your-data">
   Step 2: Load Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#use-this-for-other-smallish-datasets-you-want-to-import-to-your-ce">
   USE THIS FOR OTHER SMALLish DataSets you want to import to your CE
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-3-explore-your-data">
   Step 3: Explore Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-4-visualize-your-data">
   Step 4: Visualize Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/010_wikipediaClickStream_01ETLEDA.html">
   Wiki Clickstream Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/010_wikipediaClickStream_01ETLEDA.html#wikipedia-logo">
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_LoadExtract.html">
   Old Bailey Online Data Analysis in Apache Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_LoadExtract.html#analysing-the-full-old-bailey-online-sessions-papers-dataset">
   Analysing the Full Old Bailey Online Sessions Papers Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html">
   Piped RDDs and Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#from-a-local-collection">
   From a Local Collection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#glom">
   glom
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#checkpointing">
   Checkpointing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#pipe-rdds-to-system-commands">
   Pipe RDDs to System Commands
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#mappartitions">
   mapPartitions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#foreachpartition">
   foreachPartition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#numerically-rigorous-bayesian-ab-testing">
   Numerically Rigorous Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#usage-instructions-for-isit1or2coins">
   Usage instructions for IsIt1or2Coins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#parsing-the-output-from-isit1or2coins">
   Parsing the output from
   <code class="docutils literal notranslate">
    <span class="pre">
     IsIt1or2Coins
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#providing-case-classes-for-input-and-output-for-easy-spark-communication">
   Providing case classes for input and output for easy spark communication
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/035_LDA_CornellMovieDialogs.html">
   Topic Modeling of Movie Dialogs with Latent Dirichlet Allocation
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Distribute Deep Learning with Horovod
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_7-sds-3-x-ddl/00_DDL_Introduction.html">
   Introduction to Distributed Deep Learning (DDL) with Horovod over Tensorflow/keras and Pytorch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_7-sds-3-x-ddl/0x_mnist-tensorflow-keras.html">
   Distributed deep learning training using TensorFlow and Keras with HorovodRunner
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_7-sds-3-x-ddl/0y_mnist-pytorch.html">
   Distributed deep learning training using PyTorch with HorovodRunner for MNIST
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  WASP AI-Track Student Projects
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/035_LDA_CornellMovieDialogs.html">
   Topic Modeling of Movie Dialogs with Latent Dirichlet Allocation
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Voluntary Student Projects
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/030_Spark_GDELT_project.html">
   Plugging into GDELT Streams - TODO - IN PROGRESS
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/030_Spark_GDELT_project.html#this-is-just-dipping-our-pinky-toe-in-this-ocean-of-information">
   This is just dipping our pinky toe in this ocean of information!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/030_Spark_GDELT_project.html#download-from-gdelt-project">
   Download from gdelt-project
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../_sources/000_0-sds-3-x-projects/student-project-06_group-ParticleClustering/old notebooks/test.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://lamastex.github.io/ScaDaMaLe/index.html"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://lamastex.github.io/ScaDaMaLe/index.html/issues/new?title=Issue%20on%20page%20%2F000_0-sds-3-x-projects/student-project-06_group-ParticleClustering/old notebooks/test.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="simple nav section-nav flex-column">
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
<span class="c1">#import org.apache.spark.sql.functions._</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Hello World!&#39;</span><span class="p">)</span>


<span class="c1"># The notebooks are based on code from here:</span>
<span class="c1">#https://docs.databricks.com/applications/machine-learning/train-model/distributed-training/horovod-runner.html</span>
<span class="c1">#https://docs.databricks.com/applications/machine-learning/train-model/distributed-training/mnist-tensorflow-keras.html</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Hello World!
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#old stuff</span>
<span class="c1">#%sh</span>
<span class="c1">#pip install tensorflow==1.15 </span>

<span class="c1">#pip install horovod==0.18.1 --force-reinstall --no-deps --no-cache-dir</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Collecting tensorflow==1.15
  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)
Collecting tensorboard&lt;1.16.0,&gt;=1.15.0
  Using cached tensorboard-1.15.0-py3-none-any.whl (3.8 MB)
Requirement already satisfied: termcolor&gt;=1.1.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (1.1.0)
Requirement already satisfied: wrapt&gt;=1.11.1 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (1.11.2)
Requirement already satisfied: keras-preprocessing&gt;=1.0.5 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (1.1.2)
Requirement already satisfied: astor&gt;=0.6.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (0.8.0)
Requirement already satisfied: numpy&lt;2.0,&gt;=1.16.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (1.18.1)
Requirement already satisfied: opt-einsum&gt;=2.3.2 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (3.3.0)
Processing /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3/gast-0.2.2-py3-none-any.whl
Requirement already satisfied: six&gt;=1.10.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (1.14.0)
Requirement already satisfied: protobuf&gt;=3.6.1 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (3.11.4)
Requirement already satisfied: grpcio&gt;=1.8.6 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (1.27.2)
Collecting tensorflow-estimator==1.15.1
  Using cached tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)
Collecting keras-applications&gt;=1.0.8
  Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)
Requirement already satisfied: google-pasta&gt;=0.1.6 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (0.2.0)
Requirement already satisfied: absl-py&gt;=0.7.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (0.9.0)
Requirement already satisfied: wheel&gt;=0.26 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (0.34.2)
Requirement already satisfied: markdown&gt;=2.6.8 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorboard&lt;1.16.0,&gt;=1.15.0-&gt;tensorflow==1.15) (3.1.1)
Requirement already satisfied: setuptools&gt;=41.0.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorboard&lt;1.16.0,&gt;=1.15.0-&gt;tensorflow==1.15) (45.2.0.post20200210)
Requirement already satisfied: werkzeug&gt;=0.11.15 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorboard&lt;1.16.0,&gt;=1.15.0-&gt;tensorflow==1.15) (1.0.0)
Requirement already satisfied: h5py in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from keras-applications&gt;=1.0.8-&gt;tensorflow==1.15) (2.10.0)
ERROR: spark-tensorflow-distributor 0.1.0 has requirement tensorflow&gt;=2.1.0, but you&#39;ll have tensorflow 1.15.0 which is incompatible.
Installing collected packages: tensorboard, gast, tensorflow-estimator, keras-applications, tensorflow
  Attempting uninstall: tensorboard
    Found existing installation: tensorboard 2.3.0
    Uninstalling tensorboard-2.3.0:
      Successfully uninstalled tensorboard-2.3.0
  Attempting uninstall: gast
    Found existing installation: gast 0.3.3
    Uninstalling gast-0.3.3:
      Successfully uninstalled gast-0.3.3
  Attempting uninstall: tensorflow-estimator
    Found existing installation: tensorflow-estimator 2.3.0
    Uninstalling tensorflow-estimator-2.3.0:
      Successfully uninstalled tensorflow-estimator-2.3.0
  Attempting uninstall: tensorflow
    Found existing installation: tensorflow 2.3.0
    Uninstalling tensorflow-2.3.0:
      Successfully uninstalled tensorflow-2.3.0
Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">uninstall</span> <span class="o">-</span><span class="n">y</span> <span class="n">tensorflow</span> 
<span class="n">pip</span> <span class="n">install</span> <span class="n">tensorflow</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>WARNING: Skipping tensorflow as it is not installed.
Collecting tensorflow
  Downloading tensorflow-2.4.0-cp37-cp37m-manylinux2010_x86_64.whl (394.7 MB)
Collecting flatbuffers~=1.12.0
  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)
Requirement already satisfied: google-pasta~=0.2 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow) (0.2.0)
Collecting six~=1.15.0
  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)
Requirement already satisfied: opt-einsum~=3.3.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow) (3.3.0)
Collecting numpy~=1.19.2
  Downloading numpy-1.19.4-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)
Collecting tensorboard~=2.4
  Downloading tensorboard-2.4.0-py3-none-any.whl (10.6 MB)
Collecting grpcio~=1.32.0
  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)
Requirement already satisfied: termcolor~=1.1.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow) (1.1.0)
Collecting tensorflow-estimator&lt;2.5.0,&gt;=2.4.0rc0
  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)
Collecting typing-extensions~=3.7.4
  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)
Collecting wheel~=0.35
  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)
Requirement already satisfied: protobuf&gt;=3.9.2 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow) (3.11.4)
Requirement already satisfied: h5py~=2.10.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow) (2.10.0)
Requirement already satisfied: astunparse~=1.6.3 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow) (1.6.3)
Collecting wrapt~=1.12.1
  Downloading wrapt-1.12.1.tar.gz (27 kB)
Collecting absl-py~=0.10
  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)
Collecting gast==0.3.3
  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)
Requirement already satisfied: keras-preprocessing~=1.1.2 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow) (1.1.2)
Requirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow) (0.4.1)
Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow) (1.7.0)
Requirement already satisfied: requests&lt;3,&gt;=2.21.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow) (2.22.0)
Requirement already satisfied: markdown&gt;=2.6.8 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow) (3.1.1)
Requirement already satisfied: setuptools&gt;=41.0.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow) (45.2.0.post20200210)
Requirement already satisfied: werkzeug&gt;=0.11.15 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow) (1.0.0)
Requirement already satisfied: google-auth&lt;2,&gt;=1.6.3 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorboard~=2.4-&gt;tensorflow) (1.11.2)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard~=2.4-&gt;tensorflow) (1.3.0)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard~=2.4-&gt;tensorflow) (1.25.8)
Requirement already satisfied: certifi&gt;=2017.4.17 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard~=2.4-&gt;tensorflow) (2020.6.20)
Requirement already satisfied: idna&lt;2.9,&gt;=2.5 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard~=2.4-&gt;tensorflow) (2.8)
Requirement already satisfied: chardet&lt;3.1.0,&gt;=3.0.2 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard~=2.4-&gt;tensorflow) (3.0.4)
Requirement already satisfied: cachetools&lt;5.0,&gt;=2.0.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard~=2.4-&gt;tensorflow) (4.1.1)
Requirement already satisfied: rsa&lt;4.1,&gt;=3.1.4 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard~=2.4-&gt;tensorflow) (4.0)
Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard~=2.4-&gt;tensorflow) (0.2.7)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard~=2.4-&gt;tensorflow) (3.1.0)
Requirement already satisfied: pyasn1&gt;=0.1.3 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from rsa&lt;4.1,&gt;=3.1.4-&gt;google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard~=2.4-&gt;tensorflow) (0.4.8)
Building wheels for collected packages: wrapt
  Building wheel for wrapt (setup.py): started
  Building wheel for wrapt (setup.py): finished with status &#39;done&#39;
  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=70965 sha256=9013a5324ef1603be53ec36b5a9eddc537c7dd7c9a5ccdbee3a409d0783d8790
  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6
Successfully built wrapt
ERROR: petastorm 0.9.5 requires pyspark&gt;=2.1.0, which is not installed.
ERROR: mlflow 1.11.0 requires alembic&lt;=1.4.1, which is not installed.
ERROR: mlflow 1.11.0 requires prometheus-flask-exporter, which is not installed.
ERROR: mlflow 1.11.0 requires sqlalchemy&lt;=1.3.13, which is not installed.
ERROR: koalas 1.2.0 has requirement numpy&lt;1.19.0,&gt;=1.14, but you&#39;ll have numpy 1.19.4 which is incompatible.
Installing collected packages: flatbuffers, six, numpy, absl-py, wheel, grpcio, tensorboard, tensorflow-estimator, typing-extensions, wrapt, gast, tensorflow
  Attempting uninstall: six
    Found existing installation: six 1.14.0
    Uninstalling six-1.14.0:
      Successfully uninstalled six-1.14.0
  Attempting uninstall: numpy
    Found existing installation: numpy 1.18.1
    Uninstalling numpy-1.18.1:
      Successfully uninstalled numpy-1.18.1
  Attempting uninstall: absl-py
    Found existing installation: absl-py 0.9.0
    Uninstalling absl-py-0.9.0:
      Successfully uninstalled absl-py-0.9.0
  Attempting uninstall: wheel
    Found existing installation: wheel 0.34.2
    Uninstalling wheel-0.34.2:
      Successfully uninstalled wheel-0.34.2
  Attempting uninstall: grpcio
    Found existing installation: grpcio 1.27.2
    Uninstalling grpcio-1.27.2:
      Successfully uninstalled grpcio-1.27.2
  Attempting uninstall: tensorboard
    Found existing installation: tensorboard 1.15.0
    Uninstalling tensorboard-1.15.0:
      Successfully uninstalled tensorboard-1.15.0
  Attempting uninstall: tensorflow-estimator
    Found existing installation: tensorflow-estimator 1.15.1
    Uninstalling tensorflow-estimator-1.15.1:
      Successfully uninstalled tensorflow-estimator-1.15.1
  Attempting uninstall: wrapt
    Found existing installation: wrapt 1.11.2
    Uninstalling wrapt-1.11.2:
      Successfully uninstalled wrapt-1.11.2
  Attempting uninstall: gast
    Found existing installation: gast 0.2.2
    Uninstalling gast-0.2.2:
      Successfully uninstalled gast-0.2.2
Successfully installed absl-py-0.11.0 flatbuffers-1.12 gast-0.3.3 grpcio-1.32.0 numpy-1.19.4 six-1.15.0 tensorboard-2.4.0 tensorflow-2.4.0 tensorflow-estimator-2.4.0 typing-extensions-3.7.4.3 wheel-0.36.2 wrapt-1.12.1
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">50</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;tf.Variable &#39;y_2:0&#39; shape=() dtype=int32_ref&gt;
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">cmake</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: cmake in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (3.18.4.post1)
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">horovod</span> <span class="o">--</span><span class="n">force</span><span class="o">-</span><span class="n">reinstall</span> <span class="o">--</span><span class="n">no</span><span class="o">-</span><span class="n">deps</span> <span class="o">--</span><span class="n">no</span><span class="o">-</span><span class="n">cache</span><span class="o">-</span><span class="nb">dir</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Collecting horovod
  Downloading horovod-0.21.0.tar.gz (3.2 MB)
Building wheels for collected packages: horovod
  Building wheel for horovod (setup.py): started
  Building wheel for horovod (setup.py): still running...
  Building wheel for horovod (setup.py): still running...
  Building wheel for horovod (setup.py): finished with status &#39;done&#39;
  Created wheel for horovod: filename=horovod-0.21.0-cp37-cp37m-linux_x86_64.whl size=21178022 sha256=af6755bbb486085898ad30d312963e003de6a73267845db5b5e0b9374e2204ad
  Stored in directory: /tmp/pip-ephem-wheel-cache-ob5dy761/wheels/4a/7a/ad/e3a4e235dc846369995b95d1bf7eaed1dfa311c5f4d30a4a79
Successfully built horovod
Installing collected packages: horovod
  Attempting uninstall: horovod
    Found existing installation: horovod 0.19.5
    Uninstalling horovod-0.19.5:
      Successfully uninstalled horovod-0.19.5
Successfully installed horovod-0.21.0
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#import horovod.tensorflow as hvd</span>
<span class="c1">#import horovod as hvd</span>
<span class="c1">#hvd.init()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;We&quot;ve made it this far.&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>We&quot;ve made it this far.
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">time</span>

 

<span class="n">checkpoint_dir</span> <span class="o">=</span> <span class="s1">&#39;/dbfs/ml/MNISTDemo/train/</span><span class="si">{}</span><span class="s1">/&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span>

 

<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_dataset</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>

  <span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>

  

  <span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="s1">&#39;MNIST-data-</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">rank</span><span class="p">)</span>

  <span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">rank</span><span class="p">::</span><span class="n">size</span><span class="p">]</span>

  <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">rank</span><span class="p">::</span><span class="n">size</span><span class="p">]</span>

  <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="p">[</span><span class="n">rank</span><span class="p">::</span><span class="n">size</span><span class="p">]</span>

  <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">[</span><span class="n">rank</span><span class="p">::</span><span class="n">size</span><span class="p">]</span>

  <span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

  <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

  <span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>

  <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>

  <span class="n">x_train</span> <span class="o">/=</span> <span class="mi">255</span>

  <span class="n">x_test</span> <span class="o">/=</span> <span class="mi">255</span>

  <span class="n">y_train</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

  <span class="n">y_test</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

  <span class="k">return</span> <span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_model</span><span class="p">(</span><span class="n">num_classes</span><span class="p">):</span>

  <span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">models</span>

  <span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>

  

  <span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>

  <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>

                   <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>

                   <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>

  <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>

  <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>

  <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>

  <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>

  <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>

  <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>

  <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

  <span class="k">return</span> <span class="n">model</span>

</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Specify training parameters</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>

<span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span>

<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">10</span>        

 

 

<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>

  <span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>

  

  <span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="n">num_classes</span><span class="p">)</span>

  <span class="n">model</span> <span class="o">=</span> <span class="n">get_model</span><span class="p">(</span><span class="n">num_classes</span><span class="p">)</span>

 

  <span class="c1"># Specify the optimizer (Adadelta in this example), using the learning rate input parameter of the function so that Horovod can adjust the learning rate during training</span>

  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adadelta</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

 

  <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>

                <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>

                <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

 

  <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>

            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>

            <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>

            <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>

            <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">train</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
    8192/11490434 [..............................] - ETA: 0s  368640/11490434 [..............................] - ETA: 1s  753664/11490434 [&gt;.............................] - ETA: 1s 1114112/11490434 [=&gt;............................] - ETA: 1s 1556480/11490434 [===&gt;..........................] - ETA: 1s 2113536/11490434 [====&gt;.........................] - ETA: 1s 2801664/11490434 [======&gt;.......................] - ETA: 0s 3670016/11490434 [========&gt;.....................] - ETA: 0s 4849664/11490434 [===========&gt;..................] - ETA: 0s 6422528/11490434 [===============&gt;..............] - ETA: 0s 8503296/11490434 [=====================&gt;........] - ETA: 0s11436032/11490434 [============================&gt;.] - ETA: 0s11493376/11490434 [==============================] - 1s 0us/step
WARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
Train on 60000 samples, validate on 10000 samples
Epoch 1/5
60000/60000 - 49s - loss: 0.6314 - acc: 0.8082 - val_loss: 0.2323 - val_acc: 0.9313
Epoch 2/5
60000/60000 - 49s - loss: 0.3002 - acc: 0.9107 - val_loss: 0.1538 - val_acc: 0.9536
Epoch 3/5
60000/60000 - 48s - loss: 0.2279 - acc: 0.9330 - val_loss: 0.1164 - val_acc: 0.9642
Epoch 4/5
60000/60000 - 49s - loss: 0.1808 - acc: 0.9473 - val_loss: 0.0931 - val_acc: 0.9715
Epoch 5/5
60000/60000 - 50s - loss: 0.1488 - acc: 0.9566 - val_loss: 0.0770 - val_acc: 0.9754
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_hvd</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>

  <span class="c1"># Import tensorflow modules to each worker</span>

  <span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>

  <span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>

  <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

  <span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>

  <span class="kn">import</span> <span class="nn">horovod.tensorflow.keras</span> <span class="k">as</span> <span class="nn">hvd</span>

  

  <span class="c1"># Initialize Horovod</span>

  <span class="n">hvd</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>

 

  <span class="c1"># Pin GPU to be used to process local rank (one GPU per process)</span>

  <span class="c1"># These steps are skipped on a CPU cluster</span>

  <span class="n">gpus</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s1">&#39;GPU&#39;</span><span class="p">)</span>

  <span class="k">for</span> <span class="n">gpu</span> <span class="ow">in</span> <span class="n">gpus</span><span class="p">:</span>

    <span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">set_memory_growth</span><span class="p">(</span><span class="n">gpu</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">gpus</span><span class="p">:</span>

    <span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">set_visible_devices</span><span class="p">(</span><span class="n">gpus</span><span class="p">[</span><span class="n">hvd</span><span class="o">.</span><span class="n">local_rank</span><span class="p">()],</span> <span class="s1">&#39;GPU&#39;</span><span class="p">)</span>

 

  <span class="c1"># Call the get_dataset function you created, this time with the Horovod rank and size</span>

  <span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">hvd</span><span class="o">.</span><span class="n">rank</span><span class="p">(),</span> <span class="n">hvd</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

  <span class="n">model</span> <span class="o">=</span> <span class="n">get_model</span><span class="p">(</span><span class="n">num_classes</span><span class="p">)</span>

 

  <span class="c1"># Adjust learning rate based on number of GPUs</span>

  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adadelta</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">hvd</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

 

  <span class="c1"># Use the Horovod Distributed Optimizer</span>

  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">hvd</span><span class="o">.</span><span class="n">DistributedOptimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>

 

  <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>

                <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>

                <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

 

  <span class="c1"># Create a callback to broadcast the initial variable states from rank 0 to all other processes.</span>

  <span class="c1"># This is required to ensure consistent initialization of all workers when training is started with random weights or restored from a checkpoint.</span>

  <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span>

      <span class="n">hvd</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">BroadcastGlobalVariablesCallback</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>

  <span class="p">]</span>

 

  <span class="c1"># Save checkpoints only on worker 0 to prevent conflicts between workers</span>

  <span class="k">if</span> <span class="n">hvd</span><span class="o">.</span><span class="n">rank</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>

      <span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">checkpoint_dir</span> <span class="o">+</span> <span class="s1">&#39;/checkpoint-</span><span class="si">{epoch}</span><span class="s1">.ckpt&#39;</span><span class="p">,</span> <span class="n">save_weights_only</span> <span class="o">=</span> <span class="kc">True</span><span class="p">))</span>

 

  <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>

            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>

            <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>

            <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>

            <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>

            <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#I added all these installs because the final box of the tutorial is not working right now /Karl 201211 1650</span>

<span class="c1">#Removed installs, things work with latest version of tensorflow and horovodrunner /Karl 201216 1606</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Collecting sparkdl
  Downloading sparkdl-0.2.2-py3-none-any.whl (99 kB)
Installing collected packages: sparkdl
Successfully installed sparkdl-0.2.2
WARNING: You are using pip version 20.0.2; however, version 20.3.1 is available.
You should consider upgrading via the &#39;/databricks/python3/bin/python3.7 -m pip install --upgrade pip&#39; command.
</pre></div>
</div>
</div></blockquote>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Collecting pillow
  Downloading Pillow-8.0.1-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)
Installing collected packages: pillow
Successfully installed pillow-8.0.1
WARNING: You are using pip version 20.0.2; however, version 20.3.1 is available.
You should consider upgrading via the &#39;/databricks/python3/bin/python3.7 -m pip install --upgrade pip&#39; command.
</pre></div>
</div>
</div></blockquote>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Collecting keras==2.3.1
  Downloading Keras-2.3.1-py2.py3-none-any.whl (377 kB)
Requirement already satisfied: six&gt;=1.9.0 in /databricks/python3/lib/python3.7/site-packages (from keras==2.3.1) (1.14.0)
Requirement already satisfied: h5py in /databricks/python3/lib/python3.7/site-packages (from keras==2.3.1) (3.1.0)
Requirement already satisfied: keras-applications&gt;=1.0.6 in /databricks/python3/lib/python3.7/site-packages (from keras==2.3.1) (1.0.8)
Requirement already satisfied: scipy&gt;=0.14 in /databricks/python3/lib/python3.7/site-packages (from keras==2.3.1) (1.4.1)
Requirement already satisfied: keras-preprocessing&gt;=1.0.5 in /databricks/python3/lib/python3.7/site-packages (from keras==2.3.1) (1.1.2)
Requirement already satisfied: pyyaml in /databricks/python3/lib/python3.7/site-packages (from keras==2.3.1) (5.3.1)
Requirement already satisfied: numpy&gt;=1.9.1 in /databricks/python3/lib/python3.7/site-packages (from keras==2.3.1) (1.18.1)
Requirement already satisfied: cached-property; python_version &lt; &quot;3.8&quot; in /databricks/python3/lib/python3.7/site-packages (from h5py-&gt;keras==2.3.1) (1.5.2)
Installing collected packages: keras
  Attempting uninstall: keras
    Found existing installation: Keras 2.4.3
    Uninstalling Keras-2.4.3:
      Successfully uninstalled Keras-2.4.3
Successfully installed keras-2.3.1
WARNING: You are using pip version 20.0.2; however, version 20.3.1 is available.
You should consider upgrading via the &#39;/databricks/python3/bin/python3.7 -m pip install --upgrade pip&#39; command.
</pre></div>
</div>
</div></blockquote>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Collecting tensorframes
  Downloading tensorframes-0.2.9-py3-none-any.whl (10 kB)
Installing collected packages: tensorframes
Successfully installed tensorframes-0.2.9
WARNING: You are using pip version 20.0.2; however, version 20.3.1 is available.
You should consider upgrading via the &#39;/databricks/python3/bin/python3.7 -m pip install --upgrade pip&#39; command.
</pre></div>
</div>
</div></blockquote>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Collecting kafka-python
  Downloading kafka_python-2.0.2-py2.py3-none-any.whl (246 kB)
Installing collected packages: kafka-python
Successfully installed kafka-python-2.0.2
WARNING: You are using pip version 20.0.2; however, version 20.3.1 is available.
You should consider upgrading via the &#39;/databricks/python3/bin/python3.7 -m pip install --upgrade pip&#39; command.
</pre></div>
</div>
</div></blockquote>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Collecting tensorflowonspark
  Downloading tensorflowonspark-2.2.1-py2.py3-none-any.whl (44 kB)
Collecting packaging
  Downloading packaging-20.7-py2.py3-none-any.whl (35 kB)
Requirement already satisfied: pyparsing&gt;=2.0.2 in /databricks/python3/lib/python3.7/site-packages (from packaging-&gt;tensorflowonspark) (2.4.6)
Installing collected packages: packaging, tensorflowonspark
Successfully installed packaging-20.7 tensorflowonspark-2.2.1
WARNING: You are using pip version 20.0.2; however, version 20.3.1 is available.
You should consider upgrading via the &#39;/databricks/python3/bin/python3.7 -m pip install --upgrade pip&#39; command.
</pre></div>
</div>
</div></blockquote>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Collecting jieba
  Downloading jieba-0.42.1.tar.gz (19.2 MB)
2020-12-11 14:59:42,250 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:42,252 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:42,252 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:42,253 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:42,254 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:42,254 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:42,254 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:42,255 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:42,350 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:42,451 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:42,551 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:42,583 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:42,585 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:42,585 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:42,585 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:42,586 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:42,586 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:42,586 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:42,586 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:42,652 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:42,753 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:42,853 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:42,954 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:43,055 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:43,085 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:43,085 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:43,086 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:43,087 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:43,087 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:43,087 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:43,087 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:43,088 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:43,155 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:43,256 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:43,357 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:43,457 INFO (Thread-21-17548) Received command c on object id p0
Building wheels for collected packages: jieba
  Building wheel for jieba (setup.py): started
2020-12-11 14:59:43,558 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:43,586 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:43,587 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:43,587 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:43,588 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:43,588 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:43,588 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:43,589 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:43,589 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:43,658 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:43,759 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:43,860 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:43,960 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:44,061 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:44,087 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:44,087 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:44,088 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:44,089 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:44,089 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:44,089 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:44,089 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:44,090 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:44,162 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:44,262 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:44,363 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:44,464 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:44,565 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:44,588 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:44,588 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:44,588 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:44,589 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:44,589 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:44,590 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:44,590 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:44,590 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:44,665 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:44,766 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:44,867 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:44,967 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:45,068 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:45,089 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:45,090 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:45,090 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:45,091 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:45,091 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:45,091 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:45,092 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:45,092 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:45,168 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:45,269 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:45,370 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:45,470 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:45,571 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:45,590 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:45,591 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:45,591 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:45,592 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:45,592 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:45,593 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:45,595 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:45,595 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:45,672 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:45,772 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:45,873 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:45,973 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:46,074 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:46,091 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:46,092 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:46,092 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:46,093 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:46,093 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:46,093 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:46,093 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:46,093 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:46,175 INFO (Thread-21-17548) Received command c on object id p0
  Building wheel for jieba (setup.py): finished with status &#39;done&#39;
  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314478 sha256=41cd8913a83e4b41c56953eb933ba612cab830b3c75ed86d69ee29a77b5fde61
  Stored in directory: /root/.cache/pip/wheels/24/aa/17/5bc7c72e9a37990a9620cc3aad0acad1564dcff6dbc2359de3
Successfully built jieba
2020-12-11 14:59:46,275 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:46,376 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:46,477 INFO (Thread-21-17548) Received command c on object id p0
Installing collected packages: jieba
2020-12-11 14:59:46,577 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:46,592 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:46,592 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:46,593 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:46,593 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:46,594 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:46,594 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:46,594 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:46,595 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:46,678 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:46,778 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:46,879 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:46,980 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:47,080 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:47,094 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:47,094 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:47,096 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:47,097 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:47,097 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:47,097 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:47,098 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:47,098 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:47,181 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:47,281 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:47,382 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:47,483 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:47,583 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:47,595 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:47,596 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:47,596 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:47,597 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:47,597 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:47,597 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:47,598 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:47,598 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:47,684 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:47,785 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:47,885 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:47,986 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:48,087 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:48,099 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:48,099 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:48,099 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:48,100 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:48,100 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:48,101 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:48,101 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:48,102 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:48,187 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:48,288 INFO (Thread-21-17548) Received command c on object id p0
Successfully installed jieba-0.42.1
WARNING: You are using pip version 20.0.2; however, version 20.3.1 is available.
You should consider upgrading via the &#39;/databricks/python3/bin/python3.7 -m pip install --upgrade pip&#39; command.
2020-12-11 14:59:48,389 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:48,489 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:48,490 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:48,490 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:48,490 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:48,491 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:48,491 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:48,491 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:48,492 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:48,492 INFO (Thread-21-17548) Received command c on object id p0
2020-12-11 14:59:48,492 INFO (Thread-21-17548) Received command c on object id p0
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#hvd.init()</span>

<span class="kn">from</span> <span class="nn">sparkdl</span> <span class="kn">import</span> <span class="n">HorovodRunner</span>

 

<span class="n">hr</span> <span class="o">=</span> <span class="n">HorovodRunner</span><span class="p">(</span><span class="n">np</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">hr</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_hvd</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>HorovodRunner will stream all training logs to notebook cell output. If there are too many logs, you
can adjust the log level in your train method. Or you can set driver_log_verbosity to
&#39;log_callback_only&#39; and use a HorovodRunner log  callback on the first worker to get concise
progress updates.
The global names read or written to by the pickled function are {&#39;checkpoint_dir&#39;, &#39;num_classes&#39;, &#39;batch_size&#39;, &#39;epochs&#39;, &#39;get_model&#39;, &#39;get_dataset&#39;}.
The pickled object size is 3562 bytes.

### How to enable Horovod Timeline? ###
HorovodRunner has the ability to record the timeline of its activity with Horovod  Timeline. To
record a Horovod Timeline, set the `HOROVOD_TIMELINE` environment variable  to the location of the
timeline file to be created. You can then open the timeline file  using the chrome://tracing
facility of the Chrome browser.

Start training.
[1,1]&lt;stderr&gt;:2020-12-16 15:07:03.477687: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,0]&lt;stderr&gt;:2020-12-16 15:07:03.483544: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,1]&lt;stderr&gt;:2020-12-16 15:07:04.720962: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,0]&lt;stderr&gt;:2020-12-16 15:07:04.721840: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,1]&lt;stderr&gt;:2020-12-16 15:07:04.746571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]&lt;stderr&gt;:2020-12-16 15:07:04.747430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
[1,1]&lt;stderr&gt;:pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
[1,1]&lt;stderr&gt;:coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
[1,1]&lt;stderr&gt;:2020-12-16 15:07:04.747462: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,0]&lt;stderr&gt;:2020-12-16 15:07:04.748081: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]&lt;stderr&gt;:2020-12-16 15:07:04.749096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
[1,0]&lt;stderr&gt;:pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
[1,0]&lt;stderr&gt;:coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
[1,0]&lt;stderr&gt;:2020-12-16 15:07:04.749177: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,1]&lt;stderr&gt;:2020-12-16 15:07:04.749268: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,0]&lt;stderr&gt;:2020-12-16 15:07:04.751923: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,0]&lt;stderr&gt;:2020-12-16 15:07:04.754095: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,0]&lt;stderr&gt;:2020-12-16 15:07:04.754477: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,1]&lt;stderr&gt;:2020-12-16 15:07:04.750963: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,1]&lt;stderr&gt;:2020-12-16 15:07:04.751257: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,1]&lt;stderr&gt;:2020-12-16 15:07:04.753072: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,1]&lt;stderr&gt;:2020-12-16 15:07:04.754093: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,0]&lt;stderr&gt;:2020-12-16 15:07:04.756663: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,0]&lt;stderr&gt;:2020-12-16 15:07:04.757757: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,1]&lt;stderr&gt;:2020-12-16 15:07:04.758266: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,1]&lt;stderr&gt;:2020-12-16 15:07:04.758398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]&lt;stderr&gt;:2020-12-16 15:07:04.759281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]&lt;stderr&gt;:2020-12-16 15:07:04.760069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
[1,1]&lt;stdout&gt;:Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
[1,0]&lt;stderr&gt;:2020-12-16 15:07:04.762185: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,0]&lt;stderr&gt;:2020-12-16 15:07:04.762398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]&lt;stderr&gt;:2020-12-16 15:07:04.763383: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]&lt;stderr&gt;:2020-12-16 15:07:04.764224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
[1,0]&lt;stdout&gt;:Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
[1,1]&lt;stdout&gt;:[1,1]&lt;stdout&gt;:    8192/11490434 [..............................] - ETA: 0s[1,0]&lt;stdout&gt;:[1,0]&lt;stdout&gt;:    8192/11490434 [..............................][1,0]&lt;stdout&gt;: - ETA: 0s[1,1]&lt;stdout&gt;:[1,1]&lt;stdout&gt;:  139264/11490434 [..............................] - ETA: 4s[1,0]&lt;stdout&gt;:[1,0]&lt;stdout&gt;:  163840/11490434 [..............................] - ETA: 3s[1,1]&lt;stdout&gt;:[1,1]&lt;stdout&gt;:  294912/11490434 [..............................] - ETA: 3s[1,0]&lt;stdout&gt;:[1,0]&lt;stdout&gt;:  360448/11490434 [..............................] - ETA: 3s[1,1]&lt;stdout&gt;:[1,1]&lt;stdout&gt;:  483328/11490434 [&gt;.............................] - ETA: 3s[1,0]&lt;stdout&gt;:[1,0]&lt;stdout&gt;:  573440/11490434 [&gt;.............................] - ETA: 2s[1,1]&lt;stdout&gt;:[1,1]&lt;stdout&gt;:  671744/11490434 [&gt;.............................] - ETA: 3s[1,0]&lt;stdout&gt;:[1,0]&lt;stdout&gt;:  786432/11490434 [=&gt;............................] - ETA: 2s[1,1]&lt;stdout&gt;:[1,1]&lt;stdout&gt;:  860160/11490434 [=&gt;............................] - ETA: 3s[1,0]&lt;stdout&gt;:[1,0]&lt;stdout&gt;:  999424/11490434 [=&gt;............................] - ETA: 2s[1,1]&lt;stdout&gt;:[1,1]&lt;stdout&gt;: 1048576/11490434 [=&gt;............................] - ETA: 3s[1,0]&lt;stdout&gt;:[1,0]&lt;stdout&gt;: 1212416/11490434 [==&gt;...........................] - ETA: 2s[1,1]&lt;stdout&gt;:[1,1]&lt;stdout&gt;: 1228800/11490434 [==&gt;...........................] - ETA: 3s[1,0]&lt;stdout&gt;:[1,0]&lt;stdout&gt;: 1441792/11490434 [==&gt;...........................] - ETA: 2s[1,1]&lt;stdout&gt;:[1,1]&lt;stdout&gt;: 1425408/11490434 [==&gt;...........................] - ETA: 2s[1,0]&lt;stdout&gt;:[1,0]&lt;stdout&gt;: 1671168/11490434 [===&gt;..........................][1,0]&lt;stdout&gt;: - ETA: 2s[1,1]&lt;stdout&gt;:[1,1]&lt;stdout&gt;: 1622016/11490434 [===&gt;..........................] - ETA: 2s[1,0]&lt;stdout&gt;:[1,0]&lt;stdout&gt;: 1900544/11490434 [===&gt;..........................] - ETA: 2s[1,1]&lt;stdout&gt;:[1,1]&lt;stdout&gt;: 1818624/11490434 [===&gt;..........................] - ETA: 2s[1,0]&lt;stdout&gt;:[1,0]&lt;stdout&gt;: 2129920/11490434 [====&gt;.........................] - ETA: 2s[1,1]&lt;stdout&gt;:[1,1]&lt;stdout&gt;: 2015232/11490434 [====&gt;.........................] - ETA: 2s[1,0]&lt;stdout&gt;:[1,0]&lt;stdout&gt;: 2359296/11490434 [=====&gt;........................][1,0]&lt;stdout&gt;: - ETA: 2s[1,1]&lt;stdout&gt;:[1,1]&lt;stdout&gt;: 2211840/11490434 [====&gt;.........................] - ETA: 2s[1,0]&lt;stdout&gt;:[1,0]&lt;stdout&gt;: 2588672/11490434 [=====&gt;........................] - ETA: 2s[1,1]&lt;stdout&gt;:[1,1]&lt;stdout&gt;: 2408448/11490434 [=====&gt;........................] - ETA: 2s[1,0]&lt;stdout&gt;:...(truncated)
[1,1]&lt;stdout&gt;:[1,1]&lt;stdout&gt;:10076160/11490434 [=========================&gt;....] - ETA: 0s[1,1]&lt;stdout&gt;:[1,1]&lt;stdout&gt;:10272768/11490434 [=========================&gt;....] - ETA: 0s[1,1]&lt;stdout&gt;:[1,1]&lt;stdout&gt;:10469376/11490434 [==========================&gt;...] - ETA: 0s[1,1]&lt;stdout&gt;:[1,1]&lt;stdout&gt;:10665984/11490434 [==========================&gt;...] - ETA: 0s[1,1]&lt;stdout&gt;:[1,1]&lt;stdout&gt;:10862592/11490434 [===========================&gt;..] - ETA: 0s[1,0]&lt;stderr&gt;:2020-12-16 15:07:08.044663: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,0]&lt;stderr&gt;:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,1]&lt;stdout&gt;:[1,1]&lt;stdout&gt;:11059200/11490434 [===========================&gt;..] - ETA: 0s[1,0]&lt;stderr&gt;:2020-12-16 15:07:08.067575: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,0]&lt;stderr&gt;:2020-12-16 15:07:08.067883: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561ebcb26b50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,0]&lt;stderr&gt;:2020-12-16 15:07:08.067912: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,1]&lt;stdout&gt;:[1,1]&lt;stdout&gt;:11255808/11490434 [============================&gt;.] - ETA: 0s[1,1]&lt;stdout&gt;:[1,1]&lt;stdout&gt;:11452416/11490434 [============================&gt;.] - ETA: 0s[1,1]&lt;stdout&gt;:[1,1]&lt;stdout&gt;:11493376/11490434 [==============================] - 3s 0us/step
[1,0]&lt;stderr&gt;:2020-12-16 15:07:08.164198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]&lt;stderr&gt;:2020-12-16 15:07:08.165116: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561ebca72240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,0]&lt;stderr&gt;:2020-12-16 15:07:08.165145: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,0]&lt;stderr&gt;:2020-12-16 15:07:08.165407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]&lt;stderr&gt;:2020-12-16 15:07:08.166238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
[1,0]&lt;stderr&gt;:pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
[1,0]&lt;stderr&gt;:coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
[1,0]&lt;stderr&gt;:2020-12-16 15:07:08.166293: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,0]&lt;stderr&gt;:2020-12-16 15:07:08.166364: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,0]&lt;stderr&gt;:2020-12-16 15:07:08.166396: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,0]&lt;stderr&gt;:2020-12-16 15:07:08.166427: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,0]&lt;stderr&gt;:2020-12-16 15:07:08.166452: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,0]&lt;stderr&gt;:2020-12-16 15:07:08.166479: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,0]&lt;stderr&gt;:2020-12-16 15:07:08.166507: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,0]&lt;stderr&gt;:2020-12-16 15:07:08.166619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]&lt;stderr&gt;:2020-12-16 15:07:08.167558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]&lt;stderr&gt;:2020-12-16 15:07:08.168355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
[1,0]&lt;stderr&gt;:2020-12-16 15:07:08.168416: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,1]&lt;stderr&gt;:2020-12-16 15:07:08.455620: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,1]&lt;stderr&gt;:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,1]&lt;stderr&gt;:2020-12-16 15:07:08.481287: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,1]&lt;stderr&gt;:2020-12-16 15:07:08.481655: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561aac3674c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,1]&lt;stderr&gt;:2020-12-16 15:07:08.481688: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,1]&lt;stderr&gt;:2020-12-16 15:07:08.571052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]&lt;stderr&gt;:2020-12-16 15:07:08.571962: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561aac35e6d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,1]&lt;stderr&gt;:2020-12-16 15:07:08.571997: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,1]&lt;stderr&gt;:2020-12-16 15:07:08.572298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]&lt;stderr&gt;:2020-12-16 15:07:08.573158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
[1,1]&lt;stderr&gt;:pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
[1,1]&lt;stderr&gt;:coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
[1,1]&lt;stderr&gt;:2020-12-16 15:07:08.573218: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,1]&lt;stderr&gt;:2020-12-16 15:07:08.573295: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,1]&lt;stderr&gt;:2020-12-16 15:07:08.573330: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,1]&lt;stderr&gt;:2020-12-16 15:07:08.573356: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,1]&lt;stderr&gt;:2020-12-16 15:07:08.573381: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,1]&lt;stderr&gt;:2020-12-16 15:07:08.573405: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,1]&lt;stderr&gt;:2020-12-16 15:07:08.573453: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,1]&lt;stderr&gt;:2020-12-16 15:07:08.573575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]&lt;stderr&gt;:2020-12-16 15:07:08.574487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]&lt;stderr&gt;:2020-12-16 15:07:08.575287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
[1,1]&lt;stderr&gt;:2020-12-16 15:07:08.575343: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,0]&lt;stderr&gt;:2020-12-16 15:07:08.760606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,0]&lt;stderr&gt;:2020-12-16 15:07:08.760663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
[1,0]&lt;stderr&gt;:2020-12-16 15:07:08.760675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
[1,0]&lt;stderr&gt;:2020-12-16 15:07:08.760950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]&lt;stderr&gt;:2020-12-16 15:07:08.761899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]&lt;stderr&gt;:2020-12-16 15:07:08.762742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13943 MB memory) -&gt; physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[1,0]&lt;stdout&gt;:Epoch 1/5
[1,1]&lt;stderr&gt;:2020-12-16 15:07:09.174137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,1]&lt;stderr&gt;:2020-12-16 15:07:09.174194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
[1,1]&lt;stderr&gt;:2020-12-16 15:07:09.174209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
[1,1]&lt;stderr&gt;:2020-12-16 15:07:09.174504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]&lt;stderr&gt;:2020-12-16 15:07:09.175465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]&lt;stderr&gt;:2020-12-16 15:07:09.176297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13943 MB memory) -&gt; physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[1,0]&lt;stderr&gt;:2020-12-16 15:07:09.323552: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,1]&lt;stdout&gt;:Epoch 1/5
[1,0]&lt;stderr&gt;:2020-12-16 15:07:09.574013: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,1]&lt;stderr&gt;:2020-12-16 15:07:09.734054: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,1]&lt;stderr&gt;:2020-12-16 15:07:09.982296: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,0]&lt;stdout&gt;:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO Bootstrap : Using [0]eth0:10.149.251.184&lt;0&gt;
[1,0]&lt;stdout&gt;:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:1120-144117-apses921-10-149-251-184:3592:3595 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[1,0]&lt;stdout&gt;:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO NET/Socket : Using [0]eth0:10.149.251.184&lt;0&gt;
[1,0]&lt;stdout&gt;:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO Using network Socket
[1,0]&lt;stdout&gt;:NCCL version 2.7.3+cuda10.1
[1,1]&lt;stdout&gt;:1120-144117-apses921-10-149-231-123:3822:3825 [0] NCCL INFO Bootstrap : Using [0]eth0:10.149.231.123&lt;0&gt;
[1,1]&lt;stdout&gt;:1120-144117-apses921-10-149-231-123:3822:3825 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[1,1]&lt;stdout&gt;:
[1,1]&lt;stdout&gt;:1120-144117-apses921-10-149-231-123:3822:3825 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[1,1]&lt;stdout&gt;:1120-144117-apses921-10-149-231-123:3822:3825 [0] NCCL INFO NET/Socket : Using [0]eth0:10.149.231.123&lt;0&gt;
[1,1]&lt;stdout&gt;:1120-144117-apses921-10-149-231-123:3822:3825 [0] NCCL INFO Using network Socket
[1,0]&lt;stdout&gt;:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO Channel 00/02 :    0   1
[1,0]&lt;stdout&gt;:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO Channel 01/02 :    0   1
[1,0]&lt;stdout&gt;:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[1,0]&lt;stdout&gt;:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO Trees [0] 1/-1/-1-&gt;0-&gt;-1|-1-&gt;0-&gt;1/-1/-1 [1] -1/-1/-1-&gt;0-&gt;1|1-&gt;0-&gt;-1/-1/-1
[1,1]&lt;stdout&gt;:1120-144117-apses921-10-149-231-123:3822:3825 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[1,1]&lt;stdout&gt;:1120-144117-apses921-10-149-231-123:3822:3825 [0] NCCL INFO Trees [0] -1/-1/-1-&gt;1-&gt;0|0-&gt;1-&gt;-1/-1/-1 [1] 0/-1/-1-&gt;1-&gt;-1|-1-&gt;1-&gt;0/-1/-1
[1,0]&lt;stdout&gt;:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO Channel 00 : 1[1e0] -&gt; 0[1e0] [receive] via NET/Socket/0
[1,1]&lt;stdout&gt;:1120-144117-apses921-10-149-231-123:3822:3825 [0] NCCL INFO Channel 00 : 0[1e0] -&gt; 1[1e0] [receive] via NET/Socket/0
[1,0]&lt;stdout&gt;:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO Channel 00 : 0[1e0] -&gt; 1[1e0] [send] via NET/Socket/0
[1,1]&lt;stdout&gt;:1120-144117-apses921-10-149-231-123:3822:3825 [0] NCCL INFO Channel 00 : 1[1e0] -&gt; 0[1e0] [send] via NET/Socket/0
[1,0]&lt;stdout&gt;:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO Channel 01 : 1[1e0] -&gt; 0[1e0] [receive] via NET/Socket/0
[1,1]&lt;stdout&gt;:1120-144117-apses921-10-149-231-123:3822:3825 [0] NCCL INFO Channel 01 : 0[1e0] -&gt; 1[1e0] [receive] via NET/Socket/0
[1,0]&lt;stdout&gt;:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO Channel 01 : 0[1e0] -&gt; 1[1e0] [send] via NET/Socket/0
[1,1]&lt;stdout&gt;:1120-144117-apses921-10-149-231-123:3822:3825 [0] NCCL INFO Channel 01 : 1[1e0] -&gt; 0[1e0] [send] via NET/Socket/0
[1,0]&lt;stdout&gt;:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[1,0]&lt;stdout&gt;:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO comm 0x7fad4cbf9c40 rank 0 nranks 2 cudaDev 0 busId 1e0 - Init COMPLETE
[1,1]&lt;stdout&gt;:1120-144117-apses921-10-149-231-123:3822:3825 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[1,1]&lt;stdout&gt;:1120-144117-apses921-10-149-231-123:3822:3825 [0] NCCL INFO comm 0x7f9578300cf0 rank 1 nranks 2 cudaDev 0 busId 1e0 - Init COMPLETE
[1,0]&lt;stdout&gt;:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO Launch mode Parallel
[1,1]&lt;stdout&gt;:235/235 - 3s - loss: 0.5739 - accuracy: 0.8248 - val_loss: 0.2239 - val_accuracy: 0.9330
[1,1]&lt;stdout&gt;:Epoch 2/5
[1,0]&lt;stdout&gt;:235/235 - 5s - loss: 0.7358 - accuracy: 0.7720 - val_loss: 0.2235 - val_accuracy: 0.9346
[1,0]&lt;stdout&gt;:Epoch 2/5
[1,1]&lt;stdout&gt;:235/235 - 3s - loss: 0.2218 - accuracy: 0.9349 - val_loss: 0.1524 - val_accuracy: 0.9536
[1,1]&lt;stdout&gt;:Epoch 3/5
[1,0]&lt;stdout&gt;:235/235 - 5s - loss: 0.3690 - accuracy: 0.8885 - val_loss: 0.1502 - val_accuracy: 0.9568
[1,0]&lt;stdout&gt;:Epoch 3/5
[1,1]&lt;stdout&gt;:235/235 - 3s - loss: 0.1549 - accuracy: 0.9548 - val_loss: 0.1154 - val_accuracy: 0.9618
[1,1]&lt;stdout&gt;:Epoch 4/5
[1,0]&lt;stdout&gt;:235/235 - 5s - loss: 0.2786 - accuracy: 0.9145 - val_loss: 0.1119 - val_accuracy: 0.9656
[1,0]&lt;stdout&gt;:Epoch 4/5
[1,1]&lt;stdout&gt;:235/235 - 3s - loss: 0.1178 - accuracy: 0.9667 - val_loss: 0.0876 - val_accuracy: 0.9716
[1,1]&lt;stdout&gt;:Epoch 5/5
[1,0]&lt;stdout&gt;:235/235 - 5s - loss: 0.2151 - accuracy: 0.9358 - val_loss: 0.0827 - val_accuracy: 0.9750
[1,0]&lt;stdout&gt;:Epoch 5/5
[1,1]&lt;stdout&gt;:235/235 - 3s - loss: 0.0908 - accuracy: 0.9749 - val_loss: 0.0702 - val_accuracy: 0.9786
[1,0]&lt;stdout&gt;:235/235 - 5s - loss: 0.1805 - accuracy: 0.9453 - val_loss: 0.0656 - val_accuracy: 0.9780
</pre></div>
</div>
</div></blockquote>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./000_0-sds-3-x-projects/student-project-06_group-ParticleClustering/old notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By ScaDaMaLe Team<br/>
        
            &copy; Copyright 2020 Creative Commons Zero v1.0 Universal.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>
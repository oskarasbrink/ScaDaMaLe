<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>06_DataPredicton_LR - sds-3.x/ScaDaMaLe</title>


        <!-- Custom HTML head -->

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="../../favicon.svg">
        <link rel="shortcut icon" href="../../favicon.png">
        <link rel="stylesheet" href="../../css/variables.css">
        <link rel="stylesheet" href="../../css/general.css">
        <link rel="stylesheet" href="../../css/chrome.css">
        <link rel="stylesheet" href="../../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../../highlight.css">
        <link rel="stylesheet" href="../../tomorrow-night.css">
        <link rel="stylesheet" href="../../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../../scroll-mdbook-outputs.css">

        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../../intro.html">Introduction</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-01_group-TheTwoCultures/00_download_data.html"><strong aria-hidden="true">1.</strong> Student-project-01_group_TheTwoCultures_00_download_data</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/student-project-01_group-TheTwoCultures/01_load_data.html"><strong aria-hidden="true">1.1.</strong> 01_load_data</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-01_group-TheTwoCultures/01b_show_data.html"><strong aria-hidden="true">1.2.</strong> 01b_show_data</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-01_group-TheTwoCultures/02_logisticregression.html"><strong aria-hidden="true">1.3.</strong> 02_logisticregression</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-01_group-TheTwoCultures/03_word2vec.html"><strong aria-hidden="true">1.4.</strong> 03_word2vec</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-01_group-TheTwoCultures/04_LDA.html"><strong aria-hidden="true">1.5.</strong> 04_LDA</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../contents/student-project-02_group-LiUUmeaSceneGraphMotifs/01_SceneGraphMotifs.html"><strong aria-hidden="true">2.</strong> Student-project-02_group_LiUUmeaSceneGraphMotifs_01_SceneGraphMotifs</a></li><li class="spacer"></li><li class="chapter-item expanded "><a href="../../contents/student-project-03_group-GuangyiZhang/01_triads.html"><strong aria-hidden="true">3.</strong> Student-project-03_group_GuangyiZhang_01_triads</a></li><li class="spacer"></li><li class="chapter-item expanded "><a href="../../contents/student-project-04_group-DistributedLinearAlgebra/01_DistributedSVD.html"><strong aria-hidden="true">4.</strong> Student-project-04_group_DistributedLinearAlgebra_01_DistributedSVD</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/student-project-04_group-DistributedLinearAlgebra/02_CollaborativeFiltering.html"><strong aria-hidden="true">4.1.</strong> 02_CollaborativeFiltering</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../contents/student-project-05_group-LundDirichletAnalysts/01_Wikipedia_LDA_Analysis.html"><strong aria-hidden="true">5.</strong> Student-project-05_group_LundDirichletAnalysts_01_Wikipedia_LDA_Analysis</a></li><li class="spacer"></li><li class="chapter-item expanded "><a href="../../contents/student-project-06_group-ParticleClustering/00_Introduction.html"><strong aria-hidden="true">6.</strong> Student-project-06_group-ParticleClustering_00_Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/student-project-06_group-ParticleClustering/01_data_and_preprocessing.html"><strong aria-hidden="true">6.1.</strong> 01_data_and_preprocessing</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-06_group-ParticleClustering/02_dl_single_machine.html"><strong aria-hidden="true">6.2.</strong> 02_dl_single_machine</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-06_group-ParticleClustering/03_dl_horovod.html"><strong aria-hidden="true">6.3.</strong> 03_dl_horovod</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-06_group-ParticleClustering/04_evaluate.html"><strong aria-hidden="true">6.4.</strong> 04_evaluate</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-06_group-ParticleClustering/TF1version.html"><strong aria-hidden="true">6.5.</strong> TF1version</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../contents/student-project-07_group-MathAtKTH/01_Coding_Motifs.html"><strong aria-hidden="true">7.</strong> Student-project-07_group-MathAtKTH_01_Coding_Motifs</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/student-project-07_group-MathAtKTH/02_Data_Processing.html"><strong aria-hidden="true">7.1.</strong> 02_Data_Processing</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-07_group-MathAtKTH/03_graph_string_converter.html"><strong aria-hidden="true">7.2.</strong> 03_graph_string_converter</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../contents/student-project-08_group-DistributedEnsemble/00_project.html"><strong aria-hidden="true">8.</strong> Student-project-08_group-DistributedEnsemble_00_project</a></li><li class="spacer"></li><li class="chapter-item expanded "><a href="../../contents/student-project-09_group-TopicModeling/01_Introduction.html"><strong aria-hidden="true">9.</strong> Student-project-09_group-TopicModeling_01_Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/student-project-09_group-TopicModeling/02_Data_Processing.html"><strong aria-hidden="true">9.1.</strong> 02_Data_Processing</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-09_group-TopicModeling/03_LDA.html"><strong aria-hidden="true">9.2.</strong> 03_LDA</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-09_group-TopicModeling/04_Classification_CountVector.html"><strong aria-hidden="true">9.3.</strong> 04_Classification_CountVector</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-09_group-TopicModeling/05_Classification.html"><strong aria-hidden="true">9.4.</strong> 05_Classification</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-09_group-TopicModeling/06_Results.html"><strong aria-hidden="true">9.5.</strong> 06_Results</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../contents/student-project-10_group-Geosmus/01_Introduction.html"><strong aria-hidden="true">10.</strong> Student-project-10_group-Geosmus_01_Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/student-project-10_group-Geosmus/02_ClusteringEmoticonsBasedOnTweets.html"><strong aria-hidden="true">10.1.</strong> 02_ClusteringEmoticonsBasedOnTweets</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-10_group-Geosmus/03_Dynamic_Tweet_Maps.html"><strong aria-hidden="true">10.2.</strong> 03_Dynamic_Tweet_Maps</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-10_group-Geosmus/04_conclusion.html"><strong aria-hidden="true">10.3.</strong> 04_conclusion</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-10_group-Geosmus/05_appendix_get-cc-data.html"><strong aria-hidden="true">10.4.</strong> 05_appendix_get-cc-data</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-10_group-Geosmus/06_appendix_tweet_carto_functions.html"><strong aria-hidden="true">10.5.</strong> 06_appendix_tweet_carto_functions</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-10_group-Geosmus/07_a_appendix_extendedTwitterUtils2run.html"><strong aria-hidden="true">10.6.</strong> 07_a_appendix_extendedTwitterUtils2run</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-10_group-Geosmus/07_b_appendix_TTTDFfunctions.html"><strong aria-hidden="true">10.7.</strong> 07_b_appendix_TTTDFfunctions</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../contents/student-project-11_group-Sketchings/00_QuantileEstimation.html"><strong aria-hidden="true">11.</strong> Student-project-11_group-Sketchings_00_QuantileEstimation</a></li><li class="spacer"></li><li class="chapter-item expanded "><a href="../../contents/student-project-12_group-CovidPandemic/00_ProjectDescriptionAndPlanning.html"><strong aria-hidden="true">12.</strong> Student-project-12_group-CovidPandemic_00_ProjectDescriptionAndPlanning</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/student-project-12_group-CovidPandemic/01_DownloadFilesPeriodicallyScript.html"><strong aria-hidden="true">12.1.</strong> 01_DownloadFilesPeriodicallyScript</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-12_group-CovidPandemic/01_StreamToFile.html"><strong aria-hidden="true">12.2.</strong> 01_StreamToFile</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-12_group-CovidPandemic/02_DataPreprocess.html"><strong aria-hidden="true">12.3.</strong> 02_DataPreprocess</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-12_group-CovidPandemic/021_DataPreprocess_Explain.html"><strong aria-hidden="true">12.4.</strong> 021_DataPreprocess_Explain</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html"><strong aria-hidden="true">12.5.</strong> 03_ExplosiveAnalysis</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-12_group-CovidPandemic/04_DataVisualize.html"><strong aria-hidden="true">12.6.</strong> 04_DataVisualize</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-12_group-CovidPandemic/05_Clustering.html"><strong aria-hidden="true">12.7.</strong> 05_Clustering</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-12_group-CovidPandemic/06_DataPredicton_LR.html" class="active"><strong aria-hidden="true">12.8.</strong> 06_DataPredicton_LR</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-12_group-CovidPandemic/07_DataPredicton_ARIMA.html"><strong aria-hidden="true">12.9.</strong> 07_DataPredicton_ARIMA</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-12_group-CovidPandemic/08_DataPrediction_GP.html"><strong aria-hidden="true">12.10.</strong> 08_DataPrediction_GP</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../contents/student-project-13_group-Genomics/01_1000genomes.html"><strong aria-hidden="true">13.</strong> Student-project-13_group-Genomics_01_1000genomes</a></li><li class="spacer"></li><li class="chapter-item expanded "><a href="../../contents/student-project-14_group-NullHypothesisEvaluationCriteria/00_distributed_combinatorial_bandit.html"><strong aria-hidden="true">14.</strong> Student-project-14_group-NullHypothesisEvaluationCriteria_00_distributed_combinatorial_bandit</a></li><li class="spacer"></li><li class="chapter-item expanded "><a href="../../contents/student-project-15_group-FinancialDataStreams/00_video.html"><strong aria-hidden="true">15.</strong> Student-project-15_group-FinancialDataStreams_00_video</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/student-project-15_group-FinancialDataStreams/01_rl_intraday_trading.html"><strong aria-hidden="true">15.1.</strong> 01_rl_intraday_trading</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html"><strong aria-hidden="true">15.2.</strong> 02_rl_intraday_trading_elephas</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-15_group-FinancialDataStreams/03_resources.html"><strong aria-hidden="true">15.3.</strong> 03_resources</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../contents/student-project-16_group-IntrusionDetection/00_Introduction.html"><strong aria-hidden="true">16.</strong> Student-project-16_group-IntrusionDetection_00_Introduction</a></li><li class="spacer"></li><li class="chapter-item expanded "><a href="../../contents/student-project-17_group-TowardsScalableTDA/00_introduction.html"><strong aria-hidden="true">17.</strong> Student-project-17_group-TowardsScalableTDA_00_introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/student-project-17_group-TowardsScalableTDA/01_methodology.html"><strong aria-hidden="true">17.1.</strong> 01_methodology</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-17_group-TowardsScalableTDA/02_gaussian_analysis.html"><strong aria-hidden="true">17.2.</strong> 02_gaussian_analysis</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-17_group-TowardsScalableTDA/03_robotics_dataset.html"><strong aria-hidden="true">17.3.</strong> 03_robotics_dataset</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../contents/student-project-18_group-ProjectRL/00_Problem_Description.html"><strong aria-hidden="true">18.</strong> Student-project-18_group-ProjectRL_00_Problem_Description</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/student-project-18_group-ProjectRL/01_The_ALS_method.html"><strong aria-hidden="true">18.1.</strong> 01_The_ALS_method</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-18_group-ProjectRL/02_Extensions.html"><strong aria-hidden="true">18.2.</strong> 02_Extensions</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../contents/student-project-19_group-Featuring/01_FundamentalMatrix.html"><strong aria-hidden="true">19.</strong> Student-project-19_group-Featuring_01_FundamentalMatrix</a></li><li class="spacer"></li><li class="chapter-item expanded "><a href="../../contents/student-project-20_group-Generalization/01_Background.html"><strong aria-hidden="true">20.</strong> Student-project-20_group-Generalization_01_Background</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/student-project-20_group-Generalization/02_Random_Forest.html"><strong aria-hidden="true">20.1.</strong> 02_Random_Forest</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-20_group-Generalization/03_CNN_MNIST.html"><strong aria-hidden="true">20.2.</strong> 03_CNN_MNIST</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-20_group-Generalization/04_CNN_Intel_Image.html"><strong aria-hidden="true">20.3.</strong> 04_CNN_Intel_Image</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-20_group-Generalization/05_Horovod_test.html"><strong aria-hidden="true">20.4.</strong> 05_Horovod_test</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../contents/student-project-21_group-GraphSpectralAnalysis/00_introduction.html"><strong aria-hidden="true">21.</strong> Student-project-21_group-GraphSpectralAnalysis_00_introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/student-project-21_group-GraphSpectralAnalysis/01_preprocess_data.html"><strong aria-hidden="true">21.1.</strong> 01_preprocess_data</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-21_group-GraphSpectralAnalysis/02_generate_graphs.html"><strong aria-hidden="true">21.2.</strong> 02_generate_graphs</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-21_group-GraphSpectralAnalysis/03_compute_rsvd.html"><strong aria-hidden="true">21.3.</strong> 03_compute_rsvd.</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-21_group-GraphSpectralAnalysis/04_analyse_eigenvalues.html"><strong aria-hidden="true">21.4.</strong> 04_analyse_eigenvalues</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../contents/student-project-22_group-SwapWithDDP/00_Introduction.html"><strong aria-hidden="true">22.</strong> Student-project-22_group-SwapWithDDP_00_Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/student-project-22_group-SwapWithDDP/01_SWAP_with_DDP.html"><strong aria-hidden="true">22.1.</strong> 01_SWAP_with_DDP</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../contents/voluntary-student-project-01_group-DDLInMining/00_Introduction.html"><strong aria-hidden="true">23.</strong> Voluntary-student-project-01_group-DDLInMining_00_Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/voluntary-student-project-01_group-DDLInMining/01_ImageSegmentation_UNet.html"><strong aria-hidden="true">23.1.</strong> 01_ImageSegmentation_UNet</a></li><li class="chapter-item expanded "><a href="../../contents/voluntary-student-project-01_group-DDLInMining/02_ImageSegmenation_PSPNet.html"><strong aria-hidden="true">23.2.</strong> 02_ImageSegmenation_PSPNet</a></li><li class="chapter-item expanded "><a href="../../contents/voluntary-student-project-01_group-DDLInMining/03_ICNet_Function.html"><strong aria-hidden="true">23.3.</strong> 03_ICNet_Function</a></li><li class="chapter-item expanded "><a href="../../contents/voluntary-student-project-01_group-DDLInMining/04_ICNet_Function_hvd.html"><strong aria-hidden="true">23.4.</strong> 04_ICNet_Function_hvd</a></li><li class="chapter-item expanded "><a href="../../contents/voluntary-student-project-01_group-DDLInMining/05_ICNet_Function_Tuning_parallel.html"><strong aria-hidden="true">23.5.</strong> 05_ICNet_Function_Tuning_parallel</a></li><li class="chapter-item expanded "><a href="../../contents/voluntary-student-project-01_group-DDLInMining/XX_ICNet_Class.html"><strong aria-hidden="true">23.6.</strong> XX_ICNet_Class</a></li><li class="chapter-item expanded "><a href="../../contents/voluntary-student-project-01_group-DDLInMining/XX_ICNet_Function_hvd_tuning.html"><strong aria-hidden="true">23.7.</strong> XX_ICNet_Function_hvd_tuning</a></li><li class="chapter-item expanded "><a href="../../contents/voluntary-student-project-01_group-DDLInMining/XX_ImageSegmentation_ICNet.html"><strong aria-hidden="true">23.8.</strong> XX_ImageSegmentation_ICNet</a></li><li class="chapter-item expanded "><a href="../../contents/voluntary-student-project-01_group-DDLInMining/XXNOTWORKING_ICNet_Function_Tuning.html"><strong aria-hidden="true">23.9.</strong> XXNOTWORKING_ICNet_Function_Tuning</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">sds-3.x/ScaDaMaLe</h1>

                    <div class="right-buttons">
                        <a href="../../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <div class="cell markdown">
<p>ScaDaMaLe Course <a href="https://lamastex.github.io/scalable-data-science/sds/3/x/">site</a> and <a href="https://lamastex.github.io/ScaDaMaLe/index.html">book</a></p>
</div>
<div class="cell markdown">
<h2 id="prediction-with-linear-regression-lr-model"><a class="header" href="#prediction-with-linear-regression-lr-model">Prediction with Linear Regression (LR) Model</a></h2>
</div>
<div class="cell markdown">
<p>In this model, we use scala to process the data and predict the total cases. In this data set, there are many features which are constant for each country and donâ€™t change with time. So, we tried to predict the total cases on a selected date, from some countries to other countries, without considering the time series.</p>
</div>
<div class="cell markdown">
<ol>
<li>Import data and preprocess</li>
</ol>
<hr />
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// You need to uncomment this line if you haven't preprocess data yet.

%run &quot;./02_DataPreprocess&quot;
</code></pre>
</div>
<div class="cell markdown">
<ol start="2">
<li>Data process</li>
</ol>
<hr />
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">display(df_cleaned_time_series)
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="true">
<pre><code class="language-scala">df_cleaned_time_series.printSchema
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>root
 |-- iso_code: string (nullable = true)
 |-- continent: string (nullable = false)
 |-- location: string (nullable = true)
 |-- date: string (nullable = true)
 |-- total_cases: double (nullable = false)
 |-- new_cases: double (nullable = true)
 |-- new_cases_smoothed: double (nullable = false)
 |-- total_deaths: double (nullable = false)
 |-- new_deaths: double (nullable = true)
 |-- new_deaths_smoothed: double (nullable = false)
 |-- reproduction_rate: double (nullable = false)
 |-- icu_patients: double (nullable = true)
 |-- icu_patients_per_million: double (nullable = true)
 |-- hosp_patients: double (nullable = true)
 |-- hosp_patients_per_million: double (nullable = true)
 |-- weekly_icu_admissions: double (nullable = true)
 |-- weekly_icu_admissions_per_million: double (nullable = true)
 |-- weekly_hosp_admissions: double (nullable = true)
 |-- weekly_hosp_admissions_per_million: double (nullable = true)
 |-- total_tests: double (nullable = false)
 |-- new_tests: double (nullable = true)
 |-- total_tests_per_thousand: double (nullable = true)
 |-- new_tests_per_thousand: double (nullable = true)
 |-- new_tests_smoothed: double (nullable = true)
 |-- new_tests_smoothed_per_thousand: double (nullable = true)
 |-- tests_per_case: double (nullable = true)
 |-- positive_rate: double (nullable = true)
 |-- tests_units: double (nullable = true)
 |-- stringency_index: double (nullable = false)
 |-- population: double (nullable = true)
 |-- population_density: double (nullable = true)
 |-- median_age: double (nullable = true)
 |-- aged_65_older: double (nullable = true)
 |-- aged_70_older: double (nullable = true)
 |-- gdp_per_capita: double (nullable = true)
 |-- extreme_poverty: double (nullable = true)
 |-- cardiovasc_death_rate: double (nullable = true)
 |-- diabetes_prevalence: double (nullable = true)
 |-- female_smokers: double (nullable = true)
 |-- male_smokers: double (nullable = true)
 |-- handwashing_facilities: double (nullable = true)
 |-- hospital_beds_per_thousand: double (nullable = true)
 |-- life_expectancy: double (nullable = true)
 |-- human_development_index: double (nullable = true)
 |-- total_cases_per_million: double (nullable = true)
 |-- new_cases_per_million: double (nullable = true)
 |-- new_cases_smoothed_per_million: double (nullable = true)
 |-- total_deaths_per_million: double (nullable = true)
 |-- new_deaths_per_million: double (nullable = true)
 |-- new_deaths_smoothed_per_million: double (nullable = true)
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="true">
<pre><code class="language-scala">import org.apache.spark.sql.functions._

for (c &lt;- df_cleaned_time_series.columns) {
  println(c + &quot;: &quot; + df_cleaned_time_series.filter(col(c).isNull).count())
}
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>iso_code: 0
continent: 0
location: 0
date: 0
total_cases: 0
new_cases: 0
new_cases_smoothed: 0
total_deaths: 0
new_deaths: 0
new_deaths_smoothed: 0
reproduction_rate: 0
icu_patients: 36018
icu_patients_per_million: 36018
hosp_patients: 34870
hosp_patients_per_million: 34870
weekly_icu_admissions: 41062
weekly_icu_admissions_per_million: 41062
weekly_hosp_admissions: 40715
weekly_hosp_admissions_per_million: 40715
total_tests: 0
new_tests: 20510
total_tests_per_thousand: 0
new_tests_per_thousand: 20510
new_tests_smoothed: 18176
new_tests_smoothed_per_thousand: 18176
tests_per_case: 19301
positive_rate: 19749
tests_units: 41600
stringency_index: 0
population: 0
population_density: 0
median_age: 0
aged_65_older: 0
aged_70_older: 0
gdp_per_capita: 0
extreme_poverty: 11168
cardiovasc_death_rate: 0
diabetes_prevalence: 0
female_smokers: 0
male_smokers: 0
handwashing_facilities: 24124
hospital_beds_per_thousand: 0
life_expectancy: 0
human_development_index: 0
total_cases_per_million: 0
new_cases_per_million: 0
new_cases_smoothed_per_million: 0
total_deaths_per_million: 0
new_deaths_per_million: 0
new_deaths_smoothed_per_million: 0
import org.apache.spark.sql.functions._
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Prepare the data for training. We choose a day we want to predict, and select the constant features, and select the target column for prediction.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val df_by_location = df_cleaned_time_series.filter($&quot;date&quot; === &quot;2020-12-01&quot;).sort($&quot;continent&quot;).select($&quot;iso_code&quot;,$&quot;stringency_index&quot;, $&quot;population&quot;,$&quot;population_density&quot;,$&quot;gdp_per_capita&quot;,$&quot;diabetes_prevalence&quot;,$&quot;total_cases_per_million&quot;,$&quot;total_cases&quot;)
display(df_by_location)
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">df_by_location.count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res145: Long = 159
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Rescale the feature values and the target value.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">import org.apache.spark.sql.functions._
import org.apache.spark.sql.Column
val min_str_index = df_by_location.select(min($&quot;stringency_index&quot;)).first()(0)
val max_str_index = df_by_location.select(max($&quot;stringency_index&quot;)).first()(0)
val min_population = df_by_location.select(min($&quot;population&quot;)).first()(0)
val max_population = df_by_location.select(max($&quot;population&quot;)).first()(0)
val min_population_density = 
df_by_location.select(min($&quot;population_density&quot;)).first()(0)
val max_population_density = 
df_by_location.select(max($&quot;population_density&quot;)).first()(0)
val min_gdp_per_capita = df_by_location.select(min($&quot;gdp_per_capita&quot;)).first()(0)
val max_gdp_per_capita = df_by_location.select(max($&quot;gdp_per_capita&quot;)).first()(0)
val min_diabetes_prevalence = 
df_by_location.select(min($&quot;diabetes_prevalence&quot;)).first()(0)
val max_diabetes_prevalence = df_by_location.select(max($&quot;diabetes_prevalence&quot;)).first()(0)

val df_by_location_normalized = df_by_location
  .withColumn(&quot;normal_stringency_index&quot;,($&quot;stringency_index&quot; -lit(min_str_index))/(lit(max_str_index)-lit(min_str_index)))
  .withColumn(&quot;normal_population&quot;, ($&quot;population&quot; - lit(min_population))/(lit(max_population)-lit(min_population)))
  .withColumn(&quot;normal_population_density&quot;,($&quot;population_density&quot; - lit(min_population_density))/(lit(max_population_density) - lit(min_population_density)))
  .withColumn(&quot;normal_gdp_per_capita&quot;, ($&quot;gdp_per_capita&quot; - lit(min_gdp_per_capita))/(lit(max_gdp_per_capita)- lit(min_gdp_per_capita)))
  .withColumn(&quot;normal_diabetes_prevalence&quot;, ($&quot;diabetes_prevalence&quot; - lit(min_diabetes_prevalence))/lit(max_diabetes_prevalence) - lit(min_diabetes_prevalence)).withColumn(&quot;log_total_cases_per_million&quot;, log($&quot;total_cases_per_million&quot;)).toDF
display(df_by_location_normalized)
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">df_by_location_normalized.printSchema
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>root
 |-- iso_code: string (nullable = true)
 |-- stringency_index: double (nullable = false)
 |-- population: double (nullable = true)
 |-- population_density: double (nullable = true)
 |-- gdp_per_capita: double (nullable = true)
 |-- diabetes_prevalence: double (nullable = true)
 |-- total_cases_per_million: double (nullable = true)
 |-- total_cases: double (nullable = false)
 |-- normal_stringency_index: double (nullable = true)
 |-- normal_population: double (nullable = true)
 |-- normal_population_density: double (nullable = true)
 |-- normal_gdp_per_capita: double (nullable = true)
 |-- normal_diabetes_prevalence: double (nullable = true)
 |-- log_total_cases_per_million: double (nullable = true)
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val df_by_location_normalized_selected = df_by_location_normalized.select($&quot;normal_stringency_index&quot;,$&quot;normal_population&quot;,$&quot;normal_population_density&quot;,$&quot;normal_gdp_per_capita&quot;, $&quot;normal_diabetes_prevalence&quot;,$&quot;log_total_cases_per_million&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>df_by_location_normalized_selected: org.apache.spark.sql.DataFrame = [normal_stringency_index: double, normal_population: double ... 4 more fields]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">display(df_by_location_normalized_selected)
</code></pre>
</div>
<div class="cell markdown">
<ol start="3">
<li>Linear Regression from selected value to new cases</li>
</ol>
<hr />
<p>These values are irrelevant to time, but relevant to country. So we try to predict the total case in some contries from the data in other contries.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">df_by_location_normalized_selected.createOrReplaceTempView(&quot;covid_table&quot;)
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">import org.apache.spark.ml.feature.VectorAssembler

val vectorizer =  new VectorAssembler()
.setInputCols(Array(&quot;normal_stringency_index&quot;, &quot;normal_population&quot;, &quot;normal_population_density&quot;, &quot;normal_gdp_per_capita&quot;, &quot;normal_diabetes_prevalence&quot;))
.setOutputCol(&quot;features&quot;)

// make a DataFrame called dataset from the table
val dataset = vectorizer.transform(df_by_location_normalized_selected).select(&quot;features&quot;,&quot;log_total_cases_per_million&quot;) 
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>import org.apache.spark.ml.feature.VectorAssembler
vectorizer: org.apache.spark.ml.feature.VectorAssembler = VectorAssembler: uid=vecAssembler_a8c5337c1334, handleInvalid=error, numInputCols=5
dataset: org.apache.spark.sql.DataFrame = [features: vector, log_total_cases_per_million: double]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">display(dataset)
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">var Array(split20, split80) = dataset.randomSplit(Array(0.20, 0.80), 1800009193L)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>split20: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [features: vector, log_total_cases_per_million: double]
split80: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [features: vector, log_total_cases_per_million: double]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val testSet = split20.cache()

val trainingSet = split80.cache()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>testSet: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [features: vector, log_total_cases_per_million: double]
trainingSet: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [features: vector, log_total_cases_per_million: double]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">testSet.count() // action to actually cache
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res156: Long = 26
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">trainingSet.count() // action to actually cache
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res157: Long = 133
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">import org.apache.spark.ml.regression.LinearRegression
import org.apache.spark.ml.regression.LinearRegressionModel
import org.apache.spark.ml.Pipeline

// Let's initialize our linear regression learner
val lr = new LinearRegression()
// We use explain params to dump the parameters we can use
lr.explainParams()
// Now we set the parameters for the method
lr.setPredictionCol(&quot;prediction&quot;)
  .setLabelCol(&quot;log_total_cases_per_million&quot;)
  .setMaxIter(100)
  .setRegParam(0.1)
val lrModel = lr.fit(trainingSet)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>import org.apache.spark.ml.regression.LinearRegression
import org.apache.spark.ml.regression.LinearRegressionModel
import org.apache.spark.ml.Pipeline
lr: org.apache.spark.ml.regression.LinearRegression = linReg_04758f25dc55
lrModel: org.apache.spark.ml.regression.LinearRegressionModel = LinearRegressionModel: uid=linReg_04758f25dc55, numFeatures=5
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val trainingSummary = lrModel.summary

println(s&quot;Coefficients: ${lrModel.coefficients}, Intercept: ${lrModel.intercept}&quot;)
println(s&quot;RMSE: ${trainingSummary.rootMeanSquaredError}&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>Coefficients: [2.6214237261445112,-1.3643062210132013,-1.3234981005291635,4.903123743799173,1.0283056897021852], Intercept: 6.691449394053385
RMSE: 1.605896246405295
trainingSummary: org.apache.spark.ml.regression.LinearRegressionTrainingSummary = org.apache.spark.ml.regression.LinearRegressionTrainingSummary@3c0bba63
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="true">
<pre><code class="language-scala">import org.apache.spark.ml.evaluation.RegressionEvaluator

// make predictions on the test data
val predictions = lrModel.transform(testSet)
predictions.select(&quot;prediction&quot;, &quot;log_total_cases_per_million&quot;, &quot;features&quot;).show()

// select (prediction, true label) and compute test error.
val evaluator = new RegressionEvaluator()
  .setLabelCol(&quot;log_total_cases_per_million&quot;)
  .setPredictionCol(&quot;prediction&quot;)
  .setMetricName(&quot;rmse&quot;)
val rmse = evaluator.evaluate(predictions)
println(s&quot;Root Mean Squared Error (RMSE) on test data = $rmse&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+------------------+---------------------------+--------------------+
|        prediction|log_total_cases_per_million|            features|
+------------------+---------------------------+--------------------+
| 6.328494753118636|          2.142543078223737|[0.15958180147058...|
| 8.115061043502033|          7.528810569839765|[0.36167279411764...|
| 7.462997808492604|          6.223671398897003|[0.64889705882352...|
| 7.831137150153838|          6.524287884057365|[0.79779411764705...|
|10.269420769779092|          5.843997267897207|[0.40429687499999...|
| 7.289562258542376|         2.6304048908829563|[0.49471507352941...|
| 9.963465130096218|          9.237218853465539|[0.57444852941176...|
|13.213369998258539|         10.784078124343976|[0.74460018382352...|
| 9.213228147281598|         10.572977149641726|[0.75528492647058...|
| 9.085379666714474|          9.143147511395949|[0.82444852941176...|
| 6.750739656770235|         10.952187342908323|[0.0,3.6806047717...|
| 8.135800825140628|         10.373288860272808|[0.51056985294117...|
| 7.507644816227425|         10.203096222487993|[0.55319393382352...|
|10.048805671611257|          8.817232647019427|[0.56376378676470...|
| 9.404481665413662|         10.158884909113675|[0.61695772058823...|
| 9.488257390217875|         10.351014339169227|[0.64889705882352...|
|  9.08870238448793|         10.291011744026449|[0.71806066176470...|
| 8.899278092318433|         10.041688001727678|[0.72334558823529...|
| 8.899278092318433|         10.041688001727678|[0.72334558823529...|
| 9.353065533403424|          9.427461709192647|[0.75528492647058...|
+------------------+---------------------------+--------------------+
only showing top 20 rows

Root Mean Squared Error (RMSE) on test data = 2.2259062146564705
import org.apache.spark.ml.evaluation.RegressionEvaluator
predictions: org.apache.spark.sql.DataFrame = [features: vector, log_total_cases_per_million: double ... 1 more field]
evaluator: org.apache.spark.ml.evaluation.RegressionEvaluator = RegressionEvaluator: uid=regEval_575198e0fd5f, metricName=rmse, throughOrigin=false
rmse: Double = 2.2259062146564705
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val predictions = lrModel.transform(testSet)
display(predictions)
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val new_predictions = predictions.withColumn(&quot;new_prediction&quot;, exp($&quot;prediction&quot;)).withColumn(&quot;total_cases_per_million&quot;,exp($&quot;log_total_cases_per_million&quot;)).select(&quot;new_prediction&quot;, &quot;total_cases_per_million&quot;, &quot;features&quot;)
display(new_predictions)
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// select (prediction, true label) and compute test error.
val evaluator = new RegressionEvaluator()
  .setLabelCol(&quot;total_cases_per_million&quot;)
  .setPredictionCol(&quot;new_prediction&quot;)
  .setMetricName(&quot;rmse&quot;)
val rmse = evaluator.evaluate(new_predictions)
println(&quot;Root Mean Squared Error (RMSE) on test data = $rmse&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>Root Mean Squared Error (RMSE) on test data = $rmse
evaluator: org.apache.spark.ml.evaluation.RegressionEvaluator = RegressionEvaluator: uid=regEval_dcf763c5af79, metricName=rmse, throughOrigin=false
rmse: Double = 99893.56063834814
</code></pre>
</div>
</div>
<div class="cell markdown">
<ol start="4">
<li>Conclusion and Reflections</li>
</ol>
<hr />
</div>
<div class="cell markdown">
<p>We've tried several ways to preprocess the consant feature, but still didn't get a good result. We came to the conclusion that only predict the total cases of a country from other countries without considering the history time series values are not resonable. This is because the constant feature columns cannot reflect the total cases well. Therefore, we decided to use some time series methods to predict the value from the history value.</p>
</div>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../../contents/student-project-12_group-CovidPandemic/05_Clustering.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next" href="../../contents/student-project-12_group-CovidPandemic/07_DataPredicton_ARIMA.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../../contents/student-project-12_group-CovidPandemic/05_Clustering.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next" href="../../contents/student-project-12_group-CovidPandemic/07_DataPredicton_ARIMA.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="../../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="../../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->


    </body>
</html>

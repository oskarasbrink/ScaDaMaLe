<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>student-project-07_group-ExpsZerOInit_00_introduction_resnet - sds-3.x/ScaDaMaLe</title>


        <!-- Custom HTML head -->

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="../../../favicon.svg">
        <link rel="shortcut icon" href="../../../favicon.png">
        <link rel="stylesheet" href="../../../css/variables.css">
        <link rel="stylesheet" href="../../../css/general.css">
        <link rel="stylesheet" href="../../../css/chrome.css">
        <link rel="stylesheet" href="../../../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../../../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../../../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../../../highlight.css">
        <link rel="stylesheet" href="../../../tomorrow-night.css">
        <link rel="stylesheet" href="../../../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../../../scroll-mdbook-outputs.css">

        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../../../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/00_Introduction.html"><strong aria-hidden="true">1.</strong> student-project-01_group-GraphOfWiki_00_Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/01_DataLoading_redirectsTable.html"><strong aria-hidden="true">1.1.</strong> 01_DataLoading_redirectsTable</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/02_DataLoading_pagesTable.html"><strong aria-hidden="true">1.2.</strong> 02_DataLoading_pagesTable</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/03_DataLoading_pagelinksTable.html"><strong aria-hidden="true">1.3.</strong> 03_DataLoading_pagelinksTable</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/04_DataLoading_categorylinksTable.html"><strong aria-hidden="true">1.4.</strong> 04_DataLoading_categorylinksTable</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/05_DataLoading_categoryTable.html"><strong aria-hidden="true">1.5.</strong> 05_DataLoading_categoryTable</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/06_redirectRemoval.html"><strong aria-hidden="true">1.6.</strong> 06_redirectRemoval</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/07_createArticleGraph.html"><strong aria-hidden="true">1.7.</strong> 07_createArticleGraph</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/08_explorationArticleGraph.html"><strong aria-hidden="true">1.8.</strong> 08_explorationArticleGraph</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/09_fullGraphAnalysis.html"><strong aria-hidden="true">1.9.</strong> 09_fullGraphAnalysis</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/10_explorativeMotifs.html"><strong aria-hidden="true">1.10.</strong> 10_explorativeMotifs</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/11_conclusionDiscussionAndFutureWork.html"><strong aria-hidden="true">1.11.</strong> 11_conclusionDiscussionAndFutureWork</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/12_gameNotebookSetup.html"><strong aria-hidden="true">1.12.</strong> 12_gameNotebookSetup</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/13_gameNotebook.html"><strong aria-hidden="true">1.13.</strong> 13_gameNotebook</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-02_group-DDLOfVision/student-project-02_group-DDLOfVision/00_vqa_introduction.html"><strong aria-hidden="true">2.</strong> student-project-02_group-DDLOfVision_00_vqa_introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-02_group-DDLOfVision/student-project-02_group-DDLOfVision/01_vqa_model_training.html"><strong aria-hidden="true">2.1.</strong> 01_vqa_model_training</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-03_group-WikiKG2/student-project-03_group-WikiKG2/00_ingest_data.html"><strong aria-hidden="true">3.</strong> student-project-03_group-WikiKG2_00_ingest_data</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-03_group-WikiKG2/student-project-03_group-WikiKG2/01_fetch_descriptions.html"><strong aria-hidden="true">3.1.</strong> 01_fetch_descriptions</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-03_group-WikiKG2/student-project-03_group-WikiKG2/02_load_data.html"><strong aria-hidden="true">3.2.</strong> 02_load_data</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-03_group-WikiKG2/student-project-03_group-WikiKG2/03_data_exploration.html"><strong aria-hidden="true">3.3.</strong> 03_data_exploration</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-03_group-WikiKG2/student-project-03_group-WikiKG2/04_analysing_relation_types.html"><strong aria-hidden="true">3.4.</strong> 04_analysing_relation_types</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-03_group-WikiKG2/student-project-03_group-WikiKG2/05_motif_search.html"><strong aria-hidden="true">3.5.</strong> 05_motif_search</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-03_group-WikiKG2/student-project-03_group-WikiKG2/06_produce_pagerank_vectors.html"><strong aria-hidden="true">3.6.</strong> 06_produce_pagerank_vectors</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-03_group-WikiKG2/student-project-03_group-WikiKG2/07_pagerank_for_classification.html"><strong aria-hidden="true">3.7.</strong> 07_pagerank_for_classification</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-04_group-FedMLMedicalApp/student-project-04_group-FedMLMedicalApp/00_Notebook_Presentation.html"><strong aria-hidden="true">4.</strong> student-project-04_group-FedMLMedicalApp_00_Notebook_Presentation</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-04_group-FedMLMedicalApp/student-project-04_group-FedMLMedicalApp/01_BrainTumorSegmentation_Centralized_Training.html"><strong aria-hidden="true">4.1.</strong> 01_BrainTumorSegmentation_Centralized_Training</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-04_group-FedMLMedicalApp/student-project-04_group-FedMLMedicalApp/02_Federated_Learning_BrainTumorSegmentation.html"><strong aria-hidden="true">4.2.</strong> 02_Federated_Learning_BrainTumorSegmentation</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-04_group-FedMLMedicalApp/student-project-04_group-FedMLMedicalApp/data_upload_test.html"><strong aria-hidden="true">4.3.</strong> data_upload_test</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/00_introduction.html"><strong aria-hidden="true">5.</strong> student-project-05_group-DistOpt_00_introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/01_Bayesian_optimization.html"><strong aria-hidden="true">5.1.</strong> 01_Bayesian_optimization</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/02_Gaussian_processes.html"><strong aria-hidden="true">5.2.</strong> 02_Gaussian_processes</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/03_acquisition_functions.html"><strong aria-hidden="true">5.3.</strong> 03_acquisition_functions</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/04_scalable_Bayesian_optimization.html"><strong aria-hidden="true">5.4.</strong> 04_scalable_Bayesian_optimization</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/05_implementation_documentation.html"><strong aria-hidden="true">5.5.</strong> 05_implementation_documentation</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/06_our_implementation.html"><strong aria-hidden="true">5.6.</strong> 06_our_implementation</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/07_additional_code.html"><strong aria-hidden="true">5.7.</strong> 07_additional_code</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-07_group-ExpsZerOInit/student-project-07_group-ExpsZerOInit/00_introduction_resnet.html" class="active"><strong aria-hidden="true">6.</strong> student-project-07_group-ExpsZerOInit_00_introduction_resnet</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-07_group-ExpsZerOInit/student-project-07_group-ExpsZerOInit/01_transformer.html"><strong aria-hidden="true">6.1.</strong> 01_transformer</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-07_group-ExpsZerOInit/student-project-07_group-ExpsZerOInit/02_ddpm.html"><strong aria-hidden="true">6.2.</strong> 02_ddpm</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-08_group-WikiSearch/student-project-08_group-WikiSearch/00_Introduction.html"><strong aria-hidden="true">7.</strong> student-project-08_group-WikiSearch_00_Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-08_group-WikiSearch/student-project-08_group-WikiSearch/01_InputParsing.html"><strong aria-hidden="true">7.1.</strong> 01_InputParsing</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-08_group-WikiSearch/student-project-08_group-WikiSearch/02_PageRank.html"><strong aria-hidden="true">7.2.</strong> 02_PageRank</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-08_group-WikiSearch/student-project-08_group-WikiSearch/03_QuerySearch.html"><strong aria-hidden="true">7.3.</strong> 03_QuerySearch</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-09_group-DistEnsembles/student-project-09_group-DistEnsembles/00_Introduction.html"><strong aria-hidden="true">8.</strong> student-project-09_group-DistEnsembles_00_Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-09_group-DistEnsembles/student-project-09_group-DistEnsembles/02_Ensemble_Training.html"><strong aria-hidden="true">8.1.</strong> 02_Ensemble_Training</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-09_group-DistEnsembles/student-project-09_group-DistEnsembles/03_Ensemble_Evaluation.html"><strong aria-hidden="true">8.2.</strong> 03_Ensemble_Evaluation</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-09_group-DistEnsembles/student-project-09_group-DistEnsembles/099_extra_Ensemble.html"><strong aria-hidden="true">8.3.</strong> 099_extra_Ensemble</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-10_group-RDI/student-project-10_group-RDI/00_introduction.html"><strong aria-hidden="true">9.</strong> student-project-10_group-RDI_00_introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-10_group-RDI/student-project-10_group-RDI/01_prepare_data.html"><strong aria-hidden="true">9.1.</strong> 01_prepare_data</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-10_group-RDI/student-project-10_group-RDI/02_baseline.html"><strong aria-hidden="true">9.2.</strong> 02_baseline</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-10_group-RDI/student-project-10_group-RDI/03_single_machine.html"><strong aria-hidden="true">9.3.</strong> 03_single_machine</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-10_group-RDI/student-project-10_group-RDI/04_distributed_learning.html"><strong aria-hidden="true">9.4.</strong> 04_distributed_learning</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-11_group-CollaborativeFiltering/student-project-11_group-CollaborativeFiltering/01_Introduction.html"><strong aria-hidden="true">10.</strong> student-project-11_group-CollaborativeFiltering_01_Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-11_group-CollaborativeFiltering/student-project-11_group-CollaborativeFiltering/02_AlgorithmsBeyondALS.html"><strong aria-hidden="true">10.1.</strong> 02_AlgorithmsBeyondALS</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-11_group-CollaborativeFiltering/student-project-11_group-CollaborativeFiltering/03_Implementation.html"><strong aria-hidden="true">10.2.</strong> 03_Implementation</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-12_group-FedLearnOpt/student-project-12_group-FedLearnOpt/01_Federated_Learning_Introduction.html"><strong aria-hidden="true">11.</strong> student-project-12_group-FedLearnOpt_01_Federated_Learning_Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-12_group-FedLearnOpt/student-project-12_group-FedLearnOpt/02_Horovod_Introduction.html"><strong aria-hidden="true">11.1.</strong> 02_Horovod_Introduction</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-12_group-FedLearnOpt/student-project-12_group-FedLearnOpt/03_Implementations.html"><strong aria-hidden="true">11.2.</strong> 03_Implementations</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-13_group-DRL/student-project-13_group-DRL/00_DistributedRL.html"><strong aria-hidden="true">12.</strong> student-project-13_group-DRL_00_DistributedRL</a></li><li class="spacer"></li><li class="chapter-item expanded "><a href="../../../contents/student-project-14_group-EarthObs/student-project-14_group-EarthObs/00_Introduction.html"><strong aria-hidden="true">13.</strong> student-project-14_group-EarthObs_00_Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-14_group-EarthObs/student-project-14_group-EarthObs/01_Download_data.html"><strong aria-hidden="true">13.1.</strong> 01_Download_data</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-14_group-EarthObs/student-project-14_group-EarthObs/02_Image_preprocessing.html"><strong aria-hidden="true">13.2.</strong> 02_Image_preprocessing</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-14_group-EarthObs/student-project-14_group-EarthObs/03_Model_Architecture_and_Training.html"><strong aria-hidden="true">13.3.</strong> 03_Model_Architecture_and_Training</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-14_group-EarthObs/student-project-14_group-EarthObs/04_Prediction_And_Visualisation.html"><strong aria-hidden="true">13.4.</strong> 04_Prediction_And_Visualisation</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-14_group-EarthObs/student-project-14_group-EarthObs/05_Conclusions.html"><strong aria-hidden="true">13.5.</strong> 05_Conclusions</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-projects-BrIntSuSvConclusion/student-projects-BrIntSuSvConclusion/BrIntSuSv.html"><strong aria-hidden="true">14.</strong> student-projects-BrIntSuSvConclusion_BrIntSuSv</a></li><li class="spacer"></li><li class="chapter-item expanded "><a href="../../../editors.html"><strong aria-hidden="true">15.</strong> Editors</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">sds-3.x/ScaDaMaLe</h1>

                    <div class="right-buttons">
                        <a href="../../../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <div class="cell markdown">
<h1 id="experiments-with-zero-initialisation"><a class="header" href="#experiments-with-zero-initialisation">Experiments with ZerO initialisation</a></h1>
<p><strong>Project members:</strong></p>
<ul>
<li>Livia Qian, KTH</li>
<li>Rajmund Nagy, KTH</li>
</ul>
</div>
<div class="cell markdown">
<p><a href="https://www.youtube.com/watch?v=w1tQDg8Kz44"><img src="http://img.youtube.com/vi/w1tQDg8Kz44/0.jpg" alt="ScaDaMaLe WASP-UU 2022 - Student Group Project 07 - Experiments with ZerO initialisation" /></a></p>
</div>
<div class="cell markdown">
<h2 id="summary"><a class="header" href="#summary">Summary</a></h2>
<p>In this project, we empirically investigate the claims of a recent paper <a href="https://openreview.net/forum?id=1AxQpKmiTc"><em>ZerO Initialization: Initializing Neural Networks with only Zeros and Ones</em></a> by Jiawei Zhao, Florian Tobias Schaefer, and Anima Anandkumar (hereafter: <strong>the authors</strong>).</p>
<p>In particular, we will compare the proposed initialisation method to some standard initialization methods (<em>Xavier</em> and <em>Kaiming</em>) while training: - a ResNet-18 on <a href="https://www.cs.toronto.edu/%7Ekriz/cifar.html">CIFAR-10</a> (as in the paper), implemented with <a href="https://pytorch.org/vision/stable/index.html">torchvision</a> and the <a href="https://www.pytorchlightning.ai/">pytorch lightning</a> library, - a Transformer on <a href="https://blog.salesforceairesearch.com/the-wikitext-long-term-dependency-language-modeling-dataset/">WikiText-2</a> (as in the paper), implemented in plain <a href="https://pytorch.org">pytorch</a>, - a denoising diffusion model on CIFAR-10 (a new experiment), implemented with huggingface <a href="https://huggingface.co/docs/diffusers/index">diffusers</a>.</p>
<p>In all three cases we utilise Horovod's pytorch integration so that our experiments can run across several GPU machines on a cluster. While we do not train particularly large networks as the cluster is somewhat small, the deep learning experiments we consider typically take a long time (even weeks) to carry out in real world scenarios due to the size of the datasets and the depth of the models commonly used. Therefore, multi-GPU training is often used, usually for data parallelism (meaning that the batches are split across several nodes while the model is fully shared) but sometimes also with model parallelism (where the model itself is split across the nodes, e.g., for especially large models). In this project, we only use data parallelism as the models comfortably fit into a single GPU. Since the cluster was shared between all student groups, we only ran the first experiment on multiple GPUs and set the number of worker processes to 1 for the rest.</p>
<h2 id="background"><a class="header" href="#background">Background</a></h2>
<h4 id="standard-initialisation-techniques"><a class="header" href="#standard-initialisation-techniques">Standard initialisation techniques</a></h4>
<p>It is a widely known fact that the performance of deep neural networks can heavily depend on what values their weights are initialised to. For example, setting every weight to a constant value (such as 0) before training enforces identical weights throughout training, or may even completely prevent learning due to every gradients being zero.</p>
<p>Therefore, the standard way to initialise neural networks is to randomly sample &quot;small&quot; values around 0 for every weight \(w\):</p>
<p>\[ w \sim \mathcal{U(0-\varepsilon, 0 + \varepsilon)}\ .\]</p>
<p>One of the common methods, called <em>Xavier initialisation</em>, sets \(\varepsilon\) such that</p>
<p>\[ w \sim  \mathcal{U\Bigg(-\frac{\sqrt{6}}{\sqrt{n + m}}, -\frac{\sqrt{6}}{\sqrt{n + m}}\Bigg)}\ ,\]</p>
<p>where \(n\) and \(m\) are the size of the layer \(w\) is in, and the size of the next layer, respectively. Another well-known method is the <em>Kaiming</em> or <em>He initialisation</em>, which (reusing the definition of \(n\) from earlier) samples the weights as follows:</p>
<p>\[ w \sim \mathcal{N}\Bigg(0, \frac{2}{n}\Bigg)\ .\]</p>
<p>Deep learning libraries such as Pytorch and Tensorflow automatically apply variants of these two methods.</p>
<h4 id="drawbacks-and-the-role-of-batchnorm"><a class="header" href="#drawbacks-and-the-role-of-batchnorm">Drawbacks and the role of BatchNorm</a></h4>
<p>Even though Xavier and He initialisation are widely adopted to this day, research in the past few years has shown that they are not optimal in many scenarios. For example, with the default initialisation strategies, saturating nonlinearities (such as <em>sigmoid</em> or <em>tanh</em>) are often difficult to train with, and lower learning rates must be used in general <a href="https://arxiv.org/abs/1502.03167">(Ioffe and Szegedy, 2015)</a> to avoid unstable learning curves.</p>
<p>One way to avoid these problems is to use batch normalisation <a href="https://arxiv.org/abs/1502.03167">(Ioffe and Szegedy, 2015)</a>, an essential technique that allows one to use larger learning rates (speeding up the training process significantly) and enhances generalisation. However, batch normalisation has several drawbacks: it is computationally expensive; it can limit the expressivity of the model <a href="https://arxiv.org/abs/1912.04958">(Karras et al., 2019)</a>; and it introduces an undesired (probabilistic) dependency between datapoints of the same batch.</p>
<p><a href="https://arxiv.org/abs/1901.09321">Zhang et al.</a> showed that <em>Fixup initialisation</em> can also eliminate the above problems simply by changing the initialisation slightly. Furthermore, they find that they can match the performance of batch-normalised networks by adding a scalar multiplier and a scalar bias variable in place of the normalisation. For a literature review on similar, more modern initialisation techniques, we refer the reader to the <a href="https://openreview.net/forum?id=1AxQpKmiTc">ZerO paper</a>.</p>
</div>
<div class="cell markdown">
<h2 id="method"><a class="header" href="#method">Method</a></h2>
<p>The authors propose <em>ZerO initialisation</em>: a fully deterministic technique that fills up the weight matrices with only zeros and ones (or ones and minus ones scaled by a factor). They claim that networks initialised with ZerO can match (even outperform) the performance of networks initialisated with the default methods, and batch normalisation can be replaced with initialisation with the aforementioned scalar variables as well. Additionally, by the virtue of being deterministic, ZerO enables better reproducibility of the training process and the authors report that the method results in low-rank, sparse representations.</p>
</div>
<div class="cell markdown">
<p>Mathematically, ZerO uses two concepts from linear algebra. First, the <strong>partial identity matrix</strong> \(\mathbf{I}^\star \in \mathbb{R}^{n \times m}\), defined as:</p>
<p><img src="https://i.imgur.com/Gf6Lr4E.png" alt="" /></p>
<p>We implement a function that returns the partial identity matrix of a given size:</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">import torch
from torch import nn
from scipy.linalg import hadamard
import numpy as np

def partial_identity(out_dim, in_dim):
    &quot;&quot;&quot;Return the partial identity matrix with shape `out_dim` x `in_dim`.&quot;&quot;&quot;
    if out_dim &lt; in_dim:
        I = torch.eye(out_dim)
        O = torch.zeros(out_dim, (in_dim - out_dim))

        return torch.cat((I, O), 1)
    
    elif out_dim == in_dim:
        return torch.eye(out_dim)
    
    else:
        I = torch.eye(in_dim)
        O = torch.zeros((out_dim - in_dim), in_dim)
        return torch.cat((I, O), 0)
</code></pre>
</div>
<div class="cell markdown">
<p>The second prerequisite concept for ZerO is the <strong>Hadamard matrix</strong>, which is a matrix consisting of 1 and -1 entries, defined recursively as follows:</p>
<p><img src="https://i.imgur.com/y0CFb9f.png" alt="" /></p>
<p>with \(\mathbf{H}_0 := 1\).</p>
<p>Note that \(\mathbf{H}\) must be an n-by-n matrix where n is a multiple of two. To construct a Hadamard matrix, we will simply use the scipy library.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">from scipy.linalg import hadamard
</code></pre>
</div>
<div class="cell markdown">
<p>Now have everything we need to define ZerO initialisation. Below, we show the definition for initialising convolutional layers, but we note that the initialisation can be applied to linear layers in the same manner, disregarding the <code>n</code> indices.</p>
<p><img src="https://i.imgur.com/UCNaG2A.png" alt="" /></p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">def zerO_init_conv_layer_(weight):
    &quot;&quot;&quot;
    In-place initialise the given convolutional layer with zerO-init 
    using the following equation:
    ---------------------------------
    W[:,:,n,n] := c * I_p * H_m * I_p
    ---------------------------------
     where W:   out_dim x in_dim x n_filters
           I_p: out_dim x m  (partial identity)
           H_m: m x m        (Hadamard matrix)
           I_p: m x in_dim   (partial identity)
    &quot;&quot;&quot;
    out_dim, in_dim, k = weight.shape[:3]
    n = int(np.floor(k / 2))
    
    if out_dim == in_dim:
        weight.data[..., n, n] = torch.eye(in_dim)
    elif out_dim &lt; in_dim:
        weight.data[..., n, n] = partial_identity(out_dim, in_dim).type_as(weight)
    else:
        m = int(np.ceil(np.log2(out_dim)))
        c = 2 ** (-(m - 1) / 2)

        H = lambda dim: torch.tensor(hadamard(dim)).type_as(weight)
        I = lambda outd, ind: partial_identity(outd, ind).type_as(weight)
        
        # NOTE: scipy's hadamard function differs from the paper's definition
        #       in that we need to pass 2^m as its size input instead of m
        weight.data[..., n, n] = (
            c * I(out_dim, 2**m) @ H(2**m) @ I(2**m, in_dim)
        )
</code></pre>
</div>
<div class="cell markdown">
<h2 id="experiment-1-resnet-18-on-cifar-10"><a class="header" href="#experiment-1-resnet-18-on-cifar-10">Experiment 1: ResNet-18 on CIFAR-10</a></h2>
<p>In this notebook, we will compare ZerO with the default initialisation using ResNet-18 and CIFAR-10 in the framework of an image classification task. For this architecture, the authors initialised all convolutional layers (except the last one in in each residual block) with ZerO. We follow the instructions in our implementation below:</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">from torchvision import models

def create_model(init_mode: str):
    &quot;&quot;&quot;
    The original Torchvision implementation of ResNet-18 was adapted to ImageNet 1k;
    we need to change the number of classes to 10,
    and change the first convolutional layer to a 3x3 convolution with a stride and padding of 1.
    
    Moreover, the layers should be initialized according to the initialization method requested.
    In Torchvision, the default initialization of ResNet-18's convolutional layers is kaiming_uniform_.
    &quot;&quot;&quot;
    model = models.resnet18(weights=None, num_classes=10)
    model.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    
    for m in model.modules():
        if isinstance(m, (nn.Conv2d, nn.Linear)):
            if init_mode == &quot;kaiming&quot;:
                nn.init.kaiming_normal_(m.weight, mode=&quot;fan_out&quot;, nonlinearity=&quot;relu&quot;)
            elif init_mode == &quot;xavier&quot;:
                nn.init.xavier_uniform_(m.weight)
            elif init_mode == &quot;zerO&quot;:
                nn.init.zeros_(m.weight)
        elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
            # default batch normalisation parameters
            nn.init.constant_(m.weight, 1)
            nn.init.constant_(m.bias, 0)
    
    # Apply ZerO to convolutional layers
    if init_mode == &quot;zerO&quot;:
        for name, layer in model.named_modules():
            if isinstance(layer, nn.Conv2d):
                # Ignore last conv layer in each residual block
                if not name.endswith(&quot;.conv2&quot;):
                    zerO_init_conv_layer_(layer.weight)
                    
    return model
</code></pre>
</div>
<div class="cell markdown">
<h2 id="dataset-and-model-wrapper-classes"><a class="header" href="#dataset-and-model-wrapper-classes">Dataset and model wrapper classes</a></h2>
<p>To run the experiments, we need to implement standard boilerplate code for training the model and handling the CIFAR-10 dataset. To this end, we utilise the <a href="https://www.pytorchlightning.ai/">pytorch lightning</a> framework. Hyperparameters not mentioned by the authors are assumed to be initialised to their default value based on the <a href="https://arxiv.org/abs/1512.03385">ResNet paper</a>.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">from torchvision import transforms
from torchvision.datasets import CIFAR10
import pytorch_lightning as pl
from torch.utils.data import random_split, DataLoader
import torchmetrics
import torch.nn.functional as F
import time
import horovod as hvd
import datetime

class CIFAR10DataModule(pl.LightningDataModule):
    def __init__(
        self,
        batch_size: int = 256,
        data_dir: str = &quot;/dbfs/ml/Group_7/cifar10/&quot;,
        seed: int = 42,
    ):
        super().__init__()
        self.data_dir = data_dir
        self.batch_size = batch_size
        self.split = [45000, 5000]
        self.seed = seed
        
        # default normalization process for CIFAR-10
        self.train_transforms = transforms.Compose([
            transforms.RandomCrop(32, padding=4),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))
        ])

        self.test_transforms = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))
        ])

    def prepare_data(self):
        # download dataset
        CIFAR10(self.data_dir, train=True, download=True)
        CIFAR10(self.data_dir, train=False, download=True)
    
    def setup(self, stage=None):
        # Create train/val datasets
        if stage == 'fit' or stage is None:
            cifar_full_train = CIFAR10(self.data_dir, train=True, transform=self.train_transforms)
            self.cifar_train, _ = random_split(cifar_full_train, self.split,
                                               generator=torch.Generator().manual_seed(self.seed))
            
            # The validation dataset uses different transformations so we construct it
            # separately, but a proper split is ensured by fixing the random seed
            cifar_full_val = CIFAR10(self.data_dir, train=True, transform=self.test_transforms)
            _, self.cifar_val = random_split(cifar_full_val, self.split,
                                             generator=torch.Generator().manual_seed(self.seed))

        # Create test dataset
        if stage == 'test' or stage is None:
            self.cifar_test = CIFAR10(self.data_dir, train=False, transform=self.test_transforms)

    def train_dataloader(self):
        return DataLoader(self.cifar_train, batch_size=self.batch_size, shuffle=True, num_workers=4)

    def val_dataloader(self):
        return DataLoader(self.cifar_val, batch_size=self.batch_size, num_workers=4)

    def test_dataloader(self):
        return DataLoader(self.cifar_test, batch_size=self.batch_size, num_workers=4)

# ----------------------------------------------------------------------


class LitModel(pl.LightningModule):
    &quot;&quot;&quot;
    A wrapper class for the ResNet model that defines the training- and inference logic.
    The `{training|validation|test}_step` methods are called automatically by the Trainer class later.
    &quot;&quot;&quot;
    def __init__(self, model, learning_rate, use_lr_warmup):
        super().__init__()
        self.model = model
        self.learning_rate = learning_rate
        self.accuracy = torchmetrics.Accuracy(&quot;multiclass&quot;, num_classes=10)
        self.use_lr_warmup = use_lr_warmup
        
    def forward(self, x):
        return F.log_softmax(self.model(x), dim=-1)
    
    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        
        # training metrics
        preds = torch.argmax(logits, dim=1)
        acc = self.accuracy(preds, y)
        self.log('train_loss', loss, on_step=True, on_epoch=True, logger=True)
        self.log('train_acc', acc, on_step=True, on_epoch=True, logger=True)
        
        # ResNet paper re. LR: &quot;divide it by 10 at 32k and 48k iterations&quot;
        # We found that the model can be trained for half the number of iterations
        # without a major hit to the accuracy; we apply this change to save time
        if self.trainer.global_step == 8_000 or self.trainer.global_step == 12_000:
            for g in self.optimizers().param_groups:
                g['lr'] /= 10
        
        if self.trainer.global_step % 500 == 0:
            print(f&quot;[{datetime.datetime.now()}] Step {self.trainer.global_step}, loss = {loss:.2f}, acc = {acc*100:.2f}&quot;)
        return loss

    def validation_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)

        # validation metrics
        preds = torch.argmax(logits, dim=1)
        acc = self.accuracy(preds, y)
        self.log('val_loss', loss)
        self.log('val_acc', acc)
                
        return loss

    def test_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        
        # test metrics
        preds = torch.argmax(logits, dim=1)
        acc = self.accuracy(preds, y)
        self.log('test_loss', loss)
        self.log('test_acc', acc)
        return loss
    
    def configure_optimizers(self):
        # Default optimizer configuration
        optimizer = torch.optim.SGD(self.parameters(), lr=self.learning_rate, momentum=0.9, weight_decay=0.0001)
        # Warmup as suggested by the zerO init paper
        if self.use_lr_warmup:
            scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.001, total_iters=10)      
            return [optimizer], [scheduler]
        else:
            return [optimizer]
</code></pre>
</div>
<div class="cell markdown">
<h2 id="training-script"><a class="header" href="#training-script">Training script</a></h2>
<p>These are 1) a standard pytorch lightning training script that uses the Trainer class; 2) a function that evaluates all three initialisation methods with the given seed.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">from pytorch_lightning.callbacks.early_stopping import EarlyStopping
from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar, LearningRateMonitor
from pytorch_lightning.loggers.tensorboard import TensorBoardLogger
import datetime
import horovod as hvd

def train(model, datamodule, log_folder, n_steps, do_test: bool = False, use_lr_warmup = False):    
    model = LitModel(model, learning_rate=0.05, use_lr_warmup=use_lr_warmup)
    logger = TensorBoardLogger(log_folder)

    # Initialize a trainer
    trainer = pl.Trainer(max_steps=n_steps,
        strategy=&quot;horovod&quot;,
        accelerator='gpu',
        devices=1,
        callbacks=[
            # We save the best-performing model as measured by the validation accuracy
            ModelCheckpoint(monitor='val_acc', mode='max'),
            LearningRateMonitor(logging_interval='epoch'),
        ],
        logger=logger,
        enable_progress_bar=False
        )   

    # Train the model
    trainer.fit(model, datamodule)
   
    if do_test:
        # Evaluate the model on the test set
        trainer.test(ckpt_path='best', datamodule=datamodule)
        return trainer.callback_metrics[&quot;test_acc&quot;]
    else:
        # Evaluate the model on the validation set
        trainer.validate(ckpt_path='best', datamodule=datamodule)
        return trainer.callback_metrics[&quot;val_acc&quot;]

def run(datamodule, seed: int, n_steps: int, do_test: bool):
    &quot;&quot;&quot;
    A single training run for a given seed. Trains and evaluates the ResNet-18 model
    with the three initialisation methods on the same random seed.
    &quot;&quot;&quot;
    pl.seed_everything(seed)
    torch.manual_seed(seed)
    accs = dict()

    # Init our model
    model = create_model(init_mode=&quot;kaiming&quot;)
    pl.seed_everything(seed)
    torch.manual_seed(seed)
    accs[&quot;kaiming&quot;] = train(model, datamodule, log_folder=&quot;/dbfs/ml/Group_7/logs/resnet/kaiming&quot;, n_steps=n_steps, do_test=do_test).item()
    
    pl.seed_everything(seed)
    torch.manual_seed(seed)
    model = create_model(init_mode=&quot;xavier&quot;)
    pl.seed_everything(seed)
    torch.manual_seed(seed)
    accs[&quot;xavier&quot;] = train(model, datamodule, log_folder=&quot;/dbfs/ml/Group_7/logs/resnet/xavier&quot;, n_steps=n_steps, do_test=do_test).item()

    pl.seed_everything(seed)
    torch.manual_seed(seed)
    model = create_model(init_mode=&quot;zero&quot;)
    pl.seed_everything(seed)
    torch.manual_seed(seed)
    accs[&quot;zero&quot;] = train(model, datamodule, log_folder=&quot;/dbfs/ml/Group_7/logs/resnet/zero&quot;, n_steps=n_steps, do_test=do_test, use_lr_warmup=True).item()
    
    return accs
</code></pre>
</div>
<div class="cell markdown">
<h2 id="experimental-setup"><a class="header" href="#experimental-setup">Experimental setup</a></h2>
<p>We closely follow the setup of the paper's experiment, with the modification that we only train for 16000 instead of 64000 steps, with the two ResNet LR decays (originally at the 32000th and the 48000th steps) moved proportionally earlier. Training for fewer steps results in a much more efficient training process with only a marginal decrease in the accuracy (at least in the context of comparing intialisations). Furthermore, this change allows us compare the three initialisation methods (Kaiming, Xavier and ZerO) for 5 random seeds.</p>
<p>As described in the paper, we implement a 10 epoch learning rate warmup and we choose a batch size of 128, as the authors do not report the value of this parameter.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">import horovod.torch as hvd
from sparkdl import HorovodRunner
import json

def run_horovod_job():
    hvd.init()  
    torch.cuda.set_device(hvd.local_rank())
    seeds = [42, 151, 464, 3584, 6846]
    for seed in seeds:
        print(&quot;Random seed used:&quot;, seed)
        pl.seed_everything(seed)
        torch.manual_seed(seed)

        dm = CIFAR10DataModule(batch_size=128, data_dir='data-%d'% hvd.rank())
        dm.prepare_data()
        dm.setup()

        print(&quot;ZerO Init&quot;)
        accs = run(dm, seed=seed, n_steps = 16_000, do_test = True)
        if hvd.rank() == 0:
            print(accs)
            with open(&quot;results.txt&quot;, 'a') as out_file:
                out_file.write(f&quot;RANDOM SEED: {seed}&quot;)
                out_file.write(json.dumps(accs))

hr = HorovodRunner(np=2, driver_log_verbosity='all') 
hr.run(run_horovod_job)
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-load_ext">tensorboard
%tensorboard --logdir /dbfs/ml/Group_7/logs/resnet/


</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">import matplotlib.pyplot as plt
import numpy as np
import matplotlib
font = {'family' : 'normal',
        'weight' : 'bold',
        'size'   : 22}

matplotlib.rc('font', **font)

results = {&quot;kaiming&quot; : [0.9012, 0.8938, 0.8936, 0.8908, 0.899],
&quot;xavier&quot; : [0.9278, 0.918, 0.925, 0.9304, 0.9232],
&quot;zero&quot; : [0.9306, 0.9332, 0.9304, 0.9264, 0.9276]}

# Calculate the mean and standard deviation for each method
kaiming_mean = np.mean(results[&quot;kaiming&quot;])
kaiming_std = np.std(results[&quot;kaiming&quot;])
xavier_mean = np.mean(results[&quot;xavier&quot;])
xavier_std = np.std(results[&quot;xavier&quot;])
zero_mean = np.mean(results[&quot;zero&quot;])
zero_std = np.std(results[&quot;zero&quot;])

plt.figure(figsize=[6,10])
# Create the plot
plt.errorbar([1, 2, 3], [kaiming_mean, xavier_mean, zero_mean],
             yerr=[kaiming_std, xavier_std, zero_std], fmt='o', color='black',
             ecolor='lightgray', elinewidth=10, capsize=20)
plt.xticks([0.5,1,2,3,3.5], [&quot;&quot;,&quot;kaiming&quot;, &quot;xavier&quot;, &quot;zero&quot;,&quot;&quot;])
plt.tight_layout()
# Add labels and show the plot
plt.xlabel(&quot;Method&quot;)
plt.ylabel(&quot;Result&quot;)
plt.show()

</code></pre>
</div>
<div class="cell markdown">
<p>The results from the paper, for reference: <img src="http://i.imgur.com/TgzOuM3.png" alt="" /></p>
</div>
<div class="cell markdown">
<h1 id="conclusion"><a class="header" href="#conclusion">Conclusion</a></h1>
<p>Despite training for fewer steps, our results are close to the ones presented in the paper (in the form of test error). We found that the models initialised with ZerO perform best on average; the ones initialised with Kaiming are, however, significantly worse than those initialised with Xavier and ZerO, despite them being better than Xavier according to the paper. We further note that ZerO has the lowest std across the three methods, in accordance with the paper's results.</p>
</div>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/07_additional_code.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next" href="../../../contents/student-project-07_group-ExpsZerOInit/student-project-07_group-ExpsZerOInit/01_transformer.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/07_additional_code.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next" href="../../../contents/student-project-07_group-ExpsZerOInit/student-project-07_group-ExpsZerOInit/01_transformer.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="../../../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../../searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="../../../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->


    </body>
</html>

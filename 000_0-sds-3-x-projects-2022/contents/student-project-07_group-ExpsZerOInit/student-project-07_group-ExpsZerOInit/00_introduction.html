<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>student-project-07_group-ExpsZerOInit_00_introduction - sds-3.x/ScaDaMaLe</title>


        <!-- Custom HTML head -->

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="../../../favicon.svg">
        <link rel="shortcut icon" href="../../../favicon.png">
        <link rel="stylesheet" href="../../../css/variables.css">
        <link rel="stylesheet" href="../../../css/general.css">
        <link rel="stylesheet" href="../../../css/chrome.css">
        <link rel="stylesheet" href="../../../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../../../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../../../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../../../highlight.css">
        <link rel="stylesheet" href="../../../tomorrow-night.css">
        <link rel="stylesheet" href="../../../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../../../scroll-mdbook-outputs.css">

        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../../../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/00_Introduction.html"><strong aria-hidden="true">1.</strong> student-project-01_group-GraphOfWiki_00_Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/01_DataLoading_redirectsTable.html"><strong aria-hidden="true">1.1.</strong> 01_DataLoading_redirectsTable</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/02_DataLoading_pagesTable.html"><strong aria-hidden="true">1.2.</strong> 02_DataLoading_pagesTable</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/03_DataLoading_pagelinksTable.html"><strong aria-hidden="true">1.3.</strong> 03_DataLoading_pagelinksTable</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/04_DataLoading_categorylinksTable.html"><strong aria-hidden="true">1.4.</strong> 04_DataLoading_categorylinksTable</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/05_DataLoading_categoryTable.html"><strong aria-hidden="true">1.5.</strong> 05_DataLoading_categoryTable</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/06_redirectRemoval.html"><strong aria-hidden="true">1.6.</strong> 06_redirectRemoval</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/07_createArticleGraph.html"><strong aria-hidden="true">1.7.</strong> 07_createArticleGraph</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/08_explorationArticleGraph.html"><strong aria-hidden="true">1.8.</strong> 08_explorationArticleGraph</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/09_fullGraphAnalysis.html"><strong aria-hidden="true">1.9.</strong> 09_fullGraphAnalysis</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/10_explorativeMotifs.html"><strong aria-hidden="true">1.10.</strong> 10_explorativeMotifs</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/11_conclusionDiscussionAndFutureWork.html"><strong aria-hidden="true">1.11.</strong> 11_conclusionDiscussionAndFutureWork</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/12_gameNotebookSetup.html"><strong aria-hidden="true">1.12.</strong> 12_gameNotebookSetup</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/13_gameNotebook.html"><strong aria-hidden="true">1.13.</strong> 13_gameNotebook</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/99_PlanningAndNotes.html"><strong aria-hidden="true">1.14.</strong> 99_PlanningAndNotes</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-02_group-DDLOfVision/student-project-02_group-DDLOfVision/00_vqa_introduction.html"><strong aria-hidden="true">2.</strong> student-project-02_group-DDLOfVision_00_vqa_introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-02_group-DDLOfVision/student-project-02_group-DDLOfVision/01_vqa_model_training.html"><strong aria-hidden="true">2.1.</strong> 01_vqa_model_training</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-02_group-DDLOfVision/student-project-02_group-DDLOfVision/02_vqa_model_inference.html"><strong aria-hidden="true">2.2.</strong> 02_vqa_model_inference</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-02_group-DDLOfVision/student-project-02_group-DDLOfVision/0y_test_mnist-pytorch.html"><strong aria-hidden="true">2.3.</strong> 0y_test_mnist-pytorch</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-03_group-WikiKG90mv2/student-project-03_group-WikiKG90mv2/00_ingest_data.html"><strong aria-hidden="true">3.</strong> student-project-03_group-WikiKG90mv2_00_ingest_data</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-03_group-WikiKG90mv2/student-project-03_group-WikiKG90mv2/01_fetch_descriptions.html"><strong aria-hidden="true">3.1.</strong> 01_fetch_descriptions</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-03_group-WikiKG90mv2/student-project-03_group-WikiKG90mv2/02_load_data.html"><strong aria-hidden="true">3.2.</strong> 02_load_data</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-03_group-WikiKG90mv2/student-project-03_group-WikiKG90mv2/03_data_exploration.html"><strong aria-hidden="true">3.3.</strong> 03_data_exploration</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-03_group-WikiKG90mv2/student-project-03_group-WikiKG90mv2/04_analysing_relation_types.html"><strong aria-hidden="true">3.4.</strong> 04_analysing_relation_types</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-03_group-WikiKG90mv2/student-project-03_group-WikiKG90mv2/05_Motif_search_defination_code.html"><strong aria-hidden="true">3.5.</strong> 05_Motif_search_defination_code</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-03_group-WikiKG90mv2/student-project-03_group-WikiKG90mv2/06_python_analysis.html"><strong aria-hidden="true">3.6.</strong> 06_python_analysis</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-03_group-WikiKG90mv2/student-project-03_group-WikiKG90mv2/08_pagerank.html"><strong aria-hidden="true">3.7.</strong> 08_pagerank</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-03_group-WikiKG90mv2/student-project-03_group-WikiKG90mv2/09_outro_discussion.html"><strong aria-hidden="true">3.8.</strong> 09_outro_discussion</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-03_group-WikiKG90mv2/student-project-03_group-WikiKG90mv2/0x_Motif_search_defination_code.html"><strong aria-hidden="true">3.9.</strong> 0x_Motif_search_defination_code</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-03_group-WikiKG90mv2/student-project-03_group-WikiKG90mv2/10_motif_mining_WikiKGv2.html"><strong aria-hidden="true">3.10.</strong> 10_motif_mining_WikiKGv2</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-04_group-FedMLMedicalApp/student-project-04_group-FedMLMedicalApp/00_Notebook_Presentation.html"><strong aria-hidden="true">4.</strong> student-project-04_group-FedMLMedicalApp_00_Notebook_Presentation</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-04_group-FedMLMedicalApp/student-project-04_group-FedMLMedicalApp/01_BrainTumorSegmentation_Centralized_Training.html"><strong aria-hidden="true">4.1.</strong> 01_BrainTumorSegmentation_Centralized_Training</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-04_group-FedMLMedicalApp/student-project-04_group-FedMLMedicalApp/02_Federated_Learning_BrainTumorSegmentation.html"><strong aria-hidden="true">4.2.</strong> 02_Federated_Learning_BrainTumorSegmentation</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-04_group-FedMLMedicalApp/student-project-04_group-FedMLMedicalApp/data_upload_test.html"><strong aria-hidden="true">4.3.</strong> data_upload_test</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/00_introduction.html"><strong aria-hidden="true">5.</strong> student-project-05_group-DistOpt_00_introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/01_Bayesian_optimization.html"><strong aria-hidden="true">5.1.</strong> 01_Bayesian_optimization</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/02_Gaussian_processes.html"><strong aria-hidden="true">5.2.</strong> 02_Gaussian_processes</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/03_acquisition_functions.html"><strong aria-hidden="true">5.3.</strong> 03_acquisition_functions</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/04_scalable_Bayesian_optimization.html"><strong aria-hidden="true">5.4.</strong> 04_scalable_Bayesian_optimization</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/05_implementation_documentation.html"><strong aria-hidden="true">5.5.</strong> 05_implementation_documentation</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/06_our_implementation.html"><strong aria-hidden="true">5.6.</strong> 06_our_implementation</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/07_additional_code.html"><strong aria-hidden="true">5.7.</strong> 07_additional_code</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-07_group-ExpsZerOInit/student-project-07_group-ExpsZerOInit/00_introduction.html" class="active"><strong aria-hidden="true">6.</strong> student-project-07_group-ExpsZerOInit_00_introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-07_group-ExpsZerOInit/student-project-07_group-ExpsZerOInit/01_resnet.html"><strong aria-hidden="true">6.1.</strong> 01_resnet</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-08_group-WikiSearch/student-project-08_group-WikiSearch/00_Introduction.html"><strong aria-hidden="true">7.</strong> student-project-08_group-WikiSearch_00_Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-08_group-WikiSearch/student-project-08_group-WikiSearch/01_InputParsing.html"><strong aria-hidden="true">7.1.</strong> 01_InputParsing</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-08_group-WikiSearch/student-project-08_group-WikiSearch/02_PageRank.html"><strong aria-hidden="true">7.2.</strong> 02_PageRank</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-08_group-WikiSearch/student-project-08_group-WikiSearch/03_QuerySearch.html"><strong aria-hidden="true">7.3.</strong> 03_QuerySearch</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-09_group-DistEnsembles/student-project-09_group-DistEnsembles/00_Introduction.html"><strong aria-hidden="true">8.</strong> student-project-09_group-DistEnsembles_00_Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-09_group-DistEnsembles/student-project-09_group-DistEnsembles/01_Data.html"><strong aria-hidden="true">8.1.</strong> 01_Data</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-09_group-DistEnsembles/student-project-09_group-DistEnsembles/02_Main.html"><strong aria-hidden="true">8.2.</strong> 02_Main</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-09_group-DistEnsembles/student-project-09_group-DistEnsembles/02_non_distributed.html"><strong aria-hidden="true">8.3.</strong> 02_non_distributed</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-09_group-DistEnsembles/student-project-09_group-DistEnsembles/02a_Single_Model.html"><strong aria-hidden="true">8.4.</strong> 02a_Single_Model</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-09_group-DistEnsembles/student-project-09_group-DistEnsembles/03_Evaluation.html"><strong aria-hidden="true">8.5.</strong> 03_Evaluation</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-09_group-DistEnsembles/student-project-09_group-DistEnsembles/03_RDDs.html"><strong aria-hidden="true">8.6.</strong> 03_RDDs</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-09_group-DistEnsembles/student-project-09_group-DistEnsembles/03a_Ensemble.html"><strong aria-hidden="true">8.7.</strong> 03a_Ensemble</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-09_group-DistEnsembles/student-project-09_group-DistEnsembles/041_Data_Preprocessing.html"><strong aria-hidden="true">8.8.</strong> 041_Data_Preprocessing</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-10_group-RDI/student-project-10_group-RDI/00_introduction.html"><strong aria-hidden="true">9.</strong> student-project-10_group-RDI_00_introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-10_group-RDI/student-project-10_group-RDI/01_prepare_data.html"><strong aria-hidden="true">9.1.</strong> 01_prepare_data</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-10_group-RDI/student-project-10_group-RDI/02_baseline.html"><strong aria-hidden="true">9.2.</strong> 02_baseline</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-10_group-RDI/student-project-10_group-RDI/03_single_machine.html"><strong aria-hidden="true">9.3.</strong> 03_single_machine</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-10_group-RDI/student-project-10_group-RDI/04_distributed_learning.html"><strong aria-hidden="true">9.4.</strong> 04_distributed_learning</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-11_group-CollaborativeFiltering/student-project-11_group-CollaborativeFiltering/01_Introduction.html"><strong aria-hidden="true">10.</strong> student-project-11_group-CollaborativeFiltering_01_Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-11_group-CollaborativeFiltering/student-project-11_group-CollaborativeFiltering/01a_Implementation.html"><strong aria-hidden="true">10.1.</strong> 01a_Implementation</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-11_group-CollaborativeFiltering/student-project-11_group-CollaborativeFiltering/02_FirstOrderMethods.html"><strong aria-hidden="true">10.2.</strong> 02_FirstOrderMethods</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../editors.html"><strong aria-hidden="true">11.</strong> Editors</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">sds-3.x/ScaDaMaLe</h1>

                    <div class="right-buttons">
                        <a href="../../../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <div class="cell markdown">
<h1 id="experiments-with-zero-initialisation"><a class="header" href="#experiments-with-zero-initialisation">Experiments with ZerO initialisation</a></h1>
<p><strong>Project members:</strong></p>
<ul>
<li>FisrtName LastName, Institution</li>
<li>FisrtName LastName, Institution</li>
</ul>
</div>
<div class="cell markdown">
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>In this project, we empirically investigate the claims of a recent paper <a href="https://openreview.net/forum?id=1AxQpKmiTc"><em>ZerO Initialization: Initializing Neural Networks with only Zeros and Ones</em></a> by Jiawei Zhao, Florian Tobias Schaefer, and Anima Anandkumar (hereafter: <strong>the authors</strong>).</p>
<p>In particular, we will compare the proposed initialisation method to the standard Kaiming initialisation while training: - a ResNet-18 on CIFAR-10 (as in the paper); - a Transformer on WikiText-2 (as in the paper); and - a denoising diffusion model on CIFAR-10 (a new experiment).</p>
<h2 id="background"><a class="header" href="#background">Background</a></h2>
<h4 id="standard-initialisation-techniques"><a class="header" href="#standard-initialisation-techniques">Standard initialisation techniques</a></h4>
<p>It is a widely known fact that the performance of deep neural networks can heavily depend on what values their weights are initialised to. For example, setting every weight to a constant value (such as 0) before training enforces identical weights throughout training, or may even completely prevent learning due to every gradients being zero.</p>
<p>Therefore, the standard way to initialise neural networks is to randomly sample &quot;small&quot; values around 0 for every weight \(w\):</p>
<p>\[ w \sim \mathcal{U(0-\varepsilon, 0 + \varepsilon)}\ .\]</p>
<p>One of the common methods, called <em>Xavier initialisation</em>, sets \(\varepsilon\) such that</p>
<p>\[ w \sim  \mathcal{U\Bigg(-\frac{\sqrt{6}}{\sqrt{n + m}}, -\frac{\sqrt{6}}{\sqrt{n + m}}\Bigg)}\ ,\]</p>
<p>where \(n\) and \(m\) are the size of the layer \(w\) is in, and the size of the next layer, respectively. Another well-known method is the <em>Kaiming</em> or <em>He initialisation</em>, which (reusing the definition of \(n\) from earlier) samples the weights as follows:</p>
<p>\[ w \sim \mathcal{N}\Bigg(0, \frac{2}{n}\Bigg)\ .\]</p>
<p>Deep learning libraries such as Pytorch and Tensorflow automatically apply variants of these two methods.</p>
<h4 id="drawbacks-and-the-role-of-batchnorm"><a class="header" href="#drawbacks-and-the-role-of-batchnorm">Drawbacks and the role of BatchNorm</a></h4>
<p>Even though Xavier and He initialisation are widely adopted to this day, research in the past few years has shown that they are not optimal in many scenarios. For example, with the default initialisation strategies, saturating nonlinearities (such as <em>sigmoid</em> or <em>tanh</em>) are often difficult to train with, and lower learning rates must be used in general <a href="https://arxiv.org/abs/1502.03167">(Ioffe and Szegedy, 2015)</a> to avoid unstable learning curves. Batch normalisation <a href="https://arxiv.org/abs/1502.03167">(Ioffe and Szegedy, 2015)</a> is an essential technique that allows one to use larger learning rates (speeding up the training process significantly) and enhances generalisation. However, batch normalisation has several drawbacks: it is computationally expensive; it can limit the expressivity of the model <a href="https://arxiv.org/abs/1912.04958">(Karras et al., 2019)</a>; and it introduces an undesired (probabilistic) dependency between datapoints of the same batch.</p>
<p>Later, <a href="https://arxiv.org/abs/1901.09321">Zhang et al.</a> proposed <em>Fixup initialisation</em>, which eliminates the above problems simply by changing the initialisation slightly. Furthermore, they find that they can match the performance of batch-normalised networks by adding a scalar multiplier and a scalar bias variable in place of the normalisation.</p>
</div>
<div class="cell markdown">
<h2 id="method"><a class="header" href="#method">Method</a></h2>
<p>The authors propose <em>ZerO initialisation</em>: a fully deterministic technique that fills up the weight matrices with only zeros and ones. They claim that networks initialised with ZerO can match (even outperform) the performance of networks initialisated with the default methods, and batch normalisation can be replaced with the aforementioned two scalar variables as well. Additionally, by the virtue of being deterministic, ZerO enables better reproducibility of the training process and the authors report that the method results in low-rank, sparse representations.</p>
</div>
<div class="cell markdown">
<p>Mathematically, ZerO uses two concepts from linear algebra. First, the <strong>partial identity matrix</strong> \(\mathbf{I}^\star \in \mathbb{R}^{n \times m}\), defined as:</p>
<p><img src="https://i.imgur.com/Gf6Lr4E.png" alt="" /></p>
<p>We implement a function that returns the partial identity matrix of a given size:</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">import torch
from torch import nn
from scipy.linalg import hadamard
import numpy as np

def partial_identity(out_dim, in_dim):
    &quot;&quot;&quot;Return the partial identity matrix with shape `out_dim` x `in_dim`.&quot;&quot;&quot;
    if out_dim &lt; in_dim:
        I = torch.eye(out_dim)
        O = torch.zeros(out_dim, (in_dim - out_dim))

        return torch.cat((I, O), 1)
    
    elif out_dim == in_dim:
        return torch.eye(out_dim)
    
    else:
        I = torch.eye(in_dim)
        O = torch.zeros((out_dim - in_dim), in_dim)
        return torch.cat((I, O), 0)
</code></pre>
</div>
<div class="cell markdown">
<p>The second prerequisite concept for ZerO is the <strong>Hadamard matrix</strong>, which is a matrix consisting of 1 and -1 entries, defined recursively as follows:</p>
<p><img src="https://i.imgur.com/y0CFb9f.png" alt="" /></p>
<p>with \(\mathbf{H}_0 := 1\).</p>
<p>Note that \(\mathbf{H}\) must be an n-by-n matrix where n is a square number. To construct a hadamard matrix, we will simply use the scipy library.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">from scipy.linalg import hadamard
</code></pre>
</div>
<div class="cell markdown">
<p>Now have everything we need to define ZerO initialisation:</p>
<p><img src="https://i.imgur.com/UCNaG2A.png" alt="" /></p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">def zerO_init_conv_layer_(weight):
    &quot;&quot;&quot;
    In-place initialise the given convolutional layer with zerO-init 
    using the following equation:
    ---------------------------------
    W[:,:,n,n] := c * I_p * H_m * I_p
    ---------------------------------
     where W:   out_dim x in_dim x n_filters
           I_p: out_dim x m  (partial identity)
           H_m: m x m        (Hadamard matrix)
           I_p: m x in_dim   (partial identity)
    &quot;&quot;&quot;
    out_dim, in_dim, k = weight.shape[:3]
    n = int(np.floor(k / 2))
    
    if out_dim == in_dim:
        weight.data[..., n, n] = torch.eye(in_dim)
    elif out_dim &lt; in_dim:
        weight.data[..., n, n] = partial_identity(out_dim, in_dim).type_as(weight)
    else:
        m = int(np.ceil(np.log2(out_dim)))
        c = 2 ** (-(m - 1) / 2)

        H = lambda dim: torch.tensor(hadamard(dim)).type_as(weight)
        I = lambda outd, ind: partial_identity(outd, ind).type_as(weight)
        
        # NOTE: scipy's hadamard function differs from the paper's definition
        #       in that we need to pass 2^m as its size input instead of m
        weight.data[..., n, n] = (
            c * I(out_dim, 2**m) @ H(2**m) @ I(2**m, in_dim)
        )
</code></pre>
</div>
<div class="cell markdown">
<p>In this notebook, we will compare ZerO with the default initialisation using ResNet-18 and CIFAR-10. For this architecture, the authors initialised all convolutional layers (except the last one in in each residual block) with ZerO and the linear classification layer with 0 values when using ZerO. We follow the instructions in our implementation below:</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">from torchvision import models
def create_model(init_mode: str):
    &quot;&quot;&quot;
    The original ResNet-18 was adapted to ImageNet 1k; we need to change the number of classes to 10,
    change the first convolutional layer to a 3x3 convolution with a stride and padding of 1.
    
    Moreover, the layers should be initialized according to the initialization method requested.
    In Torchvision, the default initialization of ResNet-18's convolutional layers is kaiming_uniform_.
    &quot;&quot;&quot;
    model = models.resnet18(weights=None, num_classes=10)
    model.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    
    for m in model.modules():
        if isinstance(m, (nn.Conv2d, nn.Linear)):
            if init_mode == &quot;kaiming&quot;:
                nn.init.kaiming_normal_(m.weight, mode=&quot;fan_out&quot;, nonlinearity=&quot;relu&quot;)
            elif init_mode == &quot;xavier&quot;:
                nn.init.xavier_uniform_(m.weight)
            elif init_mode == &quot;zerO&quot;:
                # NOTE: we will apply ZerO at the end of this function
                nn.init.zeros_(m.weight)
        elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
            nn.init.constant_(m.weight, 1)
            nn.init.constant_(m.bias, 0)
    
    # Apply ZerO to convolutional layers
    if init_mode == &quot;zerO&quot;:
        for name, layer in model.named_modules():
            if isinstance(layer, nn.Conv2d):
                # Ignore last conv layer in each residual block
                if not name.endswith(&quot;.conv2&quot;):
                    zerO_init_conv_layer_(layer.weight)
                    
    return model
</code></pre>
</div>
<div class="cell markdown">
<h2 id="dataset-and-model-wrapper-classes"><a class="header" href="#dataset-and-model-wrapper-classes">Dataset and model wrapper classes</a></h2>
<p>To run the experiments, we need to implement standard boilerplate code for training the model and handling the CIFAR-10 dataset.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">from torchvision import transforms
from torchvision.datasets import CIFAR10
import pytorch_lightning as pl
from torch.utils.data import random_split, DataLoader
import torchmetrics
import torch.nn.functional as F
import time
import horovod as hvd
import datetime

class CIFAR10DataModule(pl.LightningDataModule):
    def __init__(
        self,
        batch_size: int = 256,
        data_dir: str = &quot;/dbfs/ml/Group_7/cifar10/&quot;,
        seed: int = 42,
    ):
        super().__init__()
        self.data_dir = data_dir
        self.batch_size = batch_size
        self.split = [45000, 5000]
        self.seed = seed
        
        # default normalization process for CIFAR-10
        self.train_transforms = transforms.Compose([
            transforms.RandomCrop(32, padding=4),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))
        ])

        self.test_transforms = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))
        ])

    def prepare_data(self):
        # download dataset
        CIFAR10(self.data_dir, train=True, download=True)
        CIFAR10(self.data_dir, train=False, download=True)
    
    def setup(self, stage=None):
        # Create train/val datasets
        if stage == 'fit' or stage is None:
            cifar_full_train = CIFAR10(self.data_dir, train=True, transform=self.train_transforms)
            self.cifar_train, _ = random_split(cifar_full_train, self.split,
                                               generator=torch.Generator().manual_seed(self.seed))
            
            # The validation dataset uses different transformations so we construct it
            # separately, but a proper split is ensured by fixing the random seed
            cifar_full_val = CIFAR10(self.data_dir, train=True, transform=self.test_transforms)
            _, self.cifar_val = random_split(cifar_full_val, self.split,
                                             generator=torch.Generator().manual_seed(self.seed))

        # Create test dataset
        if stage == 'test' or stage is None:
            self.cifar_test = CIFAR10(self.data_dir, train=False, transform=self.test_transforms)

    def train_dataloader(self):
        return DataLoader(self.cifar_train, batch_size=self.batch_size, shuffle=True, num_workers=4)

    def val_dataloader(self):
        return DataLoader(self.cifar_val, batch_size=self.batch_size, num_workers=4)

    def test_dataloader(self):
        return DataLoader(self.cifar_test, batch_size=self.batch_size, num_workers=4)

# ----------------------------------------------------------------------

class LitModel(pl.LightningModule):
    def __init__(self, model, learning_rate, use_lr_warmup):
        super().__init__()
        self.model = model
        self.learning_rate = learning_rate
        self.accuracy = torchmetrics.Accuracy(&quot;multiclass&quot;, num_classes=10)
        self.use_lr_warmup = use_lr_warmup
        
    def forward(self, x):
        return F.log_softmax(self.model(x), dim=-1)
    
    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        
        # training metrics
        preds = torch.argmax(logits, dim=1)
        acc = self.accuracy(preds, y)
        self.log('train_loss', loss, on_step=True, on_epoch=True, logger=True)
        self.log('train_acc', acc, on_step=True, on_epoch=True, logger=True)
        
        # ResNet paper re. LR: &quot;divide it by 10 at 32k and 48k iterations&quot;
        # We found that the model can be trained for half the number of iterations
        # without a major hit to the accuracy; we apply this change to save time
        if self.trainer.global_step == 8_000 or self.trainer.global_step == 12_000:
            for g in self.optimizers().param_groups:
                g['lr'] /= 10
        
        if self.trainer.global_step % 500 == 0:
            print(f&quot;[{datetime.datetime.now()}] Step {self.trainer.global_step}, loss = {loss:.2f}, acc = {acc*100:.2f}&quot;)
        return loss

    def validation_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)

        # validation metrics
        preds = torch.argmax(logits, dim=1)
        acc = self.accuracy(preds, y)
        self.log('val_loss', loss)
        self.log('val_acc', acc)
                
        return loss

    def test_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        
        # test metrics
        preds = torch.argmax(logits, dim=1)
        acc = self.accuracy(preds, y)
        self.log('test_loss', loss)
        self.log('test_acc', acc)
        return loss
    
    def configure_optimizers(self):
        # Default optimizer configuration
        optimizer = torch.optim.SGD(self.parameters(), lr=self.learning_rate, momentum=0.9, weight_decay=0.0001)
        # Warmup as suggested by the zerO init paper
        if self.use_lr_warmup:
            scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.001, total_iters=10)      
            return [optimizer], [scheduler]
        else:
            return [optimizer]
</code></pre>
</div>
<div class="cell markdown">
<h2 id="training-script"><a class="header" href="#training-script">Training script</a></h2>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">from pytorch_lightning.callbacks.early_stopping import EarlyStopping
from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar, LearningRateMonitor
from pytorch_lightning.loggers.tensorboard import TensorBoardLogger
import datetime
import horovod as hvd
def train(model, dm, log_folder, n_steps, do_test: bool = False, use_lr_warmup = False):
    
    model = LitModel(model, learning_rate=0.05, use_lr_warmup=use_lr_warmup)

    logger = TensorBoardLogger(log_folder)

    # Initialize a trainer
    trainer = pl.Trainer(max_steps=n_steps,
        strategy=&quot;horovod&quot;,
        accelerator='gpu',
        devices=1,
        callbacks=[
            # EarlyStopping(monitor=&quot;val_acc&quot;, min_delta=0.00, patience=3, verbose=False, mode=&quot;max&quot;),
            # TQDMProgressBar(refresh_rate=10),
            ModelCheckpoint(monitor='val_acc', mode='max'),
            LearningRateMonitor(logging_interval='epoch'),
        ],
        logger=logger,
        enable_progress_bar=False
        )   

    # Train the model
    trainer.fit(model, dm)
    # Evaluate the model on the validation set
   
    if do_test:
        # Evaluate the model on the test set
        trainer.test(ckpt_path='best', datamodule=dm)
        return trainer.callback_metrics[&quot;test_acc&quot;]
    else:
        trainer.validate(ckpt_path='best', datamodule=dm)
        return trainer.callback_metrics[&quot;val_acc&quot;]

def run(dm, seed: int, n_steps: int, do_test: bool):
    pl.seed_everything(seed)
    torch.manual_seed(seed)
    accs = dict()



    # Init our model
    model = create_model(init_mode=&quot;kaiming&quot;)
    pl.seed_everything(seed)
    torch.manual_seed(seed)
    accs[&quot;kaiming&quot;] = train(model, dm, log_folder=&quot;/dbfs/ml/Group_7/logs/resnet/kaiming&quot;, n_steps=n_steps, do_test=do_test).item()
    
    pl.seed_everything(seed)
    torch.manual_seed(seed)
    model = create_model(init_mode=&quot;xavier&quot;)
    pl.seed_everything(seed)
    torch.manual_seed(seed)
    accs[&quot;xavier&quot;] = train(model, dm, log_folder=&quot;/dbfs/ml/Group_7/logs/resnet/xavier&quot;, n_steps=n_steps, do_test=do_test).item()

    pl.seed_everything(seed)
    torch.manual_seed(seed)
    model = create_model(init_mode=&quot;zero&quot;)
    pl.seed_everything(seed)
    torch.manual_seed(seed)
    accs[&quot;zero&quot;] = train(model, dm, log_folder=&quot;/dbfs/ml/Group_7/logs/resnet/zero&quot;, n_steps=n_steps, do_test=do_test, use_lr_warmup=True).item()
    
    return accs
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">import horovod.torch as hvd
from sparkdl import HorovodRunner
import json

def run_horovod_job():
    hvd.init()  
    torch.cuda.set_device(hvd.local_rank())
    seeds = [42, 151, 464, 3584, 6846]
    for seed in seeds:
        print(&quot;Random seed used:&quot;, seed)
        pl.seed_everything(seed)
        torch.manual_seed(seed)

        dm = CIFAR10DataModule(batch_size=128, data_dir='data-%d'% hvd.rank())
        dm.prepare_data()
        dm.setup()

        print(&quot;ZerO Init&quot;)
        accs = run(dm, seed=seed, n_steps = 16_000, do_test = True)
        if hvd.rank() == 0:
            print(accs)
            with open(&quot;results.txt&quot;, 'a') as out_file:
                out_file.write(f&quot;RANDOM SEED: {seed}&quot;)
                out_file.write(json.dumps(accs))

hr = HorovodRunner(np=2, driver_log_verbosity='all') 
hr.run(run_horovod_job)
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-load_ext">tensorboard
%tensorboard --logdir /dbfs/ml/Group_7/logs/
</code></pre>
</div>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/07_additional_code.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next" href="../../../contents/student-project-07_group-ExpsZerOInit/student-project-07_group-ExpsZerOInit/01_resnet.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/07_additional_code.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next" href="../../../contents/student-project-07_group-ExpsZerOInit/student-project-07_group-ExpsZerOInit/01_resnet.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="../../../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../../searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="../../../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->


    </body>
</html>
